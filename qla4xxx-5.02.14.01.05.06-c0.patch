diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/Kconfig
--- a/drivers/scsi/qla4xxx/Kconfig
+++ b/drivers/scsi/qla4xxx/Kconfig
@@ -1,7 +1,7 @@
 config SCSI_QLA_ISCSI
-	tristate "QLogic ISP4XXX host adapter family support"
-	depends on PCI && SCSI && NET
+	tristate "QLogic ISP4XXX and ISP82XX host adapter family support"
+	depends on PCI && SCSI
 	select SCSI_ISCSI_ATTRS
 	---help---
-	This driver supports the QLogic 40xx (ISP4XXX) iSCSI host
-	adapter family.
+	This driver supports the QLogic 40xx (ISP4XXX) and 8022 (ISP82XX)
+	iSCSI host adapter family.
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/Makefile
--- a/drivers/scsi/qla4xxx/Makefile
+++ b/drivers/scsi/qla4xxx/Makefile
@@ -1,5 +1,7 @@
+EXTRA_CFLAGS += -DQLA_SLES11
+
 qla4xxx-y := ql4_os.o ql4_init.o ql4_mbx.o ql4_iocb.o ql4_isr.o \
-		ql4_nvram.o ql4_dbg.o
+		ql4im_os.o ql4im_ioctl.o ql4im_dbg.o ql4im_dump.o \
+		ql4_nx.o ql4_nvram.o ql4_dbg.o ql4_isns.o ql4_attr.o
 
 obj-$(CONFIG_SCSI_QLA_ISCSI) += qla4xxx.o
-
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_attr.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_attr.c
@@ -0,0 +1,226 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#include "ql4_def.h"
+#include "ql4_glbl.h"
+#include "ql4_dbg.h"
+
+static void qla4_8xxx_peg_halt(struct scsi_qla_host *ha, uint32_t peg);
+
+/* SYSFS attributes */
+
+#ifdef QL4_RHEL6
+static ssize_t
+qla4_8xxx_sysfs_read_fw_dump(struct file *file, struct kobject *kobj,
+			     struct bin_attribute *ba,char *buf,
+			     loff_t off, size_t count)
+
+#else
+static ssize_t
+qla4_8xxx_sysfs_read_fw_dump(struct kobject *kobj, struct bin_attribute *ba,
+			     char *buf, loff_t off, size_t count)
+#endif
+{
+	struct scsi_qla_host *ha = to_qla_host(dev_to_shost(container_of(kobj,
+					       struct device, kobj)));
+
+	if (!is_qla8022(ha))
+		return -EINVAL;
+
+	if (!test_bit(AF_82XX_DUMP_READING, &ha->flags))
+		return 0;
+
+	return memory_read_from_buffer(buf, count, &off, ha->fw_dump,
+				       ha->fw_dump_size);
+}
+
+#ifdef QL4_RHEL6
+static ssize_t
+qla4_8xxx_sysfs_write_fw_dump(struct file *file, struct kobject *kobj,
+                              struct bin_attribute *ba,
+			      char *buf, loff_t off,size_t count)
+#else
+static ssize_t
+qla4_8xxx_sysfs_write_fw_dump(struct kobject *kobj, struct bin_attribute *ba,
+			      char *buf, loff_t off,size_t count)
+#endif
+{
+	struct scsi_qla_host *ha = to_qla_host(dev_to_shost(container_of(kobj,
+					       struct device, kobj)));
+	int reading;
+	uint32_t dev_state;
+
+	if (!is_qla8022(ha))
+		return -EINVAL;
+
+	if (off != 0)
+		return 0;
+
+	reading = simple_strtol(buf, NULL, 10);
+	switch (reading) {
+	case 0:
+		if (test_and_clear_bit(AF_82XX_DUMP_READING, &ha->flags)) {
+			clear_bit(AF_82XX_FW_DUMPED, &ha->flags);
+			DEBUG2(ql4_info(ha, "Firmware dump cleared on (%ld).\n",
+					ha->host_no));
+		}
+
+		break;
+	case 1:
+		if (test_bit(AF_82XX_FW_DUMPED, &ha->flags) &&
+		    !test_bit(AF_82XX_DUMP_READING, &ha->flags)) {
+			set_bit(AF_82XX_DUMP_READING, &ha->flags);
+			ql4_info(ha, "Raw firmware dump ready for read "
+				 "on (%ld).\n", ha->host_no);
+		}
+		break;
+	case 2:
+		/* Placeholder case for similarity with FC*/
+		break;
+	case 3:
+		qla4_8xxx_idc_lock(ha);
+		dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+		if (dev_state == QLA82XX_DEV_READY) {
+			ql4_info(ha, "%s: Setting Need reset, reset_owner "
+				 "is 0x%x.\n", __func__, ha->func_num);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+					QLA82XX_DEV_NEED_RESET);
+			set_bit(AF_82XX_RST_OWNER, &ha->flags);
+		} else
+			ql4_info(ha, "%s: Device state is 0x%x\n", __func__,
+				 dev_state);
+
+		qla4_8xxx_idc_unlock(ha);
+		break;
+	default:
+		/* do nothing */
+		break;
+	}
+
+	return count;
+}
+
+static struct bin_attribute sysfs_fw_dump_attr = {
+	.attr = {
+		.name = "fw_dump",
+		.mode = S_IRUSR | S_IWUSR,
+		.owner = THIS_MODULE,
+	},
+	.size = 0,
+	.read = qla4_8xxx_sysfs_read_fw_dump,
+	.write = qla4_8xxx_sysfs_write_fw_dump,
+};
+
+static struct sysfs_entry {
+	char *name;
+	struct bin_attribute *attr;
+} bin_file_entries[] = {
+	{ "fw_dump", &sysfs_fw_dump_attr },
+	{ NULL },
+};
+
+void
+qla4_8xxx_alloc_sysfs_attr(struct scsi_qla_host *ha)
+{
+	struct Scsi_Host *host = ha->host;
+	struct sysfs_entry *iter;
+	int ret;
+
+	for (iter = bin_file_entries; iter->name; iter++) {
+		ret = sysfs_create_bin_file(&host->shost_gendev.kobj,
+					    iter->attr);
+		if (ret)
+			ql4_info(ha, "Unable to create sysfs %s binary "
+				 "attribute (%d).\n", iter->name, ret);
+	}
+}
+
+void
+qla4_8xxx_free_sysfs_attr(struct scsi_qla_host *ha)
+{
+	struct Scsi_Host *host = ha->host;
+	struct sysfs_entry *iter;
+
+	for (iter = bin_file_entries; iter->name; iter++) {
+
+		sysfs_remove_bin_file(&host->shost_gendev.kobj,
+		    iter->attr);
+	}
+
+}
+
+/* Scsi_Host attributes. */
+
+uint64_t crbaddr(uint64_t base, uint64_t offset)
+{
+	return (0x00000000 + (base + offset));
+}
+
+uint64_t pegreg_addr(u64 peg, u64 offset)
+{
+	if (peg == 4) {
+		return (crbaddr(0x00f00000, offset));
+	}
+	return (crbaddr((0x01100000 + 0x00100000 * peg), offset));
+}
+
+void qla4_8xxx_wrpegreg(struct scsi_qla_host *ha, u64 peg, u64 offset, u32 value)
+{
+	u64 addr = 0;
+
+	addr = pegreg_addr(peg, offset);
+	ql4_info(ha, "peg-halt: peg=0x%llx addr=0x%llx\n",
+		 (unsigned long long) peg, (unsigned long long) addr);
+	qla4_8xxx_wr_32(ha, (addr + QLA82XX_PCI_CRBSPACE), value);
+}
+
+static void
+qla4_8xxx_peg_halt(struct scsi_qla_host *ha, uint32_t peg)
+{
+	int iter = 0;
+
+	if ((peg < 0 || peg >= 5) && peg != 0xff) {
+		printk("Bad peg number: %d", peg);
+		return;
+	}
+
+	if (peg == 0xff) {
+		for (iter = 0; iter < 5; iter++)
+			qla4_8xxx_wrpegreg(ha, iter, 0x3c, 0x1);
+	} else
+		qla4_8xxx_wrpegreg(ha, peg, 0x3c, 0x1);
+}
+
+static ssize_t
+qla4xxx_peg_hlt_store(struct device *dev, struct device_attribute *attr,
+		      const char *buf, size_t count)
+{
+	struct scsi_qla_host *ha = to_qla_host(class_to_shost(dev));
+	int val = 0;
+
+	if (!is_qla8022(ha))
+		return -EINVAL;
+
+	if (sscanf(buf, "%d", &val) != 1)
+		return -EINVAL;
+
+	if (val == 6024) {
+		qla4_8xxx_idc_lock(ha);
+		qla4_8xxx_peg_halt(ha, 0);
+		qla4_8xxx_idc_unlock(ha);
+	} else
+		return -EINVAL;
+
+	return strlen(buf);
+}
+
+static DEVICE_ATTR(peg_hlt, S_IWUSR, NULL, qla4xxx_peg_hlt_store);
+
+struct device_attribute *qla4xxx_host_attrs[] = {
+	&dev_attr_peg_hlt,
+	NULL,
+};
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_dbg.c
--- a/drivers/scsi/qla4xxx/ql4_dbg.c
+++ b/drivers/scsi/qla4xxx/ql4_dbg.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -20,13 +20,226 @@ void qla4xxx_dump_buffer(void *b, uint32
 	printk("------------------------------------------------------------"
 	       "--\n");
 	for (cnt = 0; cnt < size; c++) {
-		printk(KERN_INFO "%02x", *c);
+		printk("%02x", *c);
 		if (!(++cnt % 16))
-			printk(KERN_INFO "\n");
+			printk("\n");
 
 		else
-			printk(KERN_INFO "  ");
+			printk("  ");
 	}
 	printk(KERN_INFO "\n");
 }
 
+void printchar(char ch)
+{
+	if (ch>=32)
+		printk("%c", ch);
+	else
+		printk(".");
+}
+
+/**************************************************************************
+ * qla4xxx_dump_bytes
+ *     This routine displays bytes in hex format
+ *
+ * Input:
+ *     dbg_mask - this call's debug print mask
+ *     buffer   - data buffer to display
+ *     size     - number of bytes to display
+ *
+ * Output:
+ *     None
+ *
+ * Returns:
+ *     None
+ **************************************************************************/
+void
+qla4xxx_dump_bytes(void *buffer, uint32_t size)
+{
+	uint32_t i;
+	uint8_t  *data = (uint8_t *)buffer;
+
+	//printk("        0  1  2  3  4  5  6  7 -  8  9  A  B  C  D  E  F\n");
+	//printk("---------------------------------------------------------\n");
+
+	for (i = 0; i < size; i++, data++) {
+		if (i % 0x10 == 0) {
+			printk("%04X:  %02X", i, *data);
+		}
+		else if (i % 0x10 == 0x08) {
+			printk(" - %02X", *data);
+		}
+		else if (i % 0x10 == 0xF) {
+			printk(" %02X:  ", *data);
+			printchar(*(data-15));
+			printchar(*(data-14));
+			printchar(*(data-13));
+			printchar(*(data-12));
+			printchar(*(data-11));
+			printchar(*(data-10));
+			printchar(*(data-9));
+			printchar(*(data-8));
+			printchar(*(data-7));
+			printchar(*(data-6));
+			printchar(*(data-5));
+			printchar(*(data-4));
+			printchar(*(data-3));
+			printchar(*(data-2));
+			printchar(*(data-1));
+			printchar(*data);
+			printk("\n");
+		}
+		else {
+			printk(" %02X", *data);
+		}
+	}
+
+	if ((i != 0) && (i % 0x10)) {
+		printk("\n");
+	}
+	printk("\n");
+}
+
+void qla4xxx_dump_mbx_cmd(struct scsi_qla_host *ha, uint32_t *mbx_cmd)
+{
+	int i;
+	ql4_info(ha, "%s: Cmd ", __func__);
+	for (i = 0; i < MBOX_REG_COUNT; i++)
+		ql4_info(ha, "mb%d=%04x ", i, mbx_cmd[i]);
+	printk("\n");
+}
+
+void qla4xxx_dump_mbx_sts(struct scsi_qla_host *ha, uint32_t *mbx_sts)
+{
+	int i;
+	ql4_info(ha, "%s: Sts ", __func__);
+	for (i = 0; i < MBOX_REG_COUNT; i++)
+		printk("mb%d=%04x ", i, mbx_sts[i]);
+	printk("\n");
+
+}
+
+void __dump_prb(struct scsi_qla_host *ha, struct isns_prb *prb)
+{
+	ql4_info(ha, "Dump struct  PRB (0x%p)\n", prb);
+	ql4_info(ha, "\tPDU=0x%p, PDU_dma=0x%llx, PDU_buf_len=0x%x\n",
+		prb->pdu, (unsigned long long)prb->pdu_dma, prb->pdu_buf_len);
+	ql4_info(ha, "\ttx_len=0x%x, rx_len=0x%x, handle=0x%x\n",
+		prb->tx_len, prb->rx_len, prb->handle);
+	ql4_info(ha, "\tin_residual=0x%x, conn_id=0x%x, prb_in_use=%d\n",
+		prb->in_residual, prb->conn_id, prb->prb_in_use);
+	ql4_info(ha, "\tresid_flags=0x%x in_residual=0x%x\n",
+		prb->resid_flags, prb->in_residual);
+	ql4_info(ha, "\tconn_id=0x%x, prb_in_use=%d\n",
+		prb->conn_id, prb->prb_in_use);
+	ql4_info(ha, "\toffset=0x%x, pkt=0x%p, pkt_dma=0x%llx\n",
+		prb->offset, prb->pkt, (unsigned long long)prb->pkt_dma);
+	ql4_info(ha, "\ttgt_qry_iscsi_name=0x%p, tgt_qry_buf=0x%p, "
+		"tgt_qry_buf_len=0x%p\n", prb->tgt_qry_iscsi_name,
+		prb->tgt_qry_buf, prb->tgt_qry_buf_len);
+}
+
+void qla4xxx_dump_registers(struct scsi_qla_host *ha)
+{
+	uint8_t i;
+
+	if (is_qla8022(ha)) {
+		for (i = 0; i < MBOX_REG_COUNT; i++)
+			printk(KERN_INFO "mailbox_in[%d]     = 0x%08X\n",
+			    i, readl(&ha->qla4_8xxx_reg->mailbox_in[i]));
+		for (i = 0; i < MBOX_REG_COUNT; i++)
+			printk(KERN_INFO "mailbox_out[%d]     = 0x%08X\n",
+			    i, readl(&ha->qla4_8xxx_reg->mailbox_out[i]));
+		return;
+	}
+
+	for (i = 0; i < MBOX_REG_COUNT; i++) {
+		printk(KERN_INFO "0x%02X mailbox[%d]      = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, mailbox[i]), i,
+		    readw(&ha->reg->mailbox[i]));
+	}
+
+	printk(KERN_INFO "0x%02X flash_address            = 0x%08X\n",
+	    (uint8_t) offsetof(struct isp_reg, flash_address),
+	    readw(&ha->reg->flash_address));
+	printk(KERN_INFO "0x%02X flash_data               = 0x%08X\n",
+	    (uint8_t) offsetof(struct isp_reg, flash_data),
+	    readw(&ha->reg->flash_data));
+	printk(KERN_INFO "0x%02X ctrl_status              = 0x%08X\n",
+	    (uint8_t) offsetof(struct isp_reg, ctrl_status),
+	    readw(&ha->reg->ctrl_status));
+
+	if (is_qla4010(ha)) {
+		printk(KERN_INFO "0x%02X nvram            = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u1.isp4010.nvram),
+		    readw(&ha->reg->u1.isp4010.nvram));
+	} else if (is_qla4022(ha) | is_qla4032(ha)) {
+		printk(KERN_INFO "0x%02X intr_mask        = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u1.isp4022.intr_mask),
+		    readw(&ha->reg->u1.isp4022.intr_mask));
+		printk(KERN_INFO "0x%02X nvram            = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u1.isp4022.nvram),
+		    readw(&ha->reg->u1.isp4022.nvram));
+		printk(KERN_INFO "0x%02X semaphore	  = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u1.isp4022.semaphore),
+		    readw(&ha->reg->u1.isp4022.semaphore));
+	}
+	printk(KERN_INFO "0x%02X req_q_in                 = 0x%08X\n",
+	    (uint8_t) offsetof(struct isp_reg, req_q_in),
+	    readw(&ha->reg->req_q_in));
+	printk(KERN_INFO "0x%02X rsp_q_out                = 0x%08X\n",
+	    (uint8_t) offsetof(struct isp_reg, rsp_q_out),
+	    readw(&ha->reg->rsp_q_out));
+
+	if (is_qla4010(ha)) {
+		printk(KERN_INFO "0x%02X ext_hw_conf      = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.ext_hw_conf),
+		    readw(&ha->reg->u2.isp4010.ext_hw_conf));
+		printk(KERN_INFO "0x%02X port_ctrl        = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.port_ctrl),
+		    readw(&ha->reg->u2.isp4010.port_ctrl));
+		printk(KERN_INFO "0x%02X port_status      = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.port_status),
+		    readw(&ha->reg->u2.isp4010.port_status));
+		printk(KERN_INFO "0x%02X req_q_out        = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.req_q_out),
+		    readw(&ha->reg->u2.isp4010.req_q_out));
+		printk(KERN_INFO "0x%02X gp_out           = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.gp_out),
+		    readw(&ha->reg->u2.isp4010.gp_out));
+		printk(KERN_INFO "0x%02X gp_in	          = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4010.gp_in),
+		    readw(&ha->reg->u2.isp4010.gp_in));
+		printk(KERN_INFO "0x%02X port_err_status  = 0x%08X\n", (uint8_t)
+		    offsetof(struct isp_reg, u2.isp4010.port_err_status),
+		    readw(&ha->reg->u2.isp4010.port_err_status));
+	} else if (is_qla4022(ha) | is_qla4032(ha)) {
+		printk(KERN_INFO "Page 0 Registers:\n");
+		printk(KERN_INFO "0x%02X ext_hw_conf      = 0x%08X\n", (uint8_t)
+		    offsetof(struct isp_reg, u2.isp4022.p0.ext_hw_conf),
+		    readw(&ha->reg->u2.isp4022.p0.ext_hw_conf));
+		printk(KERN_INFO "0x%02X port_ctrl        = 0x%08X\n", (uint8_t)
+		    offsetof(struct isp_reg, u2.isp4022.p0.port_ctrl),
+		    readw(&ha->reg->u2.isp4022.p0.port_ctrl));
+		printk(KERN_INFO "0x%02X port_status      = 0x%08X\n", (uint8_t)
+		    offsetof(struct isp_reg, u2.isp4022.p0.port_status),
+		    readw(&ha->reg->u2.isp4022.p0.port_status));
+		printk(KERN_INFO "0x%02X gp_out           = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4022.p0.gp_out),
+		    readw(&ha->reg->u2.isp4022.p0.gp_out));
+		printk(KERN_INFO "0x%02X gp_in            = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4022.p0.gp_in),
+		    readw(&ha->reg->u2.isp4022.p0.gp_in));
+		printk(KERN_INFO "0x%02X port_err_status  = 0x%08X\n", (uint8_t)
+		    offsetof(struct isp_reg, u2.isp4022.p0.port_err_status),
+		    readw(&ha->reg->u2.isp4022.p0.port_err_status));
+		printk(KERN_INFO "Page 1 Registers:\n");
+		writel(HOST_MEM_CFG_PAGE & set_rmask(CSR_SCSI_PAGE_SELECT),
+		    &ha->reg->ctrl_status);
+		printk(KERN_INFO "0x%02X req_q_out        = 0x%08X\n",
+		    (uint8_t) offsetof(struct isp_reg, u2.isp4022.p1.req_q_out),
+		    readw(&ha->reg->u2.isp4022.p1.req_q_out));
+		writel(PORT_CTRL_STAT_PAGE & set_rmask(CSR_SCSI_PAGE_SELECT),
+		    &ha->reg->ctrl_status);
+	}
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_dbg.h
--- a/drivers/scsi/qla4xxx/ql4_dbg.h
+++ b/drivers/scsi/qla4xxx/ql4_dbg.h
@@ -1,55 +1,95 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
 
+/* Defines for interim workaround code */
+/**
+ *  Enabling MIXED_INTR_MODE_WORKAROUND will prevent interrupts from falling
+ *  back to INTx mode in cases where interrupts cannot get acquired through
+ *  MSI-X or MSI mode.  This workaround will be removed once ER71218 has been
+ *  fixed in 82xx firmware.
+ **/
+#define MIXED_INTR_MODE_WORKAROUND    1
+
+/*
+ * Debug Print Macros
+ */
+#if 1
+#define ql4_printk(level, ha, format, arg...)                           \
+        printk("%s(%ld): %s: " format ,                                 \
+                dev_driver_string(&((ha)->pdev->dev)),                  \
+                (ha)->host_no, dev_name(&((ha)->pdev->dev)), ## arg)
+#else
+#define ql4_printk(level, ha, format, arg...) \
+        dev_printk(level , &((ha)->pdev->dev) , format , ## arg)
+#endif
+
+#define ql4_info(ha, format, arg...)    \
+        ql4_printk(KERN_INFO, ha, format, ## arg)
+#define ql4_warn(ha, format, arg...)    \
+        ql4_printk(KERN_WARNING, ha, format, ## arg)
+#define ql4_err(ha, format, arg...)     \
+        ql4_printk(KERN_ERR, ha, format, ## arg)
+#define ql4_dbg(ha, format, arg...)     \
+        ql4_printk(KERN_DEBUG, ha, format, ## arg)
+
 /*
  * Driver debug definitions.
  */
-/* #define QL_DEBUG  */			/* DEBUG messages */
+#define QL_DEBUG			/* DEBUG messages */
+#define QL_DEBUG_LEVEL_2
 /* #define QL_DEBUG_LEVEL_3  */		/* Output function tracing */
 /* #define QL_DEBUG_LEVEL_4  */
 /* #define QL_DEBUG_LEVEL_5  */
-/* #define QL_DEBUG_LEVEL_9  */
+#define QL_DEBUG_LEVEL_6
+#define QL_DEBUG_LEVEL_7
 
-#define QL_DEBUG_LEVEL_2	/* ALways enable error messagess */
+#ifndef _QL4_DBG_
+#define _QL4_DBG_
+
 #if defined(QL_DEBUG)
-#define DEBUG(x)   do {x;} while (0);
+#define DEBUG(x)	do {if(ql4xextended_error_logging & 0x01) x;} while (0);
 #else
-#define DEBUG(x)	do {} while (0);
+#define DEBUG(x)
 #endif
 
 #if defined(QL_DEBUG_LEVEL_2)
-#define DEBUG2(x)      do {if(ql4xextended_error_logging == 2) x;} while (0);
-#define DEBUG2_3(x)   do {x;} while (0);
-#else				/*  */
-#define DEBUG2(x)	do {} while (0);
-#endif				/*  */
+#define DEBUG2(x)	do {if(ql4xextended_error_logging & 0x02) x;} while (0);
+#else
+#define DEBUG2(x)
+#endif
 
 #if defined(QL_DEBUG_LEVEL_3)
-#define DEBUG3(x)      do {if(ql4xextended_error_logging == 3) x;} while (0);
-#else				/*  */
-#define DEBUG3(x)	do {} while (0);
-#if !defined(QL_DEBUG_LEVEL_2)
-#define DEBUG2_3(x)	do {} while (0);
-#endif				/*  */
-#endif				/*  */
+#define DEBUG3(x)	do {if(ql4xextended_error_logging & 0x04) x;} while (0);
+#else
+#define DEBUG3(x)
+#endif
+
 #if defined(QL_DEBUG_LEVEL_4)
-#define DEBUG4(x)	do {x;} while (0);
-#else				/*  */
-#define DEBUG4(x)	do {} while (0);
-#endif				/*  */
+#define DEBUG4(x)	do {if(ql4xextended_error_logging & 0x08) x;} while (0);
+#else
+#define DEBUG4(x)
+#endif
 
 #if defined(QL_DEBUG_LEVEL_5)
-#define DEBUG5(x)	do {x;} while (0);
-#else				/*  */
-#define DEBUG5(x)	do {} while (0);
-#endif				/*  */
+#define DEBUG5(x)	do {if(ql4xextended_error_logging & 0x10) x;} while (0);
+#else
+#define DEBUG5(x)
+#endif
 
-#if defined(QL_DEBUG_LEVEL_9)
-#define DEBUG9(x)	do {x;} while (0);
-#else				/*  */
-#define DEBUG9(x)	do {} while (0);
-#endif				/*  */
+#if defined(QL_DEBUG_LEVEL_6)
+#define DEBUG6(x)	do {if(ql4xextended_error_logging & 0x20) x;} while (0);
+#else
+#define DEBUG6(x)
+#endif
+
+#if defined(QL_DEBUG_LEVEL_7)
+#define DEBUG7(x)	do {if(ql4xextended_error_logging & 0x40) x;} while (0);
+#else
+#define DEBUG7(x)
+#endif
+
+#endif /*_QL4_DBG_*/
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_def.h
--- a/drivers/scsi/qla4xxx/ql4_def.h
+++ b/drivers/scsi/qla4xxx/ql4_def.h
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -33,6 +33,25 @@
 #include <scsi/scsi_transport.h>
 #include <scsi/scsi_transport_iscsi.h>
 
+#include "ql4_kcompat.h"
+
+#if defined(CONFIG_PCIEAER)
+#include <linux/aer.h>
+#else
+/* AER releated */
+static inline int pci_enable_pcie_error_reporting(struct pci_dev *dev)
+{
+	return -EINVAL;
+}
+static inline int pci_disable_pcie_error_reporting(struct pci_dev *dev)
+{
+	return -EINVAL;
+}
+static inline int pci_cleanup_aer_uncorrect_error_status(struct pci_dev *dev)
+{
+	return -EINVAL;
+}
+#endif
 
 #ifndef PCI_DEVICE_ID_QLOGIC_ISP4010
 #define PCI_DEVICE_ID_QLOGIC_ISP4010	0x4010
@@ -46,6 +65,10 @@
 #define PCI_DEVICE_ID_QLOGIC_ISP4032	0x4032
 #endif
 
+#ifndef PCI_DEVICE_ID_QLOGIC_ISP8022
+#define PCI_DEVICE_ID_QLOGIC_ISP8022	0x8022
+#endif
+
 #define QLA_SUCCESS			0
 #define QLA_ERROR			1
 
@@ -98,15 +121,17 @@
 #define INVALID_ENTRY		0xFFFF
 #define MAX_CMDS_TO_RISC	1024
 #define MAX_SRBS		MAX_CMDS_TO_RISC
-#define MBOX_AEN_REG_COUNT	5
+#define MBOX_AEN_REG_COUNT	8
 #define MAX_INIT_RETRIES	5
-#define LEGACY_IFCB_SIZE	0x200
+#define MIN_IOCBS		64
+#define MAX_IOCBS		1024
 
 /*
  * Buffer sizes
  */
 #define REQUEST_QUEUE_DEPTH		MAX_CMDS_TO_RISC
 #define RESPONSE_QUEUE_DEPTH		64
+#define RESPONSE_QUEUE_DEPTH_ISP8XXX	1024
 #define QUEUE_SIZE			64
 #define DMA_BUFFER_SIZE			512
 
@@ -114,17 +139,20 @@
  * Misc
  */
 #define MAC_ADDR_LEN			6	/* in bytes */
-#define IP_ADDR_LEN			4	/* in bytes */
+#define IP_ADDR_LEN			4	/* IPv4 address size */
 #define IPv6_ADDR_LEN			16	/* IPv6 address size */
 #define DRIVER_NAME			"qla4xxx"
 
 #define MAX_LINKED_CMDS_PER_LUN		3
-#define MAX_REQS_SERVICED_PER_INTR	16
+#define MAX_REQS_SERVICED_PER_INTR	1
+#define MAX_Q_DEPTH			32
 
 #define ISCSI_IPADDR_SIZE		4	/* IP address size */
 #define ISCSI_ALIAS_SIZE		32	/* ISCSI Alias name size */
 #define ISCSI_NAME_SIZE			0xE0	/* ISCSI Name size */
 
+#define MSB(x)  ((uint8_t)((uint16_t)(x) >> 8))
+#define LSW(x)  ((uint16_t)(x))
 #define LSDW(x) ((u32)((u64)(x)))
 #define MSDW(x) ((u32)((((u64)(x)) >> 16) >> 16))
 
@@ -135,7 +163,7 @@
 #define SOFT_RESET_TOV			30
 #define RESET_INTR_TOV			3
 #define SEMAPHORE_TOV			10
-#define ADAPTER_INIT_TOV		120
+#define ADAPTER_INIT_TOV		30
 #define ADAPTER_RESET_TOV		180
 #define EXTEND_CMD_TOV			60
 #define WAIT_CMD_TOV			30
@@ -146,9 +174,15 @@
 #define IOCB_TOV_MARGIN			10
 #define RELOGIN_TOV			18
 #define ISNS_DEREG_TOV			5
+#define HBA_ONLINE_TOV			30
+#define PDU_WAIT_TOV			10
 
 #define MAX_RESET_HA_RETRIES		2
-#define DEVICE_ONLINE_TOV		10
+
+#define CMD_SP(Cmnd)			((Cmnd)->SCp.ptr)
+
+#include "ql4_nx.h"
+#include "ql4_isns.h"
 
 /*
  * SCSI Request Block structure	 (srb)	that is placed
@@ -159,8 +193,7 @@ struct srb {
 	struct scsi_qla_host *ha;	/* HA the SP is queued on */
 	struct ddb_entry	*ddb;
 	uint16_t flags;		/* (1) Status flags. */
-
-#define SRB_SCSI_PASSTHRU	BIT_2
+#define SRB_SCSI_PASSTHRU	BIT_2	/* for scsi passthru cmds */
 #define SRB_DMA_VALID		BIT_3	/* DMA Buffer mapped. */
 #define SRB_GOT_SENSE		BIT_4	/* sense data recieved. */
 	uint8_t state;		/* (1) Status flags. */
@@ -169,12 +202,13 @@ struct srb {
 #define SRB_FREE_STATE		 1
 #define SRB_ACTIVE_STATE	 3
 #define SRB_ACTIVE_TIMEOUT_STATE 4
+#define SRB_RETRY_STATE		 5
+#define SRB_DONE_STATE		 6
 #define SRB_SUSPENDED_STATE	 7	/* Request in suspended state */
 
 	struct scsi_cmnd *cmd;	/* (4) SCSI command block */
 	dma_addr_t dma_handle;	/* (4) for unmap of single transfers */
-	atomic_t ref_count;	/* reference count for this srb */
-	uint32_t fw_ddb_index;
+	struct kref srb_ref;	/* reference count for this srb */
 	uint8_t err_id;		/* error id */
 #define SRB_ERR_PORT	   1	/* Request failed because "port down" */
 #define SRB_ERR_LOOP	   2	/* Request failed because "loop down" */
@@ -194,18 +228,6 @@ struct srb {
 };
 
 /*
- * Asynchronous Event Queue structure
- */
-struct aen {
-        uint32_t mbox_sts[MBOX_AEN_REG_COUNT];
-};
-
-struct ql4_aen_log {
-        int count;
-        struct aen entry[MAX_AEN_ENTRIES];
-};
-
-/*
  * Device Database (DDB) structure
  */
 struct ddb_entry {
@@ -215,11 +237,23 @@ struct ddb_entry {
 	struct iscsi_cls_conn *conn;
 
 	atomic_t state;		/* DDB State */
+#define DDB_STATE_DEAD		0	/* We can no longer talk to
+					 * this device */
+#define DDB_STATE_ONLINE	1	/* Device ready to accept
+					 * commands */
+#define DDB_STATE_MISSING	2	/* Device logged off, trying
+					 * to re-login */
+#define DDB_STATE_REMOVED	3	/* The fw ddb_entry is freed
+					 * the session can be destroyed */
 
 	unsigned long flags;	/* DDB Flags */
-
-	unsigned long dev_scan_wait_to_start_relogin;
-	unsigned long dev_scan_wait_to_complete_relogin;
+#define DF_RELOGIN		0	/* Relogin to device */
+#define DF_NO_RELOGIN		1	/* Do not relogin if IOCTL
+					 * logged it out */
+#define DF_SCAN_ISSUED		2
+#define DF_OFFLINE		3	/* Offline Device */
+#define DF_REMOVE		4	/* FW DDB is destroyed */
+#define DF_DYNAMIC_LUN_SCAN_NEEDED	5
 
 	uint16_t os_target_id;	/* Target ID */
 	uint16_t fw_ddb_index;	/* DDB firmware index */
@@ -245,6 +279,7 @@ struct ddb_entry {
 	atomic_t relogin_timer;	/* Max Time to wait for relogin to complete */
 	atomic_t relogin_retry_count; /* Num of times relogin has been
 				       * retried */
+
 	uint16_t port;
 	uint32_t tpgt;
 	uint8_t ip_addr[IP_ADDR_LEN];
@@ -253,45 +288,96 @@ struct ddb_entry {
 	uint8_t isid[6];
 	uint16_t ka_timeout;
 
-	struct in6_addr remote_ipv6_addr;
+	struct in6_addr ipv6_addr;
 	struct in6_addr link_local_ipv6_addr;
 };
 
 /*
- * DDB states.
+ * Asynchronous Event Queue structure
  */
-#define DDB_STATE_DEAD		0	/* We can no longer talk to
-					 * this device */
-#define DDB_STATE_ONLINE	1	/* Device ready to accept
-					 * commands */
-#define DDB_STATE_MISSING	2	/* Device logged off, trying
-					 * to re-login */
-#define DDB_STATE_REMOVED	3	/* The fw ddb_entry is freed
-					 * the session can be destroyed */
+struct aen {
+	uint32_t mbox_sts[MBOX_AEN_REG_COUNT];
+};
 
-/*
- * DDB flags.
- */
-#define DF_RELOGIN		0	/* Relogin to device */
-#define DF_NO_RELOGIN		1	/* Do not relogin if IOCTL
-					 * logged it out */
-#define DF_ISNS_DISCOVERED	2	/* Device was discovered via iSNS */
-#define DF_FO_MASKED		3
-#define DF_REMOVE		4	/* FW DDB is destroyed */
-
+struct ql4_aen_log {
+	int count;
+	struct aen entry[MAX_AEN_ENTRIES];
+};
 
 #include "ql4_fw.h"
 #include "ql4_nvram.h"
 
-/* shortcut to print ISID */
-#define ISID(addr) \
-	((unsigned char *)&addr)[5], \
-	((unsigned char *)&addr)[4], \
-	((unsigned char *)&addr)[3], \
-	((unsigned char *)&addr)[2], \
-	((unsigned char *)&addr)[1], \
-	((unsigned char *)&addr)[0]
-#define ISID_FMT "0x%02x%02x%02x%02x%02x%02x"
+struct ql82xx_hw_data {
+	/* Offsets for flash/nvram access (set to ~0 if not used). */
+	uint32_t flash_conf_off;
+	uint32_t flash_data_off;
+
+	uint32_t fdt_wrt_disable;
+	uint32_t fdt_erase_cmd;
+	uint32_t fdt_block_size;
+	uint32_t fdt_unprotect_sec_cmd;
+	uint32_t fdt_protect_sec_cmd;
+
+	uint32_t flt_region_flt;
+	uint32_t flt_region_fdt;
+	uint32_t flt_region_boot;
+	uint32_t flt_region_bootload;
+	uint32_t flt_region_fw;
+	uint32_t reserved;
+};
+
+struct qla4_8xxx_legacy_intr_set {
+	uint32_t int_vec_bit;
+	uint32_t tgt_status_reg;
+	uint32_t tgt_mask_reg;
+	uint32_t pci_int_reg;
+};
+
+/* MSI-X Support */
+
+#define QLA_MSIX_DEFAULT	0x00
+#define QLA_MSIX_RSP_Q		0x01
+
+#define QLA_MSIX_ENTRIES	2
+#define QLA_MIDX_DEFAULT	0
+#define QLA_MIDX_RSP_Q		1
+
+struct ql4_msix_entry {
+	int have_irq;
+	uint16_t msix_vector;
+	uint16_t msix_entry;
+};
+
+/*
+ * ISP Operations
+ */
+struct isp_operations {
+	int (*iospace_config) (struct scsi_qla_host *ha);
+	void (*pci_config) (struct scsi_qla_host *);
+	void (*disable_intrs) (struct scsi_qla_host *);
+	void (*enable_intrs) (struct scsi_qla_host *);
+	int (*start_firmware) (struct scsi_qla_host *);
+	irqreturn_t (*intr_handler) (int , void *);
+	void (*interrupt_service_routine) (struct scsi_qla_host *, uint32_t);
+	int (*reset_chip) (struct scsi_qla_host *);
+	int (*reset_firmware) (struct scsi_qla_host *);
+	void (*queue_iocb) (struct scsi_qla_host *);
+	void (*complete_iocb) (struct scsi_qla_host *);
+	uint16_t (*rd_shdw_req_q_out) (struct scsi_qla_host *);
+	uint16_t (*rd_shdw_rsp_q_in) (struct scsi_qla_host *);
+	void (*get_sys_info) (struct scsi_qla_host *);
+};
+
+struct ql4_mdump_size_table
+{
+		uint32_t size;
+		uint32_t size_cmask_02;
+		uint32_t size_cmask_04;
+		uint32_t size_cmask_08;
+		uint32_t size_cmask_10;
+		uint32_t size_cmask_FF;
+		uint32_t version;
+};
 
 /*
  * Linux Host Adapter structure
@@ -315,28 +401,54 @@ struct scsi_qla_host {
 #define AF_INIT_DONE			1 /* 0x00000002 */
 #define AF_MBOX_COMMAND			2 /* 0x00000004 */
 #define AF_MBOX_COMMAND_DONE		3 /* 0x00000008 */
+#define AF_DPC_SCHEDULED		5 /* 0x00000020 */
 #define AF_INTERRUPTS_ON		6 /* 0x00000040 */
 #define AF_GET_CRASH_RECORD		7 /* 0x00000080 */
 #define AF_LINK_UP			8 /* 0x00000100 */
 #define AF_IRQ_ATTACHED			10 /* 0x00000400 */
 #define AF_DISABLE_ACB_COMPLETE		11 /* 0x00000800 */
-#define AF_OS_INDEX_VALID		12 /* 0x00001000 */
+#define AF_ISNS_CMD_DONE		13 /* 0x00002000 */
+#define AF_INTx_ENABLED			15 /* 0x00008000 */
+#define AF_MSI_ENABLED			16 /* 0x00010000 */
+#define AF_MSIX_ENABLED			17 /* 0x00020000 */
+#define AF_HA_REMOVAL			18 /* 0x00040000 */
+#define AF_MBOX_COMMAND_NOPOLL		19 /* 0x00080000 */
+#define AF_PROBE_DONE			20 /* 0x00100000 */
+#define AF_FW_RECOVERY			21 /* 0x00200000 */
+#define AF_EEH_BUSY			22 /* 0x00400000 */
+#define AF_PCI_CHANNEL_IO_PERM_FAILURE	24 /* 0x01000000 */
+#define AF_PT_ACTIVE			25 /* 0x02000000 */
+#define AF_QUIESCE_OWNER                26 /* 0x04000000 */
+#define AF_82XX_FW_DUMPED		27 /* 0x08000000 */
+#define AF_82XX_RST_OWNER               28 /* 0x10000000 */
+#define AF_82XX_DUMP_READING		29 /* 0x20000000 */
 
 	unsigned long dpc_flags;
 
 #define DPC_RESET_HA			1 /* 0x00000002 */
 #define DPC_RETRY_RESET_HA		2 /* 0x00000004 */
 #define DPC_RELOGIN_DEVICE		3 /* 0x00000008 */
-#define DPC_RESET_HA_DESTROY_DDB_LIST	4 /* 0x00000010 */
+#define DPC_RESET_HA_FW_CONTEXT		4 /* 0x00000010 */
 #define DPC_RESET_HA_INTR		5 /* 0x00000020 */
 #define DPC_ISNS_RESTART		7 /* 0x00000080 */
+#define DPC_ISNS_START			8 /* 0x00000100 */
 #define DPC_AEN				9 /* 0x00000200 */
+#define DPC_ISNS_REREGISTER		10 /* 0x00000400 */
+#define DPC_ISNS_STOP			11 /* 0x00000800 */
 #define DPC_GET_DHCP_IP_ADDR		15 /* 0x00008000 */
+#define DPC_ASYNC_ISCSI_PDU		16 /* 0x00010000 */
 #define DPC_REMOVE_DEVICE		17 /* 0x00020000 */
-#define DPC_LINK_CHANGED		18 /* 0x00040000 */
-#define DPC_ASYNC_MSG_PDU		19 /* 0x00080000 */
+#define DPC_LINK_CHANGED		19 /* 0x00080000 */
+#define DPC_RESET_ACTIVE		20 /* 0x00100000 */
+#define DPC_HA_UNRECOVERABLE		21 /* 0x00200000 ISP-82xx only*/
+#define DPC_HA_NEED_QUIESCENT		22 /* 0x00400000 ISP-82xx only*/
+#define DPC_DYNAMIC_LUN_SCAN		23 /* 0x00800000 */
+#define DPC_ISNS_DEREGISTER		24 /* 0x01000000 */
+#define DPC_QUIESCE_ACTIVE             26 /* 0x04000000 */
+#define DPC_RESET_QUIESCENT            27 /* 0x08000000 */
 
-	uint16_t	iocb_cnt;
+	uint16_t iocb_cnt;
+	uint16_t rsvd;
 
 	/* SRB cache. */
 #define SRB_MIN_REQ	128
@@ -359,7 +471,7 @@ struct scsi_qla_host {
 	struct eeprom_data *nvram;
 	spinlock_t hardware_lock ____cacheline_aligned;
 	spinlock_t list_lock;
-	uint32_t   eeprom_cmd_data;
+	uint32_t eeprom_cmd_data;
 
 	/* Counters for general statistics */
 	uint64_t isr_count;
@@ -376,6 +488,7 @@ struct scsi_qla_host {
 	uint32_t mailbox_timeout_count;
 	uint32_t seconds_since_last_intr;
 	uint32_t seconds_since_last_heartbeat;
+	uint32_t temperature;
 	uint32_t mac_index;
 
 	/* Info Needed for Management App */
@@ -394,7 +507,7 @@ struct scsi_qla_host {
 	uint8_t alias[32];
 	uint8_t name_string[256];
 	uint8_t heartbeat_interval;
-	uint8_t rsvd;
+	uint8_t rsvd2;
 
 	/* --- From FlashSysInfo --- */
 	uint8_t my_mac[MAC_ADDR_LEN];
@@ -404,6 +517,7 @@ struct scsi_qla_host {
 	uint32_t firmware_state;
 	uint32_t board_id;
 	uint32_t addl_fw_state;
+	uint32_t txscvr_state;
 
 	/* Linux kernel thread */
 	struct workqueue_struct *dpc_thread;
@@ -415,7 +529,6 @@ struct scsi_qla_host {
 
 	/* Recovery Timers */
 	uint32_t port_down_retry_count;
-	uint32_t discovery_wait;
 	atomic_t check_relogin_timeouts;
 	uint32_t retry_reset_ha_cnt;
 	uint32_t isp_reset_timer;	/* reset test timer */
@@ -450,22 +563,14 @@ struct scsi_qla_host {
 	uint16_t request_out;
 	uint16_t response_in;
 	uint16_t response_out;
+	uint16_t response_qdepth;
 
 	/* aen queue variables */
-	uint16_t aen_q_count;	/* Number of available aen_q entries */
+	uint16_t resvd;
 	uint16_t aen_in;	/* Current indexes */
 	uint16_t aen_out;
 	struct aen aen_q[MAX_AEN_ENTRIES];
 
-	/* pdu variables */
-	uint16_t pdu_count;     /* Number of available aen_q entries */
-	uint16_t pdu_in;        /* Current indexes */
-	uint16_t pdu_out;
-	uint16_t pdu_active;
-	struct pdu_entry *free_pdu_top;
-	struct pdu_entry *free_pdu_bottom;
-	struct pdu_entry pdu_queue[MAX_PDU_ENTRIES];
-
 	/* This mutex protects several threads to do mailbox commands
 	 * concurrently.
 	 */
@@ -482,12 +587,9 @@ struct scsi_qla_host {
 	/* Map ddb_list entry by FW ddb index */
 	struct ddb_entry *fw_ddb_index_map[MAX_DDB_ENTRIES];
 
-	struct ql4_aen_log aen_log;/* tracks all aens */
+	struct ql4_aen_log aen_log;
 	void (*ql4getaenlog)(struct scsi_qla_host *ha, struct ql4_aen_log *aenl);
-
-#define QL_INDICES_PER_ENTRY    32
-#define QL_OSINDEX_ENTRIES      (MAX_DDB_ENTRIES/QL_INDICES_PER_ENTRY)
-        volatile unsigned long os_map[QL_OSINDEX_ENTRIES];
+	unsigned long os_map[MAX_DDB_ENTRIES/BITS_PER_LONG];
 
 	/* Saved srb for status continuation entry processing */
 	struct srb *status_srb;
@@ -496,12 +598,15 @@ struct scsi_qla_host {
 	dma_addr_t gen_req_rsp_iocb_dma;
 	void *gen_req_rsp_iocb;
 
+	/* DMA Pool for Passthru IOCBs */
+	struct dma_pool *pt_iocb_dmapool;
+
 	/* IPv6 support info from InitFW */
 	uint8_t acb_version;
 	uint8_t ipv4_addr_state;
 	uint16_t ipv4_options;
 
-	uint32_t resvd2;
+	uint32_t ipv6_tcp_options;
 	uint32_t ipv6_options;
 	uint32_t ipv6_addl_options;
 	uint8_t ipv6_link_local_state;
@@ -514,6 +619,69 @@ struct scsi_qla_host {
 	struct in6_addr ipv6_default_router_addr;
 
 	uint16_t ifcb_size;
+
+	/* qla82xx specific fields */
+	struct device_reg_82xx  __iomem *qla4_8xxx_reg; /* Base I/O address */
+	unsigned long nx_pcibase;	/* Base I/O address */
+	uint8_t *nx_db_rd_ptr;		/* Doorbell read pointer */
+	unsigned long nx_db_wr_ptr;	/* Door bell write pointer */
+	unsigned long first_page_group_start;
+	unsigned long first_page_group_end;
+
+	uint32_t crb_win;
+	uint32_t curr_window;
+	uint32_t ddr_mn_window;
+	unsigned long mn_win_crb;
+	unsigned long ms_win_crb;
+	int qdr_sn_window;
+	rwlock_t hw_lock;
+	uint16_t func_num;
+	int link_width;
+
+	void *rsvd4;
+	struct qla4_8xxx_legacy_intr_set nx_legacy_intr;
+	u32 nx_crb_mask;
+
+	uint8_t revision_id;
+	uint8_t rsvd3[3];
+
+	uint32_t fw_heartbeat_counter;
+
+	struct isp_operations *isp_ops;
+	struct ql82xx_hw_data hw;
+
+	struct ql4_msix_entry msix_entries[QLA_MSIX_ENTRIES];
+
+	uint32_t nx_dev_init_timeout;
+	uint32_t nx_reset_timeout;
+
+	void *fw_dump;
+	int fw_dump_size;
+	int fw_dump_capture_mask;
+	void *fw_dump_tmplt_hdr;
+	uint32_t fw_dump_tmplt_size;
+
+	struct completion mbx_intr_comp;
+
+	struct isns isns;
+	uint8_t (*ql4_isns_start_svc)(struct scsi_qla_host *ha);
+	void (*ql4_isns_restart_svc)(struct scsi_qla_host *ha);
+	uint8_t (*ql4_isns_stop_svc)(struct scsi_qla_host *ha);
+	void (*ql4_isns_populate_server_ip) (struct scsi_qla_host *ha,
+			struct addr_ctrl_blk *init_fw_cb);
+	void (*ql4_isns_send_dev_get_next) (struct scsi_qla_host *ha,
+			__u8 *last_iscsi_name, __u8 *buf,
+			__u32 *buf_len);
+	void (*ql4_isns_send_dev_attr_qry) (struct scsi_qla_host *ha,
+			__u8 *last_iscsi_name, __u8 *buf,
+			__u32 *buf_len);
+	uint8_t (*ql4_is_isns_active) (struct scsi_qla_host *ha);
+
+	struct workqueue_struct *pt_thread;
+	struct work_struct pt_work;
+	struct mutex  pt_sem;
+
+	uint16_t maxcmds;	/* maximum outstanding commands */
 };
 
 static inline int is_ipv4_enabled(struct scsi_qla_host *ha)
@@ -526,18 +694,20 @@ static inline int is_ipv6_enabled(struct
 	return ((ha->ipv6_options & IPV6_OPT_IPV6_PROTOCOL_ENABLE) != 0);
 }
 
-/*
- * structure to buffer Async PDUs
- */
-struct async_msg_pdu_iocb {
-	struct list_head list;
-	uint8_t iocb[0x40];
-};
+static inline int is_isnsv4_enabled(struct scsi_qla_host *ha)
+{
+	return ((ha->tcp_options & TOPT_ISNSv4_ENABLE) != 0);
+}
 
-typedef struct _ASYNC_PDU_SENSE {
-	uint16_t  sense_len;              /* 00-01 */
-	uint8_t   sense_data[0];
-} ASYNC_PDU_SENSE;
+static inline int is_isnsv6_enabled(struct scsi_qla_host *ha)
+{
+	return ((ha->ipv6_tcp_options & IPV6_TCPOPT_ISNSv6_ENABLE) != 0);
+}
+
+static inline int is_ipv6_ddb(struct ddb_entry *ddb)
+{
+	return ((ddb->options & DDB_OPT_IPV6_DEVICE) != 0);
+}
 
 static inline int is_qla4010(struct scsi_qla_host *ha)
 {
@@ -554,6 +724,20 @@ static inline int is_qla4032(struct scsi
 	return ha->pdev->device == PCI_DEVICE_ID_QLOGIC_ISP4032;
 }
 
+static inline int is_qla8022(struct scsi_qla_host *ha)
+{
+	return ha->pdev->device == PCI_DEVICE_ID_QLOGIC_ISP8022;
+}
+
+/* Note: Currently AER/EEH is now supported only for 8022 cards
+ * This function needs to be updated when AER/EEH is enabled
+ * for other cards.
+ */
+static inline int is_aer_supported(struct scsi_qla_host *ha)
+{
+	return ha->pdev->device == PCI_DEVICE_ID_QLOGIC_ISP8022;
+}
+
 static inline int adapter_up(struct scsi_qla_host *ha)
 {
 	return (test_bit(AF_ONLINE, &ha->flags) != 0) &&
@@ -607,13 +791,27 @@ static inline void __iomem* isp_port_err
 		&ha->reg->u2.isp4022.p0.port_err_status);
 }
 
-static inline void __iomem *isp_gp_out(struct scsi_qla_host *ha)
+static inline void __iomem * isp_gp_out(struct scsi_qla_host *ha)
 {
 	return (is_qla4010(ha) ?
 		&ha->reg->u2.isp4010.gp_out :
 		&ha->reg->u2.isp4022.p0.gp_out);
 }
 
+static inline void __iomem * isp_probe_mux_addr(struct scsi_qla_host *ha)
+{
+	return (is_qla4010(ha) ?
+		&ha->reg->u2.isp4010.probe_mux_addr :
+		&ha->reg->u2.isp4022.p0.probe_mux_addr);
+}
+
+static inline void __iomem * isp_probe_mux_data(struct scsi_qla_host *ha)
+{
+	return (is_qla4010(ha) ?
+		&ha->reg->u2.isp4010.probe_mux_data :
+		&ha->reg->u2.isp4022.p0.probe_mux_data);
+}
+
 static inline int eeprom_ext_hw_conf_offset(struct scsi_qla_host *ha)
 {
 	return (is_qla4010(ha) ?
@@ -682,6 +880,37 @@ static inline void ql4xxx_unlock_drvr(st
 		ql4xxx_sem_unlock(a, QL4022_DRVR_SEM_MASK);
 }
 
+static inline uint8_t ql4_is_memzero(const char *m, size_t s)
+{
+	int i, val = 0;
+
+	if (m) {
+		for (i=0; i<s; i++)
+			val |= m[i];
+	}
+	return (val == 0);
+}
+
+/* shortcut to print ISID */
+#if defined(__LITTLE_ENDIAN)
+#define ISID(addr) \
+        ((unsigned char *)&addr)[5], \
+        ((unsigned char *)&addr)[4], \
+        ((unsigned char *)&addr)[3], \
+        ((unsigned char *)&addr)[2], \
+        ((unsigned char *)&addr)[1], \
+        ((unsigned char *)&addr)[0]
+#else
+#define ISID(addr) \
+        ((unsigned char *)&addr)[0], \
+        ((unsigned char *)&addr)[1], \
+        ((unsigned char *)&addr)[2], \
+        ((unsigned char *)&addr)[3], \
+        ((unsigned char *)&addr)[4], \
+        ((unsigned char *)&addr)[5]
+#endif
+#define ISID_FMT "%02X%02X%02X%02X%02X%02X"
+
 /*---------------------------------------------------------------------------*/
 
 /* Defines for qla4xxx_initialize_adapter() and qla4xxx_recover_adapter() */
@@ -691,6 +920,8 @@ static inline void ql4xxx_unlock_drvr(st
 /* Defines for process_aen() */
 #define PROCESS_ALL_AENS	 0
 #define FLUSH_DDB_CHANGED_AENS	 1
-#define RELOGIN_DDB_CHANGED_AENS 2
+
+/* Defines for udev events */
+#define QL4_UEVENT_CODE_FW_DUMP	0	/* Uevent code for dumping firmware */
 
 #endif	/*_QLA4XXX_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_fw.h
--- a/drivers/scsi/qla4xxx/ql4_fw.h
+++ b/drivers/scsi/qla4xxx/ql4_fw.h
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -11,7 +11,7 @@
 
 #define MAX_PRST_DEV_DB_ENTRIES		64
 #define MIN_DISC_DEV_DB_ENTRY		MAX_PRST_DEV_DB_ENTRIES
-#define MAX_DEV_DB_ENTRIES 512
+#define MAX_DEV_DB_ENTRIES		512
 
 /*************************************************************************
  *
@@ -27,8 +27,12 @@ struct port_ctrl_stat_regs {
 	__le32 rsrvd1[32];	/* 0x60-0xdf */
 	__le32 gp_out;		/* 0xe0 */
 	__le32 gp_in;		/* 0xe4 */
-	__le32 rsrvd2[5];	/* 0xe8-0xfb */
-	__le32 port_err_status; /* 0xfc */
+	__le32 probe_mux_addr;	/* 0xe8 */
+	__le32 probe_mux_data;	/* 0xec */
+	__le32 stats_index;	/* 0xf0 */
+	__le32 stats_read_data_inc;	/* 0xf4 */
+	__le32 stats_read_data_noinc;	/* 0xf8 */
+	__le32 port_err_status;	/* 0xfc */
 };
 
 struct host_mem_cfg_regs {
@@ -37,6 +41,33 @@ struct host_mem_cfg_regs {
 	__le32 rsrvd1[31];	/* 0x84-0xFF */
 };
 
+/*
+ * ISP 82xx I/O Register Set structure definitions.
+ */
+struct device_reg_82xx {
+	__le32 req_q_out;	/* 0x0000 (R): Request Queue out-Pointer. */
+	__le32 reserve1[63];	/* Request Queue out-Pointer. (64 * 4) */
+	__le32 rsp_q_in;	/* 0x0100 (R/W): Response Queue In-Pointer. */
+	__le32 reserve2[63];	/* Response Queue In-Pointer. */
+	__le32 rsp_q_out;	/* 0x0200 (R/W): Response Queue Out-Pointer. */
+	__le32 reserve3[63];	/* Response Queue Out-Pointer. */
+
+	__le32 mailbox_in[8];	/* 0x0300 (R/W): Mail box In registers */
+	__le32 reserve4[24];
+	__le32 hint;		/* 0x0380 (R/W): Host interrupt register */
+#define HINT_MBX_INT_PENDING	BIT_0
+	__le32 reserve5[31];
+	__le32 mailbox_out[8];	/* 0x0400 (R): Mail box Out registers */
+	__le32 reserve6[56];
+
+	__le32 host_status;	/* Offset 0x500 (R): host status */
+#define HSRX_RISC_MB_INT	BIT_0  /* RISC to Host Mailbox interrupt */
+#define HSRX_RISC_IOCB_INT	BIT_1  /* RISC to Host IOCB interrupt */
+
+	__le32 host_int;	/* Offset 0x0504 (R/W): Interrupt status. */
+#define ISRX_82XX_RISC_INT	BIT_0 /* RISC interrupt. */
+};
+
 /*  remote register set (access via PCI memory read/write) */
 struct isp_reg {
 #define MBOX_REG_COUNT 8
@@ -61,7 +92,9 @@ struct isp_reg {
 	__le32 req_q_in;    /* SCSI Request Queue Producer Index */
 	__le32 rsp_q_out;   /* SCSI Completion Queue Consumer Index */
 
-	__le32 reserved2[4];	/* 0x40 */
+	__le32 reserved2[2];	/* 0x40 */
+	__le32 arc_madi_cmd;
+	__le32 arc_madi_data;
 
 	union {
 		struct {
@@ -79,7 +112,10 @@ struct isp_reg {
 			__le32 gp_out; /* 0xe0 */
 			__le32 gp_in;
 
-			__le32 reserved5[5];
+			__le32 probe_mux_addr;
+			__le32 probe_mux_data;
+
+			__le32 reserved5[3];
 
 			__le32 port_err_status; /* 0xfc */
 		} __attribute__ ((packed)) isp4010;
@@ -206,6 +242,80 @@ union external_hw_config_reg {
 	uint32_t Asuint32_t;
 };
 
+/* 82XX Support  start */
+/* 82xx Default FLT Addresses */
+#define FA_FLASH_LAYOUT_ADDR_82		0xFC400
+#define FA_FLASH_DESCR_ADDR_82		0xFC000
+#define FA_BOOT_LOAD_ADDR_82		0x04000
+#define FA_BOOT_CODE_ADDR_82		0x20000
+#define FA_RISC_CODE_ADDR_82		0x40000
+#define FA_GOLD_RISC_CODE_ADDR_82	0x80000
+
+/* Flash Description Table */
+struct qla_fdt_layout {
+	uint8_t sig[4];
+	uint16_t version;
+	uint16_t len;
+	uint16_t checksum;
+	uint8_t unused1[2];
+	uint8_t model[16];
+	uint16_t man_id;
+	uint16_t id;
+	uint8_t flags;
+	uint8_t erase_cmd;
+	uint8_t alt_erase_cmd;
+	uint8_t wrt_enable_cmd;
+	uint8_t wrt_enable_bits;
+	uint8_t wrt_sts_reg_cmd;
+	uint8_t unprotect_sec_cmd;
+	uint8_t read_man_id_cmd;
+	uint32_t block_size;
+	uint32_t alt_block_size;
+	uint32_t flash_size;
+	uint32_t wrt_enable_data;
+	uint8_t read_id_addr_len;
+	uint8_t wrt_disable_bits;
+	uint8_t read_dev_id_len;
+	uint8_t chip_erase_cmd;
+	uint16_t read_timeout;
+	uint8_t protect_sec_cmd;
+	uint8_t unused2[65];
+};
+
+/* Flash Layout Table */
+
+struct qla_flt_location {
+	uint8_t sig[4];
+	uint16_t start_lo;
+	uint16_t start_hi;
+	uint8_t version;
+	uint8_t unused[5];
+	uint16_t checksum;
+};
+
+struct qla_flt_header {
+	uint16_t version;
+	uint16_t length;
+	uint16_t checksum;
+	uint16_t unused;
+};
+
+/* 82xx FLT Regions */
+#define FLT_REG_FDT		0x1a
+#define FLT_REG_FLT		0x1c
+#define FLT_REG_BOOTLOAD_82	0x72
+#define FLT_REG_FW_82		0x74
+#define FLT_REG_GOLD_FW_82	0x75
+#define FLT_REG_BOOT_CODE_82	0x78
+#define FLT_REG_FW_82_1		0x97
+
+struct qla_flt_region {
+	uint32_t code;
+	uint32_t size;
+	uint32_t start;
+	uint32_t end;
+};
+
 /*************************************************************************
  *
  *		Mailbox Commands Structures and Definitions
@@ -215,21 +325,36 @@ union external_hw_config_reg {
 /*  Mailbox command definitions */
 #define MBOX_CMD_ABOUT_FW			0x0009
 #define MBOX_CMD_PING				0x000B
+#define MBOX_CMD_ENABLE_INTRS			0x0010
+#define INTR_DISABLE				0
+#define INTR_ENABLE				1
+#define MBOX_CMD_STOP_FW			0x0014
 #define MBOX_CMD_ABORT_TASK			0x0015
 #define MBOX_CMD_LUN_RESET			0x0016
 #define MBOX_CMD_TARGET_WARM_RESET		0x0017
 #define MBOX_CMD_GET_MANAGEMENT_DATA		0x001E
 #define MBOX_CMD_GET_FW_STATUS			0x001F
 #define MBOX_CMD_SET_ISNS_SERVICE		0x0021
-#define ISNS_DISABLE				0
-#define ISNS_ENABLE				1
+	/* Mailbox Cmd 1*/
+	#define ISNS_DISABLE			0
+	#define ISNS_REPORT_STATUS		2
+	#define ISNSv4_ENABLE			1
+	#define ISNSv6_ENABLE			3
+	/* Mailbox Sts 5 */
+	#define ISNS_STATUS_ACTIVE		1
+	#define ISNS_STATUS_NOT_ACTIVE		0
+
 #define MBOX_CMD_COPY_FLASH			0x0024
 #define MBOX_CMD_WRITE_FLASH			0x0025
+	/* Mailbox 5 */
+	#define WRITE_FLASH_OPTION_COMMIT_DATA	2
 #define MBOX_CMD_READ_FLASH			0x0026
-#define MBOX_CMD_CLEAR_DATABASE_ENTRY		0x0031
+#define MBOX_CMD_FREE_DATABASE_ENTRY		0x0031
+#define MBOX_CMD_CONN_CLOSE			0x0056
 #define MBOX_CMD_CONN_CLOSE_SESS_LOGOUT		0x0056
 #define LOGOUT_OPTION_CLOSE_SESSION		0x02
 #define LOGOUT_OPTION_RESET			0x04
+#define LOGOUT_OPTION_FREE_DDB			0x08
 #define MBOX_CMD_EXECUTE_IOCB_A64		0x005A
 #define MBOX_CMD_INITIALIZE_FIRMWARE		0x0060
 #define MBOX_CMD_GET_INIT_FW_CTRL_BLOCK		0x0061
@@ -243,6 +368,8 @@ union external_hw_config_reg {
 #define DDB_DS_LOGIN_IN_PROCESS			0x07
 #define MBOX_CMD_GET_FW_STATE			0x0069
 #define MBOX_CMD_GET_INIT_FW_CTRL_BLOCK_DEFAULTS 0x006A
+#define MBOX_CMD_GET_DIAGNOSTICS_DATA		0x0075
+#define MBOX_CMD_GET_SYS_INFO			0x0078
 #define MBOX_CMD_RESTORE_FACTORY_DEFAULTS	0x0087
 #define MBOX_CMD_SET_ACB			0x0088
 #define MBOX_CMD_GET_ACB			0x0089
@@ -255,6 +382,17 @@ union external_hw_config_reg {
 #define MBOX_CMD_GET_IP_ADDR_STATE		0x0091
 #define MBOX_CMD_SEND_IPV6_ROUTER_SOL		0x0092
 #define MBOX_CMD_GET_DB_ENTRY_CURRENT_IP_ADDR	0x0093
+#define MBOX_CMD_UPDATE_BEACON			0x0125
+
+/* Beacon update definitions */
+#define BEACON_DISABLE				0x000D
+#define BEACON_ENABLE				0x000E
+
+#define MBOX_CMD_MINIDUMP			0x0129
+
+/* Minidump subcommand */
+#define MINIDUMP_GET_SIZE_SUBCOMMAND		0x00
+#define MINIDUMP_GET_TMPLT_SUBCOMMAND		0x01
 
 /* Mailbox 1 */
 #define FW_STATE_READY				0x0000
@@ -281,7 +419,13 @@ union external_hw_config_reg {
 #define MBOX_STS_INTERMEDIATE_COMPLETION	0x1000
 #define MBOX_STS_COMMAND_COMPLETE		0x4000
 #define MBOX_STS_COMMAND_ERROR			0x4005
-#define MBOX_STS_COMMAND_PARAMETER_ERROR	0x4006
+
+#define MBOX_DRVR_ASYNC_EVENT_STATUS		7
+#define MBOX_DRVR_ASTS_SMDAPI_RESERVED		0x7001
+#define MBOX_DRVR_ASTS_ISNS_STATUS_CHANGE	0x7002
+#define ISNS_CHG_SERVER_OFFLINE			0x0001
+#define ISNS_CHG_TGT_DATABASE			0x0002
+#define MBOX_DRVR_ASTS_LUN_STATUS_CHANGE	0x7003
 
 #define MBOX_ASYNC_EVENT_STATUS			8
 #define MBOX_ASTS_SYSTEM_ERROR			0x8002
@@ -302,16 +446,24 @@ union external_hw_config_reg {
 #define MBOX_ASTS_IP_ADDRESS_CHANGED		0x801C
 #define MBOX_ASTS_DHCP_LEASE_EXPIRED		0x801D
 #define MBOX_ASTS_DHCP_LEASE_ACQUIRED		0x801F
-#define MBOX_ASTS_ISNS_UNSOLICITED_PDU_RECEIVED 0x8021
+#define MBOX_ASTS_ISNS				0x8021
+#define MBOX_ASTS_SOCKET_IOCB			0x8023
 #define MBOX_ASTS_DUPLICATE_IP			0x8025
 #define MBOX_ASTS_ARP_COMPLETE			0x8026
 #define MBOX_ASTS_SUBNET_STATE_CHANGE		0x8027
 #define MBOX_ASTS_RESPONSE_QUEUE_FULL		0x8028
 #define MBOX_ASTS_IP_ADDR_STATE_CHANGED		0x8029
+	/* Mailbox 5 */
+	#define IPADDR_STATECHG_IP_INDEX_MASK	0x0000000F
+	/*see IP Address Index Defines below */
+	#define IPADDR_STATECHG_ADDL_INFO_MASK	0x000000F0
+
 #define MBOX_ASTS_IPV6_PREFIX_EXPIRED		0x802B
 #define MBOX_ASTS_IPV6_ND_PREFIX_IGNORED	0x802C
 #define MBOX_ASTS_IPV6_LCL_PREFIX_IGNORED	0x802D
 #define MBOX_ASTS_ICMPV6_ERROR_MSG_RCVD		0x802E
+#define MBOX_ASTS_TXSCVR_INSERTED		0x8130
+#define MBOX_ASTS_TXSCVR_REMOVED		0x8131
 
 #define ISNS_EVENT_DATA_RECEIVED		0x0000
 #define ISNS_EVENT_CONNECTION_OPENED		0x0001
@@ -319,6 +471,25 @@ union external_hw_config_reg {
 #define MBOX_ASTS_IPSEC_SYSTEM_FATAL_ERROR	0x8022
 #define MBOX_ASTS_SUBNET_STATE_CHANGE		0x8027
 
+/* ACB Location Defines */
+#define ACB_PRIMARY		0x00
+#define ACB_SECONDARY		0x01
+
+/* ACB State Defines */
+#define ACB_STATE_UNCONFIGURED	0x00
+#define ACB_STATE_INVALID	0x01
+#define ACB_STATE_ACQUIRING	0x02
+#define ACB_STATE_TENTATIVE	0x03
+#define ACB_STATE_DEPRICATED	0x04
+#define ACB_STATE_VALID		0x05
+#define ACB_STATE_DISABLING	0x06
+
+/* IP Address Index Defines */
+#define IP_INDEX_IPv4			0x00
+#define IP_INDEX_IPv6_LINK_LOCAL	0x01
+#define IP_INDEX_IPv6_ADDR0		0x02
+#define IP_INDEX_IPv6_ADDR1		0x03
+
 /*************************************************************************/
 
 /* Host Adapter Initialization Control Block (from host) */
@@ -333,12 +504,14 @@ struct addr_ctrl_blk {
 #define	 FWOPT_SESSION_MODE		  0x0040
 #define	 FWOPT_INITIATOR_MODE		  0x0020
 #define	 FWOPT_TARGET_MODE		  0x0010
+#define	 FWOPT_ENABLE_CRBDB		  0x8000
 
 	uint16_t exec_throttle;	/* 04-05 */
 	uint8_t zio_count;	/* 06 */
 	uint8_t res0;	/* 07 */
 	uint16_t eth_mtu_size;	/* 08-09 */
 	uint16_t add_fw_options;	/* 0A-0B */
+#define	SERIALIZE_TASK_MGMT		  0x0400
 
 	uint8_t hb_interval;	/* 0C */
 	uint8_t inst_num; /* 0D */
@@ -356,6 +529,7 @@ struct addr_ctrl_blk {
 
 	uint16_t iscsi_opts;	/* 30-31 */
 	uint16_t ipv4_tcp_opts;	/* 32-33 */
+#define TOPT_ISNSv4_ENABLE		0x4000
 	uint16_t ipv4_ip_opts;	/* 34-35 */
 #define  IPOPT_IPv4_PROTOCOL_ENABLE	0x8000
 
@@ -364,7 +538,8 @@ struct addr_ctrl_blk {
 	uint8_t ipv4_ttl;	/* 39 */
 	uint8_t acb_version;	/* 3A */
 #define ACB_NOT_SUPPORTED		0x00
-#define ACB_SUPPORTED			0x02 /* Capable of ACB Version 2 Features */
+#define ACB_SUPPORTED			0x02 /* Capable of ACB Version 2
+						Features */
 
 	uint8_t res2;	/* 3B */
 	uint16_t def_timeout;	/* 3C-3D */
@@ -399,7 +574,9 @@ struct addr_ctrl_blk {
 	uint8_t ipv4_sec_ip_addr[4];	/* D0-D3 */
 	uint8_t ipv4_dhcp_vid_len;	/* D4 */
 	uint8_t ipv4_dhcp_vid[11];	/* D5-DF */
-	uint8_t res11[20];	/* E0-F3 */
+        uint8_t ipv4_isns_svr_ip[4];    /* E0-E3 */
+        uint16_t isns_svr_port;         /* E4-E5 */
+        uint8_t res11[14];              /* E6-F3 */
 	uint8_t ipv4_dhcp_alt_cid_len;	/* F4 */
 	uint8_t ipv4_dhcp_alt_cid[11];	/* F5-FF */
 	uint8_t iscsi_name[224];	/* 100-1DF */
@@ -410,10 +587,12 @@ struct addr_ctrl_blk {
 #define IPV6_OPT_IPV6_PROTOCOL_ENABLE	0x8000
 
 	uint16_t ipv6_addtl_opts;	/* 208-209 */
-#define IPV6_ADDOPT_NEIGHBOR_DISCOVERY_ADDR_ENABLE	0x0002 /* Pri ACB Only */
+#define IPV6_ADDOPT_NEIGHBOR_DISCOVERY_ADDR_ENABLE	0x0002 /* Pri ACB
+								  Only */
 #define IPV6_ADDOPT_AUTOCONFIG_LINK_LOCAL_ADDR		0x0001
 
 	uint16_t ipv6_tcp_opts;	/* 20A-20B */
+#define IPV6_TCPOPT_ISNSv6_ENABLE			0x4000
 	uint8_t ipv6_tcp_wsf;	/* 20C */
 	uint16_t ipv6_flow_lbl;	/* 20D-20F */
 	uint8_t ipv6_dflt_rtr_addr[16]; /* 210-21F */
@@ -445,7 +624,8 @@ struct addr_ctrl_blk {
 	uint32_t ipv6_nd_stale_timeout;	/* 258-25B */
 	uint8_t ipv6_dup_addr_detect_count;	/* 25C */
 	uint8_t ipv6_cache_id;	/* 25D */
-	uint8_t res13[18];	/* 25E-26F */
+	uint8_t res13[2];	/* 25E-25F */
+	uint8_t ipv6_isns_svr_ip[16];	/* 260-26F */
 	uint32_t ipv6_gw_advrt_mtu;	/* 270-273 */
 	uint8_t res14[140];	/* 274-2FF */
 };
@@ -557,6 +737,20 @@ struct flash_sys_info {
 	uint32_t reserved1[39]; /* 170-1ff */
 };	/* 200 */
 
+struct mbx_sys_info {
+	uint8_t board_id_str[16];   /*  0-f  Keep board ID string first */
+				/* in this structure for GUI. */
+	uint16_t board_id;	/* 10-11 board ID code */
+	uint16_t phys_port_cnt;	/* 12-13 number of physical network ports */
+	uint16_t port_num;	/* 14-15 network port for this PCI function */
+				/* (port 0 is first port) */
+	uint8_t mac_addr[6];	/* 16-1b MAC address for this PCI function */
+	uint32_t iscsi_pci_func_cnt;  /* 1c-1f number of iSCSI PCI functions */
+	uint32_t pci_func;	      /* 20-23 this PCI function */
+	unsigned char serial_number[16];  /* 24-33 serial number string */
+	uint8_t reserved[12];		  /* 34-3f */
+} __attribute__ ((packed));
+
 struct crash_record {
 	uint16_t fw_major_version;	/* 00 - 01 */
 	uint16_t fw_minor_version;	/* 02 - 03 */
@@ -607,19 +801,19 @@ struct conn_event_log_entry {
 
 /* IOCB header structure */
 struct qla4_header {
-	uint8_t entryType;
-#define ET_STATUS		0x03
-#define ET_MARKER		0x04
-#define ET_CONT_T1		0x0A
-#define ET_STATUS_CONTINUATION	0x10
-#define ET_CMND_T3		0x19
-#define ET_ASYNC_PDU		0x37
-#define ET_PASSTHRU0		0x3A
-#define ET_PASSTHRU_STATUS	0x3C
+	uint8_t entry_type;
+#define ET_STATUS		 0x03
+#define ET_MARKER		 0x04
+#define ET_CONT_T1		 0x0A
+#define ET_STATUS_CONTINUATION	 0x10
+#define ET_CMND_T3		 0x19
+#define ET_ASYNC_ISCSI_PDU	 0x37
+#define ET_PASSTHRU0		 0x3A
+#define ET_PASSTHRU_STATUS	 0x3C
 
-	uint8_t entryStatus;
-	uint8_t systemDefined;
-	uint8_t entryCount;
+	uint8_t entry_status;
+	uint8_t system_defined;
+	uint8_t entry_count;
 
 	/* SyetemDefined definition */
 };
@@ -640,8 +834,8 @@ struct queue_entry {
 
 struct data_seg_a64 {
 	struct {
-		uint32_t addrLow;
-		uint32_t addrHigh;
+		uint32_t addr_lo;
+		uint32_t addr_hi;
 
 	} base;
 
@@ -726,14 +920,23 @@ struct qla4_marker_entry {
 
 /* Asynchronous PDU IOCB structure */
 struct async_pdu_iocb {
-	struct qla4_header hdr;         /* 00-02 */
-	uint32_t async_pdu_handle;      /* 03-06 */
-	uint16_t target_id;             /* 07-08 */
-	uint16_t status;                /* 09-0A */
-#define ASYNC_PDU_IOCB_STS_OK   0x01
+	struct qla4_header hdr;		/* 00-02 */
+	uint32_t async_pdu_handle;	/* 03-06 */
+	uint16_t target_id;		/* 07-08 */
+	uint16_t status;		/* 09-0A */
+#define ASYNC_PDU_IOCB_STS_OK  0x01
+	uint32_t rsrvd;			/* 0B-0F */
+	uint8_t iscsi_pdu_hdr[48];	/* 10-3F */
+};
 
-	uint32_t rsrvd;                 /* 0B-0F */
-	uint8_t iscsi_pdu_hdr[48];      /* 10-3F */
+struct async_msg_pdu_iocb {
+	struct list_head list;
+	uint8_t iocb[0x40];
+};
+
+struct async_pdu_sense {
+	uint16_t  sense_len;		/* 00-01 */
+	uint8_t   sense_data[0];
 };
 
 /* Status entry structure*/
@@ -778,15 +981,6 @@ struct status_entry {
 
 };
 
-struct pdu_entry {
-	uint8_t *Buff;
-	uint32_t BuffLen;
-	uint32_t SendBuffLen;
-	uint32_t RecvBuffLen;
-	struct pdu_entry *Next;
-	dma_addr_t DmaBuff;
-};
-
 /* Status Continuation entry */
 struct status_cont_entry {
        struct qla4_header hdr; /* 00-03 */
@@ -797,9 +991,10 @@ struct passthru0 {
 	struct qla4_header hdr;		       /* 00-03 */
 	uint32_t handle;	/* 04-07 */
 	uint16_t target;	/* 08-09 */
-	uint16_t connectionID;	/* 0A-0B */
+	uint16_t conn_id;	/* 0A-0B */
 
-	uint16_t controlFlags;	/* 0C-0D */
+	uint16_t ctrl_flags;	/* 0C-0D */
+#define PT_FLAG_ETHERNET_FRAME		0x8000
 #define PT_FLAG_ISCSI_PDU		0x1000
 #define PT_FLAG_SEND_BUFFER		0x0200
 #define PT_FLAG_WAIT_4_RESPONSE		0x0100
@@ -807,31 +1002,82 @@ struct passthru0 {
 	uint16_t timeout;	/* 0E-0F */
 #define PT_DEFAULT_TIMEOUT		30 /* seconds */
 
-	struct data_seg_a64 outDataSeg64;	/* 10-1B */
+	struct data_seg_a64 out_data_seg64;	/* 10-1B */
 	uint32_t res1;		/* 1C-1F */
-	struct data_seg_a64 inDataSeg64;	/* 20-2B */
-	uint8_t res2[16];	/* 2C-3F */
-	uint32_t async_pdu_handle;
+	struct data_seg_a64 in_data_seg64;	/* 20-2B */
+	uint8_t res2[16];	/* 2C-3B */
+	uint32_t async_pdu_handle; /* 3E-3F */
 };
 
 struct passthru_status {
 	struct qla4_header hdr;		       /* 00-03 */
 	uint32_t handle;	/* 04-07 */
 	uint16_t target;	/* 08-09 */
-	uint16_t connectionID;	/* 0A-0B */
+	uint16_t conn_id;	/* 0A-0B */
 
-	uint8_t completionStatus;	/* 0C */
+	uint8_t cmpl_status;	/* 0C */
 #define PASSTHRU_STATUS_COMPLETE		0x01
 
-	uint8_t residualFlags;	/* 0D */
+	uint8_t residual_flags;	/* 0D */
+#define PT_STATUS_RESID_DATA_OUT_OVERRUN	0x01
+#define PT_STATUS_RESID_DATA_OUT_UNDERRUN	0x02
+#define PT_STATUS_RESID_DATA_IN_OVERRUN		0x04
+#define PT_STATUS_RESID_DATA_IN_UNDERRUN	0x08
 
 	uint16_t timeout;	/* 0E-0F */
-	uint16_t portNumber;	/* 10-11 */
+	uint16_t port_number;	/* 10-11 */
 	uint8_t res1[10];	/* 12-1B */
-	uint32_t outResidual;	/* 1C-1F */
+	uint32_t out_residual;	/* 1C-1F */
 	uint8_t res2[12];	/* 20-2B */
-	uint32_t inResidual;	/* 2C-2F */
+	uint32_t in_residual;	/* 2C-2F */
 	uint8_t res4[16];	/* 30-3F */
 };
 
+/*
+ * ISP queue - response queue entry definition.
+ */
+struct response {
+	uint8_t data[60];
+	uint32_t signature;
+#define RESPONSE_PROCESSED	0xDEADDEAD	/* Signature */
+};
+
+/*
+* Template Header
+* Parts of the template header can be modified by the driver.
+* These include the saved_state_array, capture_debug_level, driver_timestamp
+* The driver_info_wordX is used to add info about the drivers environment.
+* It is important that drivers add identication and system info in these fields.
+*/
+
+#define QLA82XX_DBG_STATE_ARRAY_LEN        16
+#define QLA82XX_DBG_CAP_SIZE_ARRAY_LEN     8
+#define QLA82XX_DBG_RSVD_ARRAY_LEN         8
+
+struct qla4_8xxx_minidump_template_hdr {
+	uint32_t entry_type;
+	uint32_t first_entry_offset;
+	uint32_t size_of_template;
+	uint32_t capture_debug_level;
+	uint32_t num_of_entries;
+	uint32_t version;
+	uint32_t driver_timestamp;
+	uint32_t checksum;
+
+	uint32_t driver_capture_mask;
+	uint32_t driver_info_word2;
+	uint32_t driver_info_word3;
+	uint32_t driver_info_word4;
+	
+	uint32_t saved_state_array[QLA82XX_DBG_STATE_ARRAY_LEN];
+	uint32_t capture_size_array[QLA82XX_DBG_CAP_SIZE_ARRAY_LEN];
+		
+	/*  markers_array used to capture some special locations on board */
+	uint32_t markers_array[QLA82XX_DBG_RSVD_ARRAY_LEN];
+	uint32_t num_of_free_entries;   /* For firmware internal use */
+	uint32_t free_entry_offset;     /* For firmware internal use */
+	uint32_t total_table_size;      /* For firmware internal use */
+	uint32_t bkup_table_offset;     /* For firmware internal use */
+};
+
 #endif /*  _QLA4X_FW_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_glbl.h
--- a/drivers/scsi/qla4xxx/ql4_glbl.h
+++ b/drivers/scsi/qla4xxx/ql4_glbl.h
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -10,34 +10,35 @@
 
 struct iscsi_cls_conn;
 
-void qla4xxx_hw_reset(struct scsi_qla_host *ha);
+int qla4xxx_hw_reset(struct scsi_qla_host *ha);
 int ql4xxx_lock_drvr_wait(struct scsi_qla_host *a);
 int qla4xxx_send_tgts(struct scsi_qla_host *ha, char *ip, uint16_t port);
-int qla4xxx_send_command_to_isp(struct scsi_qla_host *ha, struct srb * srb);
-int qla4xxx_initialize_adapter(struct scsi_qla_host * ha,
+int qla4xxx_send_command_to_isp(struct scsi_qla_host *ha, struct srb *srb);
+int qla4xxx_initialize_adapter(struct scsi_qla_host *ha,
 			       uint8_t renew_ddb_list);
 int qla4xxx_soft_reset(struct scsi_qla_host *ha);
 irqreturn_t qla4xxx_intr_handler(int irq, void *dev_id);
 
-void qla4xxx_free_ddb_list(struct scsi_qla_host * ha);
-void qla4xxx_free_ddb(struct scsi_qla_host *, struct ddb_entry *);
-void qla4xxx_process_aen(struct scsi_qla_host * ha, uint8_t process_aen);
+void qla4xxx_free_ddb_list(struct scsi_qla_host *ha);
+void qla4xxx_free_ddb(struct scsi_qla_host *ha, struct ddb_entry *ddb_entry);
+void qla4xxx_process_aen(struct scsi_qla_host *ha, uint8_t process_aen);
 
-int qla4xxx_get_dhcp_ip_address(struct scsi_qla_host * ha);
-int qla4xxx_relogin_device(struct scsi_qla_host * ha,
-			   struct ddb_entry * ddb_entry);
+int qla4xxx_get_dhcp_ip_address(struct scsi_qla_host *ha);
+int qla4xxx_relogin_device(struct scsi_qla_host *ha,
+			   struct ddb_entry *ddb_entry);
+void qla4xxx_relogin_all_devices(struct scsi_qla_host *ha);
 int qla4xxx_abort_task(struct scsi_qla_host *ha, struct srb *srb);
-int qla4xxx_reset_lun(struct scsi_qla_host * ha, struct ddb_entry * ddb_entry,
+int qla4xxx_reset_lun(struct scsi_qla_host *ha, struct ddb_entry *ddb_entry,
 		      int lun);
-int qla4xxx_reset_target(struct scsi_qla_host * ha,
-			 struct ddb_entry * ddb_entry);
-int qla4xxx_get_flash(struct scsi_qla_host * ha, dma_addr_t dma_addr,
+int qla4xxx_reset_target(struct scsi_qla_host *ha,
+			 struct ddb_entry *ddb_entry);
+int qla4xxx_get_flash(struct scsi_qla_host *ha, dma_addr_t dma_addr,
 		      uint32_t offset, uint32_t len);
-int qla4xxx_issue_iocb(struct scsi_qla_host *ha, uint32_t comp_offset,
-			dma_addr_t phys_addr);
-int qla4xxx_get_firmware_status(struct scsi_qla_host * ha);
-int qla4xxx_get_firmware_state(struct scsi_qla_host * ha);
-int qla4xxx_initialize_fw_cb(struct scsi_qla_host * ha);
+int qla4xxx_issue_iocb(struct scsi_qla_host * ha, uint32_t comp_offset,
+		dma_addr_t phys_addr);
+int qla4xxx_get_firmware_status(struct scsi_qla_host *ha);
+int qla4xxx_get_firmware_state(struct scsi_qla_host *ha);
+int qla4xxx_initialize_fw_cb(struct scsi_qla_host *ha);
 
 /* FIXME: Goodness!  this really wants a small struct to hold the
  * parameters. On x86 the args will get passed on the stack! */
@@ -54,41 +55,146 @@ int qla4xxx_get_fwddb_entry(struct scsi_
 
 int qla4xxx_set_ddb_entry(struct scsi_qla_host * ha, uint16_t fw_ddb_index,
 			  dma_addr_t fw_ddb_entry_dma);
-
+struct ddb_entry * qla4xxx_find_ddb_internally(struct scsi_qla_host *ha,
+						uint32_t fw_ddb_index);
 void qla4xxx_mark_device_missing(struct scsi_qla_host *ha,
 				 struct ddb_entry *ddb_entry);
-u16 rd_nvram_word(struct scsi_qla_host * ha, int offset);
-void qla4xxx_get_crash_record(struct scsi_qla_host * ha);
+u16 rd_nvram_word(struct scsi_qla_host *ha, int offset);
+void qla4xxx_get_crash_record(struct scsi_qla_host *ha);
 struct ddb_entry *qla4xxx_alloc_sess(struct scsi_qla_host *ha);
 int qla4xxx_add_sess(struct ddb_entry *);
 void qla4xxx_destroy_sess(struct ddb_entry *ddb_entry);
-int qla4xxx_conn_close_sess_logout(struct scsi_qla_host *ha,
-				   uint16_t fw_ddb_index,
-				   uint16_t connection_id,
-				   uint16_t option);
-int qla4xxx_is_nvram_configuration_valid(struct scsi_qla_host * ha);
+int qla4xxx_conn_close_sess_logout(struct scsi_qla_host * ha,
+		uint16_t fw_ddb_index,
+		uint16_t option);
+int qla4xxx_free_database_entry(struct scsi_qla_host * ha,
+                                uint16_t fw_ddb_index);
+int qla4xxx_is_nvram_configuration_valid(struct scsi_qla_host *ha);
 int qla4xxx_get_fw_version(struct scsi_qla_host * ha);
-void qla4xxx_interrupt_service_routine(struct scsi_qla_host * ha,
+void qla4xxx_interrupt_service_routine(struct scsi_qla_host *ha,
 				       uint32_t intr_status);
-int qla4xxx_init_rings(struct scsi_qla_host * ha);
-struct srb * qla4xxx_del_from_active_array(struct scsi_qla_host *ha,
-					uint32_t index);
-void qla4xxx_srb_compl(struct scsi_qla_host *ha, struct srb *srb);
-int qla4xxx_reinitialize_ddb_list(struct scsi_qla_host * ha);
+int qla4xxx_init_rings(struct scsi_qla_host *ha);
+void qla4xxx_srb_compl(struct kref *ref);
+struct srb *qla4xxx_del_from_active_array(struct scsi_qla_host *ha,
+		uint32_t index);
+int qla4xxx_reinitialize_ddb_list(struct scsi_qla_host *ha);
 int qla4xxx_process_ddb_changed(struct scsi_qla_host *ha, uint32_t fw_ddb_index,
-				uint32_t state, uint32_t conn_error);
+		uint32_t state, uint32_t conn_error);
 void qla4xxx_dump_buffer(void *b, uint32_t size);
 int qla4xxx_send_marker_iocb(struct scsi_qla_host *ha,
 	struct ddb_entry *ddb_entry, int lun, uint16_t mrkr_mod);
+int qla4_is_relogin_allowed(struct scsi_qla_host *ha, uint32_t conn_err);
 
-void sp_put(struct scsi_qla_host *ha, struct srb *sp);
-int qla4_is_relogin_allowed(struct scsi_qla_host *ha, uint32_t conn_err);
 int qla4xxx_mailbox_command(struct scsi_qla_host *ha, uint8_t inCount,
-				uint8_t outCount, uint32_t *mbx_cmd,
-				uint32_t *mbx_sts);
+		uint8_t outCount, uint32_t *mbx_cmd, uint32_t *mbx_sts);
+
+void qla4xxx_queue_iocb(struct scsi_qla_host *ha);
+void qla4xxx_complete_iocb(struct scsi_qla_host *ha);
+void qla4xxx_get_sys_info(struct scsi_qla_host *ha);
+int qla4xxx_iospace_config(struct scsi_qla_host *ha);
+void qla4xxx_pci_config(struct scsi_qla_host *ha);
+int qla4xxx_start_firmware(struct scsi_qla_host *ha);
+irqreturn_t qla4xxx_intr_handler(int irq, void *dev_id);
+uint16_t qla4xxx_rd_shdw_req_q_out(struct scsi_qla_host *ha);
+uint16_t qla4xxx_rd_shdw_rsp_q_in(struct scsi_qla_host *ha);
+int qla4xxx_request_irqs(struct scsi_qla_host *ha);
+void qla4xxx_free_irqs(struct scsi_qla_host *ha);
+void qla4xxx_process_response_queue(struct scsi_qla_host *ha);
+extern void qla4xxx_wake_dpc(struct scsi_qla_host *ha);
+void qla4xxx_get_conn_event_log(struct scsi_qla_host *ha);
+void qla4xxx_mailbox_premature_completion(struct scsi_qla_host *ha);
+void qla4xxx_dump_registers(struct scsi_qla_host *ha);
+int qla4xxx_get_req_pkt(struct scsi_qla_host *ha,
+		struct queue_entry **queue_entry);
+
+/* ql4_isns.c */
+uint8_t ql4_isns_start_service(struct scsi_qla_host *ha);
+uint8_t ql4_isns_stop_service(struct scsi_qla_host *ha);
+void ql4_isns_restart_service(struct scsi_qla_host *ha);
+void ql4_isns_restart_timer(struct scsi_qla_host *ha, __u32 time);
+void ql4_isns_send_scn_dereg(struct scsi_qla_host *ha);
+void ql4_isns_send_dev_get_next(struct scsi_qla_host *ha,
+		__u8 *last_iscsi_name,
+		__u8 *buf, __u32 *buf_len);
+void ql4_isns_send_dev_attr_qry(struct scsi_qla_host *ha,
+		__u8 *last_iscsi_name,
+		__u8 *buf, __u32 *buf_len);
+void ql4_isns_populate_server_ip(struct scsi_qla_host *ha,
+		struct addr_ctrl_blk *init_fw_cb);
+void ql4_isns_process_isns_aen(struct scsi_qla_host *ha, __u32 *mbox_sts);
+void ql4_isns_queue_passthru_sts_iocb(struct scsi_qla_host *ha,
+					struct isns_prb *prb);
+void ql4_isns_process_passthru_sts_iocb(struct scsi_qla_host *ha,
+					struct isns_prb *prb);
+void ql4_isns_process_ip_state_chg(struct scsi_qla_host *ha,
+					__u32 *mbox_sts);
+void ql4_queue_isns_sts_chg_aen(struct scsi_qla_host *ha,
+				uint32_t chg_type);
+void __dump_prb(struct scsi_qla_host *ha, struct isns_prb *prb);
+void ql4_isns_dequeue_passthru_sts_iocb(struct work_struct *work);
+__u8 ql4_is_isns_active(struct scsi_qla_host *ha);
+__u8 ql4_isns_deregister_isns_server(struct scsi_qla_host *ha);
+__u8 ql4_isns_register_isns_server(struct scsi_qla_host *ha);
+void qla4xxx_dump_bytes(void *buffer, uint32_t size);
+void qla4xxx_dump_mbx_cmd(struct scsi_qla_host *ha, uint32_t *mbx_cmd);
+void qla4xxx_dump_mbx_sts(struct scsi_qla_host *ha, uint32_t *mbx_sts);
+
+void qla4_8xxx_pci_config(struct scsi_qla_host *);
+int qla4_8xxx_iospace_config(struct scsi_qla_host *ha);
+int qla4_8xxx_load_risc(struct scsi_qla_host *);
+irqreturn_t qla4_8xxx_intr_handler(int irq, void *dev_id);
+void qla4_8xxx_queue_iocb(struct scsi_qla_host *ha);
+void qla4_8xxx_complete_iocb(struct scsi_qla_host *ha);
+
+int qla4_8xxx_crb_win_lock(struct scsi_qla_host *);
+void qla4_8xxx_crb_win_unlock(struct scsi_qla_host *);
+int qla4_8xxx_pci_get_crb_addr_2M(struct scsi_qla_host *, ulong *);
+void qla4_8xxx_wr_32(struct scsi_qla_host *, ulong, u32);
+int qla4_8xxx_rd_32(struct scsi_qla_host *, ulong);
+int qla4_8xxx_pci_mem_read_2M(struct scsi_qla_host *, u64, void *, int);
+int qla4_8xxx_pci_mem_write_2M(struct scsi_qla_host *ha, u64, void *, int);
+int qla4_8xxx_isp_reset(struct scsi_qla_host *ha);
+void qla4_8xxx_interrupt_service_routine(struct scsi_qla_host *ha,
+		uint32_t intr_status);
+uint16_t qla4_8xxx_rd_shdw_req_q_out(struct scsi_qla_host *ha);
+uint16_t qla4_8xxx_rd_shdw_rsp_q_in(struct scsi_qla_host *ha);
+void qla4_8xxx_get_sys_info(struct scsi_qla_host *ha);
+void qla4_8xxx_watchdog(struct scsi_qla_host *ha);
+int qla4_8xxx_stop_firmware(struct scsi_qla_host *ha);
+int qla4_8xxx_get_flash_info(struct scsi_qla_host *ha);
+void qla4_8xxx_enable_intrs(struct scsi_qla_host *ha);
+void qla4_8xxx_disable_intrs(struct scsi_qla_host *ha);
+int qla4_8xxx_enable_msix(struct scsi_qla_host *ha);
+void qla4_8xxx_disable_msix(struct scsi_qla_host *ha);
+irqreturn_t qla4_8xxx_msi_handler(int irq, void *dev_id);
+irqreturn_t qla4_8xxx_default_intr_handler(int irq, void *dev_id);
+irqreturn_t qla4_8xxx_msix_rsp_q(int irq, void *dev_id);
+void qla4xxx_mark_all_devices_missing(struct scsi_qla_host *ha);
+void qla4xxx_dead_adapter_cleanup(struct scsi_qla_host *ha);
+int qla4_8xxx_idc_lock(struct scsi_qla_host *ha);
+void qla4_8xxx_idc_unlock(struct scsi_qla_host *ha);
+int qla4_8xxx_device_state_handler(struct scsi_qla_host *ha);
+void qla4_8xxx_need_qsnt_handler(struct scsi_qla_host *ha);
+void qla4_8xxx_clear_drv_active(struct scsi_qla_host *ha);
+void qla4_8xxx_set_drv_active(struct scsi_qla_host *ha);
+void qla4_8xxx_clear_qsnt_ready(struct scsi_qla_host *);
+void qla4xxx_qsnt_state_cleanup(struct scsi_qla_host *ha);
+void qla4xxx_get_conn_event_log(struct scsi_qla_host *);
+int qla4xxx_cmd_wait(struct scsi_qla_host *, uint32_t timeout);
+int qla4xxx_get_minidump_template(struct scsi_qla_host *, dma_addr_t );
+int qla4xxx_req_template_size(struct scsi_qla_host * );
+void qla4_8xxx_alloc_sysfs_attr(struct scsi_qla_host *);
+void qla4_8xxx_free_sysfs_attr(struct scsi_qla_host *);
+void qla4xxx_alloc_fw_dump(struct scsi_qla_host *);
 
 extern int ql4xextended_error_logging;
-extern int ql4xdiscoverywait;
+extern int ql4xmdcapmask; 
 extern int ql4xdontresethba;
-extern int ql4_mod_unload;
+extern int ql4xenablemsix;
+extern int ql4xkeepalive;
+extern int ql4xmaxcmds;
+extern int ql4xenablemd;
+
+extern struct device_attribute *qla4xxx_host_attrs[];
+
 #endif /* _QLA4x_GBL_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_init.c
--- a/drivers/scsi/qla4xxx/ql4_init.c
+++ b/drivers/scsi/qla4xxx/ql4_init.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -11,8 +11,8 @@
 #include "ql4_dbg.h"
 #include "ql4_inline.h"
 
-static struct ddb_entry * qla4xxx_alloc_ddb(struct scsi_qla_host *ha,
-					    uint32_t fw_ddb_index);
+static struct ddb_entry *qla4xxx_alloc_ddb(struct scsi_qla_host *ha,
+					   uint32_t fw_ddb_index);
 
 static void ql4xxx_set_mac_number(struct scsi_qla_host *ha)
 {
@@ -34,13 +34,11 @@ static void ql4xxx_set_mac_number(struct
 		ha->mac_index = 3;
 		break;
 	default:
-		DEBUG2(printk("scsi%ld: %s: Invalid function number, "
-			      "ispControlStatus = 0x%x\n", ha->host_no,
-			      __func__, value));
+		DEBUG2(ql4_info(ha, "%s: Invalid function number, "
+			      "ispControlStatus = 0x%x\n", __func__, value));
 		break;
 	}
-	DEBUG2(printk("scsi%ld: %s: mac_index %d.\n", ha->host_no, __func__,
-		      ha->mac_index));
+	DEBUG2(ql4_info(ha, "%s: mac_index %d.\n", __func__, ha->mac_index));
 }
 
 /**
@@ -52,8 +50,11 @@ static void ql4xxx_set_mac_number(struct
  * adapter's
  **/
 void qla4xxx_free_ddb(struct scsi_qla_host *ha,
-			     struct ddb_entry *ddb_entry)
+    struct ddb_entry *ddb_entry)
 {
+	DEBUG2(ql4_info(ha, "%s: ddb[%d] os[%d]\n", __func__,
+		ddb_entry->fw_ddb_index, ddb_entry->os_target_id));
+
 	/* Remove device entry from list */
 	list_del_init(&ddb_entry->list);
 
@@ -86,6 +87,25 @@ void qla4xxx_free_ddb_list(struct scsi_q
 }
 
 /**
+ * qla4xxx_init_response_q_entries() - Initializes response queue entries.
+ * @ha: HA context
+ *
+ * Beginning of request ring has initialization control block already built
+ * by nvram config routine.
+ **/
+static void qla4xxx_init_response_q_entries(struct scsi_qla_host *ha)
+{
+	uint16_t cnt;
+	struct response *pkt;
+
+	pkt = (struct response *)ha->response_ptr;
+	for (cnt = 0; cnt < ha->response_qdepth; cnt++) {
+		pkt->signature = RESPONSE_PROCESSED;
+		pkt++;
+	}
+}
+
+/**
  * qla4xxx_init_rings - initialize hw queues
  * @ha: pointer to host adapter structure.
  *
@@ -103,26 +123,39 @@ int qla4xxx_init_rings(struct scsi_qla_h
 	ha->request_out = 0;
 	ha->request_in = 0;
 	ha->request_ptr = &ha->request_ring[ha->request_in];
-	ha->req_q_count = REQUEST_QUEUE_DEPTH;
+	ha->req_q_count = ha->maxcmds;
 
 	/* Initialize response queue. */
 	ha->response_in = 0;
 	ha->response_out = 0;
 	ha->response_ptr = &ha->response_ring[ha->response_out];
 
-	/*
-	 * Initialize DMA Shadow registers.  The firmware is really supposed to
-	 * take care of this, but on some uniprocessor systems, the shadow
-	 * registers aren't cleared-- causing the interrupt_handler to think
-	 * there are responses to be processed when there aren't.
-	 */
-	ha->shadow_regs->req_q_out = __constant_cpu_to_le32(0);
-	ha->shadow_regs->rsp_q_in = __constant_cpu_to_le32(0);
-	wmb();
+	if (is_qla8022(ha)) {
+		writel(0,
+		    (unsigned long  __iomem *)&ha->qla4_8xxx_reg->req_q_out);
+		writel(0,
+		    (unsigned long  __iomem *)&ha->qla4_8xxx_reg->rsp_q_in);
+		writel(0,
+		    (unsigned long  __iomem *)&ha->qla4_8xxx_reg->rsp_q_out);
+	} else {
+		/*
+		 * Initialize DMA Shadow registers.  The firmware is really
+		 * supposed to take care of this, but on some uniprocessor
+		 * systems, the shadow registers aren't cleared-- causing
+		 * the interrupt_handler to think there are responses to be
+		 * processed when there aren't.
+		 */
+		ha->shadow_regs->req_q_out = __constant_cpu_to_le32(0);
+		ha->shadow_regs->rsp_q_in = __constant_cpu_to_le32(0);
+		wmb();
 
-	writel(0, &ha->reg->req_q_in);
-	writel(0, &ha->reg->rsp_q_out);
-	readl(&ha->reg->rsp_q_out);
+		writel(0, &ha->reg->req_q_in);
+		writel(0, &ha->reg->rsp_q_out);
+		readl(&ha->reg->rsp_q_out);
+	}
+
+	qla4xxx_init_response_q_entries(ha);
+
 
 	/* Initialize active array */
 	for (i = 0; i < MAX_SRBS; i++)
@@ -134,33 +167,32 @@ int qla4xxx_init_rings(struct scsi_qla_h
 }
 
 /**
- * qla4xxx_validate_mac_address - validate adapter MAC address(es)
+ * qla4xxx_get_sys_info - validate adapter MAC address(es)
  * @ha: pointer to host adapter structure.
  *
  **/
-static int qla4xxx_validate_mac_address(struct scsi_qla_host *ha)
+void qla4xxx_get_sys_info(struct scsi_qla_host *ha)
 {
 	struct flash_sys_info *sys_info;
 	dma_addr_t sys_info_dma;
-	int status = QLA_ERROR;
 
 	sys_info = dma_alloc_coherent(&ha->pdev->dev, sizeof(*sys_info),
 				      &sys_info_dma, GFP_KERNEL);
 	if (sys_info == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Unable to allocate dma buffer.\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+			      __func__));
 
-		goto exit_validate_mac_no_free;
+		goto exit_get_sys_info_no_free;
 	}
 	memset(sys_info, 0, sizeof(*sys_info));
 
 	/* Get flash sys info */
 	if (qla4xxx_get_flash(ha, sys_info_dma, FLASH_OFFSET_SYS_INFO,
 			      sizeof(*sys_info)) != QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: get_flash FLASH_OFFSET_SYS_INFO "
-			      "failed\n", ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: get_flash FLASH_OFFSET_SYS_INFO "
+			      "failed\n", __func__));
 
-		goto exit_validate_mac;
+		goto exit_get_sys_info;
 	}
 
 	/* Save M.A.C. address & serial_number */
@@ -171,14 +203,17 @@ static int qla4xxx_validate_mac_address(
 	       min(sizeof(ha->serial_number),
 		   sizeof(sys_info->acSerialNumber)));
 
-	status = QLA_SUCCESS;
+exit_get_sys_info:
+	DEBUG2(ql4_info(ha, "%s: mac %02x:%02x:%02x:%02x:%02x:%02x "
+            "serial %s\n", __func__, ha->my_mac[0], ha->my_mac[1],
+            ha->my_mac[2], ha->my_mac[3], ha->my_mac[4], ha->my_mac[5],
+            ha->serial_number));
 
- exit_validate_mac:
 	dma_free_coherent(&ha->pdev->dev, sizeof(*sys_info), sys_info,
 			  sys_info_dma);
 
- exit_validate_mac_no_free:
-	return status;
+exit_get_sys_info_no_free:
+	return;
 }
 
 /**
@@ -188,8 +223,15 @@ static int qla4xxx_validate_mac_address(
  **/
 static int qla4xxx_init_local_data(struct scsi_qla_host *ha)
 {
-	/* Initilize aen queue */
-	ha->aen_q_count = MAX_AEN_ENTRIES;
+	/* Initialize iSNS PDU variables */
+	ha->isns.active_pdus = 0;
+	ha->isns.curr_pdu = MAX_PDU_ENTRIES-1;
+	ha->isns.flags = 0;
+	mutex_init(&ha->isns.prb_lock);
+
+	/* Initialize aen queue */
+	ha->aen_in = MAX_AEN_ENTRIES-1;
+	ha->aen_out = MAX_AEN_ENTRIES-1;
 
 	return qla4xxx_get_firmware_status(ha);
 }
@@ -206,44 +248,49 @@ qla4xxx_wait_for_ip_config(struct scsi_q
 	 * need to wait for another */
 	if (is_ipv4_enabled(ha) && is_ipv6_enabled(ha)) {
 		if (((ha->addl_fw_state & FW_ADDSTATE_DHCPv4_ENABLED) != 0) &&
-			((ha->addl_fw_state & FW_ADDSTATE_DHCPv4_LEASE_ACQUIRED) == 0)) {
+		    ((ha->addl_fw_state &
+				    FW_ADDSTATE_DHCPv4_LEASE_ACQUIRED) == 0)) {
 			ipv4_wait = 1;
 		}
-		if (((ha->ipv6_addl_options & IPV6_ADDOPT_NEIGHBOR_DISCOVERY_ADDR_ENABLE) != 0) &&
+		if (((ha->ipv6_addl_options &
+			    IPV6_ADDOPT_NEIGHBOR_DISCOVERY_ADDR_ENABLE) != 0) &&
 		    ((ha->ipv6_link_local_state == IP_ADDRSTATE_ACQUIRING) ||
 		     (ha->ipv6_addr0_state == IP_ADDRSTATE_ACQUIRING) ||
 		     (ha->ipv6_addr1_state == IP_ADDRSTATE_ACQUIRING))) {
 
 			ipv6_wait = 1;
 
-			if ((ha->ipv6_link_local_state == IP_ADDRSTATE_PREFERRED) ||
+			if ((ha->ipv6_link_local_state ==
+						     IP_ADDRSTATE_PREFERRED) ||
 			    (ha->ipv6_addr0_state == IP_ADDRSTATE_PREFERRED) ||
 			    (ha->ipv6_addr1_state == IP_ADDRSTATE_PREFERRED)) {
-				DEBUG2(printk("scsi%ld: %s: "
-						"Preferred IP configured.  Don't wait! \n",
-						ha->host_no, __func__));
+				DEBUG2(ql4_info(ha, "%s: "
+					      "Preferred IP configured."
+					      " Don't wait!\n", __func__));
 				ipv6_wait = 0;
 			}
 			if (memcmp(&ha->ipv6_default_router_addr, ip_address,
 				IPv6_ADDR_LEN) == 0) {
-				DEBUG2(printk("scsi%ld: %s: "
-					      "No Router configured.  Don't wait! \n",
-					      ha->host_no, __func__));
+				DEBUG2(ql4_info(ha, "%s: "
+					      "No Router configured. "
+					      "Don't wait!\n", __func__));
 				ipv6_wait = 0;
 			}
-			if ((ha->ipv6_default_router_state == IPV6_RTRSTATE_MANUAL) &&
-			    (ha->ipv6_link_local_state == IP_ADDRSTATE_TENTATIVE) &&
+			if ((ha->ipv6_default_router_state ==
+						IPV6_RTRSTATE_MANUAL) &&
+			    (ha->ipv6_link_local_state ==
+						IP_ADDRSTATE_TENTATIVE) &&
 			    (memcmp(&ha->ipv6_link_local_addr,
-				   &ha->ipv6_default_router_addr, 4) == 0)) {
-				DEBUG2(printk("scsi%ld: %s: LinkLocal Router & "
-					"IP configured.  Don't wait! \n",
-					ha->host_no, __func__));
+				    &ha->ipv6_default_router_addr, 4) == 0)) {
+				DEBUG2(ql4_info(ha, "%s: LinkLocal Router & "
+					"IP configured. Don't wait!\n",
+					__func__));
 				ipv6_wait = 0;
 			}
 		}
 		if (ipv4_wait || ipv6_wait) {
-			DEBUG2(printk("scsi%ld: %s: Wait for additional IP(s) \"",
-					ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: Wait for additional "
+				      "IP(s) \"", __func__));
 			if (ipv4_wait)
 				DEBUG2(printk("IPv4 "));
 			if (ha->ipv6_link_local_state == IP_ADDRSTATE_ACQUIRING)
@@ -256,7 +303,110 @@ qla4xxx_wait_for_ip_config(struct scsi_q
 		}
 	}
 
-	return (ipv4_wait|ipv6_wait);
+	return ipv4_wait|ipv6_wait;
+}
+
+/*
+ * qla4xxx_alloc_fw_dump - Retrieve minidump template and allocate memory for
+ * minidump data.
+ * @ha: pointer to host adapter structure.
+ *
+ */
+void
+qla4xxx_alloc_fw_dump(struct scsi_qla_host *ha)
+{
+	int status;
+	uint32_t capture_debug_level;
+	int hdr_entry_bit, k;
+	void *md_tmp;
+	dma_addr_t md_tmp_dma;
+	struct qla4_8xxx_minidump_template_hdr *md_hdr;
+
+	if (ha->fw_dump) {
+		ql4_warn(ha, "Firmware dump previously allocated.\n");
+		return;
+	}
+
+	status = qla4xxx_req_template_size(ha);
+	if (status != QLA_SUCCESS) {
+			ql4_info(ha, "scsi%ld: Failed to get template"
+				"size\n", ha->host_no);
+			return;
+	}
+
+	clear_bit(AF_82XX_FW_DUMPED, &ha->flags);
+
+	/* Allocate memory for saving the template */
+	md_tmp = dma_alloc_coherent(&ha->pdev->dev, ha->fw_dump_tmplt_size,
+							&md_tmp_dma, GFP_KERNEL);
+
+	/* Request template */
+	status =  qla4xxx_get_minidump_template(ha, md_tmp_dma);
+	if (status != QLA_SUCCESS) {
+			ql4_info(ha, "scsi%ld: Failed to get minidump"
+				"template\n", ha->host_no);
+			goto alloc_cleanup;
+	}
+
+
+	md_hdr = (struct qla4_8xxx_minidump_template_hdr *) md_tmp;
+
+	capture_debug_level =  md_hdr->capture_debug_level;
+
+	/* Validate whether required debug level is set */
+	if (ql4xmdcapmask && (ql4xmdcapmask & 0x3) != 0x3) {
+		ql4_info(ha, "[%s]: Capture mask 0x%x below "
+				"minimum needed set\n", __func__,
+					ha->fw_dump_capture_mask);
+		goto alloc_cleanup;
+	}
+
+	/* Get capture mask based on module loadtime setting. */
+	if (ql4xmdcapmask >= 0x3 && ql4xmdcapmask <=0x7F) {
+			ha->fw_dump_capture_mask = ql4xmdcapmask; 
+	} else {
+			ha->fw_dump_capture_mask = capture_debug_level;
+	}	
+
+	md_hdr->driver_capture_mask = ha->fw_dump_capture_mask;
+	
+	DEBUG2(ql4_info(ha, "Minimum num of entries = %d\n",
+				md_hdr->num_of_entries));
+	DEBUG2(ql4_info(ha, "Dump template size  = %d\n",
+				ha->fw_dump_tmplt_size));
+	DEBUG2(ql4_info(ha, "Selected Capture mask =0x%x\n",
+				ha->fw_dump_capture_mask));
+
+
+	/* Allocate memory for minidump data */
+	for (hdr_entry_bit = 0x2, k = 1; (hdr_entry_bit & 0xFF);
+					hdr_entry_bit <<= 1, k++) {
+		if (hdr_entry_bit & ha->fw_dump_capture_mask) {
+			ha->fw_dump_size += md_hdr->capture_size_array[k];
+		}
+	}
+
+	/* Total firmware dump size including command header */
+	ha->fw_dump_size += ha->fw_dump_tmplt_size;
+
+	/* Allocate memory for one contiguous dump */
+	ha->fw_dump = vmalloc(ha->fw_dump_size);
+	if(!ha->fw_dump)
+		goto alloc_cleanup;
+
+	DEBUG2(ql4_info(ha, "Minidump Tempalate Size "
+			"= 0x%x KB\n", ha->fw_dump_tmplt_size));
+	DEBUG2(ql4_info(ha, "Total Minidump size"
+			"= 0x%x KB\n", ha->fw_dump_size));
+
+	/* Copy the template into the dump buffer. */
+	memcpy(ha->fw_dump, md_tmp, ha->fw_dump_tmplt_size);
+	ha->fw_dump_tmplt_hdr = ha->fw_dump;
+
+alloc_cleanup:
+	/* Free up memory allocated for Template. */
+	dma_free_coherent(&ha->pdev->dev, ha->fw_dump_tmplt_size,
+				md_tmp, md_tmp_dma);
 }
 
 static int qla4xxx_fw_ready(struct scsi_qla_host *ha)
@@ -264,7 +414,7 @@ static int qla4xxx_fw_ready(struct scsi_
 	uint32_t timeout_count;
 	int ready = 0;
 
-	DEBUG2(dev_info(&ha->pdev->dev, "Waiting for Firmware Ready..\n"));
+	DEBUG2(ql4_info(ha, "Waiting for Firmware Ready..\n"));
 	for (timeout_count = ADAPTER_INIT_TOV; timeout_count > 0;
 	     timeout_count--) {
 		if (test_and_clear_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags))
@@ -272,15 +422,14 @@ static int qla4xxx_fw_ready(struct scsi_
 
 		/* Get firmware state. */
 		if (qla4xxx_get_firmware_state(ha) != QLA_SUCCESS) {
-			DEBUG2(printk("scsi%ld: %s: unable to get firmware "
-				      "state\n", ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: unable to get firmware "
+				      "state\n", __func__));
 			break;
-
 		}
 
 		if (ha->firmware_state & FW_STATE_ERROR) {
-			DEBUG2(printk("scsi%ld: %s: an unrecoverable error has"
-				      " occurred\n", ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: an unrecoverable error has"
+				      " occurred\n", __func__));
 			break;
 
 		}
@@ -297,31 +446,31 @@ static int qla4xxx_fw_ready(struct scsi_
 		}
 
 		if (ha->firmware_state & FW_STATE_WAIT_AUTOCONNECT) {
-			DEBUG2(printk("scsi%ld: %s: fwstate:"
-				      "AUTOCONNECT in progress\n",
-				      ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: fwstate:"
+				      "AUTOCONNECT in progress\n", __func__));
 		}
 
 		if (ha->firmware_state & FW_STATE_CONFIGURING_IP) {
-			DEBUG2(printk("scsi%ld: %s: fwstate: CONFIGURING IP\n",
-				       ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: fwstate: CONFIGURING IP\n",
+				      __func__));
 			/*
-			 * Check for link state after 15 secs and if link is still DOWN then,
-			 * cable is unplugged. Ignore "DHCP in Progress/CONFIGURING IP" bit
-			 * to check if firmware is in ready state or not after 15 secs.
+			 * Check for link state after 15 secs and if link is
+			 * still DOWN then, cable is unplugged. Ignore "DHCP
+			 * in Progress/CONFIGURING IP" bit to check if firmware
+			 * is in ready state or not after 15 secs.
 			 * This is applicable for both 2.x & 3.x firmware
 			 */
 			if (timeout_count <= (ADAPTER_INIT_TOV - 15)) {
 				if (ha->addl_fw_state & FW_ADDSTATE_LINK_UP) {
-					DEBUG2(printk("scsi%ld: %s: LINK UP "
-						      "(Cable plugged)\n",
-						      ha->host_no, __func__));
-				}
-				else if (ha->firmware_state &
-					(FW_STATE_CONFIGURING_IP | FW_STATE_READY)) {
-					DEBUG2(printk("scsi%ld: %s: LINK DOWN "
-						      "(Cable unplugged)\n",
-						      ha->host_no, __func__));
+					DEBUG2(ql4_info(ha, "%s:"
+						  " LINK UP (Cable plugged)\n",
+						  __func__));
+				} else if (ha->firmware_state &
+					  (FW_STATE_CONFIGURING_IP |
+							     FW_STATE_READY)) {
+					DEBUG2(ql4_info(ha, "%s: "
+						"LINK DOWN (Cable unplugged)\n",
+						__func__));
 					ha->firmware_state = FW_STATE_READY;
 				}
 			}
@@ -329,45 +478,57 @@ static int qla4xxx_fw_ready(struct scsi_
 
 		if (ha->firmware_state == FW_STATE_READY) {
 			/* If DHCP IP Addr is available, retrieve it now. */
-			if (test_and_clear_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags))
+			if (test_and_clear_bit(DPC_GET_DHCP_IP_ADDR,
+								&ha->dpc_flags))
 				qla4xxx_get_dhcp_ip_address(ha);
 
-			if (!qla4xxx_wait_for_ip_config(ha) || timeout_count == 1) {
-				DEBUG2(dev_info(&ha->pdev->dev, "Firmware Ready..\n"));
-				/* The firmware is ready to process SCSI commands. */
-				DEBUG2(dev_info(&ha->pdev->dev,
-						  "scsi%ld: %s: MEDIA TYPE - %s\n",
-						  ha->host_no,
-						  __func__, (ha->addl_fw_state &
-							     FW_ADDSTATE_OPTICAL_MEDIA)
-						  != 0 ? "OPTICAL" : "COPPER"));
-				DEBUG2(dev_info(&ha->pdev->dev,
-						  "scsi%ld: %s: DHCPv4 STATE Enabled "
-						  "%s\n",
-						  ha->host_no, __func__,
-						  (ha->addl_fw_state &
-						   FW_ADDSTATE_DHCPv4_ENABLED) != 0 ?
-						  "YES" : "NO"));
-				DEBUG2(dev_info(&ha->pdev->dev,
-						  "scsi%ld: %s: LINK %s\n",
-						  ha->host_no, __func__,
-						  (ha->addl_fw_state &
-						   FW_ADDSTATE_LINK_UP) != 0 ?
-						  "UP" : "DOWN"));
-				DEBUG2(dev_info(&ha->pdev->dev,
-						  "scsi%ld: %s: iSNS Service "
-						  "Started %s\n",
-						  ha->host_no, __func__,
-						  (ha->addl_fw_state &
-						   FW_ADDSTATE_ISNS_SVC_ENABLED) != 0 ?
-						  "YES" : "NO"));
+			if (!qla4xxx_wait_for_ip_config(ha) ||
+							timeout_count == 1) {
+				DEBUG2(ql4_info(ha, "Firmware Ready..\n"));
+				/* The firmware is ready to process SCSI
+				   commands. */
+				DEBUG2(ql4_info(ha,
+					"%s: MEDIA TYPE - %s\n", __func__,
+					(ha->addl_fw_state &
+					FW_ADDSTATE_OPTICAL_MEDIA)
+					!= 0 ? "OPTICAL" : "COPPER"));
+				DEBUG2(ql4_info(ha,
+					"%s: DHCPv4 STATE"
+					" Enabled %s\n", __func__,
+					(ha->addl_fw_state &
+					 FW_ADDSTATE_DHCPv4_ENABLED) != 0 ?
+					"YES" : "NO"));
+				DEBUG2(ql4_info(ha,
+					"%s: LINK %s\n", __func__,
+					(ha->addl_fw_state &
+					 FW_ADDSTATE_LINK_UP) != 0 ?
+					"UP" : "DOWN"));
+				DEBUG2(ql4_info(ha,
+					"%s: iSNS Service Enabled %s\n",
+					__func__,
+					(ha->addl_fw_state &
+					 FW_ADDSTATE_ISNS_SVC_ENABLED) != 0 ?
+					"YES" : "NO"));
+
+				if (test_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+						&ha->isns.flags)) {
+					if (test_bit(AF_LINK_UP, &ha->flags)) {
+						set_bit(DPC_ISNS_START,
+							&ha->dpc_flags);
+						qla4xxx_wake_dpc(ha);
+					} else {
+						DEBUG2(ql4_info(ha,
+						"Error: iSNS Service Not "
+						"Started. LINK DOWN\n"));
+					}
+				}
 
 				ready = 1;
 				break;
 			}
 		}
-		DEBUG2(printk("scsi%ld: %s: waiting on fw, state=%x:%x - "
-			      "seconds expired= %d\n", ha->host_no, __func__,
+		DEBUG2(ql4_info(ha, "%s: waiting on fw, state=%x:%x - "
+			      "seconds expired= %d\n", __func__,
 			      ha->firmware_state, ha->addl_fw_state,
 			      timeout_count));
 		if (is_qla4032(ha) &&
@@ -380,18 +541,17 @@ static int qla4xxx_fw_ready(struct scsi_
 	}			/* end of for */
 
 	if (timeout_count <= 0)
-		DEBUG2(printk("scsi%ld: %s: FW Initialization timed out!\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: FW Initialization timed out!\n",
+			      __func__));
 
 	if (ha->firmware_state & FW_STATE_CONFIGURING_IP) {
-		DEBUG2(printk("scsi%ld: %s: FW initialized, but is reporting "
+		DEBUG2(ql4_info(ha, "%s: FW initialized, but is reporting "
 			      "it's waiting to configure an IP address\n",
-			       ha->host_no, __func__));
+			       __func__));
 		ready = 1;
 	} else if (ha->firmware_state & FW_STATE_WAIT_AUTOCONNECT) {
-		DEBUG2(printk("scsi%ld: %s: FW initialized, but "
-			      "auto-discovery still in process\n",
-			       ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: FW initialized, but "
+			      "auto-discovery still in process\n", __func__));
 		ready = 1;
 	}
 
@@ -407,14 +567,27 @@ static int qla4xxx_init_firmware(struct 
 {
 	int status = QLA_ERROR;
 
-	dev_info(&ha->pdev->dev, "Initializing firmware..\n");
+	if (is_aer_supported(ha) &&
+	    test_bit(AF_PCI_CHANNEL_IO_PERM_FAILURE, &ha->flags))
+		return status;
+
+	/* For 82xx, stop firmware before initializing because if BIOS
+	 * has previously initialized firmware, then driver's initialize
+	 * firmware will fail. */
+	if (is_qla8022(ha))
+		qla4_8xxx_stop_firmware(ha);
+
+	ql4_info(ha, "Initializing firmware..\n");
 	if (qla4xxx_initialize_fw_cb(ha) == QLA_ERROR) {
-		DEBUG2(printk("scsi%ld: %s: Failed to initialize firmware "
-			      "control block\n", ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Failed to initialize firmware "
+			      "control block\n", __func__));
 		return status;
 	}
 	if (!qla4xxx_fw_ready(ha))
 		return status;
+	
+	if (is_qla8022(ha) && !test_bit(AF_INIT_DONE, &ha->flags))
+		qla4xxx_alloc_fw_dump(ha);
 
 	return qla4xxx_get_firmware_status(ha);
 }
@@ -435,45 +608,43 @@ static struct ddb_entry* qla4xxx_get_ddb
 					  sizeof(*fw_ddb_entry),
 					  &fw_ddb_entry_dma, GFP_KERNEL);
 	if (fw_ddb_entry == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Unable to allocate dma buffer.\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+			      __func__));
 		goto exit_get_ddb_entry_no_free;
 	}
 
 	if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
 				    fw_ddb_entry_dma, NULL, NULL,
 				    &device_state, NULL, NULL, NULL) ==
-	    QLA_ERROR) {
-		DEBUG2(printk("scsi%ld: %s: failed get_ddb_entry for "
-			      "fw_ddb_index %d\n", ha->host_no, __func__,
-			      fw_ddb_index));
+				    QLA_ERROR) {
+		DEBUG2(ql4_info(ha, "%s: failed get_ddb_entry for "
+			      "fw_ddb_index %d\n", __func__, fw_ddb_index));
 		goto exit_get_ddb_entry;
 	}
 
 	/* Allocate DDB if not already allocated. */
-	DEBUG2(printk("scsi%ld: %s: Looking for ddb[%d]\n", ha->host_no,
-		      __func__, fw_ddb_index));
+	DEBUG2(ql4_info(ha, "%s: Looking for ddb[%d]\n", __func__,
+			fw_ddb_index));
 	list_for_each_entry(ddb_entry, &ha->ddb_list, list) {
 		if ((memcmp(ddb_entry->iscsi_name, fw_ddb_entry->iscsi_name,
-			    ISCSI_NAME_SIZE) == 0) &&
-		    (ddb_entry->tpgt ==
-			    le32_to_cpu(fw_ddb_entry->tgt_portal_grp)) &&
-		    (memcmp(ddb_entry->isid, fw_ddb_entry->isid,
-			    sizeof(ddb_entry->isid)) == 0)) {
+			   ISCSI_NAME_SIZE) == 0) &&
+			(ddb_entry->tpgt ==
+				le32_to_cpu(fw_ddb_entry->tgt_portal_grp)) &&
+			(memcmp(ddb_entry->isid, fw_ddb_entry->isid,
+				sizeof(ddb_entry->isid)) == 0)) {
 			found++;
 			break;
 		}
 	}
 
+	/* if not found allocate new ddb */
 	if (!found) {
-		DEBUG2(printk("scsi%ld: %s: ddb[%d] not found - allocating "
-			      "new ddb\n", ha->host_no, __func__,
-			      fw_ddb_index));
+		DEBUG2(ql4_info(ha, "%s: ddb[%d] not found - allocating "
+			      "new ddb\n", __func__, fw_ddb_index));
 		*new_tgt = 1;
 		ddb_entry = qla4xxx_alloc_ddb(ha, fw_ddb_index);
 	}
 
-	/* if not found allocate new ddb */
 exit_get_ddb_entry:
 	dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry), fw_ddb_entry,
 			  fw_ddb_entry_dma);
@@ -482,6 +653,101 @@ exit_get_ddb_entry_no_free:
 	return ddb_entry;
 }
 
+static void qla4xxx_fill_ddb(struct ddb_entry *ddb_entry,
+                struct dev_db_entry *fw_ddb_entry)
+{
+	ddb_entry->options = le16_to_cpu(fw_ddb_entry->options);
+	ddb_entry->target_session_id = le16_to_cpu(fw_ddb_entry->tsid);
+	ddb_entry->task_mgmt_timeout =
+		le16_to_cpu(fw_ddb_entry->def_timeout);
+	ddb_entry->CmdSn = 0;
+	ddb_entry->exe_throttle = le16_to_cpu(fw_ddb_entry->exec_throttle);
+	ddb_entry->default_relogin_timeout =
+		le16_to_cpu(fw_ddb_entry->def_timeout);
+	ddb_entry->default_time2wait = le16_to_cpu(fw_ddb_entry->iscsi_def_time2wait);
+
+	ddb_entry->port = le16_to_cpu(fw_ddb_entry->port);
+	ddb_entry->tpgt = le32_to_cpu(fw_ddb_entry->tgt_portal_grp);
+	ddb_entry->ka_timeout = le16_to_cpu(fw_ddb_entry->ka_timeout);
+	if (ddb_entry->sess)
+		ddb_entry->sess->recovery_tmo =  (ql4xkeepalive != 0xDEAD)
+			? ql4xkeepalive : ddb_entry->ka_timeout;
+
+	memcpy(ddb_entry->isid, fw_ddb_entry->isid, sizeof(ddb_entry->isid));
+
+	memcpy(&ddb_entry->iscsi_name[0], &fw_ddb_entry->iscsi_name[0],
+	       min(sizeof(ddb_entry->iscsi_name),
+		   sizeof(fw_ddb_entry->iscsi_name)));
+	memcpy(&ddb_entry->ip_addr[0], &fw_ddb_entry->ip_addr[0],
+	       min(sizeof(ddb_entry->ip_addr), sizeof(fw_ddb_entry->ip_addr)));
+
+	if (ddb_entry->options & DDB_OPT_IPV6_DEVICE) {
+		memcpy(&ddb_entry->ipv6_addr,
+			fw_ddb_entry->ip_addr,
+			min(sizeof(ddb_entry->ipv6_addr),
+			sizeof(fw_ddb_entry->ip_addr)));
+		memcpy(&ddb_entry->link_local_ipv6_addr,
+			fw_ddb_entry->link_local_ipv6_addr,
+			min(sizeof(ddb_entry->link_local_ipv6_addr),
+			sizeof(fw_ddb_entry->link_local_ipv6_addr)));
+	}
+}
+
+static void qla4xxx_fill_dev_db_entry(struct dev_db_entry *fw_ddb_entry,
+                struct ddb_entry *ddb_entry)
+{
+	fw_ddb_entry->options = le16_to_cpu(ddb_entry->options);
+	fw_ddb_entry->tsid = le16_to_cpu(ddb_entry->target_session_id);
+	fw_ddb_entry->def_timeout =
+		le16_to_cpu(ddb_entry->task_mgmt_timeout);
+	fw_ddb_entry->exec_throttle = le16_to_cpu(ddb_entry->exe_throttle);
+	fw_ddb_entry->def_timeout =
+		le16_to_cpu(ddb_entry->default_relogin_timeout );
+
+	fw_ddb_entry->port = le16_to_cpu(ddb_entry->port);
+	fw_ddb_entry->tgt_portal_grp = le32_to_cpu(ddb_entry->tpgt);
+	fw_ddb_entry->ka_timeout = le16_to_cpu(ddb_entry->ka_timeout);
+
+	memcpy(fw_ddb_entry->isid, ddb_entry->isid, sizeof(fw_ddb_entry->isid));
+
+	memcpy(&fw_ddb_entry->iscsi_name[0], &ddb_entry->iscsi_name[0],
+		min(sizeof(ddb_entry->iscsi_name),
+		sizeof(ddb_entry->iscsi_name)));
+	memcpy(&fw_ddb_entry->ip_addr[0], &ddb_entry->ip_addr[0],
+		min(sizeof(fw_ddb_entry->ip_addr), sizeof(ddb_entry->ip_addr)));
+
+	if (fw_ddb_entry->options & DDB_OPT_IPV6_DEVICE) {
+		memcpy(&fw_ddb_entry->ip_addr[0],
+			&ddb_entry->ipv6_addr,
+			min(sizeof(fw_ddb_entry->ip_addr),
+			sizeof(ddb_entry->ipv6_addr)));
+		memcpy(&fw_ddb_entry->link_local_ipv6_addr[0],
+			&ddb_entry->link_local_ipv6_addr,
+			min(sizeof(fw_ddb_entry->link_local_ipv6_addr),
+			sizeof(ddb_entry->link_local_ipv6_addr)));
+	}
+
+	if (fw_ddb_entry->options & DDB_OPT_IPV6_DEVICE) {
+		DEBUG2(ql4_info(ddb_entry->ha, "%s: DDB[%d] State %04x %pI6 "
+			":%04d isid "ISID_FMT" tpgt %d \"%s\"\n",
+			__func__, ddb_entry->fw_ddb_index,
+			atomic_read(&ddb_entry->state),
+			fw_ddb_entry->ip_addr,
+			le16_to_cpu(fw_ddb_entry->port),
+			ISID(fw_ddb_entry->isid),
+			le32_to_cpu(fw_ddb_entry->tgt_portal_grp),
+			fw_ddb_entry->iscsi_name));
+	} else {
+		DEBUG2(ql4_info(ddb_entry->ha, "%s: DDB[%d] State %04x %pI4 "
+			":%04d \"%s\"\n", __func__,
+			ddb_entry->fw_ddb_index,
+			atomic_read(&ddb_entry->state),
+			fw_ddb_entry->ip_addr,
+			le16_to_cpu(fw_ddb_entry->port),
+			fw_ddb_entry->iscsi_name));
+	}
+}
+
 /**
  * qla4xxx_update_ddb_entry - update driver's internal ddb
  * @ha: pointer to host adapter structure.
@@ -504,8 +770,7 @@ static int qla4xxx_update_ddb_entry(stru
 	uint32_t conn_err;
 
 	if (ddb_entry == NULL) {
-		DEBUG2(printk("scsi%ld: %s: ddb_entry is NULL\n", ha->host_no,
-			      __func__));
+		DEBUG2(ql4_info(ha, "%s: ddb_entry is NULL\n", __func__));
 		goto exit_update_ddb_no_free;
 	}
 
@@ -514,73 +779,24 @@ static int qla4xxx_update_ddb_entry(stru
 					  sizeof(*fw_ddb_entry),
 					  &fw_ddb_entry_dma, GFP_KERNEL);
 	if (fw_ddb_entry == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Unable to allocate dma buffer.\n",
-			      ha->host_no, __func__));
-
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+			      __func__));
 		goto exit_update_ddb_no_free;
 	}
 
-	if ((qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
+	if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
 				    fw_ddb_entry_dma, NULL, NULL,
 				    &ddb_entry->fw_ddb_device_state, &conn_err,
 				    &ddb_entry->tcp_source_port_num,
-				    &ddb_entry->connection_id) == QLA_SUCCESS))
-		status = QLA_SUCCESS;
-	else {
-		DEBUG2(printk("scsi%ld: %s: failed get_ddb_entry for "
-			      "fw_ddb_index %d\n", ha->host_no, __func__,
-			      fw_ddb_index));
-
+				    &ddb_entry->connection_id) ==
+				    QLA_ERROR) {
+		DEBUG2(ql4_info(ha, "%s: failed get_ddb_entry for "
+			      "fw_ddb_index %d\n", __func__, fw_ddb_index));
 		goto exit_update_ddb;
 	}
 
-	ddb_entry->options = le16_to_cpu(fw_ddb_entry->options);
-	ddb_entry->target_session_id = le16_to_cpu(fw_ddb_entry->tsid);
-	ddb_entry->task_mgmt_timeout =
-		le16_to_cpu(fw_ddb_entry->def_timeout);
-	ddb_entry->CmdSn = 0;
-	ddb_entry->exe_throttle = le16_to_cpu(fw_ddb_entry->exec_throttle);
-	ddb_entry->default_relogin_timeout =
-		le16_to_cpu(fw_ddb_entry->def_timeout);
-	ddb_entry->default_time2wait = le16_to_cpu(fw_ddb_entry->iscsi_def_time2wait);
-	ddb_entry->ka_timeout = le16_to_cpu(fw_ddb_entry->ka_timeout);
-	if (ddb_entry->sess)
-		ddb_entry->sess->recovery_tmo = ddb_entry->ka_timeout;
-
-	/* Update index in case it changed */
-	ddb_entry->fw_ddb_index = fw_ddb_index;
-	ha->fw_ddb_index_map[fw_ddb_index] = ddb_entry;
-
-	ddb_entry->port = le16_to_cpu(fw_ddb_entry->port);
-	ddb_entry->tpgt = le32_to_cpu(fw_ddb_entry->tgt_portal_grp);
-	memcpy(ddb_entry->isid, fw_ddb_entry->isid, sizeof(ddb_entry->isid));
-
-	memcpy(&ddb_entry->iscsi_name[0], &fw_ddb_entry->iscsi_name[0],
-	       min(sizeof(ddb_entry->iscsi_name),
-		   sizeof(fw_ddb_entry->iscsi_name)));
-	memcpy(&ddb_entry->ip_addr[0], &fw_ddb_entry->ip_addr[0],
-	       min(sizeof(ddb_entry->ip_addr), sizeof(fw_ddb_entry->ip_addr)));
-
-	if (ddb_entry->options & DDB_OPT_IPV6_DEVICE) {
-		memcpy(&ddb_entry->remote_ipv6_addr,
-			fw_ddb_entry->ip_addr,
-			min(sizeof(ddb_entry->remote_ipv6_addr),
-			sizeof(fw_ddb_entry->ip_addr)));
-		memcpy(&ddb_entry->link_local_ipv6_addr,
-			fw_ddb_entry->link_local_ipv6_addr,
-			min(sizeof(ddb_entry->link_local_ipv6_addr),
-			sizeof(fw_ddb_entry->link_local_ipv6_addr)));
-	}
-
-	DEBUG2(dev_info(&ha->pdev->dev, "%s: DDB[%d] osIdx = %d "
-					"State %04x ConnErr %08x "
-					NIPQUAD_FMT ":%04d \"%s\"\n",
-					__func__, fw_ddb_index,
-					ddb_entry->os_target_id,
-					ddb_entry->fw_ddb_device_state, conn_err,
-					NIPQUAD(fw_ddb_entry->ip_addr),
-					le16_to_cpu(fw_ddb_entry->port),
-					fw_ddb_entry->iscsi_name));
+	status = QLA_SUCCESS;
+	qla4xxx_fill_ddb(ddb_entry, fw_ddb_entry);
 
 exit_update_ddb:
 	if (fw_ddb_entry)
@@ -604,23 +820,26 @@ static struct ddb_entry * qla4xxx_alloc_
 {
 	struct ddb_entry *ddb_entry;
 
-	DEBUG2(printk("scsi%ld: %s: fw_ddb_index [%d]\n", ha->host_no,
-		      __func__, fw_ddb_index));
+	DEBUG2(ql4_info(ha, "%s: fw_ddb_index [%d]\n", __func__, fw_ddb_index));
 
 	ddb_entry = qla4xxx_alloc_sess(ha);
 	if (ddb_entry == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Unable to allocate memory "
-			      "to add fw_ddb_index [%d]\n",
-			      ha->host_no, __func__, fw_ddb_index));
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate memory "
+			      "to add fw_ddb_index [%d]\n", __func__,
+				fw_ddb_index));
 		return ddb_entry;
 	}
 
 	ddb_entry->fw_ddb_index = fw_ddb_index;
-	atomic_set(&ddb_entry->port_down_timer, ha->port_down_retry_count);
 	atomic_set(&ddb_entry->retry_relogin_timer, INVALID_ENTRY);
 	atomic_set(&ddb_entry->relogin_timer, 0);
 	atomic_set(&ddb_entry->relogin_retry_count, 0);
 	atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
+
+        ql4_info(ha, "%s: ddb[%d] os[%d] marked ONLINE\n",
+                __func__, ddb_entry->fw_ddb_index,
+                ddb_entry->os_target_id);
+
 	list_add_tail(&ddb_entry->list, &ha->ddb_list);
 	ha->fw_ddb_index_map[fw_ddb_index] = ddb_entry;
 	ha->tot_ddbs++;
@@ -644,252 +863,166 @@ int qla4_is_relogin_allowed(struct scsi_
 	err_code = ((conn_err & 0x00ff0000) >> 16);
 	login_rsp_sts_class = ((conn_err & 0x0000ff00) >> 8);
 	if (err_code == 0x1c || err_code == 0x06) {
-		DEBUG2(dev_info(&ha->pdev->dev,
-			": conn_err=0x%08x, send target completed or access"
-			" denied failure\n", conn_err));
+		DEBUG2(ql4_info(ha,
+		    ": conn_err=0x%08x, send target completed"
+		    " or access denied failure\n", conn_err));
 		relogin = 0;
 	}
 	if ((err_code == 0x08) && (login_rsp_sts_class == 0x02)) {
 		/* Login Response PDU returned an error.
 		   Login Response Status in Error Code Detail
 		   indicates login should not be retried.*/
-		DEBUG2(dev_info(&ha->pdev->dev,
-			": conn_err=0x%08x, do not retry relogin\n", conn_err));
+		DEBUG2(ql4_info(ha,
+		    ": conn_err=0x%08x, do not retry relogin\n",
+		    conn_err));
 		relogin = 0;
 	}
 
 	return relogin;
 }
 
-/**
- * qla4xxx_configure_ddbs - builds driver ddb list
- * @ha: Pointer to host adapter structure.
+ /**
+ * qla4xxx_find_and_delete_duplicate_ddb -
+ *      Search driver's internal ddb list for a duplicate of the ddb specified
+ *      in fw_ddb_index, then delete it form both the driver and firmware's
+ *      database.
  *
- * This routine searches for all valid firmware ddb entries and builds
- * an internal ddb list. Ddbs that are considered valid are those with
- * a device state of SESSION_ACTIVE.
+ * @ha: Pointer to host adapter structure
+ * @fw_ddb_index: Firmware's device database index of the DDB that the caller
+ *	will add after completion of this function.
+ *
+ * Users are allowed to define duplicate DDBs that reference the same target.
+ * This function removes the duplicate DDB so that targets will be accessibly
+ * via only one DDB.
  **/
-static int qla4xxx_build_ddb_list(struct scsi_qla_host *ha)
+int
+qla4xxx_find_and_delete_duplicate_ddb(struct scsi_qla_host *ha,
+				      uint32_t fw_ddb_index)
 {
-	int status = QLA_ERROR;
-	uint32_t fw_ddb_index = 0;
-	uint32_t next_fw_ddb_index = 0;
-	uint32_t ddb_state;
-	uint32_t conn_err;
-	struct ddb_entry *ddb_entry;
+	struct ddb_entry *ddb_entry = NULL;
 	struct dev_db_entry *fw_ddb_entry = NULL;
-	dma_addr_t fw_ddb_entry_dma;
-	uint32_t new_tgt;
-	uint32_t ipv6_device;
+	dma_addr_t      fw_ddb_entry_dma;
+	uint8_t		found = 0;
+	int ret	= QLA_SUCCESS;
 
+	/* Make sure the dma buffer is valid */
 	fw_ddb_entry = dma_alloc_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry),
-						&fw_ddb_entry_dma, GFP_KERNEL);
+					    &fw_ddb_entry_dma, GFP_KERNEL);
+
 	if (fw_ddb_entry == NULL) {
-		DEBUG2(dev_info(&ha->pdev->dev, "%s: DMA alloc failed\n", __func__));
-		goto exit_build_ddb_list_no_free;
+		DEBUG2(ql4_info(ha, "%s: dma alloc failed\n", __func__));
+		goto exit_find_duplicate_ddb;
 	}
 
-	dev_info(&ha->pdev->dev, "Initializing DDBs ...\n");
-	for (fw_ddb_index = 0; fw_ddb_index < MAX_DDB_ENTRIES;
-	     fw_ddb_index = next_fw_ddb_index) {
-		/* First, let's see if a device exists here */
-		if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry, 0, NULL,
-					    &next_fw_ddb_index, &ddb_state,
-					    &conn_err, NULL, NULL) ==
-		    QLA_ERROR) {
-			DEBUG2(printk("scsi%ld: %s: get_ddb_entry, "
-				      "fw_ddb_index %d failed", ha->host_no,
-				      __func__, fw_ddb_index));
-			goto exit_build_ddb_list;
+	/* Retrieve database entry of ddb in firmware */
+        if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
+		fw_ddb_entry_dma, NULL, NULL, NULL,
+		NULL, NULL, NULL) == QLA_ERROR) {
+
+		DEBUG2(ql4_info(ha, "%s: get_ddb %d failed\n",
+			__func__, fw_ddb_index));
+		goto exit_find_duplicate_ddb;
+	}
+
+	DEBUG7(ql4_info(ha, "%s: Searching for ddb[%d] isid="ISID_FMT" tpgt=%d"
+		" \"%s\"\n", __func__, fw_ddb_index, ISID(fw_ddb_entry->isid),
+		le32_to_cpu(fw_ddb_entry->tgt_portal_grp),
+		fw_ddb_entry->iscsi_name));
+
+	/* Now search the driver's internal ddb list for identical ddb that
+	   is assigned to a different fw_db_index */
+	list_for_each_entry(ddb_entry, &ha->ddb_list, list) {
+		DEBUG7(ql4_info(ha, "%s: Internal ddb[%d] (%p) "
+			"isid="ISID_FMT" tpgt=%d \"%s\"\n", __func__,
+			ddb_entry->fw_ddb_index, ddb_entry,
+			ISID(ddb_entry->isid), ddb_entry->tpgt,
+			ddb_entry->iscsi_name));
+
+		if ((strcmp(ddb_entry->iscsi_name,
+			    fw_ddb_entry->iscsi_name) == 0) &&
+		    ddb_entry->tpgt == le32_to_cpu(
+			    fw_ddb_entry->tgt_portal_grp) &&
+                    (memcmp(ddb_entry->isid, fw_ddb_entry->isid,
+			    sizeof(ddb_entry->isid)) == 0) &&
+		    ddb_entry->fw_ddb_index != fw_ddb_index) {
+
+			DEBUG2(ql4_info(ha, "%s: Found fw_ddb[%d] isid="
+				ISID_FMT" tpgt=%d \"%s\" at ddb[%d]\n",
+				__func__, fw_ddb_index, ISID(ddb_entry->isid),
+				ddb_entry->tpgt, ddb_entry->iscsi_name,
+				ddb_entry->fw_ddb_index));
+
+			found = 1;
+			break;
+		}
+	}
+
+	if (found) {
+		uint32_t ddb_state;
+		uint32_t fw_ddb_state;
+		uint32_t ddb_index = ddb_entry->fw_ddb_index;
+
+		/* Delete duplicate (previously existing) DDB from both
+		 * firmware and driver's database */
+		DEBUG2(ql4_info(ha, "%s: Delete duplicate ddb[%d]\n",
+			__func__, ddb_index));
+		if (qla4xxx_get_fwddb_entry(ha, ddb_index,
+			NULL, 0, NULL, NULL, &ddb_state,
+			NULL, NULL, NULL) == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s: get_ddb %d failed\n",
+				__func__, ddb_index));
+			goto exit_find_duplicate_ddb;
 		}
 
-		DEBUG2(printk("scsi%ld: %s: Getting DDB[%d] ddbstate=0x%x, "
-			      "next_fw_ddb_index=%d.\n", ha->host_no, __func__,
-			      fw_ddb_index, ddb_state, next_fw_ddb_index));
+		if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index,
+			NULL, 0, NULL, NULL, &fw_ddb_state,
+			NULL, NULL, NULL) == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s: fw_get_ddb %d failed\n",
+				__func__, ddb_index));
+			goto exit_find_duplicate_ddb;
+		}
 
-		/* Issue relogin, if necessary. */
+		/* To delete a DDB from firmware, we must use the
+		 * close_conn_sess_logout mailbox command w/ free_ddb
+		 * option only if there is an active connection.
+		 * Otherwise, we must use the free_database_entry
+		 * mailbox command. But before deleting active driver ddb
+		 * check if firmware duplicate ddb session is failed.
+		 * If yes, then delete firmware ddb entry, rather than active
+		 * driver ddb entry */
 		if (ddb_state == DDB_DS_SESSION_FAILED ||
 		    ddb_state == DDB_DS_NO_CONNECTION_ACTIVE) {
-			/* Try and login to device */
-			DEBUG2(printk("scsi%ld: %s: Login to DDB[%d]\n",
-				      ha->host_no, __func__, fw_ddb_index));
-			ipv6_device = le16_to_cpu(fw_ddb_entry->options) &
-					DDB_OPT_IPV6_DEVICE;
-			if (qla4_is_relogin_allowed(ha, conn_err) &&
-			    ((!ipv6_device && *((uint32_t *)fw_ddb_entry->ip_addr))
-			    || ipv6_device)) {
-				qla4xxx_set_ddb_entry(ha, fw_ddb_index, 0);
-				if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index,
-					NULL, 0, NULL, &next_fw_ddb_index,
-					&ddb_state, &conn_err, NULL, NULL)
-					== QLA_ERROR) {
-					DEBUG2(printk("scsi%ld: %s:"
-						"get_ddb_entry %d failed\n",
-						ha->host_no,
-						__func__, fw_ddb_index));
-					goto exit_build_ddb_list;
-				}
-			}
+			DEBUG2(ql4_info(ha, "%s: Delete duplicate driver"
+				"ddb[%d]\n", __func__, ddb_index));
+			qla4xxx_free_database_entry(ha, ddb_index);
+			/* Delete DDB from driver's database */
+			qla4xxx_free_ddb(ha, ddb_entry);
+		} else if (fw_ddb_state == DDB_DS_SESSION_FAILED ||
+			fw_ddb_state == DDB_DS_NO_CONNECTION_ACTIVE ||
+			ddb_state == DDB_DS_LOGIN_IN_PROCESS ||
+			ddb_state == DDB_DS_UNASSIGNED) {
+			DEBUG2(ql4_info(ha, "%s: Delete duplicate firmware"
+				"ddb[%d]\n", __func__, ddb_index));
+			qla4xxx_free_database_entry(ha, fw_ddb_index);
+			ret = QLA_ERROR;
+		} else {
+			DEBUG2(ql4_info(ha, "%s: Delete duplicate active driver"
+				"ddb[%d]\n", __func__, ddb_index));
+			qla4xxx_conn_close_sess_logout(ha, ddb_index,
+				LOGOUT_OPTION_FREE_DDB);
+			/* Delete DDB from driver's database */
+			qla4xxx_free_ddb(ha, ddb_entry);
 		}
 
-		if (ddb_state != DDB_DS_SESSION_ACTIVE)
-			goto next_one;
-		/*
-		 * if fw_ddb with session active state found,
-		 * add to ddb_list
-		 */
-		DEBUG2(printk("scsi%ld: %s: DDB[%d] added to list\n",
-			      ha->host_no, __func__, fw_ddb_index));
+		clear_bit(DPC_RELOGIN_DEVICE, &ha->dpc_flags);
+	}
 
-		/* Add DDB to internal our ddb list. */
-		ddb_entry = qla4xxx_get_ddb_entry(ha, fw_ddb_index, &new_tgt);
-		if (ddb_entry == NULL) {
-			DEBUG2(printk("scsi%ld: %s: Unable to allocate memory "
-				      "for device at fw_ddb_index %d\n",
-				      ha->host_no, __func__, fw_ddb_index));
-			goto exit_build_ddb_list;
-		}
-		/* Fill in the device structure */
-		if (qla4xxx_update_ddb_entry(ha, ddb_entry, fw_ddb_index) ==
-		    QLA_ERROR) {
-			ha->fw_ddb_index_map[fw_ddb_index] =
-				(struct ddb_entry *)INVALID_ENTRY;
+exit_find_duplicate_ddb:
+	if (fw_ddb_entry)
+		dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry),
+		fw_ddb_entry, fw_ddb_entry_dma);
+	return ret;
 
-
-			DEBUG2(printk("scsi%ld: %s: update_ddb_entry failed "
-				      "for fw_ddb_index %d.\n",
-				      ha->host_no, __func__, fw_ddb_index));
-			goto exit_build_ddb_list;
-		}
-
-next_one:
-		/* We know we've reached the last device when
-		 * next_fw_ddb_index is 0 */
-		if (next_fw_ddb_index == 0)
-			break;
-	}
-	status = QLA_SUCCESS;
-	dev_info(&ha->pdev->dev, "DDB list done..\n");
-
-exit_build_ddb_list:
-	dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry), fw_ddb_entry,
-			  fw_ddb_entry_dma);
-
-exit_build_ddb_list_no_free:
-	return status;
-}
-
-struct qla4_relog_scan {
-	int halt_wait;
-	uint32_t conn_err;
-	uint32_t fw_ddb_index;
-	uint32_t next_fw_ddb_index;
-	uint32_t fw_ddb_device_state;
-};
-
-static int qla4_test_rdy(struct scsi_qla_host *ha, struct qla4_relog_scan *rs)
-{
-	struct ddb_entry *ddb_entry;
-
-	if (qla4_is_relogin_allowed(ha, rs->conn_err)) {
-		/* We either have a device that is in
-		 * the process of relogging in or a
-		 * device that is waiting to be
-		 * relogged in */
-		rs->halt_wait = 0;
-
-		ddb_entry = qla4xxx_lookup_ddb_by_fw_index(ha,
-							   rs->fw_ddb_index);
-		if (ddb_entry == NULL)
-			return QLA_ERROR;
-
-		if (ddb_entry->dev_scan_wait_to_start_relogin != 0
-		    && time_after_eq(jiffies,
-				     ddb_entry->
-				     dev_scan_wait_to_start_relogin))
-		{
-			ddb_entry->dev_scan_wait_to_start_relogin = 0;
-			qla4xxx_set_ddb_entry(ha, rs->fw_ddb_index, 0);
-		}
-	}
-	return QLA_SUCCESS;
-}
-
-static int qla4_scan_for_relogin(struct scsi_qla_host *ha,
-				 struct qla4_relog_scan *rs)
-{
-	int error;
-
-	/* scan for relogins
-	 * ----------------- */
-	for (rs->fw_ddb_index = 0; rs->fw_ddb_index < MAX_DDB_ENTRIES;
-	     rs->fw_ddb_index = rs->next_fw_ddb_index) {
-		if (qla4xxx_get_fwddb_entry(ha, rs->fw_ddb_index, NULL, 0,
-					    NULL, &rs->next_fw_ddb_index,
-					    &rs->fw_ddb_device_state,
-					    &rs->conn_err, NULL, NULL)
-		    == QLA_ERROR)
-			return QLA_ERROR;
-
-		if (rs->fw_ddb_device_state == DDB_DS_LOGIN_IN_PROCESS)
-			rs->halt_wait = 0;
-
-		if (rs->fw_ddb_device_state == DDB_DS_SESSION_FAILED ||
-		    rs->fw_ddb_device_state == DDB_DS_NO_CONNECTION_ACTIVE) {
-			error = qla4_test_rdy(ha, rs);
-			if (error)
-				return error;
-		}
-
-		/* We know we've reached the last device when
-		 * next_fw_ddb_index is 0 */
-		if (rs->next_fw_ddb_index == 0)
-			break;
-	}
-	return QLA_SUCCESS;
-}
-
-/**
- * qla4xxx_devices_ready - wait for target devices to be logged in
- * @ha: pointer to adapter structure
- *
- * This routine waits up to ql4xdiscoverywait seconds
- * F/W database during driver load time.
- **/
-static int qla4xxx_devices_ready(struct scsi_qla_host *ha)
-{
-	int error;
-	unsigned long discovery_wtime;
-	struct qla4_relog_scan rs;
-
-	discovery_wtime = jiffies + (ql4xdiscoverywait * HZ);
-
-	DEBUG(printk("Waiting (%d) for devices ...\n", ql4xdiscoverywait));
-	do {
-		/* poll for AEN. */
-		qla4xxx_get_firmware_state(ha);
-		if (test_and_clear_bit(DPC_AEN, &ha->dpc_flags)) {
-			/* Set time-between-relogin timer */
-			qla4xxx_process_aen(ha, RELOGIN_DDB_CHANGED_AENS);
-		}
-
-		/* if no relogins active or needed, halt discvery wait */
-		rs.halt_wait = 1;
-
-		error = qla4_scan_for_relogin(ha, &rs);
-
-		if (rs.halt_wait) {
-			DEBUG2(printk("scsi%ld: %s: Delay halted.  Devices "
-				      "Ready.\n", ha->host_no, __func__));
-			return QLA_SUCCESS;
-		}
-
-		msleep(2000);
-	} while (!time_after_eq(jiffies, discovery_wtime));
-
-	DEBUG3(qla4xxx_get_conn_event_log(ha));
-
-	return QLA_SUCCESS;
 }
 
 static void qla4xxx_flush_AENS(struct scsi_qla_host *ha)
@@ -914,7 +1047,146 @@ static void qla4xxx_flush_AENS(struct sc
 
 		msleep(1000);
 	} while (!time_after_eq(jiffies, wtime));
+}
 
+/**
+ * qla4xxx_build_ddb_list - builds driver ddb list
+ * @ha: Pointer to host adapter structure.
+ *
+ * This routine searches for all valid firmware ddb entries and builds
+ * an internal ddb list. Ddbs that are considered valid are those with
+ * a device state of SESSION_ACTIVE.
+ **/
+static int qla4xxx_build_ddb_list(struct scsi_qla_host *ha)
+{
+	int status = QLA_ERROR;
+	uint32_t fw_ddb_index = 0;
+	uint32_t next_fw_ddb_index = 0;
+	uint32_t ddb_state;
+	uint32_t conn_err;
+	struct ddb_entry *ddb_entry;
+	struct dev_db_entry *fw_ddb_entry = NULL;
+	dma_addr_t fw_ddb_entry_dma;
+	uint32_t ipv6_device;
+	uint32_t new_tgt;
+	struct ddb_entry *looked_up_ddb_entry;
+	int ret;
+
+	qla4xxx_flush_AENS(ha);
+
+	fw_ddb_entry = dma_alloc_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry),
+			&fw_ddb_entry_dma, GFP_KERNEL);
+	if (fw_ddb_entry == NULL) {
+		DEBUG2(ql4_info(ha, "%s: DMA alloc failed\n",
+				__func__));
+
+		goto exit_build_ddb_list_no_free;
+	}
+
+	ql4_info(ha, "Initializing DDBs ...\n");
+	for (fw_ddb_index = 0; fw_ddb_index < MAX_DDB_ENTRIES;
+	     fw_ddb_index = next_fw_ddb_index) {
+		/* First, let's see if a device exists here */
+		if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
+					    0, NULL, &next_fw_ddb_index,
+					    &ddb_state, &conn_err,
+					    NULL, NULL) ==
+					    QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s: get_ddb_entry, "
+				      "fw_ddb_index %d failed", __func__,
+					fw_ddb_index));
+			goto exit_build_ddb_list;
+		}
+
+		DEBUG2(ql4_info(ha, "%s: Getting DDB[%d] ddbstate=0x%x, "
+			      "next_fw_ddb_index=%d.\n", __func__, fw_ddb_index,
+				 ddb_state, next_fw_ddb_index));
+
+		ret = qla4xxx_find_and_delete_duplicate_ddb(ha, fw_ddb_index);
+		if(ret != QLA_SUCCESS)
+			goto next_one;
+
+		/* Issue relogin, if necessary. */
+		if (test_bit(AF_LINK_UP, &ha->flags) &&
+		    (ddb_state == DDB_DS_SESSION_FAILED ||
+		     ddb_state == DDB_DS_NO_CONNECTION_ACTIVE)) {
+			/* Try and login to device */
+			DEBUG2(ql4_info(ha, "%s: Login to DDB[%d]\n",
+				      __func__, fw_ddb_index));
+			ipv6_device = le16_to_cpu(fw_ddb_entry->options) &
+					DDB_OPT_IPV6_DEVICE;
+			if (qla4_is_relogin_allowed(ha, conn_err) &&
+					((!ipv6_device &&
+					  *((uint32_t *)fw_ddb_entry->ip_addr))
+					 || ipv6_device)) {
+				if (fw_ddb_index == 0xDEAD)
+					continue;
+
+				looked_up_ddb_entry =
+					qla4xxx_lookup_ddb_by_fw_index(ha,
+							fw_ddb_index);
+
+				qla4xxx_relogin_device(ha, looked_up_ddb_entry);
+
+				if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index,
+							NULL, 0, NULL,
+							&next_fw_ddb_index,
+							&ddb_state, &conn_err,
+							NULL, NULL)
+						== QLA_ERROR) {
+					DEBUG2(ql4_info(ha, "%s: get_ddb_entry "
+						"%d failed\n", __func__,
+						fw_ddb_index));
+					goto exit_build_ddb_list;
+				}
+			}
+		}
+
+		if (ddb_state != DDB_DS_SESSION_ACTIVE)
+			goto next_one;
+		/*
+		 * if fw_ddb with session active state found,
+		 * add to ddb_list
+		 */
+		DEBUG2(ql4_info(ha, "%s: DDB[%d] added to list\n",
+			      __func__, fw_ddb_index));
+
+		/* Add DDB to internal our ddb list. */
+		ddb_entry = qla4xxx_get_ddb_entry(ha, fw_ddb_index, &new_tgt);
+		if (ddb_entry == NULL) {
+			DEBUG2(ql4_info(ha, "%s: Unable to allocate memory "
+				      "for device at fw_ddb_index %d\n",
+				      __func__, fw_ddb_index));
+			goto exit_build_ddb_list;
+		}
+		/* Fill in the device structure */
+		if (qla4xxx_update_ddb_entry(ha, ddb_entry, fw_ddb_index) ==
+		    QLA_ERROR) {
+			ha->fw_ddb_index_map[fw_ddb_index] =
+				(struct ddb_entry *)INVALID_ENTRY;
+
+			DEBUG2(ql4_info(ha, "%s: update_ddb_entry failed "
+				      "for fw_ddb_index %d.\n",
+				      __func__, fw_ddb_index));
+			goto exit_build_ddb_list;
+		}
+
+next_one:
+		/* We know we've reached the last device when
+		 * next_fw_ddb_index is 0 */
+		if (next_fw_ddb_index == 0)
+			break;
+	}
+
+	status = QLA_SUCCESS;
+	ql4_info(ha, "DDB list done..\n");
+
+exit_build_ddb_list:
+	dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry), fw_ddb_entry,
+		fw_ddb_entry_dma);
+
+exit_build_ddb_list_no_free:
+	return status;
 }
 
 static int qla4xxx_initialize_ddb_list(struct scsi_qla_host *ha)
@@ -932,31 +1204,192 @@ static int qla4xxx_initialize_ddb_list(s
 
 	ha->tot_ddbs = 0;
 
-	qla4xxx_flush_AENS(ha);
-
-	/*
-	 * First perform device discovery for active
-	 * fw ddb indexes and build
-	 * ddb list.
-	 */
-	if ((status = qla4xxx_build_ddb_list(ha)) == QLA_ERROR)
-		return status;
-
-	/* Wait for an AEN */
-	qla4xxx_devices_ready(ha);
-
-	/*
-	 * Targets can come online after the inital discovery, so processing
-	 * the aens here will catch them.
-	 */
-	if (test_and_clear_bit(DPC_AEN, &ha->dpc_flags))
-		qla4xxx_process_aen(ha, PROCESS_ALL_AENS);
-
+	/* Perform device discovery and build ddb list. */
+	status = qla4xxx_build_ddb_list(ha);
 	return status;
 }
 
+/*
+ * qla4xxx_change_ddb_index - updates the fw_ddb_index of the ddb_entry
+ *                            to match the ddb_index in firmware
+ * @ha - scsi_qla_host pointer
+ * @ddb_entry - entry matching tuple
+ * @ddb_index - ddb_index of ddb_entry matching tuple
+ * @fw_ddb_index - ddb_index for tuple/target in firmware
+ *
+ * This function is used to update the ddb_index of the ddb_entry
+ * and point fw_ddb_index in ha->fw_ddb_index_map to this
+ * ddb_entry. If the targets are not bound persistantly, the
+ * fw_ddb_index of the entry can change based on the order in
+ * which the targets get scanned at next host_reset.
+ *
+ * NOTE: At the end of reinitialize_ddb_list, all entries in
+ * ha->ddb_list are traversed and if the ddb_entry doesnt match
+ * the ha->fw_ddb_index_map[fw_ddb_index], ddb_entry is marked
+ * DEAD.
+ */
+void qla4xxx_change_ddb_index(struct scsi_qla_host *ha,
+			      struct ddb_entry *ddb_entry,
+			      uint16_t ddb_index,
+			      uint16_t fw_ddb_index)
+{
+        if (ddb_entry == NULL) {
+                DEBUG2(ql4_info(ha, "scsi%ld: %s: Error: src DDB index [%d]"
+                                    "not present\n", ha->host_no, __func__,
+                                    ddb_index));
+                return;
+        }
+
+        DEBUG2(ql4_info(ha, "scsi%ld: %s: Changing ddb_index %d to %d\n",
+                        ha->host_no, __func__, ddb_index, fw_ddb_index));
+        ha->fw_ddb_index_map[ddb_index] =
+			(struct ddb_entry *) INVALID_ENTRY;
+        ddb_entry->fw_ddb_index = fw_ddb_index;
+        ha->fw_ddb_index_map[fw_ddb_index] = ddb_entry;
+}
+
+/*
+ * qla4xxx_find_and_update_ddb - Gets the ddb_entry from firmware and finds the
+ *                               entry with matching tuple in internal ddb_list
+ *
+ * @ha: scsi_qla_host pointer
+ * @fw_ddb_index: ddb_index to lookup on in firmware ddb_list
+ *
+ * This function looks up the ddb_entry for the given fw_ddb_index from firmware
+ * and searches the internal ddb_list for an entry with the matching tuple
+ * (iscsi_name, isid, tgpt). If the fw_ddb_index doesnt match
+ * ddb_entry->fw_ddb_index, it calls qla4xxx_change_ddb_index() to update
+ * ddb_entry's fw_ddb_index to match the index on firmware. And returns the
+ * ddb_entry.
+ *
+ * NOTE: ddb_index of an entry can change across a host_reset, if the targets
+ * are not persistantly bound. Host reset can be triggered through an sg_reset
+ * from user space, from SML if abort/device reset fail or if the
+ * peg_alive_counter times out.
+ */
+struct ddb_entry * qla4xxx_find_and_update_ddb(struct scsi_qla_host *ha,
+                                               uint32_t fw_ddb_index)
+{
+        uint8_t status = QLA_ERROR;
+        struct ddb_entry *ddb_entry = NULL;
+	struct ddb_entry *detemp;
+        struct dev_db_entry *fw_ddb_entry;
+        uint32_t fw_ddb_device_state = 0;
+        dma_addr_t fw_ddb_entry_dma;
+        uint8_t found = 0;
+
+        /* Make sure the dma buffer is valid */
+        fw_ddb_entry = dma_alloc_coherent(&ha->pdev->dev,
+                                          sizeof(*fw_ddb_entry),
+                                          &fw_ddb_entry_dma, GFP_KERNEL);
+        if (fw_ddb_entry == NULL) {
+                DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+                              __func__));
+                goto exit_find_and_update_ddb;
+        }
+
+        if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, fw_ddb_entry,
+                                    fw_ddb_entry_dma, NULL, NULL,
+                                    &fw_ddb_device_state, NULL, NULL,
+                                    NULL) == QLA_ERROR) {
+                DEBUG2(ql4_info(ha, "%s: get_ddb_entry %d failed\n",
+                                __func__, fw_ddb_index));
+                goto exit_find_and_update_ddb;
+        }
+
+	if (fw_ddb_entry->iscsi_name == NULL) {
+                DEBUG2(ql4_info(ha, "%s: ddb[%d] NULL iscsi_name!",
+                                __func__, fw_ddb_index));
+		goto exit_find_and_update_ddb;
+	}
+
+        ddb_entry = qla4xxx_lookup_ddb_by_fw_index(ha, fw_ddb_index);
+        if (ddb_entry) {
+                DEBUG6(ql4_info(ha, "%s: ddb[%d] iscsi_name=%s,"
+                        " tpgt=%d, isid="ISID_FMT"; fw_ddb iscsi_name=%s"
+                        "tgpt=%d isid=" ISID_FMT" fw_ddb_state=%d\n",
+                        __func__, ddb_entry->fw_ddb_index,
+			ddb_entry->iscsi_name,
+                        ddb_entry->tpgt, ISID(ddb_entry->isid),
+                        fw_ddb_entry->iscsi_name,
+                        le32_to_cpu(fw_ddb_entry->tgt_portal_grp),
+                        ISID(fw_ddb_entry->isid), fw_ddb_device_state));
+
+                if ((strcmp(ddb_entry->iscsi_name,
+                            fw_ddb_entry->iscsi_name) == 0) &&
+                    (ddb_entry->tpgt ==
+                        le32_to_cpu(fw_ddb_entry->tgt_portal_grp)) &&
+                    (memcmp(ddb_entry->isid, fw_ddb_entry->isid,
+                        sizeof(ddb_entry->isid)) == 0)) {
+                        DEBUG2(ql4_info(ha, "%s: Match found ddb[%d] "
+				"iscsi_name=%s\n", __func__,
+				ddb_entry->fw_ddb_index,
+                                ddb_entry->iscsi_name));
+                        found = 1;
+                        goto found_ddb_internally;
+                }
+        }
+
+        /* DDB entry's fw_ddb_index has changed. Get the entry in the
+         * internal DDB list which matches the fw_ddb_entry.
+         */
+	list_for_each_entry_safe(ddb_entry, detemp, &ha->ddb_list, list) {
+                if (ddb_entry == NULL)
+                        continue;
+
+                if ((strcmp(ddb_entry->iscsi_name,
+                            fw_ddb_entry->iscsi_name) == 0) &&
+                    (ddb_entry->tpgt ==
+                                le32_to_cpu(fw_ddb_entry->tgt_portal_grp)) &&
+                    (memcmp(ddb_entry->isid, fw_ddb_entry->isid,
+                            sizeof(ddb_entry->isid)) == 0)) {
+                        DEBUG2(ql4_info(ha, "%s: Match found ddb[%d] fw_ddb[%d]"
+                                "iscsi_name=%s\n", __func__,
+                                ddb_entry->fw_ddb_index, fw_ddb_index,
+                                ddb_entry->iscsi_name));
+                        found = 1;
+                        break;
+                }
+        }
+
+found_ddb_internally:
+        if (found) {
+		/* Found a matching entry, update the entry from firmware */
+		qla4xxx_fill_ddb(ddb_entry, fw_ddb_entry);
+                status = QLA_SUCCESS;
+                if (ddb_entry->fw_ddb_index != fw_ddb_index) {
+			/* Update the fw_ddb_index of the ddb_entry to
+			 * match the index on firmware, and point the
+			 * fw_ddb_index_map[fw_ddb_index] to point to this
+			 * ddb_entry.
+			 *
+			 * NOTE: After the update, there will be another
+			 * entry in the ha->ddb_list with index of fw_ddb_index.
+			 * At the end of reinitialize_ddb_list we go through all
+			 * entries in ha->ddb_list and if the ddb_entry in
+			 * ha->ddb_list doesnt match
+			 * fw_ddb_index_map[fw_ddb_index], we mark the entry
+			 * DEAD.
+			 */
+                        qla4xxx_change_ddb_index(ha, ddb_entry,
+                                                 ddb_entry->fw_ddb_index,
+                                                 fw_ddb_index);
+                }
+        }
+
+exit_find_and_update_ddb:
+	if (fw_ddb_entry)
+		dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry), fw_ddb_entry,
+				  fw_ddb_entry_dma);
+
+        if (status == QLA_SUCCESS)
+                return ddb_entry;
+
+        return NULL;
+}
+
 /**
- * qla4xxx_update_ddb_list - update the driver ddb list
+ * qla4xxx_reinitialize_ddb_list - update the driver ddb list
  * @ha: pointer to host adapter structure.
  *
  * This routine obtains device information from the F/W database after
@@ -965,25 +1398,104 @@ static int qla4xxx_initialize_ddb_list(s
 int qla4xxx_reinitialize_ddb_list(struct scsi_qla_host *ha)
 {
 	int status = QLA_SUCCESS;
-	struct ddb_entry *ddb_entry, *detemp;
+	struct ddb_entry *ddb_entry = NULL;
+	struct ddb_entry *detemp;
+	uint32_t fw_ddb_index = 0;
+	uint32_t next_fw_ddb_index = 0;
+	uint32_t fw_ddb_device_state = 0;
 
 	/* Update the device information for all devices. */
+	for (fw_ddb_index = 0;
+             fw_ddb_index < MAX_DDB_ENTRIES;
+             fw_ddb_index = next_fw_ddb_index) {
+		if (qla4xxx_get_fwddb_entry(ha, fw_ddb_index, NULL, 0, NULL,
+                                &next_fw_ddb_index, &fw_ddb_device_state,
+                                NULL, NULL, NULL) == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s: get_ddb_entry "
+					    "%d failed\n", __func__,
+					    fw_ddb_index));
+			status = QLA_ERROR;
+			goto exit_reinit_ddb_list;
+                }
+
+		ddb_entry = qla4xxx_find_and_update_ddb(ha,
+							fw_ddb_index);
+                if (ddb_entry == NULL) {
+                        DEBUG2(ql4_info(ha, "%s: Error! DDB entry not "
+                                        "found in internal list and "
+                                        "fw_ddb_state=%d \n", __func__,
+                                        fw_ddb_device_state));
+                } else {
+		    if (ddb_entry->fw_ddb_device_state ==
+							DDB_DS_SESSION_ACTIVE) {
+			struct Scsi_Host *shost =
+                                        iscsi_session_to_shost(ddb_entry->sess);
+                        struct scsi_device *sdev;
+
+			atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
+			DEBUG2(ql4_info (ha, "%s: ddb[%d] os[%d] marked "
+				       "ONLINE\n", __func__,
+				       ddb_entry->fw_ddb_index,
+				       ddb_entry->os_target_id));
+                        atomic_set(&ddb_entry->relogin_retry_count, 0);
+                        atomic_set(&ddb_entry->relogin_timer, 0);
+			atomic_set(&ddb_entry->retry_relogin_timer, 0);
+                        clear_bit(DF_RELOGIN, &ddb_entry->flags);
+                        clear_bit(DF_NO_RELOGIN, &ddb_entry->flags);
+
+                        DEBUG2(ql4_info(ha, "%s: iscsi_unblock_session "
+                                        "ddb[%d] os[%d] sess 0x%p conn 0x%p\n",
+                                        __func__, ddb_entry->fw_ddb_index,
+                                        ddb_entry->os_target_id,
+                                        ddb_entry->sess, ddb_entry->conn));
+                        shost_for_each_device(sdev, shost)
+                               if (sdev->sdev_state == SDEV_OFFLINE)
+                                        sdev->sdev_state = SDEV_BLOCK;
+			iscsi_unblock_session(ddb_entry->sess);
+		    } else {
+			if (atomic_read(&ddb_entry->state) ==
+							DDB_STATE_ONLINE) {
+				qla4xxx_mark_device_missing(ha, ddb_entry);
+				DEBUG2(ql4_info(ha, "%s mark missing ddb_entry "
+					"0x%p sess 0x%p conn 0x%p state=%d\n",
+                                        __func__, ddb_entry, ddb_entry->sess,
+					ddb_entry->conn,
+					atomic_read(&ddb_entry->state)));
+			}
+		    }
+		}
+		/* We know we've reached the last device when
+		 * next_fw_ddb_index is 0
+		 */
+		if (next_fw_ddb_index == 0)
+			break;
+	}
+
+	/* Verify that the fw_ddb_index_map is valid
+         * and all stale entries are marked */
 	list_for_each_entry_safe(ddb_entry, detemp, &ha->ddb_list, list) {
-		qla4xxx_update_ddb_entry(ha, ddb_entry,
-					 ddb_entry->fw_ddb_index);
-		if (ddb_entry->fw_ddb_device_state == DDB_DS_SESSION_ACTIVE) {
-			atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
-			DEBUG2(printk ("scsi%ld: %s: ddb index [%d] marked "
-				       "ONLINE\n", ha->host_no, __func__,
-				       ddb_entry->fw_ddb_index));
-			iscsi_unblock_session(ddb_entry->sess);
-		} else if (atomic_read(&ddb_entry->state) == DDB_STATE_ONLINE) {
-			DEBUG2(printk("scsi:%ld: %s: Firmware ddb state is not "
-					"active marking device missing\n",
-					ha->host_no, __func__));
-			qla4xxx_mark_device_missing(ha, ddb_entry);
-		}
-	}
+               struct ddb_entry *looked_up_ddb_entry = NULL;
+
+               if (ddb_entry->fw_ddb_index == 0xDEAD)
+                       continue;
+
+               looked_up_ddb_entry =
+                       qla4xxx_lookup_ddb_by_fw_index(ha,
+						      ddb_entry->fw_ddb_index);
+
+               if (ddb_entry != looked_up_ddb_entry) {
+			uint8_t *ip_addr = ddb_entry->ip_addr;
+			DEBUG2(ql4_info(ha, "scsi%ld: %s: stale ddb[%d] "
+                               "ip %d.%d.%d.%d \"%s\" marked INVALID\n",
+                               ha->host_no, __func__, ddb_entry->fw_ddb_index,
+                               ip_addr[0], ip_addr[1], ip_addr[2],
+                               ip_addr[3], ddb_entry->iscsi_name));
+
+			ddb_entry->fw_ddb_index = 0xDEAD;
+                }
+        }
+
+exit_reinit_ddb_list:
 	return status;
 }
 
@@ -999,58 +1511,159 @@ int qla4xxx_relogin_device(struct scsi_q
 			   struct ddb_entry * ddb_entry)
 {
 	uint16_t relogin_timer;
+	struct dev_db_entry *fw_ddb_entry = NULL;
+	dma_addr_t fw_ddb_entry_dma;
 
 	relogin_timer = max(ddb_entry->default_relogin_timeout,
 			    (uint16_t)RELOGIN_TOV);
 	atomic_set(&ddb_entry->relogin_timer, relogin_timer);
 
-	DEBUG2(printk("scsi%ld: Relogin index [%d]. TOV=%d\n", ha->host_no,
+	DEBUG2(ql4_info(ha, "Relogin ddb [%d]. TOV=%d\n",
 		      ddb_entry->fw_ddb_index, relogin_timer));
 
+	/* Make sure the dma buffer is valid */
+	fw_ddb_entry = dma_alloc_coherent(&ha->pdev->dev,
+				sizeof(*fw_ddb_entry),
+				&fw_ddb_entry_dma, GFP_KERNEL);
+	if (fw_ddb_entry == NULL) {
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+			__func__));
+		goto exit_get_ddb_entry_no_free;
+	}
+
+	qla4xxx_fill_dev_db_entry(fw_ddb_entry, ddb_entry);
+
+	qla4xxx_set_ddb_entry(ha, ddb_entry->fw_ddb_index, fw_ddb_entry_dma);
+
+	dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry), fw_ddb_entry,
+			  fw_ddb_entry_dma);
+
+	return QLA_SUCCESS;
+
+exit_get_ddb_entry_no_free:
+
 	qla4xxx_set_ddb_entry(ha, ddb_entry->fw_ddb_index, 0);
 
 	return QLA_SUCCESS;
 }
 
+
+/**
+ * qla4xxx_relogin_all_devices - re-establish session with all devices
+ * @ha: Pointer to host adapter structure.
+ *
+ * This routine is called after a LINK_UP to re-establish a session with all
+ * devices.  We do not want to set the relogin timer here as we do not want to
+ * retry relogins in this case.
+ **/
+void qla4xxx_relogin_all_devices(struct scsi_qla_host *ha)
+{
+        struct ddb_entry *ddb_entry, *dtemp;
+        uint32_t conn_err;
+	struct ddb_entry *looked_up_ddb_entry;
+
+        list_for_each_entry_safe(ddb_entry, dtemp, &ha->ddb_list, list) {
+                if ((atomic_read(&ddb_entry->state) == DDB_STATE_MISSING) ||
+                    (atomic_read(&ddb_entry->state) == DDB_STATE_DEAD)) {
+                        /* get fw_ddb_device_state and conn_err */
+
+                        if (qla4xxx_get_fwddb_entry(ha,
+				ddb_entry->fw_ddb_index, NULL, 0, NULL,
+				NULL, &ddb_entry->fw_ddb_device_state,
+				&conn_err, NULL, NULL) == QLA_ERROR) {
+				DEBUG2(ql4_info(ha, "%s: get_ddb_entry "
+                                                "%d failed\n", __func__,
+                                                ddb_entry->fw_ddb_index));
+				continue;
+			}
+
+                        if (ddb_entry->fw_ddb_device_state ==
+						DDB_DS_SESSION_ACTIVE) {
+				struct Scsi_Host *shost =
+					iscsi_session_to_shost(ddb_entry->sess);
+				struct scsi_device *sdev;
+
+				DEBUG2(ql4_info(ha, "%s: DDB_SESSION_ACTIVE, "
+						"unblock_session\n", __func__));
+				atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
+				atomic_set(&ddb_entry->relogin_retry_count, 0);
+				atomic_set(&ddb_entry->relogin_timer, 0);
+				clear_bit(DF_RELOGIN, &ddb_entry->flags);
+				clear_bit(DF_NO_RELOGIN, &ddb_entry->flags);
+
+				ql4_info(ha, "%s: ddb[%d] os[%d] marked "
+					 "ONLINE\n", __func__,
+					 ddb_entry->fw_ddb_index,
+					 ddb_entry->os_target_id);
+				DEBUG2(ql4_info(ha, "%s: iscsi_unblock_session "
+					"ddb[%d] os[%d] sess 0x%p conn 0x%p\n",
+					__func__, ddb_entry->fw_ddb_index,
+					ddb_entry->os_target_id,
+					ddb_entry->sess, ddb_entry->conn));
+
+				if (ddb_entry->conn) {
+				    shost_for_each_device(sdev, shost)
+					if (sdev->sdev_state == SDEV_OFFLINE)
+						sdev->sdev_state = SDEV_BLOCK;
+				    iscsi_unblock_session(ddb_entry->sess);
+				}
+                        } else {
+				if (qla4_is_relogin_allowed(ha, conn_err)) {
+					DEBUG2(ql4_info(ha, "%s: SESSION not "
+						"active, relogin_device with "
+						"ddb_index %d\n", __func__,
+						ddb_entry->fw_ddb_index));
+
+					if (ddb_entry->fw_ddb_index == 0xDEAD)
+						continue;
+
+					looked_up_ddb_entry =
+						qla4xxx_lookup_ddb_by_fw_index(ha,
+							ddb_entry->fw_ddb_index);
+
+					qla4xxx_relogin_device(ha,
+							       looked_up_ddb_entry);
+				}
+			}
+                }
+        }
+}
+
 static int qla4xxx_config_nvram(struct scsi_qla_host *ha)
 {
 	unsigned long flags;
 	union external_hw_config_reg extHwConfig;
 
-	DEBUG2(printk("scsi%ld: %s: Get EEProm parameters \n", ha->host_no,
-		      __func__));
+	DEBUG2(ql4_info(ha, "%s: Get EEProm parameters \n", __func__));
 	if (ql4xxx_lock_flash(ha) != QLA_SUCCESS)
-		return (QLA_ERROR);
+		return QLA_ERROR;
 	if (ql4xxx_lock_nvram(ha) != QLA_SUCCESS) {
 		ql4xxx_unlock_flash(ha);
-		return (QLA_ERROR);
+		return QLA_ERROR;
 	}
 
 	/* Get EEPRom Parameters from NVRAM and validate */
-	dev_info(&ha->pdev->dev, "Configuring NVRAM ...\n");
+	ql4_info(ha, "Configuring NVRAM ...\n");
 	if (qla4xxx_is_nvram_configuration_valid(ha) == QLA_SUCCESS) {
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 		extHwConfig.Asuint32_t =
 			rd_nvram_word(ha, eeprom_ext_hw_conf_offset(ha));
 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 	} else {
-		/*
-		 * QLogic adapters should always have a valid NVRAM.
-		 * If not valid, do not load.
-		 */
-		dev_warn(&ha->pdev->dev,
-			   "scsi%ld: %s: EEProm checksum invalid.  "
-			   "Please update your EEPROM\n", ha->host_no,
-			   __func__);
+		ql4_warn(ha,
+		    "%s: EEProm checksum invalid.  "
+		    "Please update your EEPROM\n", __func__);
 
-		/* set defaults */
+		/* Attempt to set defaults */
 		if (is_qla4010(ha))
 			extHwConfig.Asuint32_t = 0x1912;
 		else if (is_qla4022(ha) | is_qla4032(ha))
 			extHwConfig.Asuint32_t = 0x0023;
+		else
+			return QLA_ERROR;
 	}
-	DEBUG(printk("scsi%ld: %s: Setting extHwConfig to 0xFFFF%04x\n",
-		     ha->host_no, __func__, extHwConfig.Asuint32_t));
+	DEBUG(ql4_info(ha, "%s: Setting extHwConfig to 0xFFFF%04x\n",
+		     __func__, extHwConfig.Asuint32_t));
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 	writel((0xFFFF << 16) | extHwConfig.Asuint32_t, isp_ext_hw_conf(ha));
@@ -1060,15 +1673,24 @@ static int qla4xxx_config_nvram(struct s
 	ql4xxx_unlock_nvram(ha);
 	ql4xxx_unlock_flash(ha);
 
-	return (QLA_SUCCESS);
+	return QLA_SUCCESS;
 }
 
-static void qla4x00_pci_config(struct scsi_qla_host *ha)
+/**
+ * qla4_8xxx_pci_config() - Setup ISP82xx PCI configuration registers.
+ * @ha: HA context
+ */
+void qla4_8xxx_pci_config(struct scsi_qla_host *ha)
+{
+	pci_set_master(ha->pdev);
+}
+
+void qla4xxx_pci_config(struct scsi_qla_host *ha)
 {
 	uint16_t w;
 	int status;
 
-	dev_info(&ha->pdev->dev, "Configuring PCI space...\n");
+	ql4_info(ha, "Configuring PCI space...\n");
 
 	pci_set_master(ha->pdev);
 	status = pci_set_mwi(ha->pdev);
@@ -1090,7 +1712,7 @@ static int qla4xxx_start_firmware_from_f
 	unsigned long flags;
 	uint32_t mbox_status;
 
-	dev_info(&ha->pdev->dev, "Starting firmware ...\n");
+	ql4_info(ha, "Starting firmware ...\n");
 
 	/*
 	 * Start firmware from flash ROM
@@ -1101,33 +1723,26 @@ static int qla4xxx_start_firmware_from_f
 	 * connections use the same TCP ports after each reboot,
 	 * causing some connections to not get re-established.
 	 */
-	DEBUG(printk("scsi%d: %s: Start firmware from flash ROM\n",
-		     ha->host_no, __func__));
+	DEBUG(ql4_info(ha, "%s: Start firmware from flash ROM\n",
+			__func__));
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 	writel(jiffies, &ha->reg->mailbox[7]);
-
 	if (is_qla4022(ha) | is_qla4032(ha))
 		writel(set_rmask(NVR_WRITE_ENABLE),
-		    &ha->reg->u1.isp4022.nvram);
+		       &ha->reg->u1.isp4022.nvram);
 
-	/*
-	 * Firmware must be informed that the driver supports
-	 * ACB firmware features while starting firmware.
-	 * If the firmware also supports these features it will
-	 * be indicated in the IFCB offset 0x3A (acb_version).
-	 */
-	writel(ACB_SUPPORTED, &ha->reg->mailbox[6]);
-	readl(&ha->reg->mailbox[6]);
+        writel(2, &ha->reg->mailbox[6]);
+        readl(&ha->reg->mailbox[6]);
 
 	writel(set_rmask(CSR_BOOT_ENABLE), &ha->reg->ctrl_status);
 	readl(&ha->reg->ctrl_status);
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
 	/* Wait for firmware to come UP. */
-	DEBUG2(printk("scsi%ld: %s: Wait up to %d seconds for "
-		      "boot firmware to complete... \n",
-		      ha->host_no, __func__, FIRMWARE_UP_TOV));
+	DEBUG2(ql4_info(ha, "%s: Wait up to %d seconds for "
+		      "boot firmware to complete...\n",
+		      __func__, FIRMWARE_UP_TOV));
 	max_wait_time = jiffies + (FIRMWARE_UP_TOV * HZ);
 	do {
 		uint32_t ctrl_status;
@@ -1142,16 +1757,16 @@ static int qla4xxx_start_firmware_from_f
 		if (mbox_status == MBOX_STS_COMMAND_COMPLETE)
 			break;
 
-		DEBUG2(printk("scsi%ld: %s: Waiting for boot firmware to "
-			      "complete... ctrl_sts=0x%x\n",
-			      ha->host_no, __func__, ctrl_status));
+		DEBUG2(ql4_info(ha, "%s: Waiting for boot "
+		    "firmware to complete... ctrl_sts=0x%x, remaining=%ld\n",
+		    __func__, ctrl_status, max_wait_time));
 
 		msleep_interruptible(250);
 	} while (!time_after_eq(jiffies, max_wait_time));
 
 	if (mbox_status == MBOX_STS_COMMAND_COMPLETE) {
-		DEBUG(printk("scsi%ld: %s: Firmware has started\n",
-			     ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Firmware has started\n",
+				__func__));
 
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 		writel(set_rmask(CSR_SCSI_PROCESSOR_INTR),
@@ -1161,9 +1776,8 @@ static int qla4xxx_start_firmware_from_f
 
 		status = QLA_SUCCESS;
 	} else {
-		printk(KERN_INFO "scsi%ld: %s: Boot firmware failed "
-		       "-  mbox status 0x%x\n", ha->host_no, __func__,
-		       mbox_status);
+		ql4_info(ha, "%s: Boot firmware failed "
+		       "-  mbox status 0x%x\n", __func__, mbox_status);
 		status = QLA_ERROR;
 	}
 	return status;
@@ -1179,15 +1793,14 @@ int ql4xxx_lock_drvr_wait(struct scsi_ql
 		if (ql4xxx_lock_drvr(a) == 0) {
 			ssleep(QL4_LOCK_DRVR_SLEEP);
 			if (drvr_wait) {
-				DEBUG2(printk("scsi%ld: %s: Waiting for "
+				DEBUG2(ql4_info(a, "%s: Waiting for "
 					      "Global Init Semaphore(%d)...\n",
-					      a->host_no,
 					      __func__, drvr_wait));
 			}
 			drvr_wait -= QL4_LOCK_DRVR_SLEEP;
 		} else {
-			DEBUG2(printk("scsi%ld: %s: Global Init Semaphore "
-				      "acquired\n", a->host_no, __func__));
+			DEBUG2(ql4_info(a, "%s: Global Init Semaphore "
+				      "acquired\n", __func__));
 			return QLA_SUCCESS;
 		}
 	}
@@ -1201,7 +1814,7 @@ int ql4xxx_lock_drvr_wait(struct scsi_ql
  * This routine performs the necessary steps to start the firmware for
  * the QLA4010 adapter.
  **/
-static int qla4xxx_start_firmware(struct scsi_qla_host *ha)
+int qla4xxx_start_firmware(struct scsi_qla_host *ha)
 {
 	unsigned long flags = 0;
 	uint32_t mbox_status;
@@ -1217,21 +1830,21 @@ static int qla4xxx_start_firmware(struct
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 
-	DEBUG2(printk("scsi%ld: %s: port_ctrl	= 0x%08X\n", ha->host_no,
+	DEBUG2(ql4_info(ha, "%s: port_ctrl	= 0x%08X\n",
 		      __func__, readw(isp_port_ctrl(ha))));
-	DEBUG(printk("scsi%ld: %s: port_status = 0x%08X\n", ha->host_no,
+	DEBUG(ql4_info(ha, "%s: port_status = 0x%08X\n",
 		     __func__, readw(isp_port_status(ha))));
 
 	/* Is Hardware already initialized? */
 	if ((readw(isp_port_ctrl(ha)) & 0x8000) != 0) {
-		DEBUG(printk("scsi%ld: %s: Hardware has already been "
-			     "initialized\n", ha->host_no, __func__));
+		DEBUG(ql4_info(ha, "%s: Hardware has already been "
+			     "initialized\n", __func__));
 
 		/* Receive firmware boot acknowledgement */
 		mbox_status = readw(&ha->reg->mailbox[0]);
 
-		DEBUG2(printk("scsi%ld: %s: H/W Config complete - mbox[0]= "
-			      "0x%x\n", ha->host_no, __func__, mbox_status));
+		DEBUG2(ql4_info(ha, "%s: H/W Config complete - mbox[0]= "
+			      "0x%x\n", __func__, mbox_status));
 
 		/* Is firmware already booted? */
 		if (mbox_status == 0) {
@@ -1242,48 +1855,50 @@ static int qla4xxx_start_firmware(struct
 			writel(set_rmask(CSR_SCSI_PROCESSOR_INTR),
 			       &ha->reg->ctrl_status);
 			readl(&ha->reg->ctrl_status);
+			writel(set_rmask(CSR_SCSI_COMPLETION_INTR),
+			       &ha->reg->ctrl_status);
+			readl(&ha->reg->ctrl_status);
 			spin_unlock_irqrestore(&ha->hardware_lock, flags);
 			if (qla4xxx_get_firmware_state(ha) == QLA_SUCCESS) {
-				DEBUG2(printk("scsi%ld: %s: Get firmware "
+				DEBUG2(ql4_info(ha, "%s: Get firmware "
 					      "state -- state = 0x%x\n",
-					      ha->host_no,
 					      __func__, ha->firmware_state));
 				/* F/W is running */
 				if (ha->firmware_state &
 				    FW_STATE_CONFIG_WAIT) {
-					DEBUG2(printk("scsi%ld: %s: Firmware "
+					DEBUG2(ql4_info(ha, "%s: Firmware "
 						      "in known state -- "
 						      "config and "
 						      "boot, state = 0x%x\n",
-						      ha->host_no, __func__,
+						      __func__,
 						      ha->firmware_state));
 					config_chip = 1;
 					soft_reset = 0;
 				}
 			} else {
-				DEBUG2(printk("scsi%ld: %s: Firmware in "
+				DEBUG2(ql4_info(ha, "%s: Firmware in "
 					      "unknown state -- resetting,"
 					      " state = "
-					      "0x%x\n", ha->host_no, __func__,
-					      ha->firmware_state));
+					      "0x%x\n", __func__,
+						ha->firmware_state));
 			}
 			spin_lock_irqsave(&ha->hardware_lock, flags);
 		}
 	} else {
-		DEBUG(printk("scsi%ld: %s: H/W initialization hasn't been "
-			     "started - resetting\n", ha->host_no, __func__));
+		DEBUG(ql4_info(ha, "%s: H/W initialization hasn't been "
+			     "started - resetting\n", __func__));
 	}
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
-	DEBUG(printk("scsi%ld: %s: Flags soft_rest=%d, config= %d\n ",
-		     ha->host_no, __func__, soft_reset, config_chip));
+	DEBUG(ql4_info(ha, "%s: Flags soft_rest=%d, config= %d\n ",
+			__func__, soft_reset, config_chip));
 	if (soft_reset) {
-		DEBUG(printk("scsi%ld: %s: Issue Soft Reset\n", ha->host_no,
-			     __func__));
-		status = qla4xxx_soft_reset(ha);
+		DEBUG(ql4_info(ha, "%s: Issue Soft Reset\n", __func__));
+		status = qla4xxx_soft_reset(ha);	/* NOTE: acquires drvr
+							 * lock again, but ok */
 		if (status == QLA_ERROR) {
-			DEBUG(printk("scsi%d: %s: Soft Reset failed!\n",
-				     ha->host_no, __func__));
+			DEBUG(ql4_info(ha, "%s: Soft Reset failed!\n",
+					__func__));
 			ql4xxx_unlock_drvr(ha);
 			return QLA_ERROR;
 		}
@@ -1301,12 +1916,10 @@ static int qla4xxx_start_firmware(struct
 
 	ql4xxx_unlock_drvr(ha);
 	if (status == QLA_SUCCESS) {
-		qla4xxx_get_fw_version(ha);
 		if (test_and_clear_bit(AF_GET_CRASH_RECORD, &ha->flags))
 			qla4xxx_get_crash_record(ha);
 	} else {
-		DEBUG(printk("scsi%ld: %s: Firmware has NOT started\n",
-			     ha->host_no, __func__));
+		DEBUG(ql4_info(ha, "%s: Firmware has NOT started\n", __func__));
 	}
 	return status;
 }
@@ -1328,21 +1941,22 @@ int qla4xxx_initialize_adapter(struct sc
 	int status = QLA_ERROR;
 	int8_t ip_address[IP_ADDR_LEN] = {0} ;
 
-	DEBUG2(dev_info(&ha->pdev->dev, "%s: adapter OFFLINE\n", __func__));
-	clear_bit(AF_ONLINE, &ha->flags);
 	ha->eeprom_cmd_data = 0;
 
-	qla4x00_pci_config(ha);
+	ql4_info(ha, "Configuring PCI space...\n");
+	ha->isp_ops->pci_config(ha);
 
-	qla4xxx_disable_intrs(ha);
+	ha->isp_ops->disable_intrs(ha);
 
 	/* Initialize the Host adapter request/response queues and firmware */
-	if (qla4xxx_start_firmware(ha) == QLA_ERROR)
+	if (ha->isp_ops->start_firmware(ha) != QLA_SUCCESS)
 		goto exit_init_hba;
 
-	if (qla4xxx_validate_mac_address(ha) == QLA_ERROR)
+	if (qla4xxx_get_fw_version(ha) == QLA_ERROR)
 		goto exit_init_hba;
 
+	ha->isp_ops->get_sys_info(ha);
+
 	if (qla4xxx_init_local_data(ha) == QLA_ERROR)
 		goto exit_init_hba;
 
@@ -1369,7 +1983,13 @@ int qla4xxx_initialize_adapter(struct sc
 		 * for recovery initiated by the driver.  So just update
 		 * the device states for the existing ddb_list.
 		 */
-		qla4xxx_reinitialize_ddb_list(ha);
+		status = qla4xxx_reinitialize_ddb_list(ha);
+		if (status == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s(%ld) Error occurred during"
+				"reinitialize ddb list\n", __func__,
+				ha->host_no));
+			goto exit_init_hba;
+		}
 	} else if (renew_ddb_list == REBUILD_DDB_LIST) {
 		/*
 		 * We want to build the ddb_list from scratch during
@@ -1378,23 +1998,30 @@ int qla4xxx_initialize_adapter(struct sc
 		 */
 		status = qla4xxx_initialize_ddb_list(ha);
 		if (status == QLA_ERROR) {
-			DEBUG2(printk("%s(%ld) Error occurred during build"
-				      "ddb list\n", __func__, ha->host_no));
+			DEBUG2(ql4_info(ha, "%s(%ld) Error occurred during"
+				"build ddb list\n", __func__, ha->host_no));
 			goto exit_init_hba;
 		}
 
 	}
 	if (!ha->tot_ddbs) {
-		DEBUG2(printk("scsi%ld: Failed to initialize devices or none "
-			      "present in Firmware device database\n",
-			      ha->host_no));
+		DEBUG2(ql4_info(ha, "Failed to initialize devices or none "
+			      "present in Firmware device database\n"));
 	}
 
 exit_init_online:
 	set_bit(AF_ONLINE, &ha->flags);
+	ql4_info(ha, "Adapter ONLINE\n");
+
 exit_init_hba:
-	DEBUG2(printk("scsi%ld: initialize adapter: %s\n", ha->host_no,
-			status == QLA_ERROR ? "FAILED" : "SUCCEDED"));
+	if (is_qla8022(ha) && (status == QLA_ERROR)) {
+		/* Since interrupts are registered in start_firmware for
+		 * 82xx, release them here if initialize_adapter fails */
+		qla4xxx_free_irqs(ha);
+	}
+
+	DEBUG2(ql4_info(ha, "initialize adapter: %s\n",
+	    status == QLA_ERROR ? "FAILED" : "SUCCEDED"));
 	return status;
 }
 
@@ -1408,48 +2035,43 @@ exit_init_hba:
 static void qla4xxx_add_device_dynamically(struct scsi_qla_host *ha,
 					   uint32_t fw_ddb_index)
 {
-	struct ddb_entry * ddb_entry;
-	uint32_t new_tgt;
+	struct ddb_entry * ddb_entry = NULL;
 
-	/* First allocate a device structure */
-	ddb_entry = qla4xxx_get_ddb_entry(ha, fw_ddb_index, &new_tgt);
+	qla4xxx_find_and_delete_duplicate_ddb(ha, fw_ddb_index);
+
+	ddb_entry = qla4xxx_find_and_update_ddb(ha, fw_ddb_index);
 	if (ddb_entry == NULL) {
-		DEBUG2(printk(KERN_WARNING
-			      "scsi%ld: Unable to allocate memory to add "
-			      "fw_ddb_index %d\n", ha->host_no, fw_ddb_index));
-		return;
-	}
-
-	if (!new_tgt && (ddb_entry->fw_ddb_index != fw_ddb_index)) {
-		/* Target has been bound to a new fw_ddb_index */
-		qla4xxx_free_ddb(ha, ddb_entry);
 		ddb_entry = qla4xxx_alloc_ddb(ha, fw_ddb_index);
 		if (ddb_entry == NULL) {
-			DEBUG2(printk(KERN_WARNING
-				"scsi%ld: Unable to allocate memory"
-				" to add fw_ddb_index %d\n",
-				ha->host_no, fw_ddb_index));
+			DEBUG2(ql4_warn(ha, "Unable to allocate memory"
+				" to add fw_ddb_index %d\n", fw_ddb_index));
 			return;
 		}
 	}
+
 	if (qla4xxx_update_ddb_entry(ha, ddb_entry, fw_ddb_index) ==
 				    QLA_ERROR) {
 		ha->fw_ddb_index_map[fw_ddb_index] =
 					(struct ddb_entry *)INVALID_ENTRY;
-		DEBUG2(printk(KERN_WARNING
-			      "scsi%ld: failed to add new device at index "
+		DEBUG2(ql4_warn(ha, "failed to add new device at index "
 			      "[%d]\n Unable to retrieve fw ddb entry\n",
-			      ha->host_no, fw_ddb_index));
+			      fw_ddb_index));
 		qla4xxx_free_ddb(ha, ddb_entry);
 		return;
 	}
 
 	if (qla4xxx_add_sess(ddb_entry)) {
-		DEBUG2(printk(KERN_WARNING
-			      "scsi%ld: failed to add new device at index "
+		DEBUG2(ql4_warn(ha, "failed to add new device at index "
 			      "[%d]\n Unable to add connection and session\n",
-			      ha->host_no, fw_ddb_index));
+			      fw_ddb_index));
 		qla4xxx_free_ddb(ha, ddb_entry);
+	} else {
+		DEBUG6(ql4_info(ha,
+			"%s added ddb 0x%p sess 0x%p"
+			" conn 0x%p state 0x%x\n",
+			__func__, ddb_entry,
+			ddb_entry->sess, ddb_entry->conn,
+			atomic_read(&ddb_entry->state)));
 	}
 }
 
@@ -1462,7 +2084,7 @@ static void qla4xxx_add_device_dynamical
  * This routine processes a Decive Database Changed AEN Event.
  **/
 int qla4xxx_process_ddb_changed(struct scsi_qla_host *ha, uint32_t fw_ddb_index,
-				uint32_t state, uint32_t conn_err)
+		uint32_t state, uint32_t conn_err)
 {
 	struct ddb_entry * ddb_entry;
 	uint32_t old_fw_ddb_device_state;
@@ -1472,38 +2094,74 @@ int qla4xxx_process_ddb_changed(struct s
 		return QLA_ERROR;
 
 	/* Get the corresponging ddb entry */
-	ddb_entry = qla4xxx_lookup_ddb_by_fw_index(ha, fw_ddb_index);
+	ddb_entry = qla4xxx_find_and_update_ddb(ha, fw_ddb_index);
 	/* Device does not currently exist in our database. */
-	if (ddb_entry == NULL) {
+	if ((ddb_entry == NULL) || (ddb_entry->conn == NULL)) {
 		if (state == DDB_DS_SESSION_ACTIVE)
 			qla4xxx_add_device_dynamically(ha, fw_ddb_index);
 		return QLA_SUCCESS;
 	}
 
+	DEBUG6(ql4_info(ha, "%s ddb[%d] os[%d] ostate 0x%x"
+		" sess 0x%p conn 0x%p o_fwstate 0x%x n_fwstate ox%x \n",
+		__func__, ddb_entry->fw_ddb_index, ddb_entry->os_target_id,
+		atomic_read(&ddb_entry->state), ddb_entry->sess,
+		ddb_entry->conn, ddb_entry->fw_ddb_device_state, state));
+
 	/* Device already exists in our database. */
 	old_fw_ddb_device_state = ddb_entry->fw_ddb_device_state;
-	DEBUG2(printk("scsi%ld: %s DDB - old state= 0x%x, new state=0x%x for "
-		      "index [%d]\n", ha->host_no, __func__,
-		      ddb_entry->fw_ddb_device_state, state, fw_ddb_index));
+	DEBUG2(ql4_info(ha, "%s DDB - old state= 0x%x, new state=0x%x "
+		      "for index [%d]\n", __func__,
+			ddb_entry->fw_ddb_device_state, state, fw_ddb_index));
 	if (old_fw_ddb_device_state == state &&
-			state == DDB_DS_SESSION_ACTIVE) {
-		if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE) {
+	    state == DDB_DS_SESSION_ACTIVE) {
+		struct Scsi_Host *shost =
+				iscsi_session_to_shost(ddb_entry->sess);
+		struct scsi_device *sdev;
+
+		if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE)
 			atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
-			iscsi_unblock_session(ddb_entry->sess);
-		}
+
+		shost_for_each_device(sdev, shost)
+			if (sdev->sdev_state == SDEV_OFFLINE)
+				sdev->sdev_state = SDEV_BLOCK;
+
+		DEBUG2(printk("%s: iscsi_unblock_session ddb[%d] os[%d]"
+                             " sess 0x%p conn 0x%p\n", __func__,
+                              ddb_entry->fw_ddb_index, ddb_entry->os_target_id,
+                              ddb_entry->sess, ddb_entry->conn));
+		iscsi_unblock_session(ddb_entry->sess);
+
 		return QLA_SUCCESS;
 	}
 
 	ddb_entry->fw_ddb_device_state = state;
 	/* Device is back online. */
 	if (ddb_entry->fw_ddb_device_state == DDB_DS_SESSION_ACTIVE) {
+		struct Scsi_Host *shost =
+					iscsi_session_to_shost(ddb_entry->sess);
+		struct scsi_device *sdev;
+
 		atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
-		atomic_set(&ddb_entry->port_down_timer,
-			   ha->port_down_retry_count);
+		ql4_info(ha,
+                        "%s: ddb[%d] os[%d] marked ONLINE\n",
+                        __func__, ddb_entry->fw_ddb_index,
+                        ddb_entry->os_target_id);
+
 		atomic_set(&ddb_entry->relogin_retry_count, 0);
 		atomic_set(&ddb_entry->relogin_timer, 0);
 		clear_bit(DF_RELOGIN, &ddb_entry->flags);
 		clear_bit(DF_NO_RELOGIN, &ddb_entry->flags);
+
+		DEBUG2(printk("%s: iscsi_unblock_session ddb[%d] os[%d]"
+		              " sess 0x%p conn 0x%p\n", __func__,
+			      ddb_entry->fw_ddb_index, ddb_entry->os_target_id,
+			      ddb_entry->sess, ddb_entry->conn));
+
+		shost_for_each_device(sdev, shost)
+			if (sdev->sdev_state == SDEV_OFFLINE)
+				sdev->sdev_state = SDEV_BLOCK;
+
 		iscsi_unblock_session(ddb_entry->sess);
 		iscsi_session_event(ddb_entry->sess,
 				    ISCSI_KEVENT_CREATE_SESSION);
@@ -1514,7 +2172,7 @@ int qla4xxx_process_ddb_changed(struct s
 	} else {
 		/* Device went away, mark device missing */
 		if (atomic_read(&ddb_entry->state) == DDB_STATE_ONLINE) {
-			DEBUG2(dev_info(&ha->pdev->dev, "%s mark missing "
+			DEBUG2(ql4_info(ha, "%s mark missing "
 					"ddb_entry 0x%p sess 0x%p conn 0x%p\n",
 					__func__, ddb_entry,
 					ddb_entry->sess, ddb_entry->conn));
@@ -1526,8 +2184,7 @@ int qla4xxx_process_ddb_changed(struct s
 		 * However, do not relogin if a RELOGIN is in process, or
 		 * we are not allowed to relogin to this DDB.
 		 */
-		if (ddb_entry->fw_ddb_device_state == DDB_DS_SESSION_FAILED &&
-		    !test_bit(DF_RELOGIN, &ddb_entry->flags) &&
+		if (!test_bit(DF_RELOGIN, &ddb_entry->flags) &&
 		    !test_bit(DF_NO_RELOGIN, &ddb_entry->flags) &&
 		    qla4_is_relogin_allowed(ha, conn_err)) {
 			/*
@@ -1546,9 +2203,17 @@ int qla4xxx_process_ddb_changed(struct s
 			atomic_set(&ddb_entry->relogin_timer, 0);
 			atomic_set(&ddb_entry->retry_relogin_timer,
 				   ddb_entry->default_time2wait + 4);
+			DEBUG(ql4_info(ha, "%s: ddb[%d] initiate relogin after "
+				" %d seconds\n", __func__,
+				ddb_entry->fw_ddb_index,
+				ddb_entry->default_time2wait + 4));
+		} else {
+			DEBUG(ql4_info(ha, "%s: ddb[%d] relogin not initiated, "
+				"state = %d, ddb_entry->flags = 0x%lx\n",
+				__func__, ddb_entry->fw_ddb_index,
+				ddb_entry->fw_ddb_device_state,
+				ddb_entry->flags));
 		}
 	}
-
 	return QLA_SUCCESS;
 }
-
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_inline.h
--- a/drivers/scsi/qla4xxx/ql4_inline.h
+++ b/drivers/scsi/qla4xxx/ql4_inline.h
@@ -1,10 +1,41 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
 
+/**
+ * qla4xxx_queue_aen_log - queue AENs to be reported to application layer
+ * @ha: Pointer to host adapter structure.
+ * @mbox_sts: Pointer to mailbox status structure.
+ *
+ * Store AENs to be reported to the application layer when requested
+ **/
+static inline void
+qla4xxx_queue_aen_log(struct scsi_qla_host *ha, uint32_t *mbox_sts)
+{
+	int i;
+	if (ha->aen_log.count < MAX_AEN_ENTRIES) {
+		for (i = 0; i < MBOX_AEN_REG_COUNT; i++)
+			ha->aen_log.entry[ha->aen_log.count].mbox_sts[i] =
+			    mbox_sts[i];
+		ha->aen_log.count++;
+	}
+}
+
+static inline void qla4xxx_queue_lun_change_aen(struct scsi_qla_host *ha,
+                                                     uint32_t index)
+{
+        uint32_t mbox_sts[MBOX_REG_COUNT];
+        memset(mbox_sts, 0, sizeof(mbox_sts));
+        mbox_sts[0] = MBOX_DRVR_ASTS_LUN_STATUS_CHANGE;
+        mbox_sts[1] = index;
+        qla4xxx_queue_aen_log(ha, &mbox_sts[0]);
+
+        DEBUG4(ql4_info(ha, "%s: AEN 0x7003 index[%d]\n", __func__, index));
+}
+
 /*
  *
  * qla4xxx_lookup_ddb_by_fw_index
@@ -29,36 +60,57 @@ qla4xxx_lookup_ddb_by_fw_index(struct sc
 		ddb_entry = ha->fw_ddb_index_map[fw_ddb_index];
 	}
 
-	DEBUG3(printk("scsi%d: %s: index [%d], ddb_entry = %p\n",
-	    ha->host_no, __func__, fw_ddb_index, ddb_entry));
+	DEBUG3(ql4_info(ha, "s: ddb [%d], ddb_entry = %p\n",
+	    __func__, fw_ddb_index, ddb_entry));
 
 	return ddb_entry;
 }
 
-/*
- * The MBOX_CMD_CLEAR_DATABASE_ENTRY (0x31) mailbox command does not
- * result in an AEN, so we need to process it seperately.
- */
-static inline void qla4xxx_check_for_clear_ddb(struct scsi_qla_host *ha,
-						uint32_t *mbox_cmd)
+static inline struct ddb_entry *
+qla4xxx_lookup_ddb_by_os_index(struct scsi_qla_host *ha, int os_idx)
+{
+        struct ddb_entry *ddb_entry = NULL;
+        struct ddb_entry *detemp;
+
+        list_for_each_entry_safe(ddb_entry, detemp, &ha->ddb_list, list) {
+                if (ddb_entry->os_target_id == os_idx)
+                        break;
+        }
+
+        DEBUG3(ql4_info(ha, "%s: ddb[%d] os[%d], ddb_entry = %p\n",
+            __func__, fw_ddb_index, os_idx, ddb_entry));
+
+        return ddb_entry;
+}
+
+/**
+ * The mailbox commands used to free DDBs (MBOX_CMD_FREE_DATABASE_ENTRY (0x31)
+ * MBOX_CMD_CONN_CLOSE (0x56)) do not result in an AEN, so we need to explicitly
+ * check for successful completion of those mailbox commands and remove the
+ * corresponding internal ddb structure accordingly.
+ **/
+static inline void qla4xxx_check_for_free_ddb(struct scsi_qla_host *ha,
+		uint32_t *mbox_cmd)
 {
 	uint32_t fw_ddb_index;
 	struct ddb_entry *ddb_entry = NULL;
 
-	if (mbox_cmd[0] == MBOX_CMD_CLEAR_DATABASE_ENTRY) {
+	if (mbox_cmd[0] == MBOX_CMD_FREE_DATABASE_ENTRY ||
+	    (mbox_cmd[0] == MBOX_CMD_CONN_CLOSE &&
+	    mbox_cmd[3] & LOGOUT_OPTION_FREE_DDB)) {
 
 		fw_ddb_index = mbox_cmd[1];
 
 		if (fw_ddb_index < MAX_DDB_ENTRIES)
 			ddb_entry = ha->fw_ddb_index_map[fw_ddb_index];
 
-		if (ddb_entry) {
+		if (ddb_entry != ((struct ddb_entry *)INVALID_ENTRY)) {
 			dev_info(&ha->pdev->dev, "%s: ddb[%d] os[%d] freed\n",
 				__func__, ddb_entry->fw_ddb_index,
 				ddb_entry->os_target_id);
 			set_bit(DF_REMOVE, &ddb_entry->flags);
 			set_bit(DPC_REMOVE_DEVICE, &ha->dpc_flags);
-			queue_work(ha->dpc_thread, &ha->dpc_work);
+			qla4xxx_wake_dpc(ha);
 		}
 	}
 }
@@ -110,46 +162,3 @@ qla4xxx_disable_intrs(struct scsi_qla_ho
 	__qla4xxx_disable_intrs(ha);
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 }
-
-static inline void
-qla4xxx_remove_device(struct scsi_qla_host *ha)
-{
-	struct ddb_entry *ddb_entry, *dtemp;
-
-	if (test_and_clear_bit(DPC_REMOVE_DEVICE, &ha->dpc_flags)) {
-		list_for_each_entry_safe(ddb_entry, dtemp,
-			&ha->ddb_list, list) {
-			if (test_and_clear_bit(DF_REMOVE, &ddb_entry->flags)) {
-				dev_info(&ha->pdev->dev,
-					"%s: ddb[%d] os[%d] - removed\n",
-					__func__, ddb_entry->fw_ddb_index,
-					ddb_entry->os_target_id);
-				qla4xxx_free_ddb(ha, ddb_entry);
-			}
-		}
-	}
-}
-
-static void
-ql4_get_aen_log(struct scsi_qla_host *ha, struct ql4_aen_log *aenl)
-{
-        if (aenl) {
-                memcpy(aenl, &ha->aen_log, sizeof (ha->aen_log));
-                ha->aen_log.count = 0;
-        }
-}
-
-static inline int
-qla4xxx_ioctl_init(struct scsi_qla_host *ha)
-{
-        ha->ql4mbx = qla4xxx_mailbox_command;
-        ha->ql4cmd = qla4xxx_send_command_to_isp;
-        ha->ql4getaenlog = ql4_get_aen_log;
-        return 0;
-}
-
-static inline void
-qla4xxx_ioctl_exit(struct scsi_qla_host *ha)
-{
-        return;
-}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_iocb.c
--- a/drivers/scsi/qla4xxx/ql4_iocb.c
+++ b/drivers/scsi/qla4xxx/ql4_iocb.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -19,12 +19,12 @@ qla4xxx_space_in_req_ring(struct scsi_ql
 
 	/* Calculate number of free request entries. */
 	if ((req_cnt + 2) >= ha->req_q_count) {
-		cnt = (uint16_t) le32_to_cpu(ha->shadow_regs->req_q_out);
+		cnt = (uint16_t) ha->isp_ops->rd_shdw_req_q_out(ha);
 		if (ha->request_in < cnt)
 			ha->req_q_count = cnt - ha->request_in;
 		else
-			ha->req_q_count = REQUEST_QUEUE_DEPTH -
-						(ha->request_in - cnt);
+			ha->req_q_count = ha->maxcmds -
+				(ha->request_in - cnt);
 	}
 
 	/* Check if room for request in request ring. */
@@ -37,7 +37,7 @@ qla4xxx_space_in_req_ring(struct scsi_ql
 static void qla4xxx_advance_req_ring_ptr(struct scsi_qla_host *ha)
 {
 	/* Advance request queue pointer */
-	if (ha->request_in == (REQUEST_QUEUE_DEPTH - 1)) {
+	if (ha->request_in == (ha->maxcmds - 1)) {
 		ha->request_in = 0;
 		ha->request_ptr = ha->request_ring;
 	} else {
@@ -56,7 +56,7 @@ static void qla4xxx_advance_req_ring_ptr
  *	- advances the request_in pointer
  *	- checks for queue full
  **/
-static int qla4xxx_get_req_pkt(struct scsi_qla_host *ha,
+int qla4xxx_get_req_pkt(struct scsi_qla_host *ha,
 			       struct queue_entry **queue_entry)
 {
 	uint16_t req_cnt = 1;
@@ -100,16 +100,15 @@ int qla4xxx_send_marker_iocb(struct scsi
 	}
 
 	/* Put the marker in the request queue */
-	marker_entry->hdr.entryType = ET_MARKER;
-	marker_entry->hdr.entryCount = 1;
+	marker_entry->hdr.entry_type = ET_MARKER;
+	marker_entry->hdr.entry_count = 1;
 	marker_entry->target = cpu_to_le16(ddb_entry->fw_ddb_index);
 	marker_entry->modifier = cpu_to_le16(mrkr_mod);
 	int_to_scsilun(lun, &marker_entry->lun);
 	wmb();
 
 	/* Tell ISP it's got a new I/O request */
-	writel(ha->request_in, &ha->reg->req_q_in);
-	readl(&ha->reg->req_q_in);
+	ha->isp_ops->queue_iocb(ha);
 
 exit_send_marker:
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
@@ -126,9 +125,9 @@ qla4xxx_alloc_cont_entry(struct scsi_qla
 	qla4xxx_advance_req_ring_ptr(ha);
 
 	/* Load packet defaults */
-	cont_entry->hdr.entryType = ET_CONTINUE;
-	cont_entry->hdr.entryCount = 1;
-	cont_entry->hdr.systemDefined = (uint8_t) cpu_to_le16(ha->request_in);
+	cont_entry->hdr.entry_type = ET_CONTINUE;
+	cont_entry->hdr.entry_count = 1;
+	cont_entry->hdr.system_defined = (uint8_t) cpu_to_le16(ha->request_in);
 
 	return cont_entry;
 }
@@ -164,8 +163,8 @@ static void qla4xxx_build_scsi_iocbs(str
 	cur_dsd = (struct data_seg_a64 *) & (cmd_entry->dataseg[0]);
 
 	if (srb->flags & SRB_SCSI_PASSTHRU) {
-		cur_dsd->base.addrLow = cpu_to_le32(LSDW(srb->dma_handle));
-		cur_dsd->base.addrHigh = cpu_to_le32(MSDW(srb->dma_handle));
+		cur_dsd->base.addr_lo = cpu_to_le32(LSDW(srb->dma_handle));
+		cur_dsd->base.addr_hi = cpu_to_le32(MSDW(srb->dma_handle));
 		cur_dsd->count = cpu_to_le32(srb->dma_len);
 		return;
 	}
@@ -191,8 +190,8 @@ static void qla4xxx_build_scsi_iocbs(str
 		}
 
 		sle_dma = sg_dma_address(sg);
-		cur_dsd->base.addrLow = cpu_to_le32(LSDW(sle_dma));
-		cur_dsd->base.addrHigh = cpu_to_le32(MSDW(sle_dma));
+		cur_dsd->base.addr_lo = cpu_to_le32(LSDW(sle_dma));
+		cur_dsd->base.addr_hi = cpu_to_le32(MSDW(sle_dma));
 		cur_dsd->count = cpu_to_le32(sg_dma_len(sg));
 		avail_dsds--;
 
@@ -201,6 +200,64 @@ static void qla4xxx_build_scsi_iocbs(str
 }
 
 /**
+ * qla4_8xxx_queue_iocb - Tell ISP it's got new request(s)
+ * @ha: pointer to host adapter structure.
+ *
+ * This routine notifies the ISP that one or more new request
+ * queue entries have been placed on the request queue.
+ **/
+void qla4_8xxx_queue_iocb(struct scsi_qla_host *ha)
+{
+	uint32_t dbval = 0;
+
+	dbval = 0x14 | (ha->func_num << 5);
+	dbval = dbval | (0 << 8) | (ha->request_in << 16);
+
+	qla4_8xxx_wr_32(ha, ha->nx_db_wr_ptr, ha->request_in);
+}
+
+/**
+ * qla4_8xxx_complete_iocb - Tell ISP we're done with response(s)
+ * @ha: pointer to host adapter structure.
+ *
+ * This routine notifies the ISP that one or more response/completion
+ * queue entries have been processed by the driver.
+ * This also clears the interrupt.
+ **/
+void qla4_8xxx_complete_iocb(struct scsi_qla_host *ha)
+{
+	writel(ha->response_out, &ha->qla4_8xxx_reg->rsp_q_out);
+	readl(&ha->qla4_8xxx_reg->rsp_q_out);
+}
+
+/**
+ * qla4xxx_queue_iocb - Tell ISP it's got new request(s)
+ * @ha: pointer to host adapter structure.
+ *
+ * This routine is notifies the ISP that one or more new request
+ * queue entries have been placed on the request queue.
+ **/
+void qla4xxx_queue_iocb(struct scsi_qla_host *ha)
+{
+	writel(ha->request_in, &ha->reg->req_q_in);
+	readl(&ha->reg->req_q_in);
+}
+
+/**
+ * qla4xxx_complete_iocb - Tell ISP we're done with response(s)
+ * @ha: pointer to host adapter structure.
+ *
+ * This routine is notifies the ISP that one or more response/completion
+ * queue entries have been processed by the driver.
+ * This also clears the interrupt.
+ **/
+void qla4xxx_complete_iocb(struct scsi_qla_host *ha)
+{
+	writel(ha->response_out, &ha->reg->rsp_q_out);
+	readl(&ha->reg->rsp_q_out);
+}
+
+/**
  * qla4xxx_send_command_to_isp - issues command to HBA
  * @ha: pointer to host adapter structure.
  * @srb: pointer to SCSI Request Block to be sent to ISP
@@ -229,24 +286,23 @@ int qla4xxx_send_command_to_isp(struct s
 	/* Acquire hardware specific lock */
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 
-	//index = (uint32_t)cmd->request->tag;
+	/* Check for room in active srb array */
 	index = ha->current_active_index;
 	for (i = 0; i < MAX_SRBS; i++) {
 		index++;
 		if (index == MAX_SRBS)
 			index = 1;
-		if (ha->active_srb_array[index] == 0) {
+		if (ha->active_srb_array[index] == NULL) {
 			ha->current_active_index = index;
 			break;
 		}
 	}
-
 	if (i >= MAX_SRBS) {
-                printk(KERN_INFO "scsi%ld: %s: NO more SRB entries used "
-                       "iocbs=%d, \n reqs remaining=%d\n", ha->host_no,
-                       __func__, ha->iocb_cnt, ha->req_q_count);
-                goto queuing_error;
-        }
+		ql4_info(ha, "%s: NO more SRB entries used "
+			"iocbs=%d, \n reqs remaining=%d\n",
+			__func__, ha->iocb_cnt, ha->req_q_count);
+		goto queuing_error;
+	}
 
 	/*
 	 * Check to see if adapter is online before placing request on
@@ -255,9 +311,8 @@ int qla4xxx_send_command_to_isp(struct s
 	 * garbage for pointers.
 	 */
 	if (!test_bit(AF_ONLINE, &ha->flags)) {
-		DEBUG2(printk("scsi%ld: %s: Adapter OFFLINE! "
-			      "Do not issue command.\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Adapter OFFLINE! "
+			      "Do not issue command.\n", __func__));
 		goto queuing_error;
 	}
 
@@ -276,13 +331,13 @@ int qla4xxx_send_command_to_isp(struct s
 		goto queuing_error;
 
 	/* total iocbs active */
-	if ((ha->iocb_cnt + req_cnt) >= REQUEST_QUEUE_DEPTH)
+	if ((ha->iocb_cnt + req_cnt) >= ha->maxcmds)
 		goto queuing_error;
 
 	/* Build command packet */
 	cmd_entry = (struct command_t3_entry *) ha->request_ptr;
 	memset(cmd_entry, 0, sizeof(struct command_t3_entry));
-	cmd_entry->hdr.entryType = ET_COMMAND;
+	cmd_entry->hdr.entry_type = ET_COMMAND;
 	cmd_entry->handle = cpu_to_le32(index);
 	cmd_entry->target = cpu_to_le16(ddb_entry->fw_ddb_index);
 	cmd_entry->connection_id = cpu_to_le16(ddb_entry->connection_id);
@@ -292,7 +347,7 @@ int qla4xxx_send_command_to_isp(struct s
 	cmd_entry->ttlByteCnt = cpu_to_le32(scsi_bufflen(cmd));
 	memcpy(cmd_entry->cdb, cmd->cmnd, cmd->cmd_len);
 	cmd_entry->dataSegCnt = cpu_to_le16(tot_dsds);
-	cmd_entry->hdr.entryCount = req_cnt;
+	cmd_entry->hdr.entry_count = req_cnt;
 
 	/* Set data transfer direction control flags
 	 * NOTE: Look at data_direction bits iff there is data to be
@@ -328,8 +383,9 @@ int qla4xxx_send_command_to_isp(struct s
 	qla4xxx_build_scsi_iocbs(srb, cmd_entry, tot_dsds);
 	wmb();
 
-	srb->cmd->host_scribble = (unsigned char *)srb;
+	/* put command in active array */
 	ha->active_srb_array[index] = srb;
+	srb->cmd->host_scribble = (unsigned char *) (unsigned long)index;
 
 	/* update counters */
 	srb->state = SRB_ACTIVE_STATE;
@@ -340,9 +396,7 @@ int qla4xxx_send_command_to_isp(struct s
 	srb->iocb_cnt = req_cnt;
 	ha->req_q_count -= req_cnt;
 
-	/* Debug print statements */
-	writel(ha->request_in, &ha->reg->req_q_in);
-	readl(&ha->reg->req_q_in);
+	ha->isp_ops->queue_iocb(ha);
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
 	return QLA_SUCCESS;
@@ -356,4 +410,3 @@ queuing_error:
 
 	return QLA_ERROR;
 }
-
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_isns.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_isns.c
@@ -0,0 +1,2059 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+#include <linux/ctype.h>
+
+#include "ql4_def.h"
+#include "ql4_glbl.h"
+#include "ql4_dbg.h"
+#include "ql4_inline.h"
+
+/********************     iSNS Helper Functions    ***********************/
+
+/**
+ * ql4_prn_str - retrieve associated print string
+ * @val: Value of string
+ * @tbl: Table of strings
+ * @return: String corresponding to value in specified table
+ *
+ * Iterate through specified table searching for @val.  If found,
+ * returns associated string.  Otherwise, return default "UNKNOWN" string.
+ * Last element in table MUST be {-1, "UNKNOWN"}.
+ **/
+
+#if defined(QL_DEBUG_LEVEL_6)
+static const char * ql4_prn_str(int val, struct prn_str_tbl *tbl)
+{
+	for (; tbl->val != (-1); tbl++)
+		if (tbl->val == val)
+			break;
+
+	return tbl->s;
+}
+#endif
+
+struct prn_str_tbl isns_attr_str [] = {
+	{ISNS_ATTR_DELIMITER             , "ISNS_ATTR_DELIMITER"},
+	{ISNS_ATTR_ENTITY_IDENTIFIER     , "ISNS_ATTR_ENTITY_IDENTIFIER"},
+	{ISNS_ATTR_ENTITY_PROTOCOL       , "ISNS_ATTR_ENTITY_PROTOCOL"},
+	{ISNS_ATTR_MGMT_IP_ADDRESS       , "ISNS_ATTR_MGMT_IP_ADDRESS"},
+	{ISNS_ATTR_TIMESTAMP             , "ISNS_ATTR_TIMESTAMP"},
+	{ISNS_ATTR_REGISTRATION_PERIOD   , "ISNS_ATTR_REGISTRATION_PERIOD"},
+	{ISNS_ATTR_PORTAL_IP_ADDRESS     , "ISNS_ATTR_PORTAL_IP_ADDRESS"},
+	{ISNS_ATTR_PORTAL_PORT           , "ISNS_ATTR_PORTAL_PORT"},
+	{ISNS_ATTR_PORTAL_SYMBOLIC_NAME  , "ISNS_ATTR_PORTAL_SYMBOLIC_NAME"},
+	{ISNS_ATTR_ESI_INTERVAL          , "ISNS_ATTR_ESI_INTERVAL"},
+	{ISNS_ATTR_ESI_PORT              , "ISNS_ATTR_ESI_PORT"},
+	{ISNS_ATTR_PORTAL_GROUP          , "ISNS_ATTR_PORTAL_GROUP"},
+	{ISNS_ATTR_PORTAL_INDEX          , "ISNS_ATTR_PORTAL_INDEX"},
+	{ISNS_ATTR_SCN_PORT              , "ISNS_ATTR_SCN_PORT"},
+	{ISNS_ATTR_PORTAL_SECURITY_BITMAP, "ISNS_ATTR_PORTAL_SECURITY_BITMAP"},
+	{ISNS_ATTR_ISCSI_NAME            , "ISNS_ATTR_ISCSI_NAME"},
+	{ISNS_ATTR_ISCSI_NODE_TYPE       , "ISNS_ATTR_ISCSI_NODE_TYPE"},
+	{ISNS_ATTR_ISCSI_ALIAS           , "ISNS_ATTR_ISCSI_ALIAS"},
+	{ISNS_ATTR_ISCSI_SCN_BITMAP      , "ISNS_ATTR_ISCSI_SCN_BITMAP"},
+	{ISNS_ATTR_PG_ISCSI_NAME         , "ISNS_ATTR_PG_ISCSI_NAME"},
+	{ISNS_ATTR_PG_PORTAL_IP_ADDRESS  , "ISNS_ATTR_PG_PORTAL_IP_ADDRESS"},
+	{ISNS_ATTR_PG_PORTAL_PORT        , "ISNS_ATTR_PG_PORTAL_PORT"},
+	{ISNS_ATTR_PG_TAG                , "ISNS_ATTR_PG_TAG"},
+	{ISNS_ATTR_DD_ID                 , "ISNS_ATTR_DD_ID"},
+	{-1, "UNKNOWN"}
+};
+
+struct prn_str_tbl isns_func_str [] = {
+	{ISNS_FUNC_DevAttrReg   , "ISNS_FUNC_DevAttrReg"},
+	{ISNS_FUNC_DevAttrQry   , "ISNS_FUNC_DevAttrQry"},
+	{ISNS_FUNC_DevGetNext   , "ISNS_FUNC_DevGetNext"},
+	{ISNS_FUNC_DevDereg     , "ISNS_FUNC_DevDereg"},
+	{ISNS_FUNC_SCNReg       , "ISNS_FUNC_SCNReg"},
+	{ISNS_FUNC_SCNDereg     , "ISNS_FUNC_SCNDereg"},
+	{ISNS_FUNC_SCNEvent     , "ISNS_FUNC_SCNEvent"},
+	{ISNS_FUNC_SCN          , "ISNS_FUNC_SCN"},
+	{ISNS_FUNC_ESI          , "ISNS_FUNC_ESI"},
+	{ISNS_FUNC_DevAttrRegRsp, "ISNS_FUNC_DevAttrRegRsp"},
+	{ISNS_FUNC_DevAttrQryRsp, "ISNS_FUNC_DevAttrQryRsp"},
+	{ISNS_FUNC_DevGetNextRsp, "ISNS_FUNC_DevGetNextRsp"},
+	{ISNS_FUNC_DevDeregRsp  , "ISNS_FUNC_DevDeregRsp"},
+	{ISNS_FUNC_SCNRegRsp    , "ISNS_FUNC_SCNRegRsp"},
+	{ISNS_FUNC_SCNDeregRsp  , "ISNS_FUNC_SCNDeregRsp"},
+	{ISNS_FUNC_SCNEventRsp  , "ISNS_FUNC_SCNEventRsp"},
+	{ISNS_FUNC_SCNRsp       , "ISNS_FUNC_SCNRsp"},
+	{ISNS_FUNC_DDRegRsp     , "ISNS_FUNC_DDRegRsp"},
+	{ISNS_FUNC_DDDeregRsp   , "ISNS_FUNC_DDDeregRsp"},
+	{ISNS_FUNC_DDSRegRsp    , "ISNS_FUNC_DDSRegRsp"},
+	{ISNS_FUNC_DDSDeregRsp  , "ISNS_FUNC_DDSDeregRsp"},
+	{ISNS_FUNC_ESIRsp       , "ISNS_FUNC_ESIRsp"},
+	{-1, "UNKNOWN"}
+};
+
+struct prn_str_tbl isns_sts_str [] = {
+	{ISNS_STS_SUCCESS                   , "ISNS_STS_SUCCESS"},
+	{ISNS_STS_UNKNOWN                   , "ISNS_STS_UNKNOWN"},
+	{ISNS_STS_MSG_FORMAT                , "ISNS_STS_MSG_FORMAT "},
+	{ISNS_STS_INVALID_REG               , "ISNS_STS_INVALID_REG"},
+	{ISNS_STS_INVALID_QUERY             , "ISNS_STS_INVALID_QUERY "},
+	{ISNS_STS_SOURCE_UNKNOWN            , "ISNS_STS_SOURCE_UNKNOWN"},
+	{ISNS_STS_SOURCE_ABSENT             , "ISNS_STS_SOURCE_ABSENT"},
+	{ISNS_STS_SOURCE_UNAUTHORIZED       , "ISNS_STS_SOURCE_UNAUTHORIZED"},
+	{ISNS_STS_NO_SUCH_ENTRY             , "ISNS_STS_NO_SUCH_ENTRY"},
+	{ISNS_STS_VER_NOT_SUPPORTED         , "ISNS_STS_VER_NOT_SUPPORTED"},
+	{ISNS_STS_INTERNAL_ERROR            , "ISNS_STS_INTERNAL_ERROR"},
+	{ISNS_STS_BUSY                      , "ISNS_STS_BUSY"},
+	{ISNS_STS_OPT_NOT_UNDERSTOOD        , "ISNS_STS_OPT_NOT_UNDERSTOOD"},
+	{ISNS_STS_INVALID_UPDATE            , "ISNS_STS_INVALID_UPDATE"},
+	{ISNS_STS_MSG_NOT_SUPPORTED         , "ISNS_STS_MSG_NOT_SUPPORTED"},
+	{ISNS_STS_SCN_EVENT_REJECTED        , "ISNS_STS_SCN_EVENT_REJECTED"},
+	{ISNS_STS_SCN_REG_REJECTED          , "ISNS_STS_SCN_REG_REJECTED"},
+	{ISNS_STS_ATTR_NOT_IMPLEMENTED      , "ISNS_STS_ATTR_NOT_IMPLEMENTED"},
+	{ISNS_STS_FC_DOMAIN_ID_NOT_AVAIL    , "ISNS_STS_FC_DOMAIN_ID_NOT_AVAIL"},
+	{ISNS_STS_FC_DOMAIN_ID_NOT_ALLOC    , "ISNS_STS_FC_DOMAIN_ID_NOT_ALLOC"},
+	{ISNS_STS_ESI_NOT_AVAILABLE         , "ISNS_STS_ESI_NOT_AVAILABLE"},
+	{ISNS_STS_INVALID_DEREG             , "ISNS_STS_INVALID_DEREG"},
+	{ISNS_STS_REG_FEATURES_NOT_SUPPORTED, "ISNS_STS_REG_FEATURES_NOT_SUPPORTED"},
+	{-1, "UNKNOWN"}
+};
+
+struct prn_str_tbl iscsi_node_type_str [] = {
+	{ISCSI_NODE_TYPE_TARGET,    "ISCSI_NODE_TYPE_TARGET"},
+	{ISCSI_NODE_TYPE_INITIATOR, "ISCSI_NODE_TYPE_INITIATOR"},
+	{ISCSI_NODE_TYPE_CONTROL,   "ISCSI_NODE_TYPE_CONTROL"},
+	{-1, "UNKNOWN"}
+};
+
+struct prn_str_tbl iscsi_scn_str [] = {
+	{ISCSI_SCN_OBJECT_UPDATED           ,    "ISCSI_SCN_OBJECT_UPDATED"},
+	{ISCSI_SCN_OBJECT_ADDED             ,    "ISCSI_SCN_OBJECT_ADDED"},
+	{ISCSI_SCN_OBJECT_REMOVED           ,    "ISCSI_SCN_OBJECT_REMOVED"},
+	{ISCSI_SCN_TARGET_AND_SELF_INFO_ONLY,    "ISCSI_SCN_TARGET_AND_SELF_INFO_ONLY"},
+	{-1, "UNKNOWN"}
+};
+
+/**
+ * ql4_isns_get_prb - Allocate a PDU
+ * @ha: Pointer to Host Adapter structure
+ * @pdu_size: Size of PDU requested. Will be rounded up to the nearest page.
+ **/
+static struct isns_prb *ql4_isns_get_prb(struct scsi_qla_host *ha,
+					__u32 pdu_size)
+{
+	struct isns_prb *prb = NULL;
+	__u8 index = ha->isns.curr_pdu;
+
+	mutex_lock(&ha->isns.prb_lock);
+
+	if (ha->isns.active_pdus == MAX_PDU_ENTRIES) {
+		DEBUG2(ql4_info(ha, "%s: Out of PDUs!\n", __func__));
+		mutex_unlock(&ha->isns.prb_lock);
+		return NULL;
+	}
+
+	/* Find next available prb index */
+	do {
+		index++;
+		if (index == MAX_PDU_ENTRIES)
+			index = 0;
+		if (index == ha->isns.curr_pdu) {
+			mutex_unlock(&ha->isns.prb_lock);
+			return NULL;
+		}
+	} while (ha->isns.prb_array[index].prb_in_use == 1);
+
+	/* Allocate PDU. All PDU sizes are rounded up to the nearest page
+	 * and are aligned on a page boundary
+	 */
+	prb = &ha->isns.prb_array[index];
+	pdu_size = (pdu_size + (PAGE_SIZE-1)) & ~(PAGE_SIZE-1);
+	prb->pdu = dma_alloc_coherent(&ha->pdev->dev, pdu_size, &prb->pdu_dma,
+					GFP_KERNEL);
+	if (!prb->pdu) {
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate memory for PDU!\n",
+				__func__));
+		mutex_unlock(&ha->isns.prb_lock);
+		return NULL;
+	}
+
+	mutex_unlock(&ha->isns.prb_lock);
+
+	/* Allocate an IOCB */
+	prb->pkt = dma_pool_alloc(ha->pt_iocb_dmapool, GFP_KERNEL,
+					&prb->pkt_dma);
+	if (!prb->pkt) {
+		DEBUG6(ql4_info(ha,"%s: Unable to alloc memory for Passthru "
+					"IOCB\n", __func__));
+		dma_free_coherent(&ha->pdev->dev, prb->pdu_buf_len, prb->pdu,
+					prb->pdu_dma);
+		return NULL;
+	}
+
+	prb->pdu_buf_len = pdu_size;
+	prb->prb_in_use = 1;
+	ha->isns.curr_pdu = index;
+	ha->isns.active_pdus++;
+
+	DEBUG7(ql4_info(ha, "%s: prb=%p pdu=%p index=%d pkt=%p pkt_dma=%llx\n",
+	      __func__, prb, prb->pdu, index, prb->pkt,
+		(unsigned long long)prb->pkt_dma));
+
+	return prb;
+}
+
+static void ql4_isns_free_prb(struct scsi_qla_host *ha, struct isns_prb *prb)
+{
+	DEBUG7(ql4_info(ha, "%s: prb=%p, pdu=%p, pkt=%p, pkt_dma=%llx \n",
+	      __func__, prb, prb->pdu, prb->pkt,
+	      (unsigned long long)prb->pkt_dma));
+
+	mutex_lock(&ha->isns.prb_lock);
+	dma_pool_free(ha->pt_iocb_dmapool, prb->pkt, prb->pkt_dma);
+	dma_free_coherent(&ha->pdev->dev, prb->pdu_buf_len, prb->pdu,
+			  prb->pdu_dma);
+	memset(prb, 0, sizeof(*prb));
+	ha->isns.active_pdus--;
+	mutex_unlock(&ha->isns.prb_lock);
+}
+
+/* Notify application that the specified iSNS Status Change occurred */
+void ql4_queue_isns_sts_chg_aen(struct scsi_qla_host *ha,
+					uint32_t chg_type)
+{
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	memset(mbox_sts, 0, sizeof(mbox_sts));
+	mbox_sts[0] = MBOX_DRVR_ASTS_ISNS_STATUS_CHANGE;
+	mbox_sts[1] = chg_type;
+	qla4xxx_queue_aen_log(ha, &mbox_sts[0]);
+
+	DEBUG2(ql4_info(ha, "%s: AEN 0x7002\n", __func__));
+}
+
+static __u32 ql4_isns_build_iocb_handle(struct scsi_qla_host *ha,
+				__u32 type, struct isns_prb *prb)
+{
+	__u32 index = ((__u8 *)prb - (__u8 *)ha->isns.prb_array) /
+                sizeof(struct isns_prb);
+
+	return IOCB_ISNS_PT_PDU_TYPE(type) | index;
+}
+
+static void ql4_isns_build_entity_id(struct scsi_qla_host *ha)
+{
+	__u8 *s;
+
+	snprintf(ha->isns.entity_id, sizeof(ha->isns.entity_id),
+		"%02x:%02x:%02x:%02x:%02x:%02x", ha->my_mac[0], ha->my_mac[1],
+		ha->my_mac[2], ha->my_mac[3], ha->my_mac[4], ha->my_mac[5]);
+
+	for (s = ha->isns.entity_id; *s; s++)
+		*s = tolower(*s);
+	DEBUG6(ql4_info(ha, "Entity ID %s\n", ha->isns.entity_id));
+}
+
+/**
+ * ql4_isns_create_header - Populates iSNSP Header in Network Byte Order
+ * @ha: Pointer to Host Adapter structure
+ * @hdr: Pointer to iSNSP Header structure
+ * @func_id: iSNSP Function ID
+ **/
+static void ql4_isns_create_header(struct scsi_qla_host *ha,
+			    struct isnsp_header *hdr, __u16 func_id)
+{
+	hdr->ver      = htons(ISNSP_VERSION);
+	hdr->func_id  = htons(func_id);
+	hdr->trans_id = htons(++ha->isns.trans_id);
+	hdr->seq_id   = 0;
+	hdr->flags    = htons(ISNSP_FLAG_CLIENT_SENDER |
+                             ISNSP_FLAG_FIRST_PDU |
+                             ISNSP_FLAG_LAST_PDU);
+
+	if (func_id == ISNS_FUNC_DevAttrReg)
+		hdr->flags |= htons(ISNSP_FLAG_REPLACE_FLAG);
+}
+
+/**
+ * ql4_isns_append_attr - Append integer attribute to pdu message
+ * @ha: Pointer to Host Adapter structure
+ * @ptr: Pointer to attribute in pdu message buffer.
+ *       Returns pointer to next attribute.
+ * @tag: Attribute tag
+ * @len: Attribute length
+ * @val: Pointer to Attribute Value
+ * Remarks: Integers are either 0 or 4 bytes in length.
+ * Delimiters have 0 size lengths, all others have a length of 4.
+ **/
+static void ql4_isns_append_attr(struct scsi_qla_host *ha,
+				 __u8 **ptr, __u16 tag, __u16 len, __u32 val)
+{
+	struct isnsp_attribute *attr = (struct isnsp_attribute *) *ptr;
+
+	attr->tag = htonl(tag);
+	attr->len = htonl(len);
+	*(__u32 *) attr->val = htonl(val);
+
+	*ptr += sizeof(struct isnsp_attribute) + len;
+}
+
+/**
+ * ql4_isns_append_attr_ip - Append IP address attribute to pdu message
+ * @ha: Pointer to Host Adapter structure
+ * @ptr: Pointer to attribute in pdu message buffer.
+ *       Returns pointer to next attribute.
+ * @tag: Attribute tag
+ * @val: Pointer to Attribute Value
+ *
+ * Remarks: All IP addresses are fixed 16 bytes in length.
+ * IPv4 addresses are stored as IPv4-mapped IPv6 address,
+ * where the most significant bytes are 0x00,
+ * bytes 10 and 11 are 0xFF, and bytes 12-15 contain the IP address
+ **/
+static void ql4_isns_append_attr_ip(struct scsi_qla_host *ha,
+				     __u8 **ptr, __u16 tag, __u8 *val)
+{
+	struct isnsp_attribute *attr = (struct isnsp_attribute *) *ptr;
+	__u16 len = 16;
+
+	attr->tag = htonl(tag);
+	attr->len = htonl(len);
+
+	memcpy(attr->val, val, len);
+	*ptr += sizeof(struct isnsp_attribute) + len;
+}
+
+/**
+ * ql4_isns_append_attr_str - Append string attribute to pdu message
+ * @ha: Pointer to Host Adapter structure
+ * @ptr: Pointer to attribute in pdu message buffer.
+ *       Returns pointer to next attribute.
+ * @tag: Attribute tag
+ * @val: Pointer to Attribute Value
+ *
+ * Remarks: Strings must be UTF-8 encoded NULL-terminated on a 4-byte boundary.
+ * Strings must have a minimum length of 4, with the exception of iscsi_name
+ * specified in the message key attribute used to retrieve the first object
+ * with dev_get_next, * where the length must be 0.
+ * For that case we pass in val ptr of NULL
+ **/
+static void ql4_isns_append_attr_str(struct scsi_qla_host *ha,
+				     __u8 **ptr, __u16 tag, __u8 *val)
+{
+	struct isnsp_attribute *attr = (struct isnsp_attribute *) *ptr;
+	__u16 raw_len = 0;
+	__u16 len = 0;
+
+	if (val) {
+		strcpy(attr->val, val);
+
+		raw_len = strlen(val);
+		raw_len++; /* Pad for NULL termination */
+		len = ALIGN(raw_len, 4);
+
+		/* Cleanup padded bytes */
+		memset(attr->val + raw_len, 0, len - raw_len);
+	}
+
+	attr->tag = htonl(tag);
+	attr->len = htonl(len);
+
+	*ptr += sizeof(struct isnsp_attribute) + len;
+}
+
+void ql4_isns_clear_flags(struct scsi_qla_host *ha)
+{
+	clear_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags);
+	clear_bit(ISNS_FLAG_ISNS_SRV_REGISTERED, &ha->isns.flags);
+	clear_bit(ISNS_FLAG_ISNS_SCN_REGISTERED, &ha->isns.flags);
+	clear_bit(ISNS_FLAG_SRV_DEREG_IN_PROGRESS, &ha->isns.flags);
+	atomic_set(&ha->isns.state, ISNS_STATE_TCP_DISCONNECTED);
+}
+
+void ql4_isns_restart_timer(struct scsi_qla_host *ha, __u32 time)
+{
+	ql4_isns_clear_flags(ha);
+
+	/* Set timer for restart to complete */
+	atomic_set(&ha->isns.state, ISNS_STATE_RESTART_SRV_WAIT);
+	atomic_set(&ha->isns.restart_timer, time);
+	DEBUG2(ql4_info(ha,
+		"%s: (re)attempt iSNS Server connection in (%d) seconds\n",
+		__func__, time));
+}
+
+void ql4_isns_restart_service(struct scsi_qla_host *ha)
+{
+	ql4_isns_stop_service(ha);
+	ql4_isns_restart_timer(ha, ISNS_RESTART_SVR_TOV);
+}
+
+/**
+ * ql4_isns_send_passthru_iocb - Prepare and Send Passthru0 IOCB
+ *
+ * @ha: Pointer to Host Adapter structure
+ * @prb: Pointer to PDU Request Block structure
+ **/
+static __u8 ql4_isns_send_passthru_iocb(struct scsi_qla_host *ha,
+                                       struct isns_prb *prb)
+{
+	struct passthru0 *pkt;
+	struct isnsp_header *hdr;
+	__u16 ctrl_flags = PT_FLAG_ETHERNET_FRAME;
+	__u32 pdu_type = IOCB_ISNS_PT_PDU_TYPE(prb->handle);
+	__u32 wait_count;
+	__u8 status = QLA_ERROR;
+
+	if (prb->tx_len == 0 && prb->rx_len == 0) {
+		DEBUG6(ql4_info(ha,"%s: IOCB not sent.  "
+			"Non-zero xfer length required\n", __func__));
+		return status;
+	}
+
+	/* Passthru code active */
+	wait_count = MBOX_TOV * 100;
+	while (wait_count--) {
+		mutex_lock(&ha->pt_sem);
+		if (!test_bit(AF_PT_ACTIVE, &ha->flags)) {
+			set_bit(AF_PT_ACTIVE, &ha->flags);
+			mutex_unlock(&ha->pt_sem);
+			break;
+		}
+		mutex_unlock(&ha->pt_sem);
+		if (!wait_count) {
+			DEBUG2(ql4_info(ha, "%s: pt_sem failed\n", __func__));
+			return status;
+		}
+		msleep(10);
+	}
+
+	pkt = (struct passthru0 *) prb->pkt;
+	memset(pkt, 0, sizeof(struct passthru0));
+	pkt->hdr.entry_type = ET_PASSTHRU0;
+	pkt->hdr.entry_count = 1;
+	pkt->handle  = cpu_to_le32(prb->handle);
+	pkt->conn_id = cpu_to_le16(prb->conn_id);
+	pkt->target  = __constant_cpu_to_le16(ISNS_DEVICE_INDEX);
+	pkt->timeout = __constant_cpu_to_le16(PT_DEFAULT_TIMEOUT);
+
+	if (prb->tx_len) {
+		ctrl_flags |= PT_FLAG_SEND_BUFFER;
+		pkt->out_data_seg64.base.addr_hi =
+			cpu_to_le32(MSDW(prb->pdu_dma));
+		pkt->out_data_seg64.base.addr_lo =
+			cpu_to_le32(LSDW(prb->pdu_dma));
+		pkt->out_data_seg64.count =
+			cpu_to_le32(prb->tx_len);
+	}
+
+	if (prb->rx_len) {
+		pkt->in_data_seg64.base.addr_hi =
+			cpu_to_le32(MSDW(prb->pdu_dma + prb->offset));
+		pkt->in_data_seg64.base.addr_lo =
+			cpu_to_le32(LSDW(prb->pdu_dma + prb->offset));
+		pkt->in_data_seg64.count =
+			cpu_to_le32(prb->rx_len);
+	}
+
+	if (pdu_type != ISNS_ASYNC_RSP_PDU)
+		ctrl_flags |= PT_FLAG_WAIT_4_RESPONSE;
+
+	pkt->ctrl_flags = cpu_to_le16(ctrl_flags);
+	wmb();
+
+	hdr = (struct isnsp_header *) prb->pdu;
+	DEBUG6(ql4_info(ha,"------------------------\n"));
+	if (pdu_type == ISNS_ASYNC_REQ_PDU) {
+		DEBUG6(ql4_info(ha,"Requesting iSNS ASYNC PDU  handle=0x%x, "
+			"cid=0x%x, rx_len=0x%x\n",
+			prb->handle, prb->conn_id, prb->rx_len));
+	} else {
+		DEBUG6(ql4_info(ha,"Sending tid=0x%x %s   0x%x ->   "
+			"(Display MAX 0x100)\n",
+			ntohs(hdr->trans_id),
+			ql4_prn_str(ntohs(hdr->func_id), &isns_func_str[0]),
+			prb->tx_len));
+	}
+	DEBUG6(qla4xxx_dump_bytes(prb->pdu, min((__u16)prb->tx_len,
+					(__u16)0x100)));
+	DEBUG7(__dump_prb(ha,prb));
+	DEBUG7(ql4_info(ha,"dump passthru iocb %p\n", pkt));
+	DEBUG7(qla4xxx_dump_bytes(pkt, sizeof(*pkt)));
+
+	if (qla4xxx_issue_iocb(ha, 0, prb->pkt_dma) == QLA_SUCCESS) {
+		__u32 pdu_type = IOCB_ISNS_PT_PDU_TYPE(prb->handle);
+
+		status = QLA_SUCCESS;
+
+		if (pdu_type == ISNS_REQ_RSP_PDU ||
+			pdu_type == ISNS_ASYNC_REQ_PDU)
+			ql4_isns_queue_passthru_sts_iocb(ha, prb);
+		else if (pdu_type == ISNS_ASYNC_RSP_PDU)
+			ql4_isns_free_prb(ha, prb);
+		else {
+			ql4_info(ha, "%s: Error: Invalid pdu_type returned "
+				"(0x%x)! Restart iSNS Service\n",
+				__func__, pdu_type);
+			set_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+			DEBUG2(ql4_info(ha, "%s: Re-Register with iSNS "
+					"server\n", __func__));
+		}
+	} else
+		DEBUG6(ql4_info(ha,"%s: qla4xxx_issue_iocb failed\n",
+				__func__));
+
+	mutex_lock(&ha->pt_sem);
+	clear_bit(AF_PT_ACTIVE, &ha->flags);
+	mutex_unlock(&ha->pt_sem);
+	return status;
+}
+
+
+/********************    iSNS Send PDU Functions   ****************/
+
+/**
+ * ql4_isns_send_async_msg_rsp - Send response to ESI and SCN async messages
+ **/
+static void ql4_isns_send_async_msg_rsp(struct scsi_qla_host *ha,
+                                        struct isns_prb *msg_prb)
+{
+	struct isnsp_message *msg;
+	struct isnsp_response *rsp;
+	struct isns_prb *rsp_prb;
+	__u16 msg_pdu_len;
+
+	rsp_prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!rsp_prb) {
+		return;
+	}
+
+	msg = (struct isnsp_message *) msg_prb->pdu;
+	rsp = (struct isnsp_response *) rsp_prb->pdu;
+
+	msg_pdu_len = ntohs(msg->hdr.pdu_len);
+
+	rsp->hdr.ver      = htons(ISNSP_VERSION);
+	rsp->hdr.func_id  = msg->hdr.func_id | htons(ISNS_FUNC_RESPONSE);
+	rsp->hdr.trans_id = msg->hdr.trans_id;
+	rsp->hdr.seq_id   = 0;
+	rsp->hdr.flags    = htons(ISNSP_FLAG_CLIENT_SENDER |
+                                  ISNSP_FLAG_FIRST_PDU |
+                                  ISNSP_FLAG_LAST_PDU);
+	rsp->hdr.pdu_len = htons(msg_pdu_len + sizeof(rsp->status_code));
+	rsp->status_code = htonl(ISNS_STS_SUCCESS);
+	memcpy(&rsp->attributes[0], &msg->attributes[0], msg_pdu_len);
+
+	rsp_prb->conn_id = msg_prb->conn_id;
+	rsp_prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_ASYNC_RSP_PDU,
+                                                      rsp_prb);
+	rsp_prb->tx_len  = sizeof(struct isnsp_response) + msg_pdu_len;
+	rsp_prb->rx_len  = 0;
+
+	if (ql4_isns_send_passthru_iocb(ha, rsp_prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, rsp_prb);
+}
+
+static void ql4_isns_send_scn_reg(struct scsi_qla_host *ha)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_SCNReg);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* Key Attributes */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* Delimiter to indicate division between Key & Operating attributes */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DELIMITER, 0, 0);
+	/* Operating Attributes */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_SCN_BITMAP, 4,
+		ISCSI_SCN_OBJECT_UPDATED |
+		ISCSI_SCN_OBJECT_ADDED |
+		ISCSI_SCN_OBJECT_REMOVED |
+		ISCSI_SCN_TARGET_AND_SELF_INFO_ONLY);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+void ql4_isns_send_scn_dereg(struct scsi_qla_host *ha)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_SCNDereg);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* Key Attributes */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	set_bit(ISNS_FLAG_SRV_DEREG_IN_PROGRESS, &ha->isns.flags);
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+static void ql4_isns_send_dev_dereg(struct scsi_qla_host *ha)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_DevDereg);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* No Key Attribute for DevDereg */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DELIMITER, 0, 0);
+	/* Operating Attributes fo register */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ENTITY_IDENTIFIER,
+		ha->isns.entity_id);
+	ql4_isns_append_attr_ip(ha, &ptr, ISNS_ATTR_PORTAL_IP_ADDRESS,
+		ha->isns.source_ip);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PORTAL_PORT, 4,
+		(__u32) ha->isns.source_port);
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+void ql4_isns_send_dev_get_next(struct scsi_qla_host *ha,
+                                __u8 *last_iscsi_name,
+				__u8 *tgt_qry_buf,
+				__u32 *tgt_qry_buf_len)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_DevGetNext);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* Key Attribute */
+	if (last_iscsi_name && strlen(last_iscsi_name))
+		ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+			last_iscsi_name);
+	else
+		/* Length must be zero in order to retrieve the first object */
+		ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME, NULL);
+	/* Delimiter to indicate division between Key and Operating attributes */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DELIMITER, 0, 0);
+	/* Operating Attribute */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_NODE_TYPE, 4,
+		ISCSI_NODE_TYPE_TARGET);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	/* Store ptr to last_iscsi_name in prb struct, so that
+	 * next_iscsi_name can be returned to caller in
+	 * dev_get_next_rsp */
+	prb->tgt_qry_iscsi_name = last_iscsi_name;
+	prb->tgt_qry_buf = tgt_qry_buf;
+	prb->tgt_qry_buf_len = tgt_qry_buf_len;
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+
+}
+
+void ql4_isns_send_dev_attr_qry(struct scsi_qla_host *ha,
+				__u8 *last_iscsi_name,
+				__u8 *tgt_qry_buf,
+				__u32 *tgt_qry_buf_len)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_DevAttrQry);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* Key Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		last_iscsi_name);
+	/* Delimiter to indicate division between Key and Operating attrs */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DELIMITER, 0, 0);
+	/* Operating Attributes fo register */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ENTITY_PROTOCOL, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_NAME, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_NODE_TYPE, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_ALIAS, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PORTAL_IP_ADDRESS, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PORTAL_PORT, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PORTAL_SECURITY_BITMAP, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PG_ISCSI_NAME, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PG_PORTAL_IP_ADDRESS, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PG_PORTAL_PORT, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PG_TAG, 0, 0);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DD_ID, 0, 0);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	/* Store ptr to tgt_qry_buf, so that data can be
+	 * returned to caller in dev_attr_qry_rsp */
+	prb->tgt_qry_buf = tgt_qry_buf;
+	prb->tgt_qry_buf_len = tgt_qry_buf_len;
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+static void ql4_isns_send_dev_attr_reg(struct scsi_qla_host *ha)
+{
+	struct isns_prb *prb;
+	struct isnsp_message *pdu;
+	__u8 *ptr;
+
+	prb = ql4_isns_get_prb(ha, PAGE_SIZE);
+	if (!prb) {
+		return;
+	}
+
+	pdu = (struct isnsp_message *) prb->pdu;
+	ptr = (__u8 *) &pdu->attributes[0];
+
+	ql4_isns_create_header(ha, &pdu->hdr, ISNS_FUNC_DevAttrReg);
+	/* Source Attribute */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	/* No Key Attribute for DevAttrReg */
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_DELIMITER, 0, 0);
+	/* Operating Attributes fo register */
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ENTITY_IDENTIFIER,
+		ha->isns.entity_id);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ENTITY_PROTOCOL, 4,
+		ISNS_ENTITY_PROTOCOL_TPYE_ISCSI);
+	ql4_isns_append_attr_ip(ha, &ptr, ISNS_ATTR_PORTAL_IP_ADDRESS,
+		ha->isns.source_ip);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_PORTAL_PORT, 4,
+		(__u32) ha->isns.source_port);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_SCN_PORT, 4,
+		(__u32) ha->isns.scn_port);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ESI_PORT, 4,
+		(__u32) ha->isns.esi_port);
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_NAME,
+		ha->name_string);
+	ql4_isns_append_attr(ha, &ptr, ISNS_ATTR_ISCSI_NODE_TYPE, 4,
+		ISNS_ISCSI_NODE_TYPE_INITIATOR);
+	ql4_isns_append_attr_str(ha, &ptr, ISNS_ATTR_ISCSI_ALIAS, ha->alias);
+
+	prb->conn_id = ISNS_DEFAULT_SERVER_CONN_ID;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_REQ_RSP_PDU, prb);
+	prb->tx_len  = (__u16)(ptr - &prb->pdu[0]);
+	prb->rx_len  = prb->pdu_buf_len;
+	pdu->hdr.pdu_len = htons(prb->tx_len - sizeof(struct isnsp_header));
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+/**********************   iSNS Parse functions   ***********************/
+#if defined(QL_DEBUG_LEVEL_6)
+static void ql4_isns_parse_scn(struct scsi_qla_host *ha,
+			       struct isnsp_message *pdu)
+{
+	struct isnsp_attribute *attr =
+		(struct isnsp_attribute *) &pdu->attributes[0];
+	__u32 bytes_processed = 0;
+
+	__u16 pdu_len = ntohs(pdu->hdr.pdu_len);
+
+	DEBUG6(ql4_info(ha, "SCN Attributes:\n"));
+	while ((bytes_processed + sizeof(*attr) + ntohl(attr->len)) <
+	       pdu_len) {
+
+		uint32_t tag = ntohl(attr->tag);
+		uint32_t len = ntohl(attr->len);
+
+		switch (tag) {
+		case ISNS_ATTR_ISCSI_NAME:
+			DEBUG6(ql4_info(ha, "\t%s \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+				attr->val));
+		case ISNS_ATTR_ISCSI_SCN_BITMAP:
+			DEBUG6(ql4_info(ha, "\t%s = \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                ql4_prn_str(ntohl(*(__u32 *)attr->val),
+					&iscsi_scn_str[0])));
+			break;
+		case ISNS_ATTR_TIMESTAMP:
+			DEBUG6(ql4_info(ha, "\t%s 0x%llx\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+					be64_to_cpu(*(__u64 *)attr->val)));
+		default:
+			DEBUG6(ql4_info(ha, "\t%s\n",
+                               ql4_prn_str((int)attr->tag, &isns_attr_str[0])));
+			break;
+		}
+
+		bytes_processed += sizeof(struct isnsp_attribute) + len;
+		attr = (struct isnsp_attribute *) (&attr->val[0] + len);
+	}
+}
+#endif
+
+static void ql4_isns_parse_dev_attr_reg_rsp(struct scsi_qla_host *ha,
+					    struct isnsp_response *pdu)
+{
+	struct isnsp_attribute *attr =
+		(struct isnsp_attribute *) &pdu->attributes[0];
+	__u32 bytes_processed = 0;
+
+	DEBUG6(ql4_info(ha, "Attributes:\n"));
+
+	pdu->hdr.pdu_len = ntohs(pdu->hdr.pdu_len);
+	while ((bytes_processed + sizeof(*attr) + ntohl(attr->len)) <
+	       pdu->hdr.pdu_len) {
+		__u32 val32 = ntohl(*(__u32 *)attr->val);
+		attr->tag = ntohl(attr->tag);
+		attr->len = ntohl(attr->len);
+
+		switch (attr->tag) {
+		case ISNS_ATTR_PORTAL_PORT:
+		case ISNS_ATTR_SCN_PORT:
+		case ISNS_ATTR_ESI_PORT:
+		case ISNS_ATTR_REGISTRATION_PERIOD:
+			DEBUG6(ql4_info(ha, "\t%s %d\n",
+				ql4_prn_str((int)attr->tag, &isns_attr_str[0]),
+                                val32));
+			break;
+		case ISNS_ATTR_ESI_INTERVAL:
+			DEBUG6(ql4_info(ha, "\t%s %d\n",
+				ql4_prn_str((int)attr->tag, &isns_attr_str[0]),
+                                val32));
+			ha->isns.esi_interval = val32;
+			atomic_set(&ha->isns.esi_timer,
+				ha->isns.esi_interval * 2);
+			break;
+		case ISNS_ATTR_ENTITY_PROTOCOL:
+			DEBUG6(ql4_info(ha, "\t%s %d\n",
+				ql4_prn_str((int)attr->tag, &isns_attr_str[0]),
+                                val32));
+			break;
+		case ISNS_ATTR_ISCSI_NODE_TYPE:
+			DEBUG6(ql4_info(ha, "\t%s = \"%s\"\n",
+				ql4_prn_str((int)attr->tag, &isns_attr_str[0]),
+                                ql4_prn_str(val32, &iscsi_node_type_str[0])));
+			break;
+		case ISNS_ATTR_PORTAL_IP_ADDRESS:
+			if (attr->val[10] == 0xFF && attr->val[11] == 0xFF) {
+				DEBUG6(ql4_info(ha, "\t%s %pI4\n",
+					ql4_prn_str((int)attr->tag,
+					&isns_attr_str[0]),
+					&attr->val[12]));
+			}
+			else {
+				DEBUG6(ql4_info(ha, "\t%s %pI6\n",
+					ql4_prn_str((int)attr->tag,
+					&isns_attr_str[0]),
+                                        (void *) attr->val));
+			}
+
+			break;
+		case ISNS_ATTR_ENTITY_IDENTIFIER:
+		case ISNS_ATTR_ISCSI_ALIAS:
+		case ISNS_ATTR_ISCSI_NAME:
+			DEBUG6(ql4_info(ha, "\t%s \"%s\"\n",
+				ql4_prn_str((int)attr->tag, &isns_attr_str[0]),
+                                attr->val));
+			break;
+		default:
+			DEBUG6(ql4_info(ha, "\t%s\n",
+			       ql4_prn_str((int)attr->tag, &isns_attr_str[0])));
+			break;
+		}
+
+		bytes_processed += sizeof(struct isnsp_attribute) + attr->len;
+		attr = (struct isnsp_attribute *) (&attr->val[0] + attr->len);
+	}
+}
+
+/* Remarks: Preserve endian-ness of structures as structure gets passed to
+ * Application */
+static void ql4_isns_parse_dev_get_next_rsp(struct scsi_qla_host *ha,
+                                            struct isns_prb *prb)
+{
+	struct isnsp_response *pdu =
+		(struct isnsp_response *) prb->pdu;
+	struct isnsp_attribute *attr =
+		(struct isnsp_attribute *) &pdu->attributes[0];
+	__u16 pdu_len = ntohs(pdu->hdr.pdu_len);
+	__u32 bytes_processed = 0;
+	__u8 is_tgt = 0;
+	__u8 is_node_reported = 0;
+	__u8 is_ioctl = 0;
+
+	is_ioctl = test_and_clear_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY,
+		    &ha->isns.flags);
+
+	switch (ntohl(pdu->status_code)) {
+	case ISNS_STS_SUCCESS:
+		/* Return Next iSCSI Name to caller */
+	        if (is_ioctl && prb->tgt_qry_iscsi_name)
+			strcpy(prb->tgt_qry_iscsi_name, &attr->val[0]);
+		break;
+	case ISNS_STS_NO_SUCH_ENTRY:
+		/* Return NULL iSCSI Name to caller to indicate no more tgts */
+	        if (is_ioctl && prb->tgt_qry_iscsi_name)
+			strcpy(prb->tgt_qry_iscsi_name, "");
+                DEBUG2(ql4_info(ha, "%s: No more targets\n", __func__));
+		goto exit_dev_get_next_attrs;
+	default:
+		DEBUG2(ql4_info(ha, "%s: Get next failed\n", __func__));
+		goto exit_dev_get_next_attrs;
+	}
+
+	/* Copy the tgts buf and buf len back to the caller */
+	if (prb->tgt_qry_buf && prb->tgt_qry_buf_len) {
+	        *prb->tgt_qry_buf_len = pdu_len + sizeof(pdu->hdr);
+		memcpy(prb->tgt_qry_buf, pdu,
+			*prb->tgt_qry_buf_len);
+	}
+
+
+	DEBUG6(ql4_info(ha, "DevGetNextRsp Attributes:\n"));
+	while ((bytes_processed + sizeof(*attr) + ntohl(attr->len)) < pdu_len) {
+		__u32 tag = ntohl(attr->tag);
+		__u32 len = ntohl(attr->len);
+
+		switch (tag) {
+		case ISNS_ATTR_ISCSI_NAME:
+			DEBUG6(ql4_info(ha, "\t%s \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                attr->val));
+			break;
+		case ISNS_ATTR_ISCSI_NODE_TYPE:
+			DEBUG6(ql4_info(ha, "\t%s = \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                ql4_prn_str(ntohl(*(__u32 *)attr->val),
+					&iscsi_node_type_str[0])));
+			is_node_reported = 1;
+			if (*(__u32 *)attr->val == ISCSI_NODE_TYPE_TARGET)
+				is_tgt = 1;
+			break;
+		default:
+			DEBUG6(ql4_info(ha, "\t%s\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0])));
+			break;
+		}
+
+		bytes_processed += sizeof(struct isnsp_attribute) + len;
+		attr = (struct isnsp_attribute *) (&attr->val[0] + len);
+	}
+
+exit_dev_get_next_attrs:
+	return;
+}
+
+/* Remarks: Preserve endian-ness of structures as structure gets passed to
+ * Application */
+static void ql4_isns_parse_dev_attr_qry_rsp(struct scsi_qla_host *ha,
+					    struct isns_prb *prb)
+{
+	struct isnsp_response *pdu =
+		(struct isnsp_response *) prb->pdu;
+	struct isnsp_attribute *attr =
+		(struct isnsp_attribute *) &pdu->attributes[0];
+	__u32 bytes_processed = 0;
+	__u16 pdu_len = ntohs(pdu->hdr.pdu_len);
+
+	/* Copy the tgts buf and buf len back to the caller */
+	if (prb->tgt_qry_buf && prb->tgt_qry_buf_len) {
+		*prb->tgt_qry_buf_len = pdu_len + sizeof(pdu->hdr);
+		memcpy(prb->tgt_qry_buf, pdu,
+			*prb->tgt_qry_buf_len);
+	}
+
+	DEBUG6(ql4_info(ha, "DevAttrQryRsp Attributes:\n"));
+	while ((bytes_processed + sizeof(*attr) + ntohl(attr->len)) < pdu_len) {
+
+		__u32 tag = ntohl(attr->tag);
+		__u32 len = ntohl(attr->len);
+
+		switch (tag) {
+		case ISNS_ATTR_PORTAL_PORT:
+		case ISNS_ATTR_PG_PORTAL_PORT:
+		case ISNS_ATTR_SCN_PORT:
+		case ISNS_ATTR_ESI_PORT:
+		case ISNS_ATTR_REGISTRATION_PERIOD:
+		case ISNS_ATTR_ESI_INTERVAL:
+		case ISNS_ATTR_ENTITY_PROTOCOL:
+		case ISNS_ATTR_DD_ID:
+		case ISNS_ATTR_PG_TAG:
+		case ISNS_ATTR_PORTAL_SECURITY_BITMAP:
+			DEBUG6(ql4_info(ha, "\t%s %d\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                ntohl(*(__u32 *)attr->val)));
+			break;
+		case ISNS_ATTR_ISCSI_NODE_TYPE:
+			DEBUG6(ql4_info(ha, "\t%s = \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                ql4_prn_str(ntohl(*(__u32 *)attr->val),
+					&iscsi_node_type_str[0])));
+			break;
+		case ISNS_ATTR_MGMT_IP_ADDRESS:
+		case ISNS_ATTR_PORTAL_IP_ADDRESS:
+		case ISNS_ATTR_PG_PORTAL_IP_ADDRESS:
+			if (attr->val[10] == 0xFF && attr->val[11] == 0xFF) {
+				DEBUG6(ql4_info(ha, "\t%s %pI4\n",
+					ql4_prn_str((int)tag, &isns_attr_str[0]),
+					&attr->val[12]));
+			}
+			else {
+				DEBUG6(ql4_info(ha, "\t%s %pI6\n",
+				       ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                       (void *) attr->val));
+			}
+
+			break;
+		case ISNS_ATTR_ENTITY_IDENTIFIER:
+		case ISNS_ATTR_ISCSI_ALIAS:
+		case ISNS_ATTR_ISCSI_NAME:
+		case ISNS_ATTR_PORTAL_SYMBOLIC_NAME:
+		case ISNS_ATTR_PG_ISCSI_NAME:
+			DEBUG6(ql4_info(ha, "\t%s \"%s\"\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0]),
+                                attr->val));
+			break;
+		default:
+			DEBUG6(ql4_info(ha, "\t%s\n",
+				ql4_prn_str((int)tag, &isns_attr_str[0])));
+			break;
+		}
+
+		bytes_processed += sizeof(struct isnsp_attribute) + len;
+		attr = (struct isnsp_attribute *) (&attr->val[0] + len);
+	}
+
+	clear_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY, &ha->isns.flags);
+}
+
+/**
+* ql4_isns_process_response_pdu - Final processing of received PDU (Async or
+* Response Msg)
+*
+* @ha: Pointer to Host Adapter structure
+* @prb: Pointer to PDU Request Block structure
+**/
+static void ql4_isns_process_response_pdu(struct scsi_qla_host *ha,
+					  struct isns_prb *prb)
+{
+	struct isnsp_header *pdu = (struct isnsp_header *) prb->pdu;
+	__u16 func_id = ntohs(pdu->func_id);
+
+	if ((func_id & ISNS_FUNC_RESPONSE) == 0) {
+		/* Async Message PDU */
+		switch (func_id) {
+		case ISNS_FUNC_ESI:
+			DEBUG2(ql4_info(ha, "ESI Message Received\n"));
+			atomic_set(&ha->isns.esi_timer,
+				ha->isns.esi_interval * 2);
+			ql4_isns_send_async_msg_rsp(ha, prb);
+			break;
+		case ISNS_FUNC_SCN:
+			DEBUG2(ql4_info(ha, "SCN Message Received\n"));
+			DEBUG2(ql4_isns_parse_scn(ha,
+				(struct isnsp_message *) pdu));
+			ql4_isns_send_async_msg_rsp(ha, prb);
+
+			/* Tell app to retrieve tgt database */
+			ql4_queue_isns_sts_chg_aen(ha,
+				ISNS_CHG_TGT_DATABASE);
+			break;
+		}
+	} else {
+		/* Response PDU */
+		struct isnsp_response *rsp =  (struct isnsp_response *) pdu;
+		__u32 status_code = ntohl(rsp->status_code);
+
+		if (status_code)
+			DEBUG6(ql4_info(ha, "%s: iSNS Error (%d) "
+				"\"%s\"\n", __func__, status_code,
+				ql4_prn_str(status_code,
+				&isns_sts_str[0])));
+
+		switch (func_id) {
+		case ISNS_FUNC_SCNDeregRsp:
+			clear_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+				&ha->isns.flags);
+			ql4_isns_send_dev_dereg(ha);
+			break;
+		case ISNS_FUNC_DevDeregRsp:
+			clear_bit(ISNS_FLAG_ISNS_SRV_REGISTERED,
+				  &ha->isns.flags);
+			clear_bit(ISNS_FLAG_SRV_DEREG_IN_PROGRESS,
+					&ha->isns.flags);
+			break;
+		case ISNS_FUNC_DevAttrRegRsp:
+			if (status_code) {
+				clear_bit(ISNS_FLAG_ISNS_SRV_REGISTERED,
+					  &ha->isns.flags);
+			} else {
+				set_bit(ISNS_FLAG_ISNS_SRV_REGISTERED,
+					  &ha->isns.flags);
+				ql4_isns_parse_dev_attr_reg_rsp(ha, rsp);
+				ql4_isns_send_scn_reg(ha);
+			}
+			break;
+		case ISNS_FUNC_SCNRegRsp:
+			if (status_code) {
+				clear_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+					  &ha->isns.flags);
+			} else {
+				set_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+					&ha->isns.flags);
+				/* Tell app to retrieve tgt database */
+				ql4_queue_isns_sts_chg_aen(ha,
+					ISNS_CHG_TGT_DATABASE);
+			}
+			break;
+		case ISNS_FUNC_DevGetNextRsp:
+			ql4_isns_parse_dev_get_next_rsp(ha, prb);
+			break;
+		case ISNS_FUNC_DevAttrQryRsp:
+			ql4_isns_parse_dev_attr_qry_rsp(ha, prb);
+			break;
+		default:
+			DEBUG2(ql4_info(ha, "%s: Unknown iSNS function ID "
+				"0x%x\n", __func__, func_id));
+		}
+	}  /* response pdu */
+}
+
+/**
+ * ql4_isns_process_ip_state_chg -
+ * This function is called when an IP state change has occurred
+ * (i.e. initiator's IP address has changed, iSNS start/stop, etc).
+ **/
+void ql4_isns_process_ip_state_chg(struct scsi_qla_host *ha, __u32 *mbox_sts)
+{
+	uint32_t old_state = mbox_sts[2];
+	uint32_t new_state = mbox_sts[3];
+	uint32_t source_ip_index = mbox_sts[5] & IPADDR_STATECHG_IP_INDEX_MASK;
+
+	DEBUG6(ql4_info(ha, "%s: old_state=%d, new_state=%d, src_ip_idx=%d"
+		"is_ip4=%d\n", __func__, old_state, new_state, source_ip_index,
+		is_ipv4_enabled(ha)));
+
+	if (test_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: ISNS_FLAG_DISABLE_IN_PROGRESS.  "
+			"Do not process.\n", __func__));
+		return;
+	}
+
+	if ((old_state != ACB_STATE_DEPRICATED &&
+	     old_state != ACB_STATE_VALID) &&
+	    (new_state == ACB_STATE_DEPRICATED ||
+	     new_state == ACB_STATE_VALID) &&
+	    (((source_ip_index == IP_INDEX_IPv4) && is_ipv4_enabled(ha)) ||
+	     ((source_ip_index != IP_INDEX_IPv4) && is_ipv6_enabled(ha)))) {
+		set_bit(DPC_ISNS_START, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: START ISNS SERVICE\n", __func__));
+	}
+
+	if ((old_state == ACB_STATE_DEPRICATED ||
+	     old_state == ACB_STATE_VALID) &&
+	    (new_state != ACB_STATE_DEPRICATED &&
+	     new_state != ACB_STATE_VALID)) {
+		set_bit(DPC_ISNS_STOP, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: STOP ISNS SERVICE\n", __func__));
+	}
+
+	if (((old_state != ACB_STATE_DEPRICATED &&
+	      new_state == ACB_STATE_VALID) ||
+	     (old_state != ACB_STATE_VALID &&
+	      new_state == ACB_STATE_DEPRICATED)) &&
+	    (source_ip_index != ha->isns.source_ip_index)) {
+		set_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: Re-register with iSNS server\n",
+				__func__));
+	}
+}
+
+/**********************    PDU Functions    *********************/
+
+static __u8 ql4_isns_realloc_pdu(struct scsi_qla_host *ha,
+                                 struct isns_prb *prb,
+                                 __u32 new_pdu_size)
+{
+	__u8 *new_pdu;
+	dma_addr_t new_pdu_dma;
+
+	/* Overrun condition where new PDU too large
+	 * for original PDU.  Allocate larger PDU
+	 * before requesting remaining data. */
+	new_pdu = dma_alloc_coherent(&ha->pdev->dev,
+		new_pdu_size, &new_pdu_dma, GFP_KERNEL);
+	if (!new_pdu) {
+		DEBUG6(ql4_info(ha, "%s: ERROR: "
+			"Unable to allocate larger PDU "
+			"buffer (0x%x). Discard PDU\n",
+			__func__, new_pdu_size));
+		return QLA_ERROR;
+	}
+
+	memcpy(new_pdu, prb->pdu, prb->offset);
+	dma_free_coherent(&ha->pdev->dev, prb->pdu_buf_len,
+		prb->pdu, prb->pdu_dma);
+	prb->pdu = new_pdu;
+	prb->pdu_dma = new_pdu_dma;
+	prb->pdu_buf_len = (new_pdu_size +
+		(PAGE_SIZE-1)) & ~(PAGE_SIZE-1);
+	DEBUG6(ql4_info(ha, "%s: larger PDU allocated"
+		" to hold larger pdu of 0x%x\n",
+		__func__, new_pdu_size));
+	DEBUG7(__dump_prb(ha,prb));
+	return QLA_SUCCESS;
+}
+
+static __u8 ql4_isns_validate_pdu_hdr(struct scsi_qla_host *ha,
+                                  struct isnsp_header *pdu,
+				  __u16 seq_id, __u8 is_first_pdu)
+{
+	__u16 func_id = ntohs(pdu->func_id);
+	__u16 trans_id = ntohs(pdu->trans_id);
+	__u16 flags = ntohs(pdu->flags);
+	__u8 status = QLA_ERROR;
+
+	if (ntohs(pdu->ver) != ISNSP_VERSION) {
+		DEBUG6(ql4_info(ha, "%s: ERROR: Invalid version in "
+			"hdr. (%d, expecting %d).  Discard PDU\n",
+			__func__, ntohs(pdu->ver), ISNSP_VERSION));
+		goto exit_validate_pdu;
+	}
+	if (seq_id != ntohs(pdu->seq_id)) {
+		DEBUG6(ql4_info(ha, "%s: ERROR: Invalid sequence # in "
+			"pdu. (%d, expecting %d).  Discard PDU\n",
+			__func__, ntohs(pdu->seq_id), seq_id));
+		goto exit_validate_pdu;
+	}
+
+	if (!is_first_pdu) {
+		/* Continue validation of succeeding pdu headers */
+		if (flags & ISNSP_FLAG_FIRST_PDU) {
+			DEBUG6(ql4_info(ha, "%s: ERROR: FIRST_PDU flag "
+				"set in succeeding PDU.  Discard PDU\n",
+				__func__));
+			goto exit_validate_pdu;
+		}
+		if (func_id != ntohs(pdu->func_id)) {
+			DEBUG6(ql4_info(ha, "%s: ERROR: Invalid "
+				"function# in pdu. (%d, expecting %d)."
+				"  Discard PDU\n", __func__,
+				ntohs(pdu->func_id), func_id));
+			goto exit_validate_pdu;
+		}
+		if (trans_id != ntohs(pdu->trans_id)) {
+			DEBUG6(ql4_info(ha, "%s: ERROR: Invalid "
+				"trans# in pdu. (%d, expecting %d)."
+				"  Discard PDU\n", __func__,
+				ntohs(pdu->trans_id), trans_id));
+			goto exit_validate_pdu;
+		}
+	}
+
+	status = QLA_SUCCESS;
+
+exit_validate_pdu:
+	return status;
+}
+
+/**
+ *  ql4_isns_validate_and_reassemble_pdu -
+ *
+ *  iSNS messages may be packaged in one or more PDUs having the same
+ *  function id and transaction id.  However, each PDU of the same message
+ *  will have a unique sequence id. (RFC 4171, 5.2)
+ *
+ *  This function will reassemble multiple PDUs into a single PDU so that
+ *  it may be processed by the driver.
+ **/
+static __u8 ql4_isns_validate_and_reassemble_pdu(struct scsi_qla_host *ha,
+                                                 struct isns_prb *prb)
+{
+	struct isnsp_header *first_pdu = (struct isnsp_header *) prb->pdu;
+	struct isnsp_header *pdu = first_pdu;
+	__u16 seq_id = (-1);
+	__u16 flags = ntohs(pdu->flags);
+	__u8 status = QLA_ERROR;
+	__u32 bytes_remaining;
+	__u32 new_pdu_len = ntohs(first_pdu->pdu_len);
+
+	if (prb->resid_flags & PT_STATUS_RESID_DATA_IN_OVERRUN)
+		prb->offset += prb->rx_len;
+	else
+		prb->offset += prb->rx_len - prb->in_residual;
+
+	bytes_remaining = prb->offset;
+
+	do {
+		__u8 is_first_pdu = (first_pdu == pdu);
+		__u16 pdu_len = ntohs(pdu->pdu_len);
+		__u16 pdu_size = sizeof(*pdu) + pdu_len;
+
+		/* Sometimes the pdu_len indicates that the PDU is actually
+		 * larger than the amount indicated in the original 8021 Async
+		 * Data AEN.  If the original PDU buffer is not large enough,
+		 * then allocate a larger PDU. */
+		if (is_first_pdu && (pdu_size > prb->pdu_buf_len)) {
+			if (ql4_isns_realloc_pdu(ha, prb, pdu_size)
+			    == QLA_ERROR)
+				goto exit_reassemble_pdu;
+		}
+
+		/* Validate pdu header */
+		if (ql4_isns_validate_pdu_hdr(ha, pdu, ++seq_id, is_first_pdu)
+		    == QLA_ERROR)
+			goto exit_reassemble_pdu;
+
+		/* For multiple PDUs in sequence, copy the flags and payload
+		 * from the succeeding pdus to the first PDU */
+		if (!is_first_pdu) {
+			flags |= ntohs(pdu->flags);
+			memmove(&first_pdu->payload[0] + new_pdu_len,
+				&pdu->payload[0], pdu_len);
+
+			new_pdu_len += pdu_size;
+		} else if (prb->offset <= pdu_size) {
+			/* If there is only one PDU and all the bytes are here,
+			 * or if we are waiting for the rest of the pdu;
+			 * exit as no reassembly is required */
+			status = QLA_SUCCESS;
+			goto exit_reassemble_pdu;
+		}
+
+		/* Check to see if there are enough bytes in the PDU and
+		   adjust bytes_remaining accordingly */
+		if (bytes_remaining >= pdu_size)
+			bytes_remaining -= pdu_size;
+		else {
+			/* Malformed packet - The number of bytes doesn't
+			 * add up to what's specified in the PDU. */
+			DEBUG2(ql4_info(ha,
+				"%s: Malformed packet size (0x%x)\n",
+				__func__, pdu_size));
+			goto exit_reassemble_pdu;
+		}
+
+		/* Advance to next pdu */
+		pdu = (struct isnsp_header *) (&first_pdu->payload[0] +
+			new_pdu_len);
+	} while (bytes_remaining);
+
+	/* Update first pdu */
+	first_pdu->flags = htons(flags);
+	first_pdu->pdu_len = htons(new_pdu_len);
+	prb->rx_len = sizeof(*pdu) + new_pdu_len;
+
+	status = QLA_SUCCESS;
+
+ exit_reassemble_pdu:
+	return status;
+}
+
+/**
+ *  ql4_isns_is_underrun_pdu -
+ *
+ *  This function determines if we have an underrun/overrun condition
+ *  and need to request the remaining data from the firmware via Passthru
+ *  IOCB.  The firmware will not send us another 8021 Async Data AEN to
+ *  inform us that there is more data to retrieve.
+ *
+ *  The following cases are considered underruns:
+ *  1. The PDU payload contains less than the data length specified
+ *     in the 8021 Async Data AEN.
+ *  2. The PDU data length indicates that there is more data to be
+ *     transferred than specified in the 8021 Async Data AEN.
+ *  3. We only received one PDU of a message split into multiple PDUs.
+ **/
+static __u8 ql4_isns_is_underrun_pdu(struct scsi_qla_host *ha,
+				     struct isns_prb *prb)
+{
+	struct isnsp_header *hdr = (struct isnsp_header *) prb->pdu;
+	__u16 flags = ntohs(hdr->flags);
+#if defined(QL_DEBUG_LEVEL_6)
+	__u16 trans_id = ntohs(hdr->trans_id);
+#endif
+	__u16 pdu_size = ntohs(hdr->pdu_len) + sizeof(*hdr);
+	__u8 pdu_underrun = 0;
+
+	if (prb->offset < pdu_size) {
+		DEBUG6(ql4_info(ha, "%s: tid=0x%x  cid=0x%x PDU over/underrun. "
+			"Residual=%lx. Request remaining payload\n",
+			__func__, trans_id, prb->conn_id,
+			(u_long)(pdu_size - prb->offset) ));
+		pdu_underrun = 1;
+	} else if ((prb->offset == pdu_size) &&
+		   !(flags & ISNSP_FLAG_LAST_PDU)) {
+		/* It's possible for multiple PDUs to make up a single PDU
+		 * message.  Request the remaining PDUs and reassemble them
+		 * later. */
+		DEBUG2(ql4_info(ha, "%s: tid=0x%x  cid=0x%x LAST_PDU flag not "
+			"set. Request remaining payload\n",
+			__func__, trans_id, prb->conn_id));
+		pdu_underrun = 1;
+	}
+
+	return pdu_underrun;
+}
+
+/**********************    Start/Stop Functions    *********************/
+
+void ql4_isns_populate_server_ip(struct scsi_qla_host *ha,
+				 struct addr_ctrl_blk *init_fw_cb)
+{
+	if (init_fw_cb == NULL) {
+		DEBUG2(ql4_info(ha, "%s: ERROR: NULL ifcb pointer \n",
+			__func__));
+		return;
+	}
+	ha->isns.server_port = le16_to_cpu(init_fw_cb->isns_svr_port);
+
+	if (is_isnsv4_enabled(ha) &&
+	    !ql4_is_memzero(init_fw_cb->ipv4_isns_svr_ip,
+                     sizeof(init_fw_cb->ipv4_isns_svr_ip))) {
+
+		/* encoded as IPv4-mapped IPv6 address */
+		memset(&ha->isns.server_ip[0], 0, sizeof(ha->isns.server_ip));
+                ha->isns.server_ip[10] = 0xFF;
+                ha->isns.server_ip[11] = 0xFF;
+		memcpy(&ha->isns.server_ip[12],
+		       init_fw_cb->ipv4_isns_svr_ip,
+                       sizeof(init_fw_cb->ipv4_isns_svr_ip));
+		DEBUG2(ql4_info(ha, "%s: iSNS ENABLED. Server IP %pI4: %d\n",
+			__func__, (void *) &ha->isns.server_ip[12],
+			ha->isns.server_port));
+	} else if (is_isnsv6_enabled(ha) &&
+		   !ql4_is_memzero(init_fw_cb->ipv6_isns_svr_ip,
+                            sizeof(init_fw_cb->ipv6_isns_svr_ip))) {
+
+		memcpy(ha->isns.server_ip,
+		       init_fw_cb->ipv6_isns_svr_ip,
+                       sizeof(init_fw_cb->ipv6_isns_svr_ip));
+		DEBUG2(ql4_info(ha, "%s: iSNS ENABLED. Server IP %pI6:"
+				" %d\n", __func__,
+			(void *) ha->isns.server_ip, ha->isns.server_port));
+	} else {
+		DEBUG2(ql4_info(ha, "%s: iSNS DISABLED \n",  __func__));
+		ql4_isns_clear_flags(ha);
+	}
+}
+
+/**
+ * ql4_isns_populate_source_ip - Populate iSNS Source IP Address
+ * @ha: Pointer to Host Adapter structure
+ *
+ * Fill in iSNS Source (Initiator) IP Address based on the current
+ * iSNS Source IP Index
+ **/
+static void
+ql4_isns_populate_source_ip(struct scsi_qla_host *ha)
+{
+       memset(ha->isns.source_ip, 0, sizeof(ha->isns.source_ip));
+       if (ha->isns.source_ip_index == IP_INDEX_IPv4) {
+               /* encoded as IPv4-mapped IPv6 address */
+               ha->isns.source_ip[10] = 0xFF;
+               ha->isns.source_ip[11] = 0xFF;
+               memcpy(&ha->isns.source_ip[12], &ha->ip_address, 4);
+
+	       DEBUG6(ql4_info(ha, "%s: iSNS Source IPv4 Address = %pI4 "
+			       "idx=%d\n", __func__, ha->ip_address,
+				ha->isns.source_ip_index));
+       } else {
+	       switch (ha->isns.source_ip_index) {
+	       case IP_INDEX_IPv6_ADDR0:
+		       memcpy(&ha->isns.source_ip[0], &ha->ipv6_addr0,
+			      min(sizeof(ha->ipv6_addr0),
+				  sizeof(ha->isns.source_ip)));
+		       break;
+	       case IP_INDEX_IPv6_ADDR1:
+		       memcpy(&ha->isns.source_ip[0], &ha->ipv6_addr1,
+			      min(sizeof(ha->ipv6_addr1),
+				  sizeof(ha->isns.source_ip)));
+		       break;
+	       case IP_INDEX_IPv6_LINK_LOCAL:
+		       memcpy(&ha->isns.source_ip[0], &ha->ipv6_link_local_addr,
+			      min(sizeof(ha->ipv6_link_local_addr),
+				  sizeof(ha->isns.source_ip)));
+		       break;
+	       }
+
+	       DEBUG6(ql4_info(ha, "%s: iSNS Source IPv6 Address = %pI6"
+			" idx=%d\n", __func__,
+			(void *) ha->isns.source_ip,
+			ha->isns.source_ip_index));
+       }
+}
+
+static void ql4_isns_process_isns_conn_open(struct scsi_qla_host *ha,
+					    __u32 *mbox_sts)
+{
+	__u16 conn_id		= (__u16) (mbox_sts[2] & 0x0000FFFF);
+	ha->isns.source_port	= (__u16) (mbox_sts[2] >> 16);
+	ha->isns.scn_port	= (__u16) (mbox_sts[3] >> 16);
+	ha->isns.esi_port	= (__u16) (mbox_sts[4] >> 16);
+
+	if (test_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: ISNS_FLAG_DISABLE_IN_PROGRESS.  "
+			"Do not process.\n", __func__));
+		return;
+	}
+
+	if (conn_id == (__u16) -1) {
+		DEBUG2(ql4_info(ha, "%s: "
+			"iSNS Server refused connection!\n", __func__));
+		ql4_isns_restart_service(ha);
+		return;
+	}
+
+	atomic_set(&ha->isns.state, ISNS_STATE_TCP_CONNECTED);
+
+	ha->isns.source_ip_index = mbox_sts[6];
+        ql4_isns_populate_source_ip(ha);
+
+	DEBUG2(ql4_info(ha, "%s: Entity ID \"%s\" Conn ID %d "
+		"SCN Listen %d ESI Listen %d!\n",
+		__func__, ha->isns.entity_id, conn_id,
+		ha->isns.scn_port, ha->isns.esi_port));
+	if (!ha->isns.scn_port)
+		ql4_info(ha, "ERROR: SCN Listening Port is NULL! "
+			"iSNS Database changes will not be detected!\n");
+	if (!ha->isns.esi_port)
+		ql4_info(ha, "ERROR: ESI Listening Port is NULL! "
+                        "Frequent iSNS server registration will occur!\n");
+
+	ql4_isns_register_isns_server(ha);
+}
+
+/**
+ *  ql4_isns_get_remaining_payload -
+ *
+ *  We are retrieving the remaining data for a previous underrun pdu.
+ *  The remaining data will be appended to the pdu starting at prb->offset.
+ **/
+static void ql4_isns_get_remaining_payload(struct scsi_qla_host *ha,
+                                           struct isns_prb *prb)
+{
+	struct isnsp_message *msg = (struct isnsp_message *) prb->pdu;
+
+	prb->tx_len = 0;
+	prb->rx_len = ntohs(msg->hdr.pdu_len) + sizeof(*msg) - prb->offset;
+	prb->handle  = ql4_isns_build_iocb_handle(ha, ISNS_ASYNC_REQ_PDU, prb);
+
+	DEBUG6(ql4_info(ha, "%s: offset=0x%x, rx_len=0x%x\n",
+		__func__, prb->offset, prb->rx_len));
+
+	if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+		ql4_isns_free_prb(ha, prb);
+}
+
+/**
+ * ql4_isns_get_async_data - Request PDU payload for Async request
+ *
+ * Remarks: We received a *Data Received* status code from an
+ *          8021h AEN, so retrieve the data (i.e. ESI or SCN) via
+ *	    Passthru IOCB.
+ **/
+static void ql4_isns_get_async_data(struct scsi_qla_host *ha,
+				__u32 conn_id, __u32 payload_len)
+{
+	struct isns_prb *prb;
+
+	prb = ql4_isns_get_prb(ha, payload_len);
+	if (prb) {
+		prb->conn_id = (__u16) conn_id;
+		prb->tx_len = 0;
+		prb->rx_len = payload_len;
+		prb->handle = ql4_isns_build_iocb_handle(ha,
+			ISNS_ASYNC_REQ_PDU, prb);
+
+		if (ql4_isns_send_passthru_iocb(ha, prb) != QLA_SUCCESS)
+			ql4_isns_free_prb(ha, prb);
+	}
+}
+
+/**
+ * ql4_isns_process_passthru_sts_iocb - Performs initial processing of
+ * received PDU (Async or Response Msg
+ *
+ * @ha: Pointer to Host Adapter structure
+ * @prb: Pointer to PDU Request Block structure
+ *
+ * NOTE: The following passthru_status fields are NOT populated for 4032:
+ *	 - residual_flags in underrun case
+ *	 - in_residual in overrun case.
+ **/
+void ql4_isns_queue_passthru_sts_iocb(struct scsi_qla_host *ha,
+                                        struct isns_prb *prb)
+{
+	struct passthru_status *sts_entry =
+					(struct passthru_status *) prb->pkt;
+
+	if (sts_entry->cmpl_status != PASSTHRU_STATUS_COMPLETE){
+		DEBUG2(ql4_info(ha, "%s: ERROR: cmpl_status (0x%x)\n",
+			__func__, sts_entry->cmpl_status));
+		ql4_isns_free_prb(ha, prb);
+
+		set_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: Re-Register with iSNS server\n",
+					__func__));
+		return;
+	}
+
+	if (le32_to_cpu(sts_entry->handle) != prb->handle){
+		DEBUG2(ql4_info(ha, "%s: ERROR: handle mismatch iocb(0x%x)"
+					" prb (0x%x)\n", __func__,
+					sts_entry->handle, prb->handle));
+		ql4_isns_free_prb(ha, prb);
+		return;
+	}
+
+	mutex_lock(&ha->isns.prb_lock);
+	list_add_tail(&prb->list, &ha->isns.rcvd_pdu_list);
+	mutex_unlock(&ha->isns.prb_lock);
+
+	queue_work(ha->pt_thread, &ha->pt_work);
+}
+
+/**
+ * ql4_isns_dequeue_passthru_sts_iocb -  Process queued (Async or
+ * Response Msg) PDUs.
+ * @data: in our case pointer to adapter structure
+ **/
+void ql4_isns_dequeue_passthru_sts_iocb(struct work_struct *data)
+{
+	struct scsi_qla_host *ha =
+		container_of(data, struct scsi_qla_host, pt_work);
+	struct isns_prb *prb, *prb_tmp;
+
+	mutex_lock(&ha->isns.prb_lock);
+	list_for_each_entry_safe(prb, prb_tmp,
+		&ha->isns.rcvd_pdu_list, list) {
+		list_del_init(&prb->list);
+		mutex_unlock(&ha->isns.prb_lock);
+		ql4_isns_process_passthru_sts_iocb(ha, prb);
+		mutex_lock(&ha->isns.prb_lock);
+	}
+	mutex_unlock(&ha->isns.prb_lock);
+}
+
+/**
+ * ql4_isns_process_passthru_sts_iocb - Performs initial processing of
+ * received PDU (Async or Response Msg
+ *
+ * @ha: Pointer to Host Adapter structure
+ * @prb: Pointer to PDU Request Block structure
+ *
+ * NOTE: The following passthru_status fields are NOT populated for 4032:
+ *	 - residual_flags in underrun case
+ *	 - in_residual in overrun case.
+ **/
+void ql4_isns_process_passthru_sts_iocb(struct scsi_qla_host *ha,
+					struct isns_prb *prb)
+{
+	struct passthru_status *sts_entry = (struct passthru_status *) prb->pkt;
+#if defined(QL_DEBUG_LEVEL_6)
+	struct isnsp_header *pdu = (struct isnsp_header *) prb->pdu;
+	__u16 func_id = ntohs(pdu->func_id);
+	__u16 pdu_len = ntohs(pdu->pdu_len);
+#endif
+
+	prb->conn_id = __le16_to_cpu(sts_entry->conn_id);
+	prb->in_residual = __le32_to_cpu(sts_entry->in_residual);
+	prb->resid_flags = sts_entry->residual_flags;
+
+	DEBUG6(ql4_info(ha,"------------------------\n"));
+	DEBUG6(ql4_info(ha,"Receiving tid=0x%x cid=0x%x  %s  <- rx_len=0x%x "
+		"(Display MAX 100h)\n",
+		ntohs(pdu->trans_id), prb->conn_id,
+		ql4_prn_str(func_id, &isns_func_str[0]),
+		prb->rx_len));
+	DEBUG6(ql4_info(ha,"pdu_size=0x%x, in_residual=0x%x offset=0x%x "
+		"actual_rx=0x%x\n",
+		(__u32)(sizeof(*pdu) + pdu_len), prb->in_residual, prb->offset,
+		(prb->resid_flags & PT_STATUS_RESID_DATA_IN_OVERRUN) ?
+		prb->rx_len : prb->rx_len-prb->in_residual));
+	DEBUG6(qla4xxx_dump_bytes(prb->pdu + prb->offset,
+		min(prb->rx_len, (__u32)0x100)));
+	DEBUG7(__dump_prb(ha,prb));
+	DEBUG7(ql4_info(ha,"dump passthru status iocb %p\n", sts_entry));
+	DEBUG7(qla4xxx_dump_bytes(sts_entry, sizeof(*sts_entry)));
+
+	if (ql4_isns_validate_and_reassemble_pdu(ha, prb)
+	    != QLA_SUCCESS) {
+		ql4_isns_free_prb(ha, prb);
+		set_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: Re-Register with iSNS server\n",
+			__func__));
+		return;
+	}
+
+	if (ql4_isns_is_underrun_pdu(ha, prb))
+		/* If a PDU underrun has occurred, then we need to
+		 * request the remaining payload from the firmware */
+		ql4_isns_get_remaining_payload(ha, prb);
+	else {
+		ql4_isns_process_response_pdu(ha, prb);
+		ql4_isns_free_prb(ha, prb);
+	}
+ }
+
+/**
+ * ql4_isns_process_isns_aen - Process 8021h iSNS AEN
+ *
+ * Remarks: We received an 8021h AEN in response to a
+ *          Mailbox 21h (Enable iSNS) command, or the driver is
+ *	    being notified that Asynchronous data needs to be
+ *	    retrieved.
+ * Context: Interrupt
+ **/
+void ql4_isns_process_isns_aen(struct scsi_qla_host *ha, __u32 *mbox_sts)
+{
+	__u32 aen_status_code = mbox_sts[1];
+
+	switch (aen_status_code) {
+	case ISNS_EVENT_DATA_RECEIVED:
+	{
+		__u32 conn_id = mbox_sts[2];
+		__u32 payload_len = mbox_sts[3];
+
+		DEBUG6(ql4_info(ha, "AEN %04x, iSNS Async Data Received\n",
+			mbox_sts[0]));
+		ql4_isns_get_async_data(ha, conn_id, payload_len);
+		break;
+	}
+	case ISNS_EVENT_CONNECTION_OPENED:
+		DEBUG2(ql4_info(ha, "AEN %04x, iSNS Server Connection Open\n",
+			mbox_sts[0]));
+		ql4_isns_process_isns_conn_open(ha, mbox_sts);
+		break;
+	case ISNS_EVENT_CONNECTION_FAILED:
+		DEBUG2(ql4_info(ha,
+			"AEN %04x, iSNS Service Connection FAILED!"
+			" reason %04x\n", mbox_sts[0], mbox_sts[2]));
+
+		atomic_set(&ha->isns.state, ISNS_STATE_TCP_DISCONNECTED);
+		break;
+	default:
+		break;
+	}
+}
+
+/**
+ * ql4_is_isns_active -  Retrieve iSNS Server TCP Connection status
+ * @ha: Pointer to Host Adapter structure
+ * @return: 1=active, 0=not active
+ *
+ * Remarks: Sometimes the Application can stop the iSNS connection without the
+ * driver's knowledge, so the driver must get real-time status.
+ **/
+__u8 ql4_is_isns_active(struct scsi_qla_host *ha)
+{
+	__u32 mbox_cmd[MBOX_REG_COUNT];
+	__u32 mbox_sts[MBOX_REG_COUNT];
+	__u8 isns_active  = 0xFF;
+
+	memset(mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SET_ISNS_SERVICE;
+	mbox_cmd[1] = ISNS_REPORT_STATUS;
+
+	if (qla4xxx_mailbox_command(ha, 2, 6, &mbox_cmd[0], &mbox_sts[0])
+	    == QLA_ERROR) {
+		DEBUG2(ql4_info(ha,
+			"%s: MBOX_CMD_SET_ISNS_SERVICE failed. "
+			"status %04x %04x\n", __func__,
+			mbox_sts[0], mbox_sts[1]));
+
+		goto exit_get_svc_status;
+	}
+
+	isns_active = mbox_sts[5] & 0xF;
+
+exit_get_svc_status:
+	DEBUG6(ql4_info(ha, "%s (%d)\n", __func__, isns_active));
+	return(isns_active);
+}
+
+/**
+ * ql4_isns_deregister_isns_server - De-register with the iSNS server.
+ * @ha: Pointer to Host Adapter structure
+ *
+ *  NOTE: This function assumes that a TCP connection to the iSNS server is
+ *  currently established
+ **/
+__u8 ql4_isns_deregister_isns_server(struct scsi_qla_host *ha)
+{
+	__u8 status = QLA_SUCCESS;
+	unsigned long wtime;
+
+	DEBUG2(ql4_info(ha, "De-Register iSNS Server\n"));
+
+	/* NOTE: scn_dereg subsequently invokes dev_dereg */
+	ql4_isns_send_scn_dereg(ha);
+
+	/* Wait for deregistration to complete */
+	wtime = jiffies + (ISNS_DEREG_TOV * HZ);
+	while (!time_after_eq(jiffies, wtime)) {
+		if (!test_bit(ISNS_FLAG_SRV_DEREG_IN_PROGRESS, &ha->isns.flags))
+			break;
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(1 * HZ);
+	}
+
+	if (test_bit (ISNS_FLAG_SRV_DEREG_IN_PROGRESS, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, " ERROR: De-Register iSNS Server\n"));
+		ql4_isns_clear_flags(ha);
+		status = QLA_ERROR;
+	}
+
+	return status;
+}
+
+/**
+ * ql4_isns_register_isns_server - Register with the iSNS server.
+ * @ha: Pointer to Host Adapter structure
+ *
+ *  NOTE: This function assumes that a TCP connection to the iSNS server is
+ *  currently established
+ **/
+__u8 ql4_isns_register_isns_server(struct scsi_qla_host *ha)
+{
+	unsigned long wtime;
+	__u8 status = QLA_ERROR;
+	__u8 retry;
+
+	clear_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+
+	for (retry = 1; retry <= 2; retry++) {
+		/* If iSNS is already registered, de-register before
+		 * re-registering */
+		if (test_bit(ISNS_FLAG_ISNS_SRV_REGISTERED, &ha->isns.flags) ||
+		    retry > 1)
+			ql4_isns_deregister_isns_server(ha);
+
+		DEBUG2(ql4_info(ha, "Register iSNS Server\n"));
+		ql4_isns_send_dev_attr_reg(ha);
+
+		/* Wait for iSNS registration to complete */
+		wtime = jiffies + ISNS_DEREG_TOV * HZ;
+		while (!time_after_eq(jiffies, wtime)) {
+			if (test_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+			    &ha->isns.flags))
+				break;
+			set_current_state(TASK_UNINTERRUPTIBLE);
+			schedule_timeout(1 * HZ);
+		}
+
+		if (test_bit(ISNS_FLAG_ISNS_SCN_REGISTERED, &ha->isns.flags)) {
+			DEBUG2(ql4_info(ha, "Register iSNS Server complete\n"));
+			status = QLA_SUCCESS;
+			break;
+		} else
+			/* It's possible that there was a previous abnormal
+			 * exit that prevented iSNS server deregistration
+			 * (thus SRV_REGISTERED bit was not set); however,
+			 * we must first de-register with the iSNS server before
+			 * re-registering with it, so retry once */
+			DEBUG2(ql4_info(ha, "Retry register iSNS Server\n"));
+	}
+
+	if (status == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "Register iSNS Server failed\n"));
+	}
+	return status;
+}
+
+uint8_t ql4_isns_start_service(struct scsi_qla_host *ha)
+{
+	__u32 mbox_cmd[MBOX_REG_COUNT];
+	__u32 mbox_sts[MBOX_REG_COUNT];
+	__u8 status = QLA_ERROR;
+
+	if (test_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: ISNS_FLAG_DISABLE_IN_PROGRESS.  "
+			"Do not process.\n", __func__));
+		return status;
+	}
+
+	if (ql4_is_isns_active(ha)) {
+		DEBUG2(ql4_info(ha, "%s: iSNS connection already established.  "
+				"Stopping old connection first.\n", __func__));
+		ql4_isns_stop_service(ha);
+        }
+
+	DEBUG2(ql4_info(ha, "Connecting to iSNS Server...\n"));
+	atomic_set(&ha->isns.state, ISNS_STATE_STARTING_SRV);
+
+	memset(mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SET_ISNS_SERVICE;
+	mbox_cmd[3] = ha->isns.server_port;
+
+	if (ql4_is_memzero(&ha->isns.server_ip[0], sizeof(ha->isns.server_ip))) {
+		DEBUG6(ql4_info(ha, "%s: ERROR: iSNS Server IP is NULL!\n",
+			__func__));
+		goto exit_start_svc;
+	} else if (ql4_is_memzero(&ha->name_string[0], sizeof(ha->name_string))) {
+		DEBUG6(ql4_info(ha, "%s: ERROR: iSNS Name String is NULL!\n",
+			__func__));
+		goto exit_start_svc;
+	} else if (is_isnsv4_enabled(ha)) {
+		mbox_cmd[1] = ISNSv4_ENABLE;
+		mbox_cmd[2] |= ha->isns.server_ip[15] << 24;
+		mbox_cmd[2] |= ha->isns.server_ip[14] << 16;
+		mbox_cmd[2] |= ha->isns.server_ip[13] << 8;
+		mbox_cmd[2] |= ha->isns.server_ip[12];
+		DEBUG6(ql4_info(ha, "%s: iSNS Server IPv4 "NIPQUAD_FMT
+		", port %d\n", __func__,
+		NIPQUAD(ha->isns.server_ip[12]), ha->isns.server_port));
+	} else if (is_isnsv6_enabled(ha)) {
+		mbox_cmd[1] = ISNSv6_ENABLE;
+		memcpy(&mbox_cmd[4], ha->isns.server_ip,
+		       sizeof(ha->isns.server_ip));
+		DEBUG6(ql4_info(ha, "%s: iSNS Server IPv6 %pI6, port %d\n",
+			__func__, (void *) ha->isns.server_ip,
+			ha->isns.server_port));
+	}
+
+	ql4_isns_build_entity_id(ha);
+
+	status = qla4xxx_mailbox_command(ha, 8, 5, &mbox_cmd[0], &mbox_sts[0]);
+	if (status != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: "
+				"MBOX_CMD_SET_ISNS_SERVICE failed. "
+				"status %04x %04x\n", __func__,
+				mbox_sts[0], mbox_sts[1]));
+
+		/* Trigger DPC to poll for iSNS connection */
+		atomic_set(&ha->isns.state, ISNS_STATE_TCP_DISCONNECTED);
+	} else {
+		DEBUG6(ql4_info(ha, "%s: Wait for iSNS AEN. "
+				"status %04x %04x\n", __func__,
+				mbox_sts[0], mbox_sts[1]));
+	}
+
+exit_start_svc:
+	return status;
+}
+
+uint8_t ql4_isns_stop_service(struct scsi_qla_host *ha)
+{
+	__u32 mbox_cmd[MBOX_REG_COUNT];
+	__u32 mbox_sts[MBOX_REG_COUNT];
+	__u8 status = QLA_ERROR;
+
+	if (test_bit(ISNS_FLAG_ISNS_SRV_REGISTERED, &ha->isns.flags))
+		ql4_isns_deregister_isns_server(ha);
+
+	if (!ql4_is_isns_active(ha)) {
+		DEBUG2(ql4_info(ha, "%s: ERROR: iSNS Service not connected.\n",
+			__func__));
+		goto exit_stop_svc;
+	}
+
+	DEBUG2(ql4_info(ha, "Disconnecting from iSNS Server ...\n"));
+	memset(mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SET_ISNS_SERVICE;
+	mbox_cmd[1] = ISNS_DISABLE;
+
+	status = qla4xxx_mailbox_command(ha, 2, 2, &mbox_cmd[0], &mbox_sts[0]);
+	if (status != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha,
+			"%s: MBOX_CMD_SET_ISNS_SERVICE failed. "
+			"status %04x %04x\n", __func__,
+			mbox_sts[0], mbox_sts[1]));
+		set_bit(DPC_ISNS_DEREGISTER, &ha->dpc_flags);
+		DEBUG2(ql4_info(ha, "%s: De-Register with iSNS server\n",
+				__func__));
+		goto exit_stop_svc;
+	}
+
+	DEBUG2(ql4_info(ha, "iSNS Server Disconnected\n"));
+	/* Notify application iSNS server is off-line */
+	if (atomic_read(&ha->isns.state) != ISNS_STATE_TCP_DISCONNECTED)
+		ql4_queue_isns_sts_chg_aen(ha, ISNS_CHG_SERVER_OFFLINE);
+
+	atomic_set(&ha->isns.state, ISNS_STATE_TCP_DISCONNECTED);
+
+	ql4_isns_clear_flags(ha);
+	atomic_set(&ha->isns.esi_timer, 0);
+	memset(ha->isns.entity_id, 0, sizeof(ha->isns.entity_id));
+
+exit_stop_svc:
+	return status;
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_isns.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_isns.h
@@ -0,0 +1,301 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef __QL4_ISNS_H
+#define __QL4_ISNS_H
+#include <linux/dmapool.h>
+
+/* NOTE: ALL PDUs tx in Network Byte Order (NBO) */
+struct isnsp_header {
+	__u16 ver;	/* 00-01 */
+        #define ISNSP_VERSION			0x0001
+
+	__u16 func_id;	/* 02-03 */
+	__u16 pdu_len;	/* 04-05 pdu length does not include header */
+	__u16 flags;	/* 06-07 */
+	/* The following #defines are in Host Byte Order (HBO),
+	 * as all NBO structs are converted to HBO before use */
+	#define ISNSP_FLAG_CLIENT_SENDER         0x8000
+	#define ISNSP_FLAG_SERVER_SENDER         0x4000
+	#define ISNSP_FLAG_AUTH_BLOCK_PRESENT    0x2000
+	#define ISNSP_FLAG_REPLACE_FLAG          0x1000 /* for DevAttrReg */
+	#define ISNSP_FLAG_LAST_PDU              0x0800
+	#define ISNSP_FLAG_FIRST_PDU             0x0400
+
+	__u16 trans_id;	/* 08-09 */
+	__u16 seq_id;	/* 0A-0B */
+	__u8 payload[0];
+};
+
+struct isnsp_message {
+	struct isnsp_header hdr;
+	__u8 attributes[0];
+};
+
+struct isnsp_response {
+	struct isnsp_header hdr;
+	__u32 status_code;
+	__u8  attributes[0];
+};
+
+struct isnsp_attribute {
+	uint32_t tag;
+	uint32_t len;
+	__u8  val[0];
+};
+
+/* iSNS Attribute Tags */
+#define ISNS_ATTR_DELIMITER                     0   /* x00 */
+#define ISNS_ATTR_ENTITY_IDENTIFIER             1   /* x01 */
+#define ISNS_ATTR_ENTITY_PROTOCOL               2   /* x02 */
+#define ISNS_ATTR_MGMT_IP_ADDRESS               3   /* x03 */
+#define ISNS_ATTR_TIMESTAMP                     4   /* x04 */
+#define ISNS_ATTR_REGISTRATION_PERIOD           6   /* x06 */
+#define ISNS_ATTR_PORTAL_IP_ADDRESS             16  /* x10 */
+#define ISNS_ATTR_PORTAL_PORT                   17  /* x11 */
+#define ISNS_ATTR_PORTAL_SYMBOLIC_NAME          18  /* x12 */
+#define ISNS_ATTR_ESI_INTERVAL                  19  /* x13 */
+#define ISNS_ATTR_ESI_PORT                      20  /* x14 */
+#define ISNS_ATTR_PORTAL_GROUP                  21  /* x15 */
+#define ISNS_ATTR_PORTAL_INDEX                  22  /* x16 */
+#define ISNS_ATTR_SCN_PORT                      23  /* x17 */
+#define ISNS_ATTR_PORTAL_SECURITY_BITMAP	27  /* x1B */
+#define ISNS_ATTR_ISCSI_NAME                    32  /* x20 */
+#define ISNS_ATTR_ISCSI_NODE_TYPE               33  /* x21 */
+#define ISNS_ATTR_ISCSI_ALIAS                   34  /* x22 */
+#define ISNS_ATTR_ISCSI_SCN_BITMAP              35  /* x23 */
+#define ISNS_ATTR_PG_ISCSI_NAME                 48  /* x30 */
+#define ISNS_ATTR_PG_PORTAL_IP_ADDRESS          49  /* x31 */
+#define ISNS_ATTR_PG_PORTAL_PORT                50  /* x32 */
+#define ISNS_ATTR_PG_TAG                        51  /* x33 */
+#define ISNS_ATTR_DD_ID                         2065 /* x811 */
+
+/* iSNS Message Function ID codes */
+#define ISNS_FUNC_DevAttrReg      0x0001      /* Device Attribute Registration Request */
+#define ISNS_FUNC_DevAttrQry      0x0002      /* Device Attribute Query Request */
+#define ISNS_FUNC_DevGetNext      0x0003      /* Device Get Next Request  */
+#define ISNS_FUNC_DevDereg        0x0004      /* Device Deregister Request */
+#define ISNS_FUNC_SCNReg          0x0005      /* SCN Register Request */
+#define ISNS_FUNC_SCNDereg        0x0006      /* SCN Deregister Request */
+#define ISNS_FUNC_SCNEvent        0x0007      /* SCN Event */
+#define ISNS_FUNC_SCN             0x0008      /* State Change Notification */
+#define ISNS_FUNC_ESI             0x000D      /* Entity Status Inquiry  */
+
+/* iSNS Response Function ID codes */
+#define ISNS_FUNC_RESPONSE	  0x8000      /* Response Function ID Mask */
+#define ISNS_FUNC_DevAttrRegRsp   0x8001      /* Device Attribute Registration Response */
+#define ISNS_FUNC_DevAttrQryRsp   0x8002      /* Device Attribute Query Response */
+#define ISNS_FUNC_DevGetNextRsp   0x8003      /* Device Get Next Response */
+#define ISNS_FUNC_DevDeregRsp     0x8004      /* Deregister Device Response */
+#define ISNS_FUNC_SCNRegRsp       0x8005      /* SCN Register Response */
+#define ISNS_FUNC_SCNDeregRsp     0x8006      /* SCN Deregister Response */
+#define ISNS_FUNC_SCNEventRsp     0x8007      /* SCN Event Response */
+#define ISNS_FUNC_SCNRsp          0x8008      /* SCN Response */
+#define ISNS_FUNC_DDRegRsp        0x8009      /* DD Register Response */
+#define ISNS_FUNC_DDDeregRsp      0x800A      /* DD Deregister Response */
+#define ISNS_FUNC_DDSRegRsp       0x800B      /* DDS Register Response */
+#define ISNS_FUNC_DDSDeregRsp     0x800C      /* DDS Deregister Response */
+#define ISNS_FUNC_ESIRsp          0x800D      /* Entity Status Inquiry Response */
+
+/* iSNSP Response Status Codes */
+#define ISNS_STS_SUCCESS                    0   /* Successful */
+#define ISNS_STS_UNKNOWN                    1   /* Unknown Error */
+#define ISNS_STS_MSG_FORMAT                 2   /* Message Format Error */
+#define ISNS_STS_INVALID_REG                3   /* Invalid Registration */
+#define ISNS_STS_INVALID_QUERY              5   /* Invalid Query */
+#define ISNS_STS_SOURCE_UNKNOWN             6   /* Source Unknown */
+#define ISNS_STS_SOURCE_ABSENT              7   /* Source Absent */
+#define ISNS_STS_SOURCE_UNAUTHORIZED        8   /* Source Unauthorized */
+#define ISNS_STS_NO_SUCH_ENTRY              9   /* No Such Entry */
+#define ISNS_STS_VER_NOT_SUPPORTED          10  /* Version Not Supported */
+#define ISNS_STS_INTERNAL_ERROR             11  /* Internal Error */
+#define ISNS_STS_BUSY                       12  /* Busy */
+#define ISNS_STS_OPT_NOT_UNDERSTOOD         13  /* Option Not Understood */
+#define ISNS_STS_INVALID_UPDATE             14  /* Invalid Update */
+#define ISNS_STS_MSG_NOT_SUPPORTED          15  /* Message (FUNCTION_ID) Not Supported */
+#define ISNS_STS_SCN_EVENT_REJECTED         16  /* SCN Event Rejected */
+#define ISNS_STS_SCN_REG_REJECTED           17  /* SCN Registration Rejected */
+#define ISNS_STS_ATTR_NOT_IMPLEMENTED       18  /* Attribute Not Implemented */
+#define ISNS_STS_FC_DOMAIN_ID_NOT_AVAIL     19  /* FC_DOMAIN_ID Not Available */
+#define ISNS_STS_FC_DOMAIN_ID_NOT_ALLOC     20  /* FC_DOMAIN_ID Not Allocated */
+#define ISNS_STS_ESI_NOT_AVAILABLE          21  /* ESI Not Available */
+#define ISNS_STS_INVALID_DEREG              22  /* Invalid Deregistration */
+#define ISNS_STS_REG_FEATURES_NOT_SUPPORTED 23  /* Registration Features Not Supported */
+
+/* iSNS Entity Protocol Type */
+#define ISNS_ENTITY_PROTOCOL_TPYE_ISCSI		2
+
+/* iSNS iSCSI Node Type */
+#define ISNS_ISCSI_NODE_TYPE_INITIATOR		2
+
+/* iSCSI Node Types */
+#define ISCSI_NODE_TYPE_TARGET                  0x00000001
+#define ISCSI_NODE_TYPE_INITIATOR               0x00000002
+#define ISCSI_NODE_TYPE_CONTROL                 0x00000004
+
+/* iSCSI Node SCN Bitmap */
+#define ISCSI_SCN_OBJECT_UPDATED                0x00000004
+#define ISCSI_SCN_OBJECT_ADDED                  0x00000008
+#define ISCSI_SCN_OBJECT_REMOVED                0x00000010
+#define ISCSI_SCN_TARGET_AND_SELF_INFO_ONLY     0x00000040
+
+/* Structure used for printing string values */
+struct prn_str_tbl
+{
+	int val;
+	const char *s;
+};
+
+/*
+ * Driver defined fields used for iSNS Passthru handle
+ */
+#define IOCB_ISNS_PT_PDU_TYPE(x)        ((x) & 0x0F000000)
+#define IOCB_ISNS_PT_PDU_INDEX(x)       ((x) & (MAX_PDU_ENTRIES-1))
+
+#define ISNS_ASYNC_REQ_PDU              0x01000000 /* Request Data from
+						      ASYNC PDU */
+#define ISNS_ASYNC_RSP_PDU              0x02000000
+#define ISNS_REQ_RSP_PDU                0x03000000
+
+/* Pseudo DDB index for Passthru */
+#define ISNS_DEVICE_INDEX               MAX_DEV_DB_ENTRIES
+
+/* The default iSNS Connection ID is used to allow the firmware to
+ * automatically reopen the connection after an iSNS server FIN has occurred.
+ * Only PDUs generated by our driver use the default iSNS Connection ID,
+ * PDUs generated by the iSNS server use different Connection IDs. */
+#define ISNS_DEFAULT_SERVER_CONN_ID     ((uint16_t)0x8000)
+
+/* iSNS PDU Request Block - local structure used to send and receive PDUs */
+struct isns_prb {
+	struct list_head list;
+
+	/* Ptrs to PDU buffer */
+	dma_addr_t pdu_dma;
+	__u8 *pdu;
+
+	/* Ptrs to IOCB struct */
+	dma_addr_t pkt_dma;
+	__u8 *pkt;
+
+	/* Ptrs needed to return isns tgt query info back to caller */
+	__u8 *tgt_qry_iscsi_name;
+	__u8 *tgt_qry_buf;
+	__u32 *tgt_qry_buf_len;
+
+	/* Offset to indicate the end of the pdu data received.
+	 * Used to solicit remainder of PDU */
+	__u32 offset;
+
+	/* Length of allocated PDU buffer */
+	__u32 pdu_buf_len;
+
+	/* Stored variables used to build passthsu IOCB */
+	__u32 tx_len;
+	__u32 rx_len;
+	__u32 handle;
+
+	/* Cached variables from sts_entry */
+	__u32 in_residual; /* over/underrun amt based on resid_flags */
+	__u16 conn_id;
+	__u8  resid_flags; /* see passthsu_status struct for definition */
+
+	/* Housekeeping variable to indicate this prb is being used */
+	__u8 prb_in_use;
+	__u8 resvd[4]; /* pad for structure alignment */
+};
+
+struct isns {
+	unsigned long   flags;
+
+	/* The ISNS_FLAG_ISNS_ENABLED_IN_ISP flag is set when iSNS
+	 * is enabled in the firmware.  This flag is used as a shortcut to
+	 * minimize having to check both ipv4 and ipv6 tcp options in the ifcb
+	 * at multiple places in the code. */
+	#define ISNS_FLAG_ISNS_ENABLED_IN_ISP   0  /* 0x00000001 */
+
+	/* The ISNS_FLAG_DISABLE_IN_PROGRESS flag is set in the IOCTL Module
+	 * to indicate that iSNS is being disabled by the user.
+	 * Since the MBOX_ASTS_IP_ADDR_STATE_CHANGED AEN can occur
+	 * simultaneously and attempt to start the iSNS server,
+	 * the ISNS_FLAG_DISABLE_IN_PROGRESS flag is checked multiple
+	 * places in the MBOX_ASTS_IP_ADDR_STATE_CHANGED path. */
+	#define ISNS_FLAG_DISABLE_IN_PROGRESS   1  /* 0x00000002 */
+
+	/* The ISNS_FLAG_ISNS_SRV_REGISTERED flag is set to indicate that
+	 * the driver has registered the initiator with the iSNS server
+	 * (DevAttrReg)*/
+	#define ISNS_FLAG_ISNS_SRV_REGISTERED   2  /* 0x00000004 */
+
+	/* The ISNS_FLAG_ISNS_SCN_REGISTERED flag is set to indicate that
+	 * the driver has registered for State Change Notification (SCN)
+	 * messages from the iSNS server (SCNReg)*/
+	#define ISNS_FLAG_ISNS_SCN_REGISTERED   4  /* 0x00000010 */
+
+	/* The ISNS_FLAG_SRV_DEREG_IN_PROGRESS flag is set to indicate that
+	 * the driver is in the process of de-registering with the iSNS
+	 * server (DevDereg).  This flag is used to wait until the de-
+	 * registration process has completed (i.e. DevDeregRsp received)*/
+	#define ISNS_FLAG_SRV_DEREG_IN_PROGRESS 6  /* 0x00000040 */
+
+	/* The ISNS_FLAG_IOCTL_INVOKED_QUERY flag is used to communicate to
+	 * the IOCTL module that (DevGetNext & DevAttrQry) iSNS transactions
+	 * have completed.  This flag is set in the IOCTL module and cleared
+	 * in the driver*/
+	#define ISNS_FLAG_IOCTL_INVOKED_QUERY   8  /* 0x00000100 */
+
+	/* State of iSNS Server connection */
+	atomic_t	state;
+	#define ISNS_STATE_TCP_DISCONNECTED	0
+	#define ISNS_STATE_TCP_CONNECTED	1
+	#define ISNS_STATE_STARTING_SRV		2
+	#define ISNS_STATE_RESTART_SRV_WAIT	3
+
+	/* Timer used to restart the iSNS server */
+	atomic_t restart_timer;
+	#define ISNS_RESTART_SVR_TOV	5	/* almost immediate restart */
+	#define ISNS_POLL_SVR_TOV	60	/* polling interval */
+
+	/* Variables used to monitor ESI timer functionality */
+	atomic_t esi_timer;
+	__u32    esi_interval;
+
+	/* Lock to protect prb structure */
+	struct mutex  prb_lock;
+
+	/* List containing received PDUs (Async and Response Msg),
+	 * where processing is delayed to DPC */
+	struct list_head rcvd_pdu_list;
+
+	/* Cached iSNS Server connection info */
+	__u16 esi_port;
+	__u16 scn_port;
+	__u16 source_port;
+	__u16 server_port;
+
+	/* Driver generated transaction ID (unique per transaction) */
+	__u16 trans_id;
+
+	__u16 resvd1;
+	__u8  resvd2;
+
+	/* PDU Housekeeping variables */
+	__u8 curr_pdu;
+	__u8 active_pdus;
+
+	/* More cached iSNS Server connection info */
+	__u8  source_ip_index;
+	__u8  source_ip[16];
+	__u8  server_ip[16];
+	__u8  entity_id[256];
+
+	/* Array of prb structures, used to store all information related to
+	 * iSNS PDU transactions */
+	struct isns_prb prb_array[MAX_PDU_ENTRIES];
+};
+
+#endif /* QL4_ISNS_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_isr.c
--- a/drivers/scsi/qla4xxx/ql4_isr.c
+++ b/drivers/scsi/qla4xxx/ql4_isr.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -12,12 +12,12 @@
 #include <scsi/iscsi_proto.h>
 
 /**
- * qla4xxx_copy_sense - copy sense data	into cmd sense buffer
+ * qla4xxx_check_and_copy_sense - copy sense data into cmd sense buffer
  * @ha: Pointer to host adapter structure.
  * @sts_entry: Pointer to status entry structure.
  * @srb: Pointer to srb structure.
  **/
-static void qla4xxx_copy_sense(struct scsi_qla_host *ha,
+static void qla4xxx_check_and_copy_sense(struct scsi_qla_host *ha,
                                struct status_entry *sts_entry,
                                struct srb *srb)
 {
@@ -26,8 +26,13 @@ static void qla4xxx_copy_sense(struct sc
 
 	memset(cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
 	sense_len = le16_to_cpu(sts_entry->senseDataByteCnt);
-	if (sense_len == 0)
+	if (sense_len == 0) {
+		DEBUG2(ql4_info(ha, "%d:%d:%d: %s: sense len 0\n",
+				cmd->device->channel, cmd->device->id,
+				cmd->device->lun, __func__));
+		ha->status_srb = NULL;
 		return;
+	}
 
 	/* Save total available sense length,
 	 * not to exceed cmd's sense buffer size */
@@ -39,8 +44,8 @@ static void qla4xxx_copy_sense(struct sc
 	sense_len = min_t(uint16_t, sense_len, IOCB_MAX_SENSEDATA_LEN);
 	memcpy(cmd->sense_buffer, sts_entry->senseData, sense_len);
 
-	DEBUG2(printk(KERN_INFO "scsi%ld:%d:%d:%d: %s: sense key = %x, "
-		"ASL= %02x, ASC/ASCQ = %02x/%02x\n", ha->host_no,
+	DEBUG2(ql4_info(ha, "%d:%d:%d: %s: sense key = %x, "
+		"ASL= %02x, ASC/ASCQ = %02x/%02x\n",
 		cmd->device->channel, cmd->device->id,
 		cmd->device->lun, __func__,
 		sts_entry->senseData[2] & 0x0f,
@@ -58,6 +63,35 @@ static void qla4xxx_copy_sense(struct sc
 		ha->status_srb = srb;
 	else
 		ha->status_srb = NULL;
+
+	if ((srb->flags & SRB_SCSI_PASSTHRU))
+		return;
+
+	/* check for vaild sense data */
+	if ((sts_entry->senseData[0] & 0x70) != 0x70)
+		return;
+
+	switch (sts_entry->senseData[2] & 0x0f) {
+	case UNIT_ATTENTION:
+		if (sts_entry->senseData[12] == 0x3F &&
+		    sts_entry->senseData[13] == 0x0E) {
+			struct ddb_entry *ddb_entry;
+
+			ddb_entry = qla4xxx_lookup_ddb_by_os_index(ha,
+				cmd->device->id);
+			if (ddb_entry) {
+				dev_info(&ha->pdev->dev,"%s: ddb[%d] os[%d] "
+					"schedule dynamic lun scan\n",
+					__func__, ddb_entry->fw_ddb_index,
+					ddb_entry->os_target_id);
+
+				set_bit(DF_DYNAMIC_LUN_SCAN_NEEDED,
+					&ddb_entry->flags);
+				set_bit(DPC_DYNAMIC_LUN_SCAN, &ha->dpc_flags);
+			}
+		}
+		break;
+	}
 }
 
 /**
@@ -73,15 +107,15 @@ qla4xxx_status_cont_entry(struct scsi_ql
 {
 	struct srb *srb = ha->status_srb;
 	struct scsi_cmnd *cmd;
-	uint8_t sense_len;
+	uint16_t sense_len;
 
 	if (srb == NULL)
 		return;
 
 	cmd = srb->cmd;
 	if (cmd == NULL) {
-		DEBUG2(printk(KERN_INFO "scsi%ld: %s: Cmd already returned "
-			"back to OS srb=%p srb->state:%d\n", ha->host_no,
+		DEBUG2(ql4_info(ha, "%s: Cmd already returned "
+			"back to OS srb=%p srb->state:%d\n",
 			__func__, srb, srb->state));
 		ha->status_srb = NULL;
 		return;
@@ -98,7 +132,7 @@ qla4xxx_status_cont_entry(struct scsi_ql
 
 	/* Place command on done queue. */
 	if (srb->req_sense_len == 0) {
-		sp_put(ha, srb);
+		kref_put(&srb->srb_ref, qla4xxx_srb_compl);
 		ha->status_srb = NULL;
 	}
 }
@@ -119,25 +153,27 @@ static void qla4xxx_status_entry(struct 
 
 	srb = qla4xxx_del_from_active_array(ha, le32_to_cpu(sts_entry->handle));
 	if (!srb) {
-		/* FIXMEdg: Don't we need to reset ISP in this case??? */
-		DEBUG2(printk(KERN_WARNING "scsi%ld: %s: Status Entry invalid "
+		DEBUG2(ql4_warn(ha, "%s: Status Entry invalid "
 			      "handle 0x%x, sp=%p. This cmd may have already "
-			      "been completed.\n", ha->host_no, __func__,
+			      "been completed.\n", __func__,
 			      le32_to_cpu(sts_entry->handle), srb));
-		dev_warn(&ha->pdev->dev, "%s invalid status entry:"
-			" handle=0x%0x\n", __func__, sts_entry->handle);
-		set_bit(DPC_RESET_HA, &ha->dpc_flags);
+		ql4_warn(ha, "%s invalid status entry:"
+		    " handle=0x%0x\n", __func__, sts_entry->handle);
+		if (is_qla8022(ha))
+			set_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+		else
+			set_bit(DPC_RESET_HA, &ha->dpc_flags);
 		return;
 	}
 
 	cmd = srb->cmd;
 	if (cmd == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Command already returned back to "
+		DEBUG2(ql4_info(ha, "%s: Command already returned back to "
 			      "OS pkt->handle=%d srb=%p srb->state:%d\n",
-			      ha->host_no, __func__, sts_entry->handle,
+			      __func__, sts_entry->handle,
 			      srb, srb->state));
-		dev_warn(&ha->pdev->dev, "Command is NULL:"
-			" already returned to OS (srb=%p)\n", srb);
+		ql4_warn(ha, "Command is NULL:"
+		    " already returned to OS (srb=%p)\n", srb);
 		return;
 	}
 
@@ -166,10 +202,10 @@ static void qla4xxx_status_entry(struct 
 
 				cmd->result = DID_ERROR << 16;
 
-				DEBUG2(printk("scsi%ld:%d:%d:%d: %s: "
+				DEBUG2(ql4_info(ha, "%d:%d:%d: %s: "
 					"Mid-layer Data underrun0, "
 					"xferlen = 0x%x, "
-					"residual = 0x%x\n", ha->host_no,
+					"residual = 0x%x\n",
 					cmd->device->channel,
 					cmd->device->id,
 					cmd->device->lun, __func__,
@@ -184,7 +220,7 @@ static void qla4xxx_status_entry(struct 
 			break;
 
 		/* Copy Sense Data into sense buffer. */
-		qla4xxx_copy_sense(ha, sts_entry, srb);
+		qla4xxx_check_and_copy_sense(ha, sts_entry, srb);
 		break;
 
 	case SCS_INCOMPLETE:
@@ -194,24 +230,24 @@ static void qla4xxx_status_entry(struct 
 		break;
 
 	case SCS_RESET_OCCURRED:
-		DEBUG2(printk("scsi%ld:%d:%d:%d: %s: Device RESET occurred\n",
-			      ha->host_no, cmd->device->channel,
-			      cmd->device->id, cmd->device->lun, __func__));
+		DEBUG2(ql4_info(ha, "%d:%d:%d: %s: Device RESET occurred\n",
+			      cmd->device->channel, cmd->device->id,
+			      cmd->device->lun, __func__));
 
 		cmd->result = DID_RESET << 16;
 		break;
 
 	case SCS_ABORTED:
-		DEBUG2(printk("scsi%ld:%d:%d:%d: %s: Abort occurred\n",
-			      ha->host_no, cmd->device->channel,
-			      cmd->device->id, cmd->device->lun, __func__));
+		DEBUG2(ql4_info(ha, "%d:%d:%d: %s: Abort occurred\n",
+			      cmd->device->channel, cmd->device->id,
+			      cmd->device->lun, __func__));
 
 		cmd->result = DID_RESET << 16;
 		break;
 
 	case SCS_TIMEOUT:
-		DEBUG2(printk(KERN_INFO "scsi%ld:%d:%d:%d: Timeout\n",
-			      ha->host_no, cmd->device->channel,
+		DEBUG2(ql4_info(ha, "%d:%d:%d: Timeout\n",
+			      cmd->device->channel,
 			      cmd->device->id, cmd->device->lun));
 
 		cmd->result = DID_TRANSPORT_DISRUPTED << 16;
@@ -229,8 +265,7 @@ static void qla4xxx_status_entry(struct 
 	case SCS_DATA_OVERRUN:
 		if ((sts_entry->iscsiFlags & ISCSI_FLAG_RESIDUAL_OVER) ||
 		     (sts_entry->completionStatus == SCS_DATA_OVERRUN)) {
-			DEBUG2(printk("scsi%ld:%d:%d:%d: %s: " "Data overrun\n",
-				      ha->host_no,
+			DEBUG2(ql4_info(ha, "%d:%d:%d: %s: " "Data overrun\n",
 				      cmd->device->channel, cmd->device->id,
 				      cmd->device->lun, __func__));
 
@@ -251,7 +286,7 @@ static void qla4xxx_status_entry(struct 
 				break;
 
 			/* Copy Sense Data into sense buffer. */
-			qla4xxx_copy_sense(ha, sts_entry, srb);
+			qla4xxx_check_and_copy_sense(ha, sts_entry, srb);
 		} else {
 			/*
 			 * If RISC reports underrun and target does not
@@ -276,10 +311,10 @@ static void qla4xxx_status_entry(struct 
 				 * actually being done.	 In the interim, we
 				 * will return DID_ERROR.
 				 */
-				DEBUG2(printk("scsi%ld:%d:%d:%d: %s: "
+				DEBUG2(ql4_info(ha, "%d:%d:%d: %s: "
 					"Mid-layer Data underrun1, "
 					"xferlen = 0x%x, "
-					"residual = 0x%x\n", ha->host_no,
+					"residual = 0x%x\n",
 					cmd->device->channel,
 					cmd->device->id,
 					cmd->device->lun, __func__,
@@ -294,10 +329,9 @@ static void qla4xxx_status_entry(struct 
 
 	case SCS_DEVICE_LOGGED_OUT:
 	case SCS_DEVICE_UNAVAILABLE:
-		DEBUG2(printk(KERN_INFO "scsi%ld:%d:%d:%d: SCS_DEVICE "
-			      "state: 0x%x\n", ha->host_no,
-			      cmd->device->channel, cmd->device->id,
-			      cmd->device->lun, sts_entry->completionStatus));
+		DEBUG2(ql4_info(ha, "%d:%d:%d: SCS_DEVICE "
+		    "state: 0x%x\n", cmd->device->channel, cmd->device->id,
+		    cmd->device->lun, sts_entry->completionStatus));
 		/*
 		 * Mark device missing so that we won't continue to
 		 * send I/O to this device.  We should get a ddb
@@ -314,9 +348,9 @@ static void qla4xxx_status_entry(struct 
 		 * SCSI Mid-Layer handles device queue full
 		 */
 		cmd->result = DID_OK << 16 | sts_entry->scsiStatus;
-		DEBUG2(printk("scsi%ld:%d:%d: %s: QUEUE FULL detected "
+		DEBUG2(ql4_info(ha, "%d:%d: %s: QUEUE FULL detected "
 			      "compl=%02x, scsi=%02x, state=%02x, iFlags=%02x,"
-			      " iResp=%02x\n", ha->host_no, cmd->device->id,
+			      " iResp=%02x\n", cmd->device->id,
 			      cmd->device->lun, __func__,
 			      sts_entry->completionStatus,
 			      sts_entry->scsiStatus, sts_entry->state_flags,
@@ -334,7 +368,7 @@ status_entry_exit:
 	/* complete the request, if not waiting for status_continuation pkt */
 	srb->cc_stat = sts_entry->completionStatus;
 	if (ha->status_srb == NULL)
-		sp_put(ha, srb);
+		kref_put(&srb->srb_ref, qla4xxx_srb_compl);
 }
 
 /**
@@ -344,7 +378,7 @@ status_entry_exit:
  * This routine process response queue completions in interrupt context.
  * Hardware_lock locked upon entry
  **/
-static void qla4xxx_process_response_queue(struct scsi_qla_host * ha)
+void qla4xxx_process_response_queue(struct scsi_qla_host *ha)
 {
 	uint32_t count = 0;
 	struct srb *srb = NULL;
@@ -354,14 +388,12 @@ static void qla4xxx_process_response_que
 	struct async_msg_pdu_iocb *apdu_iocb;
 
 	/* Process all responses from response queue */
-	while ((ha->response_in =
-		(uint16_t)le32_to_cpu(ha->shadow_regs->rsp_q_in)) !=
-	       ha->response_out) {
+	while ((ha->response_ptr->signature != RESPONSE_PROCESSED)) {
 		sts_entry = (struct status_entry *) ha->response_ptr;
 		count++;
 
 		/* Advance pointers for next entry */
-		if (ha->response_out == (RESPONSE_QUEUE_DEPTH - 1)) {
+		if (ha->response_out == (ha->response_qdepth - 1)) {
 			ha->response_out = 0;
 			ha->response_ptr = ha->response_ring;
 		} else {
@@ -370,46 +402,42 @@ static void qla4xxx_process_response_que
 		}
 
 		/* process entry */
-		switch (sts_entry->hdr.entryType) {
+		switch (sts_entry->hdr.entry_type) {
 		case ET_STATUS:
 			/* Common status */
 			qla4xxx_status_entry(ha, sts_entry);
 			break;
 
-		case ET_PASSTHRU_STATUS:
-			break;
-
-		case ET_ASYNC_PDU:
+		case ET_ASYNC_ISCSI_PDU:
 			apdu = (struct async_pdu_iocb *)sts_entry;
 			if (apdu->status != ASYNC_PDU_IOCB_STS_OK)
 				break;
 
 			pdu_hdr = (struct iscsi_hdr *)apdu->iscsi_pdu_hdr;
 			if (pdu_hdr->hlength || pdu_hdr->dlength[0] ||
-				pdu_hdr->dlength[1] || pdu_hdr->dlength[2]){
-				apdu_iocb = kmalloc(sizeof(struct async_msg_pdu_iocb),
-							GFP_ATOMIC);
+			    pdu_hdr->dlength[1] || pdu_hdr->dlength[2]) {
+				apdu_iocb = kmalloc(
+				    sizeof(struct async_msg_pdu_iocb),
+				    GFP_ATOMIC);
 				if (apdu_iocb) {
 					memcpy(apdu_iocb->iocb, apdu,
-						sizeof(struct async_pdu_iocb));
+					    sizeof(struct async_pdu_iocb));
 					list_add_tail(&apdu_iocb->list,
-							&ha->async_iocb_list);
-					DEBUG2(printk("scsi%ld:"
-						"%s: schedule async msg pdu\n",
-						ha->host_no, __func__));
-					set_bit(DPC_ASYNC_MSG_PDU,
-							&ha->dpc_flags);
+					    &ha->async_iocb_list);
+					DEBUG2(ql4_info(ha, "%s: schedule async "
+						"msg pdu\n", __func__));
+					set_bit(DPC_ASYNC_ISCSI_PDU,
+					    &ha->dpc_flags);
 				} else {
-					DEBUG2(printk("scsi%ld:"
-							"%s: unable to alloc ASYNC PDU\n",
-							ha->host_no, __func__));
+					DEBUG2(ql4_info(ha, "%s: unable to "
+					    "alloc ASYNC PDU\n", __func__));
 				}
 			}
 			break;
 
 		case ET_STATUS_CONTINUATION:
 			qla4xxx_status_cont_entry(ha,
-				(struct status_cont_entry *) sts_entry);
+					(struct status_cont_entry *) sts_entry);
 			break;
 
 		case ET_COMMAND:
@@ -423,19 +451,19 @@ static void qla4xxx_process_response_que
 			if (srb == NULL)
 				goto exit_prq_invalid_handle;
 
-			DEBUG2(printk("scsi%ld: %s: FW device queue full, "
-				      "srb %p\n", ha->host_no, __func__, srb));
+			DEBUG2(ql4_info(ha, "%s: FW device queue full, "
+				      "srb %p\n", __func__, srb));
 
 			/* ETRY normally by sending it back with
 			 * DID_BUS_BUSY */
 			srb->cmd->result = DID_BUS_BUSY << 16;
-			sp_put(ha, srb);
+			kref_put(&srb->srb_ref, qla4xxx_srb_compl);
 			break;
 
 		case ET_CONTINUE:
 			/* Just throw away the continuation entries */
-			DEBUG2(printk("scsi%ld: %s: Continuation entry - "
-				      "ignoring\n", ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: Continuation entry - "
+				      "ignoring\n", __func__));
 			break;
 
 		default:
@@ -443,32 +471,29 @@ static void qla4xxx_process_response_que
 			 * Invalid entry in response queue, reset RISC
 			 * firmware.
 			 */
-			DEBUG2(printk("scsi%ld: %s: Invalid entry %x in "
-				      "response queue \n", ha->host_no,
-				      __func__,
-				      sts_entry->hdr.entryType));
+			DEBUG2(ql4_info(ha, "%s: Invalid entry %x in "
+				      "response queue \n", __func__,
+				      sts_entry->hdr.entry_type));
 			goto exit_prq_error;
 		}
+		((struct response *)sts_entry)->signature = RESPONSE_PROCESSED;
+		wmb();
 	}
 
 	/*
-	 * Done with responses, update the ISP For QLA4010, this also clears
-	 * the interrupt.
+	 * Tell ISP we're done with response(s). This also clears the interrupt.
 	 */
-	writel(ha->response_out, &ha->reg->rsp_q_out);
-	readl(&ha->reg->rsp_q_out);
+	ha->isp_ops->complete_iocb(ha);
 
 	return;
 
 exit_prq_invalid_handle:
-	DEBUG2(printk("scsi%ld: %s: Invalid handle(srb)=%p type=%x IOCS=%x\n",
-		      ha->host_no, __func__, srb, sts_entry->hdr.entryType,
+	DEBUG2(ql4_info(ha, "%s: Invalid handle(srb)=%p type=%x IOCS=%x\n",
+		      __func__, srb, sts_entry->hdr.entry_type,
 		      sts_entry->completionStatus));
 
 exit_prq_error:
-	writel(ha->response_out, &ha->reg->rsp_q_out);
-	readl(&ha->reg->rsp_q_out);
-
+	ha->isp_ops->complete_iocb(ha);
 	set_bit(DPC_RESET_HA, &ha->dpc_flags);
 }
 
@@ -484,7 +509,7 @@ static void qla4xxx_isr_decode_mailbox(s
 				       uint32_t mbox_status)
 {
 	int i;
-	uint32_t mbox_stat2, mbox_stat3;
+	uint32_t mbox_sts[MBOX_REG_COUNT];
 
 	if ((mbox_status == MBOX_STS_BUSY) ||
 	    (mbox_status == MBOX_STS_INTERMEDIATE_COMPLETION) ||
@@ -496,31 +521,43 @@ static void qla4xxx_isr_decode_mailbox(s
 			 * Copy all mailbox registers to a temporary
 			 * location and set mailbox command done flag
 			 */
-			for (i = 1; i < ha->mbox_status_count; i++)
-				ha->mbox_status[i] =
-					readl(&ha->reg->mailbox[i]);
+			for (i = 0; i < ha->mbox_status_count; i++)
+				ha->mbox_status[i] = is_qla8022(ha)
+				    ? readl(&ha->qla4_8xxx_reg->mailbox_out[i])
+				    : readl(&ha->reg->mailbox[i]);
 
 			set_bit(AF_MBOX_COMMAND_DONE, &ha->flags);
+
+			if (test_bit(AF_MBOX_COMMAND_NOPOLL, &ha->flags))
+				complete(&ha->mbx_intr_comp);
 		}
 	} else if (mbox_status >> 12 == MBOX_ASYNC_EVENT_STATUS) {
-		/* Immediately process the AENs that don't require much work.
-		 * Only queue the database_changed AENs */
-		if (ha->aen_log.count < MAX_AEN_ENTRIES) {
-			for (i = 0; i < MBOX_AEN_REG_COUNT; i++)
-				ha->aen_log.entry[ha->aen_log.count].mbox_sts[i] =
-					readl(&ha->reg->mailbox[i]);
-			ha->aen_log.count++;
-		}
+		for (i = 0; i < MBOX_REG_COUNT; i++)
+			mbox_sts[i] = is_qla8022(ha)
+			    ? readl(&ha->qla4_8xxx_reg->mailbox_out[i])
+			    : readl(&ha->reg->mailbox[i]);
+
+		/* Queue all AENs into internal AEN database.  The driver will
+		 * report AEN information to Application layer when requested.*/
+		qla4xxx_queue_aen_log(ha, &mbox_sts[0]);
+
 		switch (mbox_status) {
 		case MBOX_ASTS_SYSTEM_ERROR:
+			ql4_info(ha, "%s: System Err\n", __func__);
+			qla4xxx_dump_registers(ha);
+
 			/* Log Mailbox registers */
+			ql4_info(ha, "%s: System Err\n", __func__);
 			if (ql4xdontresethba) {
-				DEBUG2(printk("%s:Dont Reset HBA\n",
-					      __func__));
-			} else {
+				DEBUG2(ql4_info(ha, "%s:Don't Reset HBA\n",
+				    __func__));
+			} else if (is_qla4022(ha) || is_qla4032(ha)) {
 				set_bit(AF_GET_CRASH_RECORD, &ha->flags);
 				set_bit(DPC_RESET_HA, &ha->dpc_flags);
 			}
+			/* For ISP8xxx we rely on PEG_ALIVE_COUNTER
+			 * to set the flags to reset the chip
+			 */
 			break;
 
 		case MBOX_ASTS_REQUEST_TRANSFER_ERROR:
@@ -528,9 +565,12 @@ static void qla4xxx_isr_decode_mailbox(s
 		case MBOX_ASTS_NVRAM_INVALID:
 		case MBOX_ASTS_IP_ADDRESS_CHANGED:
 		case MBOX_ASTS_DHCP_LEASE_EXPIRED:
-			DEBUG2(printk("scsi%ld: AEN %04x, ERROR Status, "
-				      "Reset HA\n", ha->host_no, mbox_status));
-			set_bit(DPC_RESET_HA, &ha->dpc_flags);
+			DEBUG2(ql4_info(ha, "AEN %04x, ERROR Status, "
+				      "Reset HA\n", mbox_status));
+			if (is_qla8022(ha))
+				set_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+			else
+				set_bit(DPC_RESET_HA, &ha->dpc_flags);
 			break;
 
 		case MBOX_ASTS_LINK_UP:
@@ -538,16 +578,15 @@ static void qla4xxx_isr_decode_mailbox(s
 			if (test_bit(AF_INIT_DONE, &ha->flags))
 				set_bit(DPC_LINK_CHANGED, &ha->dpc_flags);
 
-			DEBUG2(printk("scsi%ld: AEN %04x Adapter LINK UP\n",
-					ha->host_no, mbox_status));
+			ql4_info(ha, "%s: LINK UP\n", __func__);
 			break;
 
 		case MBOX_ASTS_LINK_DOWN:
 			clear_bit(AF_LINK_UP, &ha->flags);
-			set_bit(DPC_LINK_CHANGED, &ha->dpc_flags);
+			if (test_bit(AF_INIT_DONE, &ha->flags))
+				set_bit(DPC_LINK_CHANGED, &ha->dpc_flags);
 
-			DEBUG2(printk("scsi%ld: AEN %04x Adapter LINK DOWN\n",
-                                      ha->host_no, mbox_status));
+			ql4_info(ha, "%s: LINK DOWN\n", __func__);
 			break;
 
 		case MBOX_ASTS_HEARTBEAT:
@@ -555,8 +594,8 @@ static void qla4xxx_isr_decode_mailbox(s
 			break;
 
 		case MBOX_ASTS_DHCP_LEASE_ACQUIRED:
-			DEBUG2(printk("scsi%ld: AEN %04x DHCP LEASE "
-				      "ACQUIRED\n", ha->host_no, mbox_status));
+			DEBUG2(ql4_info(ha, "AEN %04x DHCP LEASE "
+				      "ACQUIRED\n", mbox_status));
 			set_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags);
 			break;
 
@@ -567,107 +606,133 @@ static void qla4xxx_isr_decode_mailbox(s
 		case MBOX_ASTS_UNSOLICITED_PDU_RECEIVED:  /* Connection mode */
 		case MBOX_ASTS_IPSEC_SYSTEM_FATAL_ERROR:
 		case MBOX_ASTS_SUBNET_STATE_CHANGE:
+		case MBOX_ASTS_DUPLICATE_IP:
 			/* No action */
-			DEBUG2(printk("scsi%ld: AEN %04x\n", ha->host_no,
-				      mbox_status));
+			DEBUG2(ql4_info(ha, "AEN %04x\n", mbox_status));
 			break;
 
 		case MBOX_ASTS_IP_ADDR_STATE_CHANGED:
-			mbox_stat2 = readl(&ha->reg->mailbox[2]);
-			mbox_stat3 = readl(&ha->reg->mailbox[3]);
+			DEBUG2(ql4_info(ha, "AEN %04x, mbox_sts[2]=%04x, "
+			    "mbox_sts[3]=%04x, mbox_sts[4]=%04x\n",
+			    mbox_sts[0],
+			    mbox_sts[2], mbox_sts[3], mbox_sts[4]));
 
-			if ((mbox_stat3 == 5) && (mbox_stat2 == 3))
+			if (test_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+			    &ha->isns.flags) &&
+			    !test_bit(ISNS_FLAG_DISABLE_IN_PROGRESS,
+					&ha->isns.flags)) {
+				ql4_isns_process_ip_state_chg(ha, &mbox_sts[0]);
+			}
+
+			/* mbox_sts[2] = Old ACB state
+			 * mbox_sts[3] = new ACB state */
+			if ((mbox_sts[3] == ACB_STATE_VALID) &&
+			    (mbox_sts[2] == ACB_STATE_TENTATIVE ||
+			     mbox_sts[2] == ACB_STATE_ACQUIRING))
 				set_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags);
-			else if ((mbox_stat3 == 2) && (mbox_stat2 == 5))
-				set_bit(DPC_RESET_HA, &ha->dpc_flags);
+			else if ((mbox_sts[3] == ACB_STATE_ACQUIRING) &&
+			         (mbox_sts[2] == ACB_STATE_VALID)) {
+				if (is_qla8022(ha))
+					set_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+				else
+					set_bit(DPC_RESET_HA, &ha->dpc_flags);
+			}
 			break;
 
 		case MBOX_ASTS_MAC_ADDRESS_CHANGED:
 		case MBOX_ASTS_DNS:
 			/* No action */
-			DEBUG2(printk(KERN_INFO "scsi%ld: AEN %04x, "
+			DEBUG2(ql4_info(ha, "AEN %04x, "
 				      "mbox_sts[1]=%04x, mbox_sts[2]=%04x\n",
-				      ha->host_no, mbox_status,
-				      readl(&ha->reg->mailbox[1]),
-				      readl(&ha->reg->mailbox[2])));
+				      mbox_sts[0], mbox_sts[1], mbox_sts[2]));
 			break;
 
 		case MBOX_ASTS_SELF_TEST_FAILED:
 		case MBOX_ASTS_LOGIN_FAILED:
 			/* No action */
-			DEBUG2(printk("scsi%ld: AEN %04x, mbox_sts[1]=%04x, "
+			DEBUG2(ql4_info(ha, "AEN %04x, mbox_sts[1]=%04x, "
 				      "mbox_sts[2]=%04x, mbox_sts[3]=%04x\n",
-				      ha->host_no, mbox_status,
-				      readl(&ha->reg->mailbox[1]),
-				      readl(&ha->reg->mailbox[2]),
-				      readl(&ha->reg->mailbox[3])));
+				      mbox_sts[0], mbox_sts[1], mbox_sts[2],
+				      mbox_sts[3]));
 			break;
 
 		case MBOX_ASTS_DATABASE_CHANGED:
-			/* Queue AEN information and process it in the DPC
-			 * routine */
-			if (ha->aen_q_count > 0) {
+		case MBOX_ASTS_ISNS:
+			/* Advance pointers for next entry */
+			ha->aen_in++;
+			if (ha->aen_in == MAX_AEN_ENTRIES)
+				ha->aen_in = 0;
 
-				/* decrement available counter */
-				ha->aen_q_count--;
+			/* copy aen information to local structure */
+                        for (i = 0; i < MBOX_AEN_REG_COUNT; i++)
+                                ha->aen_q[ha->aen_in].mbox_sts[i] =
+                                        mbox_sts[i];
 
-				for (i = 1; i < MBOX_AEN_REG_COUNT; i++)
-					ha->aen_q[ha->aen_in].mbox_sts[i] =
-						readl(&ha->reg->mailbox[i]);
+			/* The DPC routine will process the aen */
+			set_bit(DPC_AEN, &ha->dpc_flags);
 
-				ha->aen_q[ha->aen_in].mbox_sts[0] = mbox_status;
+			DEBUG2(ql4_info(ha, "scsi%ld: AEN[%d] %04x,"
+				"mbox_sts[1]=%04x, mbox_sts[2]=%04x, "
+				"mbox_sts[3]=%04x, mbox_sts[4]=%04x, "
+				"mbox_sts[5]=%04x, mbox_sts[6]=%04x\n",
+				ha->host_no, ha->aen_in, mbox_sts[0],
+				mbox_sts[1], mbox_sts[2], mbox_sts[3],
+				mbox_sts[4], mbox_sts[5], mbox_sts[6]));
+			break;
 
-				/* print debug message */
-				DEBUG2(printk("scsi%ld: AEN[%d] %04x queued"
-					      " mb1:0x%x mb2:0x%x mb3:0x%x mb4:0x%x\n",
-					      ha->host_no, ha->aen_in,
-					      mbox_status,
-					      ha->aen_q[ha->aen_in].mbox_sts[1],
-					      ha->aen_q[ha->aen_in].mbox_sts[2],
-					      ha->aen_q[ha->aen_in].mbox_sts[3],
-					      ha->aen_q[ha->aen_in].  mbox_sts[4]));
-				/* advance pointer */
-				ha->aen_in++;
-				if (ha->aen_in == MAX_AEN_ENTRIES)
-					ha->aen_in = 0;
+		case MBOX_ASTS_SOCKET_IOCB:
+			DEBUG2(ql4_warn(ha, "AEN %04x, mbox_sts[1]=%04x, "
+				"mbox_sts[2]=%04x, mbox_sts[3]=%04x\n",
+				mbox_sts[0], mbox_sts[1], mbox_sts[2],
+				mbox_sts[3]));
 
-				/* The DPC routine will process the aen */
-				set_bit(DPC_AEN, &ha->dpc_flags);
-			} else {
-				DEBUG2(printk("scsi%ld: %s: aen %04x, queue "
-					      "overflowed!  AEN LOST!!\n",
-					      ha->host_no, __func__,
-					      mbox_status));
+		case MBOX_ASTS_TXSCVR_INSERTED:
+			DEBUG2(ql4_warn(ha, "AEN %04x Transceiver inserted\n",
+					mbox_sts[0]));
+			break;
 
-				DEBUG2(printk("scsi%ld: DUMP AEN QUEUE\n",
-					      ha->host_no));
-
-				for (i = 0; i < MAX_AEN_ENTRIES; i++) {
-					DEBUG2(printk("AEN[%d] %04x %04x %04x "
-						      "%04x\n", i,
-						      ha->aen_q[i].mbox_sts[0],
-						      ha->aen_q[i].mbox_sts[1],
-						      ha->aen_q[i].mbox_sts[2],
-						      ha->aen_q[i].mbox_sts[3]));
-				}
-			}
+		case MBOX_ASTS_TXSCVR_REMOVED:
+			DEBUG2(ql4_warn(ha, "AEN %04x Transceiver"
+					" removed\n", mbox_sts[0]));
 			break;
 
 		default:
-			DEBUG2(printk(KERN_WARNING
-				      "scsi%ld: AEN %04x UNKNOWN\n",
-				      ha->host_no, mbox_status));
+			DEBUG2(ql4_warn(ha, "AEN %04x UNKNOWN\n", mbox_sts[0]));
 			break;
 		}
 	} else {
-		DEBUG2(printk("scsi%ld: Unknown mailbox status %08X\n",
-			      ha->host_no, mbox_status));
+		DEBUG2(ql4_info(ha, "Unknown mailbox status %08X\n",
+			      mbox_status));
 
 		ha->mbox_status[0] = mbox_status;
 	}
 }
 
 /**
+ * qla4_8xxx_interrupt_service_routine - isr
+ * @ha: pointer to host adapter structure.
+ *
+ * This is the main interrupt service routine.
+ * hardware_lock locked upon entry. runs in interrupt context.
+ **/
+void qla4_8xxx_interrupt_service_routine(struct scsi_qla_host *ha,
+    uint32_t intr_status)
+{
+	/* Process response queue interrupt. */
+	if (intr_status & HSRX_RISC_IOCB_INT)
+		qla4xxx_process_response_queue(ha);
+
+	/* Process mailbox/asynch event interrupt.*/
+	if (intr_status & HSRX_RISC_MB_INT)
+		qla4xxx_isr_decode_mailbox(ha,
+		    readl(&ha->qla4_8xxx_reg->mailbox_out[0]));
+
+	/* clear the interrupt */
+	writel(0, &ha->qla4_8xxx_reg->host_int);
+	readl(&ha->qla4_8xxx_reg->host_int);
+}
+
+/**
  * qla4xxx_interrupt_service_routine - isr
  * @ha: pointer to host adapter structure.
  *
@@ -694,6 +759,28 @@ void qla4xxx_interrupt_service_routine(s
 }
 
 /**
+ * qla4_8xxx_spurious_interrupt - processes spurious interrupt
+ * @ha: pointer to host adapter structure.
+ * @reqs_count: .
+ *
+ **/
+static void qla4_8xxx_spurious_interrupt(struct scsi_qla_host *ha,
+    uint8_t reqs_count)
+{
+	if (reqs_count)
+		return;
+
+	DEBUG2(ql4_info(ha, "Spurious Interrupt\n"));
+	if (is_qla8022(ha)) {
+		writel(0, &ha->qla4_8xxx_reg->host_int);
+		if (test_bit(AF_INTx_ENABLED, &ha->flags))
+			qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_mask_reg,
+			    0xfbff);
+	}
+	ha->spurious_int_count++;
+}
+
+/**
  * qla4xxx_intr_handler - hardware interrupt handler.
  * @irq: Unused
  * @dev_id: Pointer to host adapter structure
@@ -707,7 +794,7 @@ irqreturn_t qla4xxx_intr_handler(int irq
 
 	ha = (struct scsi_qla_host *) dev_id;
 	if (!ha) {
-		DEBUG2(printk(KERN_INFO
+		DEBUG2(ql4_info(ha,
 			      "qla4xxx: Interrupt with NULL host ptr\n"));
 		return IRQ_NONE;
 	}
@@ -723,23 +810,21 @@ irqreturn_t qla4xxx_intr_handler(int irq
 		/*
 		 * Read interrupt status
 		 */
-		if (le32_to_cpu(ha->shadow_regs->rsp_q_in) !=
+		if (ha->isp_ops->rd_shdw_rsp_q_in(ha) !=
 		    ha->response_out)
 			intr_status = CSR_SCSI_COMPLETION_INTR;
 		else
 			intr_status = readl(&ha->reg->ctrl_status);
 
 		if ((intr_status &
-		     (CSR_SCSI_RESET_INTR|CSR_FATAL_ERROR|INTR_PENDING)) ==
-		    0) {
+		    (CSR_SCSI_RESET_INTR|CSR_FATAL_ERROR|INTR_PENDING)) == 0) {
 			if (reqs_count == 0)
 				ha->spurious_int_count++;
 			break;
 		}
 
 		if (intr_status & CSR_FATAL_ERROR) {
-			DEBUG2(printk(KERN_INFO "scsi%ld: Fatal Error, "
-				      "Status 0x%04x\n", ha->host_no,
+			DEBUG2(ql4_info(ha, "Fatal Error, Status 0x%04x\n",
 				      readl(isp_port_error_status (ha))));
 
 			/* Issue Soft Reset to clear this error condition.
@@ -766,25 +851,23 @@ irqreturn_t qla4xxx_intr_handler(int irq
 
 			break;
 		} else if (intr_status & CSR_SCSI_RESET_INTR) {
-			scsi_block_requests(ha->host);
 			clear_bit(AF_ONLINE, &ha->flags);
+			ql4_info(ha,"%s: Adapter OFFLINE\n", __func__);
 			__qla4xxx_disable_intrs(ha);
 
 			writel(set_rmask(CSR_SCSI_RESET_INTR),
 			       &ha->reg->ctrl_status);
 			readl(&ha->reg->ctrl_status);
 
-			if (!ql4_mod_unload)
+			if (!test_bit(AF_HA_REMOVAL, &ha->flags))
 				set_bit(DPC_RESET_HA_INTR, &ha->dpc_flags);
 
 			break;
 		} else if (intr_status & INTR_PENDING) {
-			qla4xxx_interrupt_service_routine(ha, intr_status);
+			ha->isp_ops->interrupt_service_routine(ha, intr_status);
 			ha->total_io_count++;
 			if (++reqs_count == MAX_REQS_SERVICED_PER_INTR)
 				break;
-
-			intr_status = 0;
 		}
 	}
 
@@ -794,6 +877,154 @@ irqreturn_t qla4xxx_intr_handler(int irq
 }
 
 /**
+ * qla4_8xxx_intr_handler - hardware interrupt handler.
+ * @irq: Unused
+ * @dev_id: Pointer to host adapter structure
+ **/
+irqreturn_t qla4_8xxx_intr_handler(int irq, void *dev_id)
+{
+	struct scsi_qla_host *ha = dev_id;
+	uint32_t intr_status = 0;
+	uint32_t status;
+	unsigned long flags = 0;
+	uint8_t reqs_count = 0;
+
+	if (unlikely(pci_channel_offline(ha->pdev)))
+		return IRQ_HANDLED;
+
+	ha->isr_count++;
+	status = qla4_8xxx_rd_32(ha, ISR_INT_VECTOR);
+	if (!(status & ha->nx_legacy_intr.int_vec_bit))
+		return IRQ_NONE;
+
+	status = qla4_8xxx_rd_32(ha, ISR_INT_STATE_REG);
+	if (!ISR_IS_LEGACY_INTR_TRIGGERED(status)) {
+		DEBUG2(ql4_info(ha,
+		    "%s legacy Int not triggered\n", __func__));
+		return IRQ_NONE;
+	}
+
+	/* clear the interrupt */
+	qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_status_reg, 0xffffffff);
+
+	/* read twice to ensure write is flushed */
+	qla4_8xxx_rd_32(ha, ISR_INT_VECTOR);
+	qla4_8xxx_rd_32(ha, ISR_INT_VECTOR);
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	while (1) {
+		if (!(readl(&ha->qla4_8xxx_reg->host_int) &
+		    ISRX_82XX_RISC_INT)) {
+			qla4_8xxx_spurious_interrupt(ha, reqs_count);
+			break;
+		}
+		intr_status =  readl(&ha->qla4_8xxx_reg->host_status);
+		if ((intr_status &
+		    (HSRX_RISC_MB_INT | HSRX_RISC_IOCB_INT)) == 0)  {
+			qla4_8xxx_spurious_interrupt(ha, reqs_count);
+			break;
+		}
+
+		ha->isp_ops->interrupt_service_routine(ha, intr_status);
+
+		/* Enable Interrupt */
+		qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_mask_reg, 0xfbff);
+
+		if (++reqs_count == MAX_REQS_SERVICED_PER_INTR)
+			break;
+	}
+
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+
+	if (!irq && (test_bit(AF_EEH_BUSY, &ha->flags))) {
+		DEBUG2(ql4_info(ha, "%s: status %x, intr_status"
+			" %x\n", __func__, status, intr_status));
+	}
+
+	return IRQ_HANDLED;
+}
+
+irqreturn_t
+qla4_8xxx_msi_handler(int irq, void *dev_id)
+{
+	struct scsi_qla_host *ha;
+
+	ha = (struct scsi_qla_host *) dev_id;
+	if (!ha) {
+		DEBUG2(ql4_info(ha, "qla4xxx: MSIX: Interrupt with NULL host "
+				" ptr\n"));
+		return IRQ_NONE;
+	}
+
+	ha->isr_count++;
+	/* clear the interrupt */
+	qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_status_reg, 0xffffffff);
+
+	/* read twice to ensure write is flushed */
+	qla4_8xxx_rd_32(ha, ISR_INT_VECTOR);
+	qla4_8xxx_rd_32(ha, ISR_INT_VECTOR);
+
+	return qla4_8xxx_default_intr_handler(irq, dev_id);
+}
+
+/**
+ * qla4_8xxx_default_intr_handler - hardware interrupt handler.
+ * @irq: Unused
+ * @dev_id: Pointer to host adapter structure
+ *
+ * This interrupt handler is called directly for MSI-X, and
+ * called indirectly for MSI.
+ **/
+irqreturn_t
+qla4_8xxx_default_intr_handler(int irq, void *dev_id)
+{
+	struct scsi_qla_host *ha = dev_id;
+	unsigned long   flags;
+	uint32_t intr_status;
+	uint8_t reqs_count = 0;
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	while (1) {
+		if (!(readl(&ha->qla4_8xxx_reg->host_int) &
+		    ISRX_82XX_RISC_INT)) {
+			qla4_8xxx_spurious_interrupt(ha, reqs_count);
+			break;
+		}
+
+		intr_status =  readl(&ha->qla4_8xxx_reg->host_status);
+		if ((intr_status &
+		    (HSRX_RISC_MB_INT | HSRX_RISC_IOCB_INT)) == 0) {
+			qla4_8xxx_spurious_interrupt(ha, reqs_count);
+			break;
+		}
+
+		ha->isp_ops->interrupt_service_routine(ha, intr_status);
+
+		if (++reqs_count == MAX_REQS_SERVICED_PER_INTR)
+			break;
+	}
+
+	ha->isr_count++;
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t
+qla4_8xxx_msix_rsp_q(int irq, void *dev_id)
+{
+	struct scsi_qla_host *ha = dev_id;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	qla4xxx_process_response_queue(ha);
+	writel(0, &ha->qla4_8xxx_reg->host_int);
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+
+	ha->isr_count++;
+	return IRQ_HANDLED;
+}
+
+/**
  * qla4xxx_process_aen - processes AENs generated by firmware
  * @ha: pointer to host adapter structure.
  * @process_aen: type of AENs to process
@@ -802,7 +1033,6 @@ irqreturn_t qla4xxx_intr_handler(int irq
  * The type of AENs to process is specified by process_aen and can be
  *	PROCESS_ALL_AENS	 0
  *	FLUSH_DDB_CHANGED_AENS	 1
- *	RELOGIN_DDB_CHANGED_AENS 2
  **/
 void qla4xxx_process_aen(struct scsi_qla_host * ha, uint8_t process_aen)
 {
@@ -813,72 +1043,137 @@ void qla4xxx_process_aen(struct scsi_qla
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 	while (ha->aen_out != ha->aen_in) {
+		/* Advance pointers for next entry */
+		ha->aen_out++;
+		if (ha->aen_out == MAX_AEN_ENTRIES)
+			ha->aen_out = 0;
+
+		/* copy aen information to local structure */
 		aen = &ha->aen_q[ha->aen_out];
-		/* copy aen information to local structure */
 		for (i = 0; i < MBOX_AEN_REG_COUNT; i++)
 			mbox_sts[i] = aen->mbox_sts[i];
 
-		ha->aen_q_count++;
-		ha->aen_out++;
-
-		if (ha->aen_out == MAX_AEN_ENTRIES)
-			ha->aen_out = 0;
-
 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
-		DEBUG2(printk("qla4xxx(%ld): AEN[%d]=0x%08x, mbx1=0x%08x mbx2=0x%08x"
-			" mbx3=0x%08x mbx4=0x%08x\n", ha->host_no,
-			(ha->aen_out ? (ha->aen_out-1): (MAX_AEN_ENTRIES-1)),
-			mbox_sts[0], mbox_sts[1], mbox_sts[2],
-			mbox_sts[3], mbox_sts[4]));
+		switch (mbox_sts[0]) {
+		case MBOX_ASTS_ISNS:
+			ql4_isns_process_isns_aen(ha, &mbox_sts[0]);
+			break;
+		case MBOX_ASTS_DATABASE_CHANGED:
+			switch(process_aen )  {
+			case FLUSH_DDB_CHANGED_AENS:
+				DEBUG2(ql4_info(ha, "AEN[%d] %04x, index "
+					      "[%d] state=%04x FLUSHED!\n",
+					      ha->aen_out, mbox_sts[0],
+					      mbox_sts[2], mbox_sts[3]));
+				break;
+			case PROCESS_ALL_AENS:
+			default:
+				/* WARNING: Post init only */
 
-		switch (mbox_sts[0]) {
-		case MBOX_ASTS_DATABASE_CHANGED:
-			if (process_aen == FLUSH_DDB_CHANGED_AENS) {
-				DEBUG2(printk("scsi%ld: AEN[%d] %04x, index "
-					      "[%d] state=%04x FLUSHED!\n",
-					      ha->host_no, ha->aen_out,
-					      mbox_sts[0], mbox_sts[2],
-					      mbox_sts[3]));
+				DEBUG2(ql4_info(ha, "AEN[%d] %04x %s: "
+					"mb1:0x%04x mb2:0x%04x mb3:0x%04x "
+					"mb4:0x%08x ddb 0x%p\n",
+					ha->aen_out, mbox_sts[0], __func__,
+					mbox_sts[1], mbox_sts[2], mbox_sts[3],
+					mbox_sts[4],
+					qla4xxx_lookup_ddb_by_fw_index(ha,
+					mbox_sts[2])));
+
+				if (mbox_sts[1] == 0) {
+					/* Global DB change. */
+					qla4xxx_reinitialize_ddb_list(ha);
+				} else if (mbox_sts[1] == 1) {
+					/* Specific device. */
+					qla4xxx_process_ddb_changed(ha,
+						mbox_sts[2],
+						mbox_sts[3], mbox_sts[4]);
+				}
 				break;
-			} else if (process_aen == RELOGIN_DDB_CHANGED_AENS) {
-				/* for use during init time, we only want to
-				 * relogin non-active ddbs */
-				struct ddb_entry *ddb_entry;
-
-				ddb_entry =
-					/* FIXME: name length? */
-					qla4xxx_lookup_ddb_by_fw_index(ha,
-								       mbox_sts[2]);
-				if (!ddb_entry)
-					break;
-
-				ddb_entry->dev_scan_wait_to_complete_relogin =
-					0;
-				ddb_entry->dev_scan_wait_to_start_relogin =
-					jiffies +
-					((ddb_entry->default_time2wait +
-					  4) * HZ);
-
-				DEBUG2(printk("scsi%ld: ddb index [%d] initate"
-					      " RELOGIN after %d seconds\n",
-					      ha->host_no,
-					      ddb_entry->fw_ddb_index,
-					      ddb_entry->default_time2wait +
-					      4));
-				break;
-			}
-
-			if (mbox_sts[1] == 0) {	/* Global DB change. */
-				qla4xxx_reinitialize_ddb_list(ha);
-			} else if (mbox_sts[1] == 1) {	/* Specific device. */
-				qla4xxx_process_ddb_changed(ha, mbox_sts[2],
-							    mbox_sts[3], mbox_sts[4]);
-			}
+			} /* switch process_aen */
 			break;
-		}
+		} /* switch mbox_sts[0] */
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 	}
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 }
 
+int qla4xxx_request_irqs(struct scsi_qla_host *ha)
+{
+	int ret;
+
+	if (!is_qla8022(ha) || ql4xenablemsix == 0)
+		goto try_intx;
+
+	if (ql4xenablemsix == 2)
+		goto try_msi;
+
+	/* Trying MSI-X */
+	ret = qla4_8xxx_enable_msix(ha);
+	if (!ret) {
+		DEBUG2(ql4_info(ha, "MSI-X: Enabled (0x%X).\n",
+					ha->revision_id));
+		goto irq_attached;
+	}
+
+	ql4_warn(ha, "MSI-X: Falling back-to MSI mode -- %d.\n", ret);
+
+try_msi:
+	/* Trying MSI */
+	ret = pci_enable_msi(ha->pdev);
+	if (!ret) {
+		ret = request_irq(ha->pdev->irq, qla4_8xxx_msi_handler,
+			IRQF_DISABLED, DRIVER_NAME, ha);
+		if (!ret) {
+			DEBUG2(ql4_info(ha, "MSI: Enabled.\n"));
+			set_bit(AF_MSI_ENABLED, &ha->flags);
+			goto irq_attached;
+		} else {
+			ql4_warn(ha, "MSI: Failed to reserve interrupt %d "
+			    "already in use.\n", ha->pdev->irq);
+			pci_disable_msi(ha->pdev);
+		}
+	}
+
+	#if MIXED_INTR_MODE_WORKAROUND
+	goto irq_not_attached;
+	#else
+	ql4_warn(ha, "MSI: Falling back-to INTx mode -- %d.\n", ret);
+	#endif
+
+try_intx:
+	/* Trying INTx */
+	ret = request_irq(ha->pdev->irq, ha->isp_ops->intr_handler,
+	    IRQF_DISABLED|IRQF_SHARED, DRIVER_NAME, ha);
+	if (!ret) {
+		DEBUG2(ql4_info(ha, "INTx: Enabled.\n"));
+		set_bit(AF_INTx_ENABLED, &ha->flags);
+		goto irq_attached;
+
+	} else {
+		ql4_warn(ha, "INTx: Failed to reserve interrupt %d already in"
+		         " use.\n", ha->pdev->irq);
+		goto irq_not_attached;
+	}
+
+irq_attached:
+	set_bit(AF_IRQ_ATTACHED, &ha->flags);
+	ha->host->irq = ha->pdev->irq;
+	ql4_info(ha, "IRQ %d attached\n", ha->pdev->irq);
+	return ret;
+
+irq_not_attached:
+	ql4_warn(ha, "IRQ not attached -- %d.\n", ret);
+	return ret;
+}
+
+void qla4xxx_free_irqs(struct scsi_qla_host *ha)
+{
+	if (test_bit(AF_MSIX_ENABLED, &ha->flags))
+		qla4_8xxx_disable_msix(ha);
+	else if (test_and_clear_bit(AF_MSI_ENABLED, &ha->flags)) {
+		free_irq(ha->pdev->irq, ha);
+		pci_disable_msi(ha->pdev);
+	} else if (test_and_clear_bit(AF_INTx_ENABLED, &ha->flags))
+		free_irq(ha->pdev->irq, ha);
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_kcompat.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_kcompat.h
@@ -0,0 +1,58 @@
+/*
+ * QLogic ISCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ *
+ * PCI searching functions pci_get_domain_bus_and_slot & pci_channel_offline
+ * Copyright (C) 1993 -- 1997 Drew Eckhardt, Frederic Potter,
+ *                                      David Mosberger-Tang
+ * Copyright (C) 1997 -- 2000 Martin Mares <mj@ucw.cz>
+ * Copyright (C) 2003 -- 2004 Greg Kroah-Hartman <greg@kroah.com>.
+ */
+
+#ifndef __QLA_KCOMPAT_H
+#define __QLA_KCOMPAT_H
+
+#include <linux/version.h>
+#include <linux/pci.h>
+#include <scsi/scsi.h>
+
+#if defined (QL4_PCIGBDS)
+static inline struct pci_dev *pci_get_domain_bus_and_slot(int domain, unsigned int bus,
+		unsigned int devfn)
+{
+	struct pci_dev *dev = NULL;
+
+	while ((dev = pci_get_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
+		if (pci_domain_nr(dev->bus) == domain &&
+		    (dev->bus->number == bus && dev->devfn == devfn))
+			return dev;
+	}
+	return NULL;
+}
+#endif
+
+#ifndef FAST_IO_FAIL
+#define FAST_IO_FAIL	FAILED;
+#endif
+
+#if (LINUX_VERSION_CODE == KERNEL_VERSION(2,6,32))
+/*
+ * Display an IP address in readable format.
+ */
+
+#define NIP6(addr) \
+        ntohs((addr).s6_addr16[0]), \
+        ntohs((addr).s6_addr16[1]), \
+        ntohs((addr).s6_addr16[2]), \
+        ntohs((addr).s6_addr16[3]), \
+        ntohs((addr).s6_addr16[4]), \
+        ntohs((addr).s6_addr16[5]), \
+        ntohs((addr).s6_addr16[6]), \
+        ntohs((addr).s6_addr16[7])
+
+#define NIP6_FMT "%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x"
+#define NIP6_SEQFMT "%04x%04x%04x%04x%04x%04x%04x%04x"
+#endif
+#endif
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_mbx.c
--- a/drivers/scsi/qla4xxx/ql4_mbx.c
+++ b/drivers/scsi/qla4xxx/ql4_mbx.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -19,26 +19,53 @@
  * @mbx_cmd: data pointer for mailbox in registers.
  * @mbx_sts: data pointer for mailbox out registers.
  *
- * This routine sssue mailbox commands and waits for completion.
+ * This routine isssue mailbox commands and waits for completion.
  * If outCount is 0, this routine completes successfully WITHOUT waiting
  * for the mailbox command to complete.
  **/
 int qla4xxx_mailbox_command(struct scsi_qla_host *ha, uint8_t inCount,
-				   uint8_t outCount, uint32_t *mbx_cmd,
-				   uint32_t *mbx_sts)
+			    uint8_t outCount, uint32_t *mbx_cmd,
+			    uint32_t *mbx_sts)
 {
 	int status = QLA_ERROR;
 	uint8_t i;
 	u_long wait_count;
 	uint32_t intr_status;
 	unsigned long flags = 0;
+	uint32_t dev_state;
 
 	/* Make sure that pointers are valid */
 	if (!mbx_cmd || !mbx_sts) {
-		DEBUG2(printk("scsi%ld: %s: Invalid mbx_cmd or mbx_sts "
-			      "pointer\n", ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Invalid mbx_cmd or mbx_sts pointer\n",
+				__func__));
 		return status;
 	}
+
+	if (is_qla8022(ha)) {
+		if (test_bit(AF_FW_RECOVERY, &ha->flags)) {
+			DEBUG2(ql4_warn(ha, "%s: prematurely completing"
+				" mbx cmd as firmware recovery detected\n", __func__));
+			return status;
+		}
+
+		qla4_8xxx_idc_lock(ha);
+		dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+		qla4_8xxx_idc_unlock(ha);
+		if (dev_state == QLA82XX_DEV_FAILED) {
+		dev_info(&ha->pdev->dev, "%s: don't retry "
+				"adapter init. H/W is in Failed state\n",
+				__func__);
+			return status;
+		}
+	}
+
+	if ((is_aer_supported(ha)) &&
+	    (test_bit(AF_PCI_CHANNEL_IO_PERM_FAILURE, &ha->flags))) {
+		DEBUG2(ql4_info(ha, "%s: Perm failure on EEH, "
+				"timeout MBX Exiting.\n", __func__));
+		return status;
+	}
+
 	/* Mailbox code active */
 	wait_count = MBOX_TOV * 100;
 
@@ -51,40 +78,49 @@ int qla4xxx_mailbox_command(struct scsi_
 		}
 		mutex_unlock(&ha->mbox_sem);
 		if (!wait_count) {
-			DEBUG2(printk("scsi%ld: %s: mbox_sem failed\n",
-				ha->host_no, __func__));
+			DEBUG2(ql4_info(ha, "%s: mbox_sem failed\n", __func__));
 			return status;
 		}
 		msleep(10);
 	}
 
 	/* To prevent overwriting mailbox registers for a command that has
-	 * not yet been serviced, check to see if a previously issued
-	 * mailbox command is interrupting.
+	 * not yet been serviced, check to see if an active command
+	 * (AEN, IOCB, etc.) is interrupting, then service it.
 	 * -----------------------------------------------------------------
 	 */
 	spin_lock_irqsave(&ha->hardware_lock, flags);
-	intr_status = readl(&ha->reg->ctrl_status);
-	if (intr_status & CSR_SCSI_PROCESSOR_INTR) {
-		/* Service existing interrupt */
-		qla4xxx_interrupt_service_routine(ha, intr_status);
-		clear_bit(AF_MBOX_COMMAND_DONE, &ha->flags);
-	}
 
-	/* Send the mailbox command to the firmware */
 	ha->mbox_status_count = outCount;
 	for (i = 0; i < outCount; i++)
 		ha->mbox_status[i] = 0;
 
-	/* Load all mailbox registers, except mailbox 0. */
-	for (i = 1; i < inCount; i++)
-		writel(mbx_cmd[i], &ha->reg->mailbox[i]);
+	if (is_qla8022(ha)) {
+		/* Load all mailbox registers, except mailbox 0. */
+		DEBUG5(
+		    printk("%s: Cmd ", __func__);
+		    for (i = 0; i < inCount; i++)
+			printk("mb%d=%04x ", i, mbx_cmd[i]);
+		    printk("\n"));
 
-	/* Wakeup firmware  */
-	writel(mbx_cmd[0], &ha->reg->mailbox[0]);
-	readl(&ha->reg->mailbox[0]);
-	writel(set_rmask(CSR_INTR_RISC), &ha->reg->ctrl_status);
-	readl(&ha->reg->ctrl_status);
+		for (i = 1; i < inCount; i++)
+			writel(mbx_cmd[i], &ha->qla4_8xxx_reg->mailbox_in[i]);
+		writel(mbx_cmd[0], &ha->qla4_8xxx_reg->mailbox_in[0]);
+		readl(&ha->qla4_8xxx_reg->mailbox_in[0]);
+		writel(HINT_MBX_INT_PENDING, &ha->qla4_8xxx_reg->hint);
+	} else {
+		/* Load all mailbox registers, except mailbox 0. */
+		DEBUG5(qla4xxx_dump_mbx_cmd(ha, mbx_cmd));
+		for (i = 1; i < inCount; i++)
+			writel(mbx_cmd[i], &ha->reg->mailbox[i]);
+
+		/* Wakeup firmware  */
+		writel(mbx_cmd[0], &ha->reg->mailbox[0]);
+		readl(&ha->reg->mailbox[0]);
+		writel(set_rmask(CSR_INTR_RISC), &ha->reg->ctrl_status);
+		readl(&ha->reg->ctrl_status);
+	}
+
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
 	/* Wait for completion */
@@ -98,36 +134,89 @@ int qla4xxx_mailbox_command(struct scsi_
 		status = QLA_SUCCESS;
 		goto mbox_exit;
 	}
-	/* Wait for command to complete */
-	wait_count = jiffies + MBOX_TOV * HZ;
-	while (test_bit(AF_MBOX_COMMAND_DONE, &ha->flags) == 0) {
-		if (time_after_eq(jiffies, wait_count))
-			break;
 
-		spin_lock_irqsave(&ha->hardware_lock, flags);
-		intr_status = readl(&ha->reg->ctrl_status);
-		if (intr_status & INTR_PENDING) {
+	/*
+	 * Wait for completion: Poll or completion queue
+	 */
+	if (test_bit(AF_IRQ_ATTACHED, &ha->flags) &&
+	    test_bit(AF_INTERRUPTS_ON, &ha->flags) &&
+	    test_bit(AF_ONLINE, &ha->flags) &&
+	    !test_bit(AF_HA_REMOVAL, &ha->flags)) {
+		/* Do not poll for completion. Use completion queue */
+		set_bit(AF_MBOX_COMMAND_NOPOLL, &ha->flags);
+		wait_for_completion_timeout(&ha->mbx_intr_comp, MBOX_TOV * HZ);
+		clear_bit(AF_MBOX_COMMAND_NOPOLL, &ha->flags);
+	} else {
+		/* Poll for command to complete */
+		wait_count = jiffies + MBOX_TOV * HZ;
+		while (test_bit(AF_MBOX_COMMAND_DONE, &ha->flags) == 0) {
+			if (time_after_eq(jiffies, wait_count))
+				break;
+
 			/*
 			 * Service the interrupt.
 			 * The ISR will save the mailbox status registers
 			 * to a temporary storage location in the adapter
 			 * structure.
 			 */
-			ha->mbox_status_count = outCount;
-			qla4xxx_interrupt_service_routine(ha, intr_status);
+
+			spin_lock_irqsave(&ha->hardware_lock, flags);
+			if (is_qla8022(ha)) {
+				intr_status =
+				    readl(&ha->qla4_8xxx_reg->host_int);
+				if (intr_status & ISRX_82XX_RISC_INT) {
+					ha->mbox_status_count = outCount;
+					intr_status =
+					 readl(&ha->qla4_8xxx_reg->host_status);
+					ha->isp_ops->interrupt_service_routine(
+					    ha, intr_status);
+					if (test_bit(AF_INTERRUPTS_ON,
+					    &ha->flags) &&
+					    test_bit(AF_INTx_ENABLED,
+					    &ha->flags))
+						qla4_8xxx_wr_32(ha,
+						ha->nx_legacy_intr.tgt_mask_reg,
+						0xfbff);
+				}
+			} else {
+				intr_status = readl(&ha->reg->ctrl_status);
+				if (intr_status & INTR_PENDING) {
+					/*
+					 * Service the interrupt.
+					 * The ISR will save the mailbox status
+					 * registers to a temporary storage
+					 * location in the adapter structure.
+					 */
+					ha->mbox_status_count = outCount;
+					ha->isp_ops->interrupt_service_routine(
+					    ha, intr_status);
+				}
+			}
+			spin_unlock_irqrestore(&ha->hardware_lock, flags);
+			msleep(10);
 		}
-		spin_unlock_irqrestore(&ha->hardware_lock, flags);
-		msleep(10);
 	}
 
 	/* Check for mailbox timeout. */
 	if (!test_bit(AF_MBOX_COMMAND_DONE, &ha->flags)) {
-		DEBUG2(printk("scsi%ld: Mailbox Cmd 0x%08X timed out ...,"
-			      " Scheduling Adapter Reset\n", ha->host_no,
-			      mbx_cmd[0]));
+		if (is_qla8022(ha) &&
+		    test_bit(AF_FW_RECOVERY, &ha->flags)) {
+			DEBUG2(ql4_info(ha, "%s: prematurely completing mbx cmd"
+					" as firmware recovery detected\n",
+					__func__));
+			goto mbox_exit;
+		}
+		DEBUG2(ql4_info(ha, "Mailbox Cmd 0x%08X timed out ...,"
+			      " Scheduling Adapter Reset\n", mbx_cmd[0]));
 		ha->mailbox_timeout_count++;
 		mbx_sts[0] = (-1);
 		set_bit(DPC_RESET_HA, &ha->dpc_flags);
+		if (is_qla8022(ha)) {
+			ql4_info(ha,
+			    "disabling pause transmit on port 0 & 1.\n");
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x98,
+			    CRB_NIU_XG_PAUSE_CTL_P0|CRB_NIU_XG_PAUSE_CTL_P1);
+		}
 		goto mbox_exit;
 	}
 
@@ -150,22 +239,24 @@ int qla4xxx_mailbox_command(struct scsi_
 		break;
 
 	case MBOX_STS_BUSY:
-		DEBUG2( printk("scsi%ld: %s: Cmd = %08X, ISP BUSY\n",
-			       ha->host_no, __func__, mbx_cmd[0]));
+		DEBUG2(ql4_info(ha, "%s: Cmd = %08X, ISP BUSY\n", __func__,
+				mbx_cmd[0]));
 		ha->mailbox_timeout_count++;
 		break;
 
 	default:
-		DEBUG2(printk("scsi%ld: %s: **** FAILED, cmd = %08X, "
-			      "sts = %08X ****\n", ha->host_no, __func__,
-			      mbx_cmd[0], mbx_sts[0]));
+		DEBUG2(ql4_info(ha, "%s: **** FAILED, cmd = %08X, "
+				"sts = %08X ****\n", __func__, mbx_cmd[0],
+				mbx_sts[0]));
+		DEBUG2(qla4xxx_dump_mbx_sts(ha, mbx_sts));
 		break;
 	}
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
 mbox_exit:
 	if (status == QLA_SUCCESS)
-		qla4xxx_check_for_clear_ddb(ha, mbx_cmd);
+		qla4xxx_check_for_free_ddb(ha, mbx_cmd);
+
 	mutex_lock(&ha->mbox_sem);
 	clear_bit(AF_MBOX_COMMAND, &ha->flags);
 	mutex_unlock(&ha->mbox_sem);
@@ -174,12 +265,104 @@ mbox_exit:
 	return status;
 }
 
+
+/*
+ * qla4xxx_get_minidump_template: Get the firmware template
+ * scsi_qla_host: ha
+ * dma_addr_t: Allocated memory for template
+ * 
+ * Obtain the minidump template from firmware during initialisation 
+ * as it may not be available when minidump is desired. 
+*/
+
+int qla4xxx_get_minidump_template(struct scsi_qla_host * ha, dma_addr_t phys_addr)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	int status;
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	
+	mbox_cmd[0] = MBOX_CMD_MINIDUMP;
+	mbox_cmd[1] = MINIDUMP_GET_TMPLT_SUBCOMMAND;
+	mbox_cmd[2] = LSDW(phys_addr);
+	mbox_cmd[3] = MSDW(phys_addr);
+	mbox_cmd[4] = ha->fw_dump_tmplt_size;
+	mbox_cmd[5] = 0;                //Offset
+	
+	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]);
+	if (status != QLA_SUCCESS) {
+		DEBUG2(printk("scsi%ld: %s: Cmd = %08X, mbx[0] = 0x%04x, mbx[1] = 0x%04x\n",
+				ha->host_no, __func__, mbox_cmd[0], mbox_sts[0], mbox_sts[1]));
+	}
+	return status;
+}
+
+/*
+ * qla4xxx_req_template_size: Function to identify of the Firmware support minidump 
+ * scsi_qla_host
+ * Function use mailbox command to indicate if the firmware support minidump or not
+*/
+int qla4xxx_req_template_size(struct scsi_qla_host * ha)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+
+	int status;
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	
+	mbox_cmd[0] = MBOX_CMD_MINIDUMP;
+	mbox_cmd[1] = MINIDUMP_GET_SIZE_SUBCOMMAND;
+
+	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 8, &mbox_cmd[0], &mbox_sts[0]);
+	if (status == QLA_SUCCESS) {
+		ha->fw_dump_tmplt_size = mbox_sts[1];
+		DEBUG2(printk("sts[0]=0x%04x, template size=0x%04x, "
+				"size_cm_02 =0x%04x, size_cm_04 =0x%04x\n"
+				"size_cm_08 =0x%04x, size_cm_10 =0x%04x ,"
+				"size_cm_FF =0x%04x, version =0x%04x\n",
+				mbox_sts[0], mbox_sts[1], mbox_sts[2],
+				mbox_sts[3], mbox_sts[4], mbox_sts[5],
+				mbox_sts[6], mbox_sts[7]));
+		if (ha->fw_dump_tmplt_size == 0)
+			status = 1;
+	} else {
+		printk("Error sts[0]=0x%04x, mbx[1] = 0x%04x\n", mbox_sts[0], mbox_sts[1]);
+			status = 1;
+	}
+
+	return status;
+}
+
+
+void qla4xxx_mailbox_premature_completion(struct scsi_qla_host *ha)
+{
+	set_bit(AF_FW_RECOVERY, &ha->flags);
+	ql4_info(ha, "%s: set FW RECOVERY!\n", __func__);
+
+	if (test_bit(AF_MBOX_COMMAND, &ha->flags)) {
+		if (test_bit(AF_MBOX_COMMAND_NOPOLL, &ha->flags)) {
+			ql4_info(ha, "%s: Due to fw "
+			    "recovery, doing premature completion of "
+			    "mbx cmd\n", __func__);
+			complete(&ha->mbx_intr_comp);
+
+		} else {
+			ql4_info(ha, "%s: Due to fw "
+			    "recovery, doing premature completion of "
+			    "polling mbx cmd\n", __func__);
+			set_bit(AF_MBOX_COMMAND_DONE, &ha->flags);
+		}
+	}
+}
+
 /**
- * qla4xxx_issue_iocb - issue mailbox iocb command
+ * qla4xxx_issue_iocb - issue iocb via ExecuteIOCB mailbox command
  * @ha: adapter state pointer.
- * @buffer: buffer pointer.
+ * @comp_offset: Offset to completion status.
  * @phys_addr: physical address of buffer.
- * @size: size of buffer.
  *
  * Issues iocbs via mailbox commands.
  * TARGET_QUEUE_LOCK must be released.
@@ -187,7 +370,7 @@ mbox_exit:
  **/
 int
 qla4xxx_issue_iocb(struct scsi_qla_host *ha, uint32_t comp_offset,
-			dma_addr_t phys_addr)
+		dma_addr_t phys_addr)
 {
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
@@ -201,14 +384,14 @@ qla4xxx_issue_iocb(struct scsi_qla_host 
 	mbox_cmd[2] = LSDW(phys_addr);
 	mbox_cmd[3] = MSDW(phys_addr);
 
-	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]);
+	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0],
+	    &mbox_sts[0]);
 	return status;
 }
 
-int qla4xxx_conn_close_sess_logout(struct scsi_qla_host *ha,
-				    uint16_t fw_ddb_index,
-				    uint16_t connection_id,
-				    uint16_t option)
+int qla4xxx_conn_close_sess_logout(struct scsi_qla_host * ha,
+		uint16_t fw_ddb_index,
+		uint16_t option)
 {
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
@@ -216,89 +399,102 @@ int qla4xxx_conn_close_sess_logout(struc
 	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
 	memset(&mbox_sts, 0, sizeof(mbox_sts));
 
-	mbox_cmd[0] = MBOX_CMD_CONN_CLOSE_SESS_LOGOUT;
+	mbox_cmd[0] = MBOX_CMD_CONN_CLOSE;
 	mbox_cmd[1] = fw_ddb_index;
-	mbox_cmd[2] = connection_id;
-	mbox_cmd[3] = LOGOUT_OPTION_RESET;
+	mbox_cmd[3] = option;
 
-	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) !=
-	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_CONN_CLOSE_SESS_LOGOUT "
-			      "option %04x failed sts %04X %04X",
-			      ha->host_no, __func__,
-			      option, mbox_sts[0], mbox_sts[1]));
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0],
+	    &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_CONN_CLOSE "
+			"option %04x failed sts %04X %04X", __func__,
+			option, mbox_sts[0], mbox_sts[1]));
 		if (mbox_sts[0] == 0x4005)
-			DEBUG2(printk("%s reason %04X\n", __func__,
-				      mbox_sts[1]));
+			DEBUG2(ql4_info(ha, "%s reason %04X\n", __func__,
+				mbox_sts[1]));
 	}
 	return QLA_SUCCESS;
 }
 
-uint8_t
-qla4xxx_set_ifcb(struct scsi_qla_host *ha, uint32_t *mbox_cmd, uint32_t *mbox_sts,
-			dma_addr_t init_fw_cb_dma)
+int qla4xxx_free_database_entry(struct scsi_qla_host * ha,
+                                 uint16_t fw_ddb_index)
+{
+        uint32_t mbox_cmd[MBOX_REG_COUNT];
+        uint32_t mbox_sts[MBOX_REG_COUNT];
+        int status;
+
+        memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+        memset(&mbox_sts, 0, sizeof(mbox_sts));
+        mbox_cmd[0] = MBOX_CMD_FREE_DATABASE_ENTRY;
+        mbox_cmd[1] = fw_ddb_index;
+
+        status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5,
+                &mbox_cmd[0], &mbox_sts[0]);
+        if (status != QLA_SUCCESS)
+                DEBUG2(ql4_info(ha, "%s:  MBOX failed w/ "
+                        "cmd0=0x%04x cmd1=0x%04x cmd3=0x%04x, "
+                        "sts0=0x%04x sts1=0x%04x sts4=0x%04x \n",
+                        __func__, mbox_cmd[0], mbox_cmd[1], mbox_cmd[3],
+                        mbox_sts[0], mbox_sts[1], mbox_sts[4]));
+
+        return status;
+}
+
+static uint8_t
+qla4xxx_set_ifcb(struct scsi_qla_host *ha, uint32_t *mbox_cmd,
+		 uint32_t *mbox_sts, dma_addr_t init_fw_cb_dma)
 {
 	memset(mbox_cmd, 0, sizeof(mbox_cmd[0]) * MBOX_REG_COUNT);
 	memset(mbox_sts, 0, sizeof(mbox_sts[0]) * MBOX_REG_COUNT);
+
+	if (is_qla8022(ha))
+		qla4_8xxx_wr_32(ha, ha->nx_db_wr_ptr, 0);
+
 	mbox_cmd[0] = MBOX_CMD_INITIALIZE_FIRMWARE;
 	mbox_cmd[1] = 0;
 	mbox_cmd[2] = LSDW(init_fw_cb_dma);
 	mbox_cmd[3] = MSDW(init_fw_cb_dma);
-	if (ha->ifcb_size > LEGACY_IFCB_SIZE) {
-		mbox_cmd[4] = ha->ifcb_size;
-		mbox_cmd[5] = (IFCB_VER_MAX << 8) | IFCB_VER_MIN;
+	mbox_cmd[4] = sizeof(struct addr_ctrl_blk);
+	mbox_cmd[5] = (IFCB_VER_MAX << 8) | IFCB_VER_MIN;
+
+	if (qla4xxx_mailbox_command(ha, 6, 6, mbox_cmd, mbox_sts) !=
+	    QLA_SUCCESS) {
+		DEBUG2(ql4_warn(ha, "%s: "
+			      "MBOX_CMD_INITIALIZE_FIRMWARE"
+			      " failed w/ status %04X\n",
+			      __func__, mbox_sts[0]));
+		return QLA_ERROR;
 	}
-
-	if (qla4xxx_mailbox_command(ha, 6, 6, mbox_cmd, mbox_sts)
-		!= QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: "
-			      "MBOX_CMD_INITIALIZE_FIRMWARE failed w/ status %04X\n",
-			      ha->host_no, __func__, mbox_sts[0]));
-		return (QLA_ERROR);
-	}
-	return (QLA_SUCCESS);
+	return QLA_SUCCESS;
 }
 
-uint8_t
-qla4xxx_get_ifcb(struct scsi_qla_host *ha, uint32_t *mbox_cmd, uint32_t *mbox_sts,
-                dma_addr_t init_fw_cb_dma)
+static uint8_t
+qla4xxx_get_ifcb(struct scsi_qla_host *ha, uint32_t *mbox_cmd,
+		 uint32_t *mbox_sts, dma_addr_t init_fw_cb_dma)
 {
-	int i;
-
 	memset(mbox_cmd, 0, sizeof(mbox_cmd[0]) * MBOX_REG_COUNT);
 	memset(mbox_sts, 0, sizeof(mbox_sts[0]) * MBOX_REG_COUNT);
 	mbox_cmd[0] = MBOX_CMD_GET_INIT_FW_CTRL_BLOCK;
 	mbox_cmd[2] = LSDW(init_fw_cb_dma);
 	mbox_cmd[3] = MSDW(init_fw_cb_dma);
-	if (init_fw_cb_dma != 0 && ha->ifcb_size > LEGACY_IFCB_SIZE)
-		mbox_cmd[4] = ha->ifcb_size;
+	mbox_cmd[4] = sizeof(struct addr_ctrl_blk);
 
-	if (qla4xxx_mailbox_command(ha, 5, 5, mbox_cmd, mbox_sts)
-		!= QLA_SUCCESS) {
-		if (init_fw_cb_dma == 0 &&
-		    mbox_sts[0] == MBOX_STS_COMMAND_PARAMETER_ERROR)
-			return (QLA_SUCCESS);
-
-		DEBUG2(printk("scsi%ld: %s: "
-			      "MBOX_CMD_GET_INIT_FW_CTRL_BLOCK failed w/ status %04X\n",
-			      ha->host_no, __func__, mbox_sts[0]));
-
-		for (i = 0; i < MBOX_REG_COUNT; i++) {
-			DEBUG2(printk("mbox_cmd[%d] = %08x,     "
-				"mbox_sts[%d] = %08x\n",
-				i, mbox_cmd[i], i, mbox_sts[i]));
-		}
-
-		return (QLA_ERROR);
+	if (qla4xxx_mailbox_command(ha, 5, 5, mbox_cmd, mbox_sts) !=
+	    QLA_SUCCESS) {
+		DEBUG2(ql4_warn(ha, "%s: MBOX_CMD_GET_INIT_FW_CTRL_BLOCK"
+			      " failed w/ status %04X\n",
+			      __func__, mbox_sts[0]));
+		return QLA_ERROR;
 	}
-	return (QLA_SUCCESS);
+	return QLA_SUCCESS;
 }
 
-void
+static void
 qla4xxx_update_local_ip(struct scsi_qla_host *ha,
 			 struct addr_ctrl_blk  *init_fw_cb)
 {
 	/* Save IPv4 Address Info */
+	ha->ipv4_options = le16_to_cpu(init_fw_cb->ipv4_ip_opts);
+	ha->ipv4_addr_state = le16_to_cpu(init_fw_cb->ipv4_addr_state);
 	memcpy(ha->ip_address, init_fw_cb->ipv4_addr,
 		min(sizeof(ha->ip_address), sizeof(init_fw_cb->ipv4_addr)));
 	memcpy(ha->subnet_mask, init_fw_cb->ipv4_subnet,
@@ -307,7 +503,8 @@ qla4xxx_update_local_ip(struct scsi_qla_
 		min(sizeof(ha->gateway), sizeof(init_fw_cb->ipv4_gw_addr)));
 
 	if (is_ipv6_enabled(ha)) {
-		 /* Save IPv6 Address */
+		/* Save IPv6 Address */
+		ha->ipv6_options = init_fw_cb->ipv6_opts;
 		ha->ipv6_link_local_state = init_fw_cb->ipv6_lnk_lcl_addr_state;
 		ha->ipv6_addr0_state = init_fw_cb->ipv6_addr0_state;
 		ha->ipv6_addr1_state = init_fw_cb->ipv6_addr1_state;
@@ -315,18 +512,25 @@ qla4xxx_update_local_ip(struct scsi_qla_
 		ha->ipv6_link_local_addr.in6_u.u6_addr8[0] = 0xFE;
 		ha->ipv6_link_local_addr.in6_u.u6_addr8[1] = 0x80;
 
-		memcpy(&ha->ipv6_link_local_addr.in6_u.u6_addr8[8], init_fw_cb->ipv6_if_id,
-			min(sizeof(ha->ipv6_link_local_addr)/2, sizeof(init_fw_cb->ipv6_if_id)));
+		memcpy(&ha->ipv6_link_local_addr.in6_u.u6_addr8[8],
+			init_fw_cb->ipv6_if_id,
+			min(sizeof(ha->ipv6_link_local_addr)/2,
+			sizeof(init_fw_cb->ipv6_if_id)));
 		memcpy(&ha->ipv6_addr0, init_fw_cb->ipv6_addr0,
-			min(sizeof(ha->ipv6_addr0), sizeof(init_fw_cb->ipv6_addr0)));
+			min(sizeof(ha->ipv6_addr0),
+			sizeof(init_fw_cb->ipv6_addr0)));
 		memcpy(&ha->ipv6_addr1, init_fw_cb->ipv6_addr1,
-			min(sizeof(ha->ipv6_addr1), sizeof(init_fw_cb->ipv6_addr1)));
-		memcpy(&ha->ipv6_default_router_addr, init_fw_cb->ipv6_dflt_rtr_addr,
-			min(sizeof(ha->ipv6_default_router_addr), sizeof(init_fw_cb->ipv6_dflt_rtr_addr)));
+			min(sizeof(ha->ipv6_addr1),
+			sizeof(init_fw_cb->ipv6_addr1)));
+		memcpy(&ha->ipv6_default_router_addr,
+			init_fw_cb->ipv6_dflt_rtr_addr,
+			min(sizeof(ha->ipv6_default_router_addr),
+			sizeof(init_fw_cb->ipv6_dflt_rtr_addr)));
 	}
+	ql4_isns_populate_server_ip(ha, init_fw_cb);
 }
 
-uint8_t
+static uint8_t
 qla4xxx_update_local_ifcb(struct scsi_qla_host *ha,
 			  uint32_t *mbox_cmd,
 			  uint32_t *mbox_sts,
@@ -335,37 +539,35 @@ qla4xxx_update_local_ifcb(struct scsi_ql
 {
 	if (qla4xxx_get_ifcb(ha, mbox_cmd, mbox_sts, init_fw_cb_dma)
 	    != QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: Failed to get init_fw_ctrl_blk\n",
-				ha->host_no, __func__));
-		return (QLA_ERROR);
+		DEBUG2(ql4_warn(ha, "%s: Failed to get init_fw_ctrl_blk\n",
+			      __func__));
+		return QLA_ERROR;
 	}
 
-	DEBUG3(qla4xxx_dump_buffer(init_fw_cb, sizeof(struct addr_ctrl_blk)));
+	DEBUG2(qla4xxx_dump_buffer(init_fw_cb, sizeof(struct addr_ctrl_blk)));
 
 	/* Save some info in adapter structure. */
 	ha->acb_version = init_fw_cb->acb_version;
 	ha->firmware_options = le16_to_cpu(init_fw_cb->fw_options);
 	ha->tcp_options = le16_to_cpu(init_fw_cb->ipv4_tcp_opts);
-	ha->ipv4_options = le16_to_cpu(init_fw_cb->ipv4_ip_opts);
-	ha->ipv4_addr_state = le16_to_cpu(init_fw_cb->ipv4_addr_state);
 	ha->heartbeat_interval = init_fw_cb->hb_interval;
 	memcpy(ha->name_string, init_fw_cb->iscsi_name,
 		min(sizeof(ha->name_string),
 		sizeof(init_fw_cb->iscsi_name)));
-	/*memcpy(ha->alias, init_fw_cb->Alias,
-	       min(sizeof(ha->alias), sizeof(init_fw_cb->Alias)));*/
 
-	/* Save Command Line Paramater info */
-	ha->port_down_retry_count = le16_to_cpu(init_fw_cb->conn_ka_timeout);
-	ha->discovery_wait = ql4xdiscoverywait;
+	if (is_isnsv4_enabled(ha) || is_isnsv6_enabled(ha))
+		set_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP, &ha->isns.flags);
 
 	if (ha->acb_version == ACB_SUPPORTED) {
 		ha->ipv6_options = init_fw_cb->ipv6_opts;
 		ha->ipv6_addl_options = init_fw_cb->ipv6_addtl_opts;
 	}
+
+	ha->port_down_retry_count = le16_to_cpu(init_fw_cb->conn_ka_timeout);
+
 	qla4xxx_update_local_ip(ha, init_fw_cb);
 
-	return (QLA_SUCCESS);
+	return QLA_SUCCESS;
 }
 
 /**
@@ -380,41 +582,21 @@ int qla4xxx_initialize_fw_cb(struct scsi
 	uint32_t mbox_sts[MBOX_REG_COUNT];
 	int status = QLA_ERROR;
 
-	/* Default to Legacy IFCB Size */
-	ha->ifcb_size = LEGACY_IFCB_SIZE;
-
-	if (qla4xxx_get_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], 0) !=
-	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: get ifcb failed\n",
-			       ha->host_no, __func__));
-		return status;
-	}
-
-	if (mbox_sts[0] == MBOX_STS_COMMAND_PARAMETER_ERROR &&
-	    mbox_sts[4] > LEGACY_IFCB_SIZE) {
-		/* Supports larger ifcb size */
-		ha->ifcb_size = mbox_sts[4] / 2;
-	}
-
 	init_fw_cb = dma_alloc_coherent(&ha->pdev->dev,
-					ha->ifcb_size,
+					sizeof(struct addr_ctrl_blk),
 					&init_fw_cb_dma, GFP_KERNEL);
 	if (init_fw_cb == NULL) {
-		DEBUG2(printk("scsi%ld: %s: Unable to alloc init_cb\n",
-			       ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Unable to alloc init_cb\n", __func__));
 		goto exit_init_fw_cb_no_free;
 	}
-	memset(init_fw_cb, 0, ha->ifcb_size);
+	memset(init_fw_cb, 0, sizeof(struct addr_ctrl_blk));
 
 	/* Get Initialize Firmware Control Block. */
 	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
 	memset(&mbox_sts, 0, sizeof(mbox_sts));
 
-	/*
-	 * Determine if larger IFCB is supported
-	 */
-	if (qla4xxx_get_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], init_fw_cb_dma)
-		!= QLA_SUCCESS) {
+	if (qla4xxx_get_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], init_fw_cb_dma) !=
+	    QLA_SUCCESS) {
 		dma_free_coherent(&ha->pdev->dev,
 				  sizeof(struct addr_ctrl_blk),
 				  init_fw_cb, init_fw_cb_dma);
@@ -427,8 +609,8 @@ int qla4xxx_initialize_fw_cb(struct scsi
 	/* Fill in the request and response queue information. */
 	init_fw_cb->rqq_consumer_idx = cpu_to_le16(ha->request_out);
 	init_fw_cb->compq_producer_idx = cpu_to_le16(ha->response_in);
-	init_fw_cb->rqq_len = __constant_cpu_to_le16(REQUEST_QUEUE_DEPTH);
-	init_fw_cb->compq_len = __constant_cpu_to_le16(RESPONSE_QUEUE_DEPTH);
+	init_fw_cb->rqq_len = cpu_to_le16(ha->maxcmds);
+	init_fw_cb->compq_len = cpu_to_le16(ha->response_qdepth);
 	init_fw_cb->rqq_addr_lo = cpu_to_le32(LSDW(ha->request_dma));
 	init_fw_cb->rqq_addr_hi = cpu_to_le32(MSDW(ha->request_dma));
 	init_fw_cb->compq_addr_lo = cpu_to_le32(LSDW(ha->response_dma));
@@ -440,19 +622,25 @@ int qla4xxx_initialize_fw_cb(struct scsi
 	init_fw_cb->fw_options |=
 		__constant_cpu_to_le16(FWOPT_SESSION_MODE |
 				       FWOPT_INITIATOR_MODE);
+
+	if (is_qla8022(ha))
+		init_fw_cb->fw_options |=
+		    __constant_cpu_to_le16(FWOPT_ENABLE_CRBDB);
+
 	init_fw_cb->fw_options &= __constant_cpu_to_le16(~FWOPT_TARGET_MODE);
+	init_fw_cb->add_fw_options &= __constant_cpu_to_le16(SERIALIZE_TASK_MGMT);
 
 	if (qla4xxx_set_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], init_fw_cb_dma)
 		!= QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: Failed to set init_fw_ctrl_blk\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_warn(ha, "%s: Failed to set init_fw_ctrl_blk\n",
+			      __func__));
 		goto exit_init_fw_cb;
 	}
 
 	if (qla4xxx_update_local_ifcb(ha, &mbox_cmd[0], &mbox_sts[0],
 		init_fw_cb, init_fw_cb_dma) != QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: Failed to update local ifcb\n",
-				ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Failed to update local ifcb\n",
+				__func__));
 		goto exit_init_fw_cb;
 	}
 	status = QLA_SUCCESS;
@@ -460,7 +648,6 @@ int qla4xxx_initialize_fw_cb(struct scsi
 exit_init_fw_cb:
 	dma_free_coherent(&ha->pdev->dev, sizeof(struct addr_ctrl_blk),
 				init_fw_cb, init_fw_cb_dma);
-
 exit_init_fw_cb_no_free:
 	return status;
 }
@@ -475,36 +662,34 @@ int qla4xxx_get_dhcp_ip_address(struct s
 	dma_addr_t init_fw_cb_dma;
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
-	uint8_t	status = QLA_ERROR;
 
 	init_fw_cb = dma_alloc_coherent(&ha->pdev->dev,
 					sizeof(struct addr_ctrl_blk),
 					&init_fw_cb_dma, GFP_KERNEL);
 	if (init_fw_cb == NULL) {
-		printk("scsi%ld: %s: Unable to alloc init_cb\n", ha->host_no,
+		ql4_info(ha, "%s: Unable to alloc init_cb\n",
 		       __func__);
-		goto exit_get_dhcp_ip_address_no_free;
+		return QLA_ERROR;
 	}
 
 	/* Get Initialize Firmware Control Block. */
 	memset(init_fw_cb, 0, sizeof(struct addr_ctrl_blk));
-	if (qla4xxx_get_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], init_fw_cb_dma)
-		!= QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: Failed to get init_fw_ctrl_blk\n",
-			      ha->host_no, __func__));
-		goto exit_get_dhcp_ip_address;
+	if (qla4xxx_get_ifcb(ha, &mbox_cmd[0], &mbox_sts[0], init_fw_cb_dma) !=
+	    QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: Failed to get init_fw_ctrl_blk\n",
+			      __func__));
+		dma_free_coherent(&ha->pdev->dev,
+				  sizeof(struct addr_ctrl_blk),
+				  init_fw_cb, init_fw_cb_dma);
+		return QLA_ERROR;
 	}
 
 	/* Save IP Address. */
 	qla4xxx_update_local_ip(ha, init_fw_cb);
-	status = QLA_SUCCESS;
-
-exit_get_dhcp_ip_address:
 	dma_free_coherent(&ha->pdev->dev, sizeof(struct addr_ctrl_blk),
 				init_fw_cb, init_fw_cb_dma);
 
-exit_get_dhcp_ip_address_no_free:
-	return status;
+	return QLA_SUCCESS;
 }
 
 /**
@@ -524,18 +709,17 @@ int qla4xxx_get_firmware_state(struct sc
 
 	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 4, &mbox_cmd[0], &mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_GET_FW_STATE failed w/ "
-			      "status %04X\n", ha->host_no, __func__,
-			      mbox_sts[0]));
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_GET_FW_STATE failed w/ "
+			      "status %04X\n", __func__, mbox_sts[0]));
 		return QLA_ERROR;
 	}
 	ha->firmware_state = mbox_sts[1];
 	ha->board_id = mbox_sts[2];
 	ha->addl_fw_state = mbox_sts[3];
-	DEBUG2(printk("scsi%ld: %s firmware_state=0x%x\n",
-		      ha->host_no, __func__, ha->firmware_state);)
+	DEBUG2(ql4_info(ha, "%s firmware_state=0x%x\n", __func__,
+			ha->firmware_state);)
 
-		return QLA_SUCCESS;
+	return QLA_SUCCESS;
 }
 
 /**
@@ -553,13 +737,16 @@ int qla4xxx_get_firmware_status(struct s
 
 	mbox_cmd[0] = MBOX_CMD_GET_FW_STATUS;
 
-	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 3, &mbox_cmd[0], &mbox_sts[0]) !=
-	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_GET_FW_STATUS failed w/ "
-			      "status %04X\n", ha->host_no, __func__,
-			      mbox_sts[0]));
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 3, &mbox_cmd[0],
+				    &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_GET_FW_STATUS failed w/ "
+			      "status %04X\n", __func__, mbox_sts[0]));
 		return QLA_ERROR;
 	}
+
+	DEBUG2(ql4_info(ha, "%s: firmare IOCBs available (%d).\n",
+		__func__, mbox_sts[2]));
+
 	return QLA_SUCCESS;
 }
 
@@ -584,13 +771,14 @@ int qla4xxx_get_fwddb_entry(struct scsi_
 			    uint16_t *connection_id)
 {
 	int status = QLA_ERROR;
+	uint16_t options;
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
 
 	/* Make sure the device index is valid */
 	if (fw_ddb_index >= MAX_DDB_ENTRIES) {
-		DEBUG2(printk("scsi%ld: %s: index [%d] out of range.\n",
-			      ha->host_no, __func__, fw_ddb_index));
+		DEBUG2(ql4_info(ha, "%s: ddb [%d] out of range.\n",
+			      __func__, fw_ddb_index));
 		goto exit_get_fwddb;
 	}
 	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
@@ -604,26 +792,39 @@ int qla4xxx_get_fwddb_entry(struct scsi_
 
 	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) ==
 	    QLA_ERROR) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_GET_DATABASE_ENTRY failed"
-			      " with status 0x%04X\n", ha->host_no, __func__,
-			      mbox_sts[0]));
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_GET_DATABASE_ENTRY failed"
+			      " with status 0x%04X\n", __func__, mbox_sts[0]));
 		goto exit_get_fwddb;
 	}
 	if (fw_ddb_index != mbox_sts[1]) {
-		DEBUG2(printk("scsi%ld: %s: index mismatch [%d] != [%d].\n",
-			      ha->host_no, __func__, fw_ddb_index,
-			      mbox_sts[1]));
+		DEBUG2(ql4_info(ha, "%s: ddb mismatch [%d] != [%d].\n",
+			      __func__, fw_ddb_index, mbox_sts[1]));
 		goto exit_get_fwddb;
 	}
 	if (fw_ddb_entry) {
-		dev_info(&ha->pdev->dev, "%s: DDB[%d] MB0 %04x Tot %d "
-				"Next %d State %04x ConnErr %08x " NIPQUAD_FMT
+		options = le16_to_cpu(fw_ddb_entry->options);
+		if (options & DDB_OPT_IPV6_DEVICE) {
+			ql4_info(ha, "%s: DDB[%d] MB0 %04x Tot %d "
+				"Next %d State %04x ConnErr %08x %pI6 "
+				":%04d isid "ISID_FMT" tpgt %d \"%s\"\n",
+				__func__, fw_ddb_index,
+				mbox_sts[0], mbox_sts[2], mbox_sts[3],
+				mbox_sts[4], mbox_sts[5],
+				fw_ddb_entry->ip_addr,
+				le16_to_cpu(fw_ddb_entry->port),
+				ISID(fw_ddb_entry->isid),
+				le32_to_cpu(fw_ddb_entry->tgt_portal_grp),
+				fw_ddb_entry->iscsi_name);
+		} else {
+			ql4_info(ha, "%s: DDB[%d] MB0 %04x Tot %d "
+				"Next %d State %04x ConnErr %08x %pI4 "
 				":%04d \"%s\"\n", __func__, fw_ddb_index,
 				mbox_sts[0], mbox_sts[2], mbox_sts[3],
 				mbox_sts[4], mbox_sts[5],
-				NIPQUAD(fw_ddb_entry->ip_addr),
+				fw_ddb_entry->ip_addr,
 				le16_to_cpu(fw_ddb_entry->port),
 				fw_ddb_entry->iscsi_name);
+		}
 	}
 	if (num_valid_ddb_entries)
 		*num_valid_ddb_entries = mbox_sts[2];
@@ -642,7 +843,7 @@ int qla4xxx_get_fwddb_entry(struct scsi_
 	if (conn_err_detail)
 		*conn_err_detail = mbox_sts[5];
 	if (tcp_source_port_num)
-		*tcp_source_port_num = (uint16_t) mbox_sts[6] >> 16;
+		*tcp_source_port_num = (uint16_t) (mbox_sts[6] >> 16);
 	if (connection_id)
 		*connection_id = (uint16_t) mbox_sts[6] & 0x00FF;
 	status = QLA_SUCCESS;
@@ -667,6 +868,7 @@ int qla4xxx_set_ddb_entry(struct scsi_ql
 {
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
+	int status;
 
 	/* Do not wait for completion. The firmware will send us an
 	 * ASTS_DATABASE_CHANGED (0x8014) to notify us of the login status.
@@ -680,7 +882,12 @@ int qla4xxx_set_ddb_entry(struct scsi_ql
 	mbox_cmd[3] = MSDW(fw_ddb_entry_dma);
 	mbox_cmd[4] = sizeof(struct dev_db_entry);
 
-	return qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]);
+	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+	    &mbox_sts[0]);
+	DEBUG2(ql4_info(ha, "%s: status=%d mbx0=0x%x mbx4=0x%x\n",
+	    __func__, status, mbox_sts[0], mbox_sts[4]);)
+
+	return status;
 }
 
 /**
@@ -703,16 +910,17 @@ void qla4xxx_get_crash_record(struct scs
 	/* Get size of crash record. */
 	mbox_cmd[0] = MBOX_CMD_GET_CRASH_RECORD;
 
-	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) !=
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+			&mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: ERROR: Unable to retrieve size!\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: ERROR: Unable to retrieve size!\n",
+			      __func__));
 		goto exit_get_crash_record;
 	}
 	crash_record_size = mbox_sts[4];
 	if (crash_record_size == 0) {
-		DEBUG2(printk("scsi%ld: %s: ERROR: Crash record size is 0!\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: ERROR: Crash record size is 0!\n",
+			      __func__));
 		goto exit_get_crash_record;
 	}
 
@@ -766,7 +974,8 @@ void qla4xxx_get_conn_event_log(struct s
 	/* Get size of crash record. */
 	mbox_cmd[0] = MBOX_CMD_GET_CONN_EVENT_LOG;
 
-	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) !=
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+				&mbox_sts[0]) !=
 	    QLA_SUCCESS)
 		goto exit_get_event_log;
 
@@ -788,10 +997,11 @@ void qla4xxx_get_conn_event_log(struct s
 	mbox_cmd[2] = LSDW(event_log_dma);
 	mbox_cmd[3] = MSDW(event_log_dma);
 
-	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) !=
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+		&mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: ERROR: Unable to retrieve event "
-			      "log!\n", ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: ERROR: Unable to retrieve event "
+			      "log!\n", __func__));
 		goto exit_get_event_log;
 	}
 
@@ -804,8 +1014,8 @@ void qla4xxx_get_conn_event_log(struct s
 	if (num_valid_entries > max_event_log_entries)
 		oldest_entry = num_valid_entries % max_event_log_entries;
 
-	DEBUG3(printk("scsi%ld: Connection Event Log Dump (%d entries):\n",
-		      ha->host_no, num_valid_entries));
+	DEBUG3(ql4_info(ha, "Connection Event Log Dump (%d entries):\n",
+		      num_valid_entries));
 
 	if (ql4xextended_error_logging == 3) {
 		if (oldest_entry == 0) {
@@ -853,9 +1063,8 @@ int qla4xxx_abort_task(struct scsi_qla_h
 	uint32_t mbox_sts[MBOX_REG_COUNT];
 	struct scsi_cmnd *cmd = srb->cmd;
 	int status = QLA_SUCCESS;
-
-	DEBUG2(printk("scsi%ld:%d:%d:%d: abort task issued\n", ha->host_no,
-			cmd->device->channel, cmd->device->id, cmd->device->lun));
+	unsigned long flags = 0;
+	uint32_t index;
 
 	/*
 	 * Send abort task command to ISP, so that the ISP will return
@@ -864,32 +1073,41 @@ int qla4xxx_abort_task(struct scsi_qla_h
 	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
 	memset(&mbox_sts, 0, sizeof(mbox_sts));
 
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	index = (unsigned long)(unsigned char *)cmd->host_scribble;
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+
+	/* Firmware already posted completion on response queue */
+        if (index == MAX_SRBS)
+                return status;
+
 	mbox_cmd[0] = MBOX_CMD_ABORT_TASK;
-	mbox_cmd[1] = srb->fw_ddb_index;
-	mbox_cmd[2] = (unsigned long)(unsigned char *)cmd->host_scribble;
-	mbox_cmd[5] = 0x01;     /* Immediate Command Enable */
+	mbox_cmd[1] = srb->ddb->fw_ddb_index;
+	mbox_cmd[2] = index;
+	/* Immediate Command Enable */
+	mbox_cmd[5] = 0x01;
 
-	qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]);
+	DEBUG2(qla4xxx_dump_mbx_cmd(ha, &mbox_cmd[0]));
+
+	qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+	    &mbox_sts[0]);
 	if (mbox_sts[0] != MBOX_STS_COMMAND_COMPLETE) {
 		status = QLA_ERROR;
 
-		DEBUG2(printk("scsi%ld:%d:%d:%d: abort task FAILED: ", ha->host_no,
-			cmd->device->channel, cmd->device->id, cmd->device->lun));
-		DEBUG2(printk("mbx0=%04X, mb1=%04X, mb2=%04X, mb3=%04X, mb4=%04X\n",
-			mbox_sts[0], mbox_sts[1], mbox_sts[2], mbox_sts[3],
-			mbox_sts[4]));
+		DEBUG2(ql4_warn(ha, "%d:%d: abort task FAILED: "
+		    "mbx0=%04X, mb1=%04X, mb2=%04X, mb3=%04X, mb4=%04X\n",
+		    cmd->device->id, cmd->device->lun, mbox_sts[0],
+		    mbox_sts[1], mbox_sts[2], mbox_sts[3], mbox_sts[4]));
 	}
 
 	return status;
 }
 
-
-
 /**
  * qla4xxx_reset_lun - issues LUN Reset
  * @ha: Pointer to host adapter structure.
- * @db_entry: Pointer to device database entry
- * @un_entry: Pointer to lun entry structure
+ * @ddb_entry: Pointer to device database entry
+ * @lun: lun number
  *
  * This routine performs a LUN RESET on the specified target/lun.
  * The caller must ensure that the ddb_entry and lun_entry pointers
@@ -901,33 +1119,11 @@ int qla4xxx_reset_lun(struct scsi_qla_ho
 	uint32_t mbox_cmd[MBOX_REG_COUNT];
 	uint32_t mbox_sts[MBOX_REG_COUNT];
 	int status = QLA_SUCCESS;
-	unsigned long wait_online;
 
-	DEBUG2(printk("scsi%ld:%d:%d: lun reset issued\n", ha->host_no,
+	DEBUG2(ql4_info(ha, "%d:%d: lun reset issued\n",
 		      ddb_entry->os_target_id, lun));
 
 	/*
-	 * If device is not online wait for 10 sec for device to come online.
-	 * else return error
-	 */
-	if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE) {
-		wait_online = jiffies + (DEVICE_ONLINE_TOV * HZ);
-		while (time_before(jiffies, wait_online)) {
-			set_current_state(TASK_INTERRUPTIBLE);
-			schedule_timeout(HZ);
-			if (atomic_read(&ddb_entry->state) == DDB_STATE_ONLINE)
-				break;
-		}
-
-		if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE) {
-			DEBUG2(printk("scsi%ld: %s: Unable to reset lun."
-					"Device is not online.\n", ha->host_no
-					, __func__));
-			return QLA_ERROR;
-		}
-	}
-
-	/*
 	 * Send lun reset command to ISP, so that the ISP will return all
 	 * outstanding requests with RESET status
 	 */
@@ -964,8 +1160,8 @@ int qla4xxx_reset_target(struct scsi_qla
 	uint32_t mbox_sts[MBOX_REG_COUNT];
 	int status = QLA_SUCCESS;
 
-	DEBUG2(printk("scsi%ld:%d: target reset issued\n", ha->host_no,
-		      ddb_entry->os_target_id));
+	DEBUG2(ql4_info(ha, "%d: target reset issued\n",
+		      ddb_entry->fw_ddb_index));
 
 	/*
 	 * Send target reset command to ISP, so that the ISP will return all
@@ -1004,8 +1200,8 @@ int qla4xxx_get_flash(struct scsi_qla_ho
 
 	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_READ_FLASH, failed w/ "
-		    "status %04X %04X, offset %08x, len %08x\n", ha->host_no,
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_READ_FLASH, failed w/ "
+		    "status %04X %04X, offset %08x, len %08x\n",
 		    __func__, mbox_sts[0], mbox_sts[1], offset, len));
 		return QLA_ERROR;
 	}
@@ -1033,8 +1229,8 @@ int qla4xxx_get_fw_version(struct scsi_q
 
 	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: MBOX_CMD_ABOUT_FW failed w/ "
-		    "status %04X\n", ha->host_no, __func__, mbox_sts[0]));
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_ABOUT_FW failed w/ "
+		    "status %04X\n", __func__, mbox_sts[0]));
 		return QLA_ERROR;
 	}
 
@@ -1062,8 +1258,8 @@ static int qla4xxx_get_default_ddb(struc
 
 	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) !=
 	    QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld: %s: failed status %04X\n",
-		     ha->host_no, __func__, mbox_sts[0]));
+		DEBUG2(ql4_info(ha, "%s: failed status %04X\n", __func__,
+				mbox_sts[0]));
 		return QLA_ERROR;
 	}
 	return QLA_SUCCESS;
@@ -1085,8 +1281,8 @@ static int qla4xxx_req_ddb_entry(struct 
 		if (mbox_sts[0] == MBOX_STS_COMMAND_ERROR) {
 			*ddb_index = mbox_sts[2];
 		} else {
-			DEBUG2(printk("scsi%ld: %s: failed status %04X\n",
-			     ha->host_no, __func__, mbox_sts[0]));
+			DEBUG2(ql4_info(ha, "%s: failed status %04X\n",
+					__func__, mbox_sts[0]));
 			return QLA_ERROR;
 		}
 	} else {
@@ -1109,19 +1305,19 @@ int qla4xxx_send_tgts(struct scsi_qla_ho
 					  sizeof(*fw_ddb_entry),
 					  &fw_ddb_entry_dma, GFP_KERNEL);
 	if (!fw_ddb_entry) {
-		DEBUG2(printk("scsi%ld: %s: Unable to allocate dma buffer.\n",
-			      ha->host_no, __func__));
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+			      __func__));
 		ret_val = QLA_ERROR;
-		goto qla4xxx_send_tgts_exit_no_exit;
+		goto exit_send_tgts_no_free;
 	}
 
 	ret_val = qla4xxx_get_default_ddb(ha, fw_ddb_entry_dma);
 	if (ret_val != QLA_SUCCESS)
-		goto qla4xxx_send_tgts_exit;
+		goto exit_send_tgts;
 
 	ret_val = qla4xxx_req_ddb_entry(ha, &ddb_index);
 	if (ret_val != QLA_SUCCESS)
-		goto qla4xxx_send_tgts_exit;
+		goto exit_send_tgts;
 
 	memset(fw_ddb_entry->iscsi_alias, 0,
 	       sizeof(fw_ddb_entry->iscsi_alias));
@@ -1143,11 +1339,9 @@ int qla4xxx_send_tgts(struct scsi_qla_ho
 
 	ret_val = qla4xxx_set_ddb_entry(ha, ddb_index, fw_ddb_entry_dma);
 
-qla4xxx_send_tgts_exit:
+exit_send_tgts:
 	dma_free_coherent(&ha->pdev->dev, sizeof(*fw_ddb_entry),
 			  fw_ddb_entry, fw_ddb_entry_dma);
-
-qla4xxx_send_tgts_exit_no_exit:
+exit_send_tgts_no_free:
 	return ret_val;
 }
-
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_nvram.c
--- a/drivers/scsi/qla4xxx/ql4_nvram.c
+++ b/drivers/scsi/qla4xxx/ql4_nvram.c
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -35,7 +35,7 @@ static inline int eeprom_no_data_bits(st
 
 static int fm93c56a_select(struct scsi_qla_host * ha)
 {
-	DEBUG5(printk(KERN_ERR "fm93c56a_select:\n"));
+	DEBUG5(ql4_err(ha, "fm93c56a_select:\n"));
 
 	ha->eeprom_cmd_data = AUBURN_EEPROM_CS_1 | 0x000f0000;
 	eeprom_cmd(ha->eeprom_cmd_data, ha);
@@ -149,7 +149,7 @@ static int eeprom_readword(int eepromAdd
 /* Hardware_lock must be set before calling */
 u16 rd_nvram_word(struct scsi_qla_host * ha, int offset)
 {
-	u16 val;
+	u16 val = 0;
 
 	/* NOTE: NVRAM uses half-word addresses */
 	eeprom_readword(offset, &val, ha);
@@ -185,17 +185,16 @@ int ql4xxx_sem_spinlock(struct scsi_qla_
 	unsigned long flags;
 	unsigned int seconds = 30;
 
-	DEBUG2(printk("scsi%ld : Trying to get SEM lock - mask= 0x%x, code = "
-		      "0x%x\n", ha->host_no, sem_mask, sem_bits));
+	DEBUG2(ql4_info(ha, "Trying to get SEM lock - mask= 0x%x, code = "
+		      "0x%x\n", sem_mask, sem_bits));
 	do {
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 		writel((sem_mask | sem_bits), isp_semaphore(ha));
 		value = readw(isp_semaphore(ha));
 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 		if ((value & (sem_mask >> 16)) == sem_bits) {
-			DEBUG2(printk("scsi%ld : Got SEM LOCK - mask= 0x%x, "
-				      "code = 0x%x\n", ha->host_no,
-				      sem_mask, sem_bits));
+			DEBUG2(ql4_info(ha, "Got SEM LOCK - mask= 0x%x, "
+				      "code = 0x%x\n", sem_mask, sem_bits));
 			return QLA_SUCCESS;
 		}
 		ssleep(1);
@@ -212,8 +211,7 @@ void ql4xxx_sem_unlock(struct scsi_qla_h
 	readl(isp_semaphore(ha));
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
-	DEBUG2(printk("scsi%ld : UNLOCK SEM - mask= 0x%x\n", ha->host_no,
-		      sem_mask));
+	DEBUG2(ql4_info(ha, "UNLOCK SEM - mask= 0x%x\n", sem_mask));
 }
 
 int ql4xxx_sem_lock(struct scsi_qla_host * ha, u32 sem_mask, u32 sem_bits)
@@ -226,9 +224,9 @@ int ql4xxx_sem_lock(struct scsi_qla_host
 	value = readw(isp_semaphore(ha));
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 	if ((value & (sem_mask >> 16)) == sem_bits) {
-		DEBUG2(printk("scsi%ld : Got SEM LOCK - mask= 0x%x, code = "
-			      "0x%x, sema code=0x%x\n", ha->host_no,
-			      sem_mask, sem_bits, value));
+		DEBUG2(ql4_info(ha, "Got SEM LOCK - mask= 0x%x, code = "
+			      "0x%x, sema code=0x%x\n", sem_mask, sem_bits,
+				value));
 		return 1;
 	}
 	return 0;
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_nvram.h
--- a/drivers/scsi/qla4xxx/ql4_nvram.h
+++ b/drivers/scsi/qla4xxx/ql4_nvram.h
@@ -1,6 +1,6 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
@@ -8,9 +8,9 @@
 #ifndef _QL4XNVRM_H_
 #define _QL4XNVRM_H_
 
-/*
+/**
  * AM29LV Flash definitions
- */
+ **/
 #define FM93C56A_SIZE_8	 0x100
 #define FM93C56A_SIZE_16 0x80
 #define FM93C66A_SIZE_8	 0x200
@@ -19,7 +19,7 @@
 
 #define	 FM93C56A_START	      0x1
 
-// Commands
+/* Commands */
 #define	 FM93C56A_READ	      0x2
 #define	 FM93C56A_WEN	      0x0
 #define	 FM93C56A_WRITE	      0x1
@@ -62,9 +62,9 @@
 #define	 AUBURN_EEPROM_CLK_RISE	    0x1
 #define	 AUBURN_EEPROM_CLK_FALL	    0x0
 
-/* */
+/**/
 /* EEPROM format */
-/* */
+/**/
 struct bios_params {
 	uint16_t SpinUpDelay:1;
 	uint16_t BIOSDisable:1;
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_nx.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_nx.c
@@ -0,0 +1,3232 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+#include <linux/delay.h>
+#include <linux/pci.h>
+#include "ql4_def.h"
+#include "ql4_glbl.h"
+#include "ql4_dbg.h"
+
+#define MASK(n)		DMA_BIT_MASK(n)
+#define MN_WIN(addr)	(((addr & 0x1fc0000) >> 1) | ((addr >> 25) & 0x3ff))
+#define OCM_WIN(addr)	(((addr & 0x1ff0000) >> 1) | ((addr >> 25) & 0x3ff))
+#define MS_WIN(addr)	(addr & 0x0ffc0000)
+#define QLA82XX_PCI_MN_2M	(0)
+#define QLA82XX_PCI_MS_2M	(0x80000)
+#define QLA82XX_PCI_OCM0_2M	(0xc0000)
+#define VALID_OCM_ADDR(addr)	(((addr) & 0x3f800) != 0x3f800)
+#define GET_MEM_OFFS_2M(addr)	(addr & MASK(18))
+
+/* CRB window related */
+#define CRB_BLK(off)	((off >> 20) & 0x3f)
+#define CRB_SUBBLK(off)	((off >> 16) & 0xf)
+#define CRB_WINDOW_2M	(0x130060)
+#define CRB_HI(off)	((qla4_8xxx_crb_hub_agt[CRB_BLK(off)] << 20) | \
+			((off) & 0xf0000))
+#define QLA82XX_PCI_CAMQM_2M_END	(0x04800800UL)
+#define QLA82XX_PCI_CAMQM_2M_BASE	(0x000ff800UL)
+#define CRB_INDIRECT_2M			(0x1e0000UL)
+
+static inline void __iomem *
+qla4_8xxx_pci_base_offsetfset(struct scsi_qla_host *ha, unsigned long off)
+{
+	if ((off < ha->first_page_group_end) &&
+	    (off >= ha->first_page_group_start))
+		return (void __iomem *)(ha->nx_pcibase + off);
+
+	return NULL;
+}
+
+#define MAX_CRB_XFORM 60
+static unsigned long crb_addr_xform[MAX_CRB_XFORM];
+static int qla4_8xxx_crb_table_initialized;
+
+#define qla4_8xxx_crb_addr_transform(name) \
+	(crb_addr_xform[QLA82XX_HW_PX_MAP_CRB_##name] = \
+	 QLA82XX_HW_CRB_HUB_AGT_ADR_##name << 20)
+static void
+qla4_8xxx_crb_addr_transform_setup(void)
+{
+	qla4_8xxx_crb_addr_transform(XDMA);
+	qla4_8xxx_crb_addr_transform(TIMR);
+	qla4_8xxx_crb_addr_transform(SRE);
+	qla4_8xxx_crb_addr_transform(SQN3);
+	qla4_8xxx_crb_addr_transform(SQN2);
+	qla4_8xxx_crb_addr_transform(SQN1);
+	qla4_8xxx_crb_addr_transform(SQN0);
+	qla4_8xxx_crb_addr_transform(SQS3);
+	qla4_8xxx_crb_addr_transform(SQS2);
+	qla4_8xxx_crb_addr_transform(SQS1);
+	qla4_8xxx_crb_addr_transform(SQS0);
+	qla4_8xxx_crb_addr_transform(RPMX7);
+	qla4_8xxx_crb_addr_transform(RPMX6);
+	qla4_8xxx_crb_addr_transform(RPMX5);
+	qla4_8xxx_crb_addr_transform(RPMX4);
+	qla4_8xxx_crb_addr_transform(RPMX3);
+	qla4_8xxx_crb_addr_transform(RPMX2);
+	qla4_8xxx_crb_addr_transform(RPMX1);
+	qla4_8xxx_crb_addr_transform(RPMX0);
+	qla4_8xxx_crb_addr_transform(ROMUSB);
+	qla4_8xxx_crb_addr_transform(SN);
+	qla4_8xxx_crb_addr_transform(QMN);
+	qla4_8xxx_crb_addr_transform(QMS);
+	qla4_8xxx_crb_addr_transform(PGNI);
+	qla4_8xxx_crb_addr_transform(PGND);
+	qla4_8xxx_crb_addr_transform(PGN3);
+	qla4_8xxx_crb_addr_transform(PGN2);
+	qla4_8xxx_crb_addr_transform(PGN1);
+	qla4_8xxx_crb_addr_transform(PGN0);
+	qla4_8xxx_crb_addr_transform(PGSI);
+	qla4_8xxx_crb_addr_transform(PGSD);
+	qla4_8xxx_crb_addr_transform(PGS3);
+	qla4_8xxx_crb_addr_transform(PGS2);
+	qla4_8xxx_crb_addr_transform(PGS1);
+	qla4_8xxx_crb_addr_transform(PGS0);
+	qla4_8xxx_crb_addr_transform(PS);
+	qla4_8xxx_crb_addr_transform(PH);
+	qla4_8xxx_crb_addr_transform(NIU);
+	qla4_8xxx_crb_addr_transform(I2Q);
+	qla4_8xxx_crb_addr_transform(EG);
+	qla4_8xxx_crb_addr_transform(MN);
+	qla4_8xxx_crb_addr_transform(MS);
+	qla4_8xxx_crb_addr_transform(CAS2);
+	qla4_8xxx_crb_addr_transform(CAS1);
+	qla4_8xxx_crb_addr_transform(CAS0);
+	qla4_8xxx_crb_addr_transform(CAM);
+	qla4_8xxx_crb_addr_transform(C2C1);
+	qla4_8xxx_crb_addr_transform(C2C0);
+	qla4_8xxx_crb_addr_transform(SMB);
+	qla4_8xxx_crb_addr_transform(OCM0);
+	qla4_8xxx_crb_addr_transform(I2C0);
+
+	qla4_8xxx_crb_table_initialized = 1;
+}
+
+static struct crb_128M_2M_block_map crb_128M_2M_map[64] = {
+	{{{0, 0,         0,         0} } },		/* 0: PCI */
+	{{{1, 0x0100000, 0x0102000, 0x120000},	/* 1: PCIE */
+		{1, 0x0110000, 0x0120000, 0x130000},
+		{1, 0x0120000, 0x0122000, 0x124000},
+		{1, 0x0130000, 0x0132000, 0x126000},
+		{1, 0x0140000, 0x0142000, 0x128000},
+		{1, 0x0150000, 0x0152000, 0x12a000},
+		{1, 0x0160000, 0x0170000, 0x110000},
+		{1, 0x0170000, 0x0172000, 0x12e000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{1, 0x01e0000, 0x01e0800, 0x122000},
+		{0, 0x0000000, 0x0000000, 0x000000} } },
+	{{{1, 0x0200000, 0x0210000, 0x180000} } },/* 2: MN */
+	{{{0, 0,         0,         0} } },	    /* 3: */
+	{{{1, 0x0400000, 0x0401000, 0x169000} } },/* 4: P2NR1 */
+	{{{1, 0x0500000, 0x0510000, 0x140000} } },/* 5: SRE   */
+	{{{1, 0x0600000, 0x0610000, 0x1c0000} } },/* 6: NIU   */
+	{{{1, 0x0700000, 0x0704000, 0x1b8000} } },/* 7: QM    */
+	{{{1, 0x0800000, 0x0802000, 0x170000},  /* 8: SQM0  */
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{1, 0x08f0000, 0x08f2000, 0x172000} } },
+	{{{1, 0x0900000, 0x0902000, 0x174000},	/* 9: SQM1*/
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{1, 0x09f0000, 0x09f2000, 0x176000} } },
+	{{{0, 0x0a00000, 0x0a02000, 0x178000},	/* 10: SQM2*/
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{1, 0x0af0000, 0x0af2000, 0x17a000} } },
+	{{{0, 0x0b00000, 0x0b02000, 0x17c000},	/* 11: SQM3*/
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{1, 0x0bf0000, 0x0bf2000, 0x17e000} } },
+	{{{1, 0x0c00000, 0x0c04000, 0x1d4000} } },/* 12: I2Q */
+	{{{1, 0x0d00000, 0x0d04000, 0x1a4000} } },/* 13: TMR */
+	{{{1, 0x0e00000, 0x0e04000, 0x1a0000} } },/* 14: ROMUSB */
+	{{{1, 0x0f00000, 0x0f01000, 0x164000} } },/* 15: PEG4 */
+	{{{0, 0x1000000, 0x1004000, 0x1a8000} } },/* 16: XDMA */
+	{{{1, 0x1100000, 0x1101000, 0x160000} } },/* 17: PEG0 */
+	{{{1, 0x1200000, 0x1201000, 0x161000} } },/* 18: PEG1 */
+	{{{1, 0x1300000, 0x1301000, 0x162000} } },/* 19: PEG2 */
+	{{{1, 0x1400000, 0x1401000, 0x163000} } },/* 20: PEG3 */
+	{{{1, 0x1500000, 0x1501000, 0x165000} } },/* 21: P2ND */
+	{{{1, 0x1600000, 0x1601000, 0x166000} } },/* 22: P2NI */
+	{{{0, 0,         0,         0} } },	/* 23: */
+	{{{0, 0,         0,         0} } },	/* 24: */
+	{{{0, 0,         0,         0} } },	/* 25: */
+	{{{0, 0,         0,         0} } },	/* 26: */
+	{{{0, 0,         0,         0} } },	/* 27: */
+	{{{0, 0,         0,         0} } },	/* 28: */
+	{{{1, 0x1d00000, 0x1d10000, 0x190000} } },/* 29: MS */
+	{{{1, 0x1e00000, 0x1e01000, 0x16a000} } },/* 30: P2NR2 */
+	{{{1, 0x1f00000, 0x1f10000, 0x150000} } },/* 31: EPG */
+	{{{0} } },				/* 32: PCI */
+	{{{1, 0x2100000, 0x2102000, 0x120000},	/* 33: PCIE */
+		{1, 0x2110000, 0x2120000, 0x130000},
+		{1, 0x2120000, 0x2122000, 0x124000},
+		{1, 0x2130000, 0x2132000, 0x126000},
+		{1, 0x2140000, 0x2142000, 0x128000},
+		{1, 0x2150000, 0x2152000, 0x12a000},
+		{1, 0x2160000, 0x2170000, 0x110000},
+		{1, 0x2170000, 0x2172000, 0x12e000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000},
+		{0, 0x0000000, 0x0000000, 0x000000} } },
+	{{{1, 0x2200000, 0x2204000, 0x1b0000} } },/* 34: CAM */
+	{{{0} } },				/* 35: */
+	{{{0} } },				/* 36: */
+	{{{0} } },				/* 37: */
+	{{{0} } },				/* 38: */
+	{{{0} } },				/* 39: */
+	{{{1, 0x2800000, 0x2804000, 0x1a4000} } },/* 40: TMR */
+	{{{1, 0x2900000, 0x2901000, 0x16b000} } },/* 41: P2NR3 */
+	{{{1, 0x2a00000, 0x2a00400, 0x1ac400} } },/* 42: RPMX1 */
+	{{{1, 0x2b00000, 0x2b00400, 0x1ac800} } },/* 43: RPMX2 */
+	{{{1, 0x2c00000, 0x2c00400, 0x1acc00} } },/* 44: RPMX3 */
+	{{{1, 0x2d00000, 0x2d00400, 0x1ad000} } },/* 45: RPMX4 */
+	{{{1, 0x2e00000, 0x2e00400, 0x1ad400} } },/* 46: RPMX5 */
+	{{{1, 0x2f00000, 0x2f00400, 0x1ad800} } },/* 47: RPMX6 */
+	{{{1, 0x3000000, 0x3000400, 0x1adc00} } },/* 48: RPMX7 */
+	{{{0, 0x3100000, 0x3104000, 0x1a8000} } },/* 49: XDMA */
+	{{{1, 0x3200000, 0x3204000, 0x1d4000} } },/* 50: I2Q */
+	{{{1, 0x3300000, 0x3304000, 0x1a0000} } },/* 51: ROMUSB */
+	{{{0} } },				/* 52: */
+	{{{1, 0x3500000, 0x3500400, 0x1ac000} } },/* 53: RPMX0 */
+	{{{1, 0x3600000, 0x3600400, 0x1ae000} } },/* 54: RPMX8 */
+	{{{1, 0x3700000, 0x3700400, 0x1ae400} } },/* 55: RPMX9 */
+	{{{1, 0x3800000, 0x3804000, 0x1d0000} } },/* 56: OCM0 */
+	{{{1, 0x3900000, 0x3904000, 0x1b4000} } },/* 57: CRYPTO */
+	{{{1, 0x3a00000, 0x3a04000, 0x1d8000} } },/* 58: SMB */
+	{{{0} } },				/* 59: I2C0 */
+	{{{0} } },				/* 60: I2C1 */
+	{{{1, 0x3d00000, 0x3d04000, 0x1dc000} } },/* 61: LPC */
+	{{{1, 0x3e00000, 0x3e01000, 0x167000} } },/* 62: P2NC */
+	{{{1, 0x3f00000, 0x3f01000, 0x168000} } }	/* 63: P2NR0 */
+};
+
+/*
+ * top 12 bits of crb internal address (hub, agent)
+ */
+static unsigned qla4_8xxx_crb_hub_agt[64] = {
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PS,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_MN,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_MS,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SRE,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_NIU,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_QMN,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SQN0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SQN1,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SQN2,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SQN3,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_I2Q,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_TIMR,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_ROMUSB,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGN4,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_XDMA,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGN0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGN1,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGN2,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGN3,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGND,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGNI,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGS0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGS1,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGS2,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGS3,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGSI,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SN,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_EG,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PS,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_CAM,
+	0,
+	0,
+	0,
+	0,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_TIMR,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX1,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX2,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX3,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX4,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX5,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX6,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX7,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_XDMA,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_I2Q,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_ROMUSB,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX8,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX9,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_OCM0,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_SMB,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_I2C0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_I2C1,
+	0,
+	QLA82XX_HW_CRB_HUB_AGT_ADR_PGNC,
+	0,
+};
+
+/* Device states */
+static char *qdev_state[] = {
+	"Unknown",
+	"Cold",
+	"Initializing",
+	"Ready",
+	"Need Reset",
+	"Need Quiescent",
+	"Failed",
+	"Quiescent",
+};
+
+/*
+ * In: 'off' is offset from CRB space in 128M pci map
+ * Out: 'off' is 2M pci map addr
+ * side effect: lock crb window
+ */
+static void
+qla4_8xxx_pci_set_crbwindow_2M(struct scsi_qla_host *ha, ulong *off)
+{
+	u32 win_read;
+
+	ha->crb_win = CRB_HI(*off);
+	writel(ha->crb_win,
+		(void __iomem *)(CRB_WINDOW_2M + ha->nx_pcibase));
+
+	/* Read back value to make sure write has gone through before trying
+	* to use it. */
+	win_read = readl((void __iomem *)(CRB_WINDOW_2M + ha->nx_pcibase));
+	if (win_read != ha->crb_win) {
+		DEBUG2(ql4_info(ha, "%s: Written crbwin (0x%x) != Read crbwin "
+				"(0x%x), off=0x%lx\n", __func__, ha->crb_win,
+				win_read, *off));
+	}
+	*off = (*off & MASK(16)) + CRB_INDIRECT_2M + ha->nx_pcibase;
+}
+
+void
+qla4_8xxx_wr_32(struct scsi_qla_host *ha, ulong off, u32 data)
+{
+	unsigned long flags = 0;
+	int rv;
+
+	rv = qla4_8xxx_pci_get_crb_addr_2M(ha, &off);
+
+	BUG_ON(rv == -1);
+
+	if (rv == 1) {
+		write_lock_irqsave(&ha->hw_lock, flags);
+		qla4_8xxx_crb_win_lock(ha);
+		qla4_8xxx_pci_set_crbwindow_2M(ha, &off);
+	}
+
+	writel(data, (void __iomem *)off);
+
+	if (rv == 1) {
+		qla4_8xxx_crb_win_unlock(ha);
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+	}
+}
+
+int
+qla4_8xxx_rd_32(struct scsi_qla_host *ha, ulong off)
+{
+	unsigned long flags = 0;
+	int rv;
+	u32 data;
+
+	rv = qla4_8xxx_pci_get_crb_addr_2M(ha, &off);
+
+	BUG_ON(rv == -1);
+
+	if (rv == 1) {
+		write_lock_irqsave(&ha->hw_lock, flags);
+		qla4_8xxx_crb_win_lock(ha);
+		qla4_8xxx_pci_set_crbwindow_2M(ha, &off);
+	}
+	data = readl((void __iomem *)off);
+
+	if (rv == 1) {
+		qla4_8xxx_crb_win_unlock(ha);
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+	}
+	return data;
+}
+
+/* Minidump related functions */
+int
+qla4_8xxx_md_rw_32(struct scsi_qla_host *ha, uint32_t off,
+					u32 data, uint8_t flag)
+{
+	uint32_t win_read, off_value, rval = 0;
+	unsigned long flags = 0;
+
+	off_value  = off & 0xFFFF0000;
+	writel(off_value, (void *)(CRB_WINDOW_2M + ha->nx_pcibase));
+
+	/* Read back value to make sure write has gone through before trying
+	 * to use it.
+	 */
+	win_read = readl((void *)(CRB_WINDOW_2M + ha->nx_pcibase));
+	if (win_read != off_value) {
+		DEBUG2(printk(KERN_INFO "%s: Written (0x%x) != Read (0x%x), "
+		    "off=0x%x\n", __func__, off_value, win_read, off));
+		qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM7_UNLOCK));
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+		return 0;
+	}
+
+	off_value  = off & 0x0000FFFF;
+
+	if (flag)
+		writel(data, (void *)(off_value + CRB_INDIRECT_2M + ha->nx_pcibase));
+	else
+		rval = readl((void *)(off_value + CRB_INDIRECT_2M + ha->nx_pcibase));
+
+	return rval;
+}
+
+#define CRB_WIN_LOCK_TIMEOUT 100000000
+
+int qla4_8xxx_crb_win_lock(struct scsi_qla_host *ha)
+{
+	int i;
+	int done = 0, timeout = 0;
+
+	while (!done) {
+		/* acquire semaphore3 from PCI HW block */
+		done = qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM7_LOCK));
+		if (done == 1)
+			break;
+		if (timeout >= CRB_WIN_LOCK_TIMEOUT)
+			return -1;
+
+		timeout++;
+
+		/* Yield CPU */
+		if (!in_interrupt())
+			schedule();
+		else {
+			for (i = 0; i < 20; i++)
+				cpu_relax();    /*This a nop instr on i386*/
+		}
+	}
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_WIN_LOCK_ID, ha->func_num);
+	return 0;
+}
+
+void qla4_8xxx_crb_win_unlock(struct scsi_qla_host *ha)
+{
+	qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM7_UNLOCK));
+}
+
+#define IDC_LOCK_TIMEOUT 100000000
+
+/**
+ * qla4_8xxx_idc_lock - hw_lock
+ * @ha: pointer to adapter structure
+ *
+ * General purpose lock used to synchronize access to
+ * CRB_DEV_STATE, CRB_DEV_REF_COUNT, etc.
+ **/
+int qla4_8xxx_idc_lock(struct scsi_qla_host *ha)
+{
+	int i;
+	int done = 0, timeout = 0;
+
+	while (!done) {
+		/* acquire semaphore5 from PCI HW block */
+		done = qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM5_LOCK));
+		if (done == 1)
+			break;
+		if (timeout >= IDC_LOCK_TIMEOUT)
+			return -1;
+
+		timeout++;
+
+		/* Yield CPU */
+		if (!in_interrupt())
+			schedule();
+		else {
+			for (i = 0; i < 20; i++)
+				cpu_relax();    /*This a nop instr on i386*/
+		}
+	}
+	return 0;
+}
+
+void qla4_8xxx_idc_unlock(struct scsi_qla_host *ha)
+{
+	qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM5_UNLOCK));
+}
+
+int
+qla4_8xxx_pci_get_crb_addr_2M(struct scsi_qla_host *ha, ulong *off)
+{
+	struct crb_128M_2M_sub_block_map *m;
+
+	if (*off >= QLA82XX_CRB_MAX)
+		return -1;
+
+	if (*off >= QLA82XX_PCI_CAMQM && (*off < QLA82XX_PCI_CAMQM_2M_END)) {
+		*off = (*off - QLA82XX_PCI_CAMQM) +
+		    QLA82XX_PCI_CAMQM_2M_BASE + ha->nx_pcibase;
+		return 0;
+	}
+
+	if (*off < QLA82XX_PCI_CRBSPACE)
+		return -1;
+
+	*off -= QLA82XX_PCI_CRBSPACE;
+	/*
+	 * Try direct map
+	 */
+
+	m = &crb_128M_2M_map[CRB_BLK(*off)].sub_block[CRB_SUBBLK(*off)];
+
+	if (m->valid && (m->start_128M <= *off) && (m->end_128M > *off)) {
+		*off = *off + m->start_2M - m->start_128M + ha->nx_pcibase;
+		return 0;
+	}
+
+	/*
+	 * Not in direct map, use crb window
+	 */
+	return 1;
+}
+
+/*  PCI Windowing for DDR regions.  */
+#define QLA82XX_ADDR_IN_RANGE(addr, low, high)            \
+	(((addr) <= (high)) && ((addr) >= (low)))
+
+/*
+* check memory access boundary.
+* used by test agent. support ddr access only for now
+*/
+static unsigned long
+qla4_8xxx_pci_mem_bound_check(struct scsi_qla_host *ha,
+		unsigned long long addr, int size)
+{
+	if (!QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_DDR_NET,
+	    QLA82XX_ADDR_DDR_NET_MAX) ||
+	    !QLA82XX_ADDR_IN_RANGE(addr + size - 1,
+	    QLA82XX_ADDR_DDR_NET, QLA82XX_ADDR_DDR_NET_MAX) ||
+	    ((size != 1) && (size != 2) && (size != 4) && (size != 8))) {
+		return 0;
+	}
+	return 1;
+}
+
+static int qla4_8xxx_pci_set_window_warning_count;
+
+static unsigned long
+qla4_8xxx_pci_set_window(struct scsi_qla_host *ha, unsigned long long addr)
+{
+	int window;
+	u32 win_read;
+
+	if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_DDR_NET,
+	    QLA82XX_ADDR_DDR_NET_MAX)) {
+		/* DDR network side */
+		window = MN_WIN(addr);
+		ha->ddr_mn_window = window;
+		qla4_8xxx_wr_32(ha, ha->mn_win_crb |
+		    QLA82XX_PCI_CRBSPACE, window);
+		win_read = qla4_8xxx_rd_32(ha, ha->mn_win_crb |
+		    QLA82XX_PCI_CRBSPACE);
+		if ((win_read << 17) != window) {
+			ql4_warn(ha, "%s: Written MNwin (0x%x) != Read MNwin "
+				"(0x%x)\n", __func__, window, win_read);
+		}
+		addr = GET_MEM_OFFS_2M(addr) + QLA82XX_PCI_DDR_NET;
+	} else if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_OCM0,
+				QLA82XX_ADDR_OCM0_MAX)) {
+		unsigned int temp1;
+		/* if bits 19:18&17:11 are on */
+		if ((addr & 0x00ff800) == 0xff800) {
+			ql4_info(ha, "%s: QM access not handled.\n", __func__);
+			addr = -1UL;
+		}
+
+		window = OCM_WIN(addr);
+		ha->ddr_mn_window = window;
+		qla4_8xxx_wr_32(ha, ha->mn_win_crb |
+		    QLA82XX_PCI_CRBSPACE, window);
+		win_read = qla4_8xxx_rd_32(ha, ha->mn_win_crb |
+		    QLA82XX_PCI_CRBSPACE);
+		temp1 = ((window & 0x1FF) << 7) |
+		    ((window & 0x0FFFE0000) >> 17);
+		if (win_read != temp1) {
+			ql4_info(ha, "%s: Written OCMwin (0x%x) != Read"
+			    " OCMwin (0x%x)\n", __func__, temp1, win_read);
+		}
+		addr = GET_MEM_OFFS_2M(addr) + QLA82XX_PCI_OCM0_2M;
+
+	} else if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_QDR_NET,
+				QLA82XX_P3_ADDR_QDR_NET_MAX)) {
+		/* QDR network side */
+		window = MS_WIN(addr);
+		ha->qdr_sn_window = window;
+		qla4_8xxx_wr_32(ha, ha->ms_win_crb |
+		    QLA82XX_PCI_CRBSPACE, window);
+		win_read = qla4_8xxx_rd_32(ha,
+		     ha->ms_win_crb | QLA82XX_PCI_CRBSPACE);
+		if (win_read != window) {
+			ql4_info(ha, "%s: Written MSwin (0x%x) != Read "
+			    "MSwin (0x%x)\n", __func__, window, win_read);
+		}
+		addr = GET_MEM_OFFS_2M(addr) + QLA82XX_PCI_QDR_NET;
+
+	} else {
+		/*
+		 * peg gdb frequently accesses memory that doesn't exist,
+		 * this limits the chit chat so debugging isn't slowed down.
+		 */
+		if ((qla4_8xxx_pci_set_window_warning_count++ < 8) ||
+		    (qla4_8xxx_pci_set_window_warning_count%64 == 0)) {
+			ql4_info(ha, "%s: Warning:%s Unknown address range!\n",
+			    __func__, DRIVER_NAME);
+		}
+		addr = -1UL;
+	}
+	return addr;
+}
+
+/* check if address is in the same windows as the previous access */
+static int qla4_8xxx_pci_is_same_window(struct scsi_qla_host *ha,
+		unsigned long long addr)
+{
+	int window;
+	unsigned long long qdr_max;
+
+	qdr_max = QLA82XX_P3_ADDR_QDR_NET_MAX;
+
+	if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_DDR_NET,
+	    QLA82XX_ADDR_DDR_NET_MAX)) {
+		/* DDR network side */
+		BUG();	/* MN access can not come here */
+	} else if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_OCM0,
+	     QLA82XX_ADDR_OCM0_MAX)) {
+		return 1;
+	} else if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_OCM1,
+	     QLA82XX_ADDR_OCM1_MAX)) {
+		return 1;
+	} else if (QLA82XX_ADDR_IN_RANGE(addr, QLA82XX_ADDR_QDR_NET,
+	    qdr_max)) {
+		/* QDR network side */
+		window = ((addr - QLA82XX_ADDR_QDR_NET) >> 22) & 0x3f;
+		if (ha->qdr_sn_window == window)
+			return 1;
+	}
+
+	return 0;
+}
+
+static int qla4_8xxx_pci_mem_read_direct(struct scsi_qla_host *ha,
+		u64 off, void *data, int size)
+{
+	unsigned long flags;
+	void __iomem *addr;
+	int ret = 0;
+	u64 start;
+	void __iomem *mem_ptr = NULL;
+	unsigned long mem_base;
+	unsigned long mem_page;
+
+	write_lock_irqsave(&ha->hw_lock, flags);
+
+	/*
+	 * If attempting to access unknown address or straddle hw windows,
+	 * do not access.
+	 */
+	start = qla4_8xxx_pci_set_window(ha, off);
+	if ((start == -1UL) ||
+	    (qla4_8xxx_pci_is_same_window(ha, off + size - 1) == 0)) {
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+		ql4_err(ha, "%s out of bound pci memory access. "
+				"offset is 0x%llx\n", DRIVER_NAME, off);
+		return -1;
+	}
+
+	addr = qla4_8xxx_pci_base_offsetfset(ha, start);
+	if (!addr) {
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+		mem_base = pci_resource_start(ha->pdev, 0);
+		mem_page = start & PAGE_MASK;
+		/* Map two pages whenever user tries to access addresses in two
+		   consecutive pages.
+		 */
+		if (mem_page != ((start + size - 1) & PAGE_MASK))
+			mem_ptr = ioremap(mem_base + mem_page, PAGE_SIZE * 2);
+		else
+			mem_ptr = ioremap(mem_base + mem_page, PAGE_SIZE);
+
+		if (mem_ptr == NULL) {
+			*(u8 *)data = 0;
+			return -1;
+		}
+		addr = mem_ptr;
+		addr += start & (PAGE_SIZE - 1);
+		write_lock_irqsave(&ha->hw_lock, flags);
+	}
+
+	switch (size) {
+	case 1:
+		*(u8  *)data = readb(addr);
+		break;
+	case 2:
+		*(u16 *)data = readw(addr);
+		break;
+	case 4:
+		*(u32 *)data = readl(addr);
+		break;
+	case 8:
+		*(u64 *)data = readq(addr);
+		break;
+	default:
+		ret = -1;
+		break;
+	}
+	write_unlock_irqrestore(&ha->hw_lock, flags);
+
+	if (mem_ptr)
+		iounmap(mem_ptr);
+	return ret;
+}
+
+static int
+qla4_8xxx_pci_mem_write_direct(struct scsi_qla_host *ha, u64 off,
+		void *data, int size)
+{
+	unsigned long flags;
+	void __iomem *addr;
+	int ret = 0;
+	u64 start;
+	void __iomem *mem_ptr = NULL;
+	unsigned long mem_base;
+	unsigned long mem_page;
+
+	write_lock_irqsave(&ha->hw_lock, flags);
+
+	/*
+	 * If attempting to access unknown address or straddle hw windows,
+	 * do not access.
+	 */
+	start = qla4_8xxx_pci_set_window(ha, off);
+	if ((start == -1UL) ||
+	    (qla4_8xxx_pci_is_same_window(ha, off + size - 1) == 0)) {
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+		ql4_err(ha, "%s out of bound pci memory access. "
+				"offset is 0x%llx\n", DRIVER_NAME, off);
+		return -1;
+	}
+
+	addr = qla4_8xxx_pci_base_offsetfset(ha, start);
+	if (!addr) {
+		write_unlock_irqrestore(&ha->hw_lock, flags);
+		mem_base = pci_resource_start(ha->pdev, 0);
+		mem_page = start & PAGE_MASK;
+		/* Map two pages whenever user tries to access addresses in two
+		   consecutive pages.
+		 */
+		if (mem_page != ((start + size - 1) & PAGE_MASK))
+			mem_ptr = ioremap(mem_base + mem_page, PAGE_SIZE*2);
+		else
+			mem_ptr = ioremap(mem_base + mem_page, PAGE_SIZE);
+		if (mem_ptr == NULL)
+			return -1;
+
+		addr = mem_ptr;
+		addr += start & (PAGE_SIZE - 1);
+		write_lock_irqsave(&ha->hw_lock, flags);
+	}
+
+	switch (size) {
+	case 1:
+		writeb(*(u8 *)data, addr);
+		break;
+	case 2:
+		writew(*(u16 *)data, addr);
+		break;
+	case 4:
+		writel(*(u32 *)data, addr);
+		break;
+	case 8:
+		writeq(*(u64 *)data, addr);
+		break;
+	default:
+		ret = -1;
+		break;
+	}
+	write_unlock_irqrestore(&ha->hw_lock, flags);
+	if (mem_ptr)
+		iounmap(mem_ptr);
+	return ret;
+}
+
+static unsigned long
+qla4_8xxx_decode_crb_addr(unsigned long addr)
+{
+	int i;
+	unsigned long base_addr, offset, pci_base;
+
+	if (!qla4_8xxx_crb_table_initialized)
+		qla4_8xxx_crb_addr_transform_setup();
+
+	pci_base = ADDR_ERROR;
+	base_addr = addr & 0xfff00000;
+	offset = addr & 0x000fffff;
+
+	for (i = 0; i < MAX_CRB_XFORM; i++) {
+		if (crb_addr_xform[i] == base_addr) {
+			pci_base = i << 20;
+			break;
+		}
+	}
+	if (pci_base == ADDR_ERROR)
+		return pci_base;
+	else
+		return pci_base + offset;
+}
+
+static long rom_max_timeout = 100;
+static long qla4_8xxx_rom_lock_timeout = 100;
+
+static int
+qla4_8xxx_rom_lock(struct scsi_qla_host *ha)
+{
+	int i;
+	int done = 0, timeout = 0;
+
+	while (!done) {
+		/* acquire semaphore2 from PCI HW block */
+
+		done = qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM2_LOCK));
+		if (done == 1)
+			break;
+		if (timeout >= qla4_8xxx_rom_lock_timeout) {
+			ql4_warn(ha, "%s: Failed to acquire rom lock",
+				 __func__);
+			return -1;
+		}
+
+		timeout++;
+
+		/* Yield CPU */
+		if (!in_interrupt())
+			schedule();
+		else {
+			for (i = 0; i < 20; i++)
+				cpu_relax();    /*This a nop instr on i386*/
+		}
+	}
+	qla4_8xxx_wr_32(ha, QLA82XX_ROM_LOCK_ID, ROM_LOCK_DRIVER);
+	return 0;
+}
+
+static void
+qla4_8xxx_rom_unlock(struct scsi_qla_host *ha)
+{
+	qla4_8xxx_rd_32(ha, QLA82XX_PCIE_REG(PCIE_SEM2_UNLOCK));
+}
+
+static int
+qla4_8xxx_wait_rom_done(struct scsi_qla_host *ha)
+{
+	long timeout = 0;
+	long done = 0 ;
+
+	while (done == 0) {
+		done = qla4_8xxx_rd_32(ha, QLA82XX_ROMUSB_GLB_STATUS);
+		done &= 2;
+		timeout++;
+		if (timeout >= rom_max_timeout) {
+			ql4_info(ha, "%s: Timeout reached  waiting for rom done",
+					DRIVER_NAME);
+			return -1;
+		}
+	}
+	return 0;
+}
+
+static int
+qla4_8xxx_do_rom_fast_read(struct scsi_qla_host *ha, int addr, int *valp)
+{
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_ADDRESS, addr);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_DUMMY_BYTE_CNT, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_ABYTE_CNT, 3);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_INSTR_OPCODE, 0xb);
+	if (qla4_8xxx_wait_rom_done(ha)) {
+		ql4_info(ha, "%s: Error waiting for rom done\n", DRIVER_NAME);
+		return -1;
+	}
+	/* reset abyte_cnt and dummy_byte_cnt */
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_DUMMY_BYTE_CNT, 0);
+	udelay(10);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_ROM_ABYTE_CNT, 0);
+
+	*valp = qla4_8xxx_rd_32(ha, QLA82XX_ROMUSB_ROM_RDATA);
+	return 0;
+}
+
+static int
+qla4_8xxx_rom_fast_read(struct scsi_qla_host *ha, int addr, int *valp)
+{
+	int ret, loops = 0;
+
+	while ((qla4_8xxx_rom_lock(ha) != 0) && (loops < 50000)) {
+		udelay(100);
+		loops++;
+	}
+	if (loops >= 50000) {
+		ql4_info(ha, "%s: qla4_8xxx_rom_lock failed\n", DRIVER_NAME);
+		return -1;
+	}
+	ret = qla4_8xxx_do_rom_fast_read(ha, addr, valp);
+	qla4_8xxx_rom_unlock(ha);
+	return ret;
+}
+
+/**
+ * This routine does CRB initialize sequence
+ * to put the ISP into operational state
+ **/
+static int
+qla4_8xxx_pinit_from_rom(struct scsi_qla_host *ha, int verbose)
+{
+	int addr, val;
+	int i ;
+	struct crb_addr_pair *buf;
+	unsigned long off;
+	unsigned offset, n;
+
+	struct crb_addr_pair {
+		long addr;
+		long data;
+	};
+
+	/* Halt all the indiviual PEGs and other blocks of the ISP */
+	qla4_8xxx_rom_lock(ha);
+
+	/* disable all I2Q */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x10, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x14, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x18, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x1c, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x20, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_I2Q + 0x24, 0x0);
+
+	/* disable all niu interrupts */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x40, 0xff);
+	/* disable xge rx/tx */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x70000, 0x00);
+	/* disable xg1 rx/tx */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x80000, 0x00);
+	/* disable sideband mac */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x90000, 0x00);
+	/* disable ap0 mac */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0xa0000, 0x00);
+	/* disable ap1 mac */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0xb0000, 0x00);
+
+	/* halt sre */
+	val = qla4_8xxx_rd_32(ha, QLA82XX_CRB_SRE + 0x1000);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_SRE + 0x1000, val & (~(0x1)));
+
+	/* halt peg */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_EPG + 0x1300, 0x1);
+
+	/* halt timers */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x0, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x8, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x10, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x18, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x100, 0x0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_TIMER + 0x200, 0x0);
+
+	/* halt pegs */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_0 + 0x3c, 1);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_1 + 0x3c, 1);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_2 + 0x3c, 1);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_3 + 0x3c, 1);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_4 + 0x3c, 1);
+
+	msleep(5);
+
+	if (test_bit(DPC_RESET_HA, &ha->dpc_flags))
+		/* don't reset CAM block on reset */
+		qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_GLB_SW_RESET, 0xfeffffff);
+	else
+		qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_GLB_SW_RESET, 0xffffffff);
+
+	qla4_8xxx_rom_unlock(ha);
+
+	/* Read the signature value from the flash.
+	 * Offset 0: Contain signature (0xcafecafe)
+	 * Offset 4: Offset and number of addr/value pairs
+	 * that present in CRB initialize sequence
+	 */
+	if (qla4_8xxx_rom_fast_read(ha, 0, &n) != 0 || n != 0xcafecafeUL ||
+	    qla4_8xxx_rom_fast_read(ha, 4, &n) != 0) {
+		ql4_warn(ha, "[ERROR] Reading crb_init area: n: %08x\n", n);
+		return -1;
+	}
+
+	/* Offset in flash = lower 16 bits
+	 * Number of enteries = upper 16 bits
+	 */
+	offset = n & 0xffffU;
+	n = (n >> 16) & 0xffffU;
+
+	/* number of addr/value pair should not exceed 1024 enteries */
+	if (n  >= 1024) {
+		ql4_warn(ha, "%s: %s:n=0x%x [ERROR] Card flash not "
+			 "initialized.\n", DRIVER_NAME, __func__, n);
+		return -1;
+	}
+
+	ql4_info(ha, "%s: %d CRB init values found in ROM.\n", DRIVER_NAME, n);
+
+	buf = kmalloc(n * sizeof(struct crb_addr_pair), GFP_KERNEL);
+	if (buf == NULL) {
+		ql4_warn(ha, "%s: [ERROR] Unable to malloc memory.\n",
+			 DRIVER_NAME);
+		return -1;
+	}
+
+	for (i = 0; i < n; i++) {
+		if (qla4_8xxx_rom_fast_read(ha, 8*i + 4*offset, &val) != 0 ||
+		    qla4_8xxx_rom_fast_read(ha, 8*i + 4*offset + 4, &addr) !=
+		    0) {
+			kfree(buf);
+			return -1;
+		}
+
+		buf[i].addr = addr;
+		buf[i].data = val;
+	}
+
+	for (i = 0; i < n; i++) {
+		/* Translate internal CRB initialization
+		 * address to PCI bus address
+		 */
+		off = qla4_8xxx_decode_crb_addr((unsigned long)buf[i].addr) +
+		    QLA82XX_PCI_CRBSPACE;
+		/* Not all CRB  addr/value pair to be written,
+		 * some of them are skipped
+		 */
+
+		/* skip if LS bit is set*/
+		if (off & 0x1) {
+			DEBUG2(ql4_warn(ha, "Skip CRB init replay for "
+					"offset = 0x%lx\n", off));
+			continue;
+		}
+
+		/* skipping cold reboot MAGIC */
+		if (off == QLA82XX_CAM_RAM(0x1fc))
+			continue;
+
+		/* do not reset PCI */
+		if (off == (ROMUSB_GLB + 0xbc))
+			continue;
+
+		/* skip core clock, so that firmware can increase the clock */
+		if (off == (ROMUSB_GLB + 0xc8))
+			continue;
+
+		/* skip the function enable register */
+		if (off == QLA82XX_PCIE_REG(PCIE_SETUP_FUNCTION))
+			continue;
+
+		if (off == QLA82XX_PCIE_REG(PCIE_SETUP_FUNCTION2))
+			continue;
+
+		if ((off & 0x0ff00000) == QLA82XX_CRB_SMB)
+			continue;
+
+		if ((off & 0x0ff00000) == QLA82XX_CRB_DDR_NET)
+			continue;
+
+		if (off == ADDR_ERROR) {
+			ql4_warn(ha, "%s: [ERROR] Unknown addr: 0x%08lx\n",
+			    DRIVER_NAME, buf[i].addr);
+			continue;
+		}
+
+		qla4_8xxx_wr_32(ha, off, buf[i].data);
+
+		/* ISP requires much bigger delay to settle down,
+		 * else crb_window returns 0xffffffff
+		 */
+		if (off == QLA82XX_ROMUSB_GLB_SW_RESET)
+			msleep(1000);
+
+		/* ISP requires millisec delay between
+		 * successive CRB register updation
+		 */
+		msleep(1);
+	}
+
+	kfree(buf);
+
+	/* Resetting the data and instruction cache */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_D+0xec, 0x1e);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_D+0x4c, 8);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_I+0x4c, 8);
+
+	/* Clear all protocol processing engines */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_0+0x8, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_0+0xc, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_1+0x8, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_1+0xc, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_2+0x8, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_2+0xc, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_3+0x8, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_3+0xc, 0);
+
+	return 0;
+}
+
+static int
+qla4_8xxx_load_from_flash(struct scsi_qla_host *ha, uint32_t image_start)
+{
+	int  i;
+	long size = 0;
+	long flashaddr, memaddr;
+	u64 data;
+	u32 high, low;
+
+	flashaddr = memaddr = ha->hw.flt_region_bootload;
+	size = (image_start - flashaddr)/8;
+
+	DEBUG2(ql4_info(ha, "%s: bootldr=0x%lx, fw_image=0x%x\n",
+			__func__, flashaddr, image_start));
+
+	for (i = 0; i < size; i++) {
+		if ((qla4_8xxx_rom_fast_read(ha, flashaddr, (int *)&low)) ||
+		    (qla4_8xxx_rom_fast_read(ha, flashaddr + 4,
+		    (int *)&high))) {
+			return -1;
+		}
+		data = ((u64)high << 32) | low ;
+		if( qla4_8xxx_pci_mem_write_2M(ha, memaddr, &data, 8))
+			return -1;
+		flashaddr += 8;
+		memaddr   += 8;
+
+		if (i%0x1000 == 0)
+			msleep(1);
+
+	}
+
+	udelay(100);
+
+	read_lock(&ha->hw_lock);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_PEG_NET_0 + 0x18, 0x1020);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_GLB_SW_RESET, 0x80001e);
+	read_unlock(&ha->hw_lock);
+
+	return 0;
+}
+
+static int qla4_8xxx_load_fw(struct scsi_qla_host *ha, uint32_t image_start)
+{
+	u32 rst;
+
+	qla4_8xxx_wr_32(ha, CRB_CMDPEG_STATE, 0);
+	if (qla4_8xxx_pinit_from_rom(ha, 0) != QLA_SUCCESS) {
+		ql4_warn(ha, "%s: Error during CRB Initialization\n", __func__);
+		return QLA_ERROR;
+	}
+
+	udelay(500);
+
+	/* at this point, QM is in reset. This could be a problem if there are
+	 * incoming d* transition queue messages. QM/PCIE could wedge.
+	 * To get around this, QM is brought out of reset.
+	 */
+
+	rst = qla4_8xxx_rd_32(ha, QLA82XX_ROMUSB_GLB_SW_RESET);
+	/* unreset qm */
+	rst &= ~(1 << 28);
+	qla4_8xxx_wr_32(ha, QLA82XX_ROMUSB_GLB_SW_RESET, rst);
+
+	if (qla4_8xxx_load_from_flash(ha, image_start)) {
+		ql4_info(ha, "%s: Error trying to load fw from flash!\n",
+			__func__);
+		return QLA_ERROR;
+	}
+
+	return QLA_SUCCESS;
+}
+
+int
+qla4_8xxx_pci_mem_read_2M(struct scsi_qla_host *ha,
+		u64 off, void *data, int size)
+{
+	int i, j = 0, k, start, end, loop, sz[2], off0[2];
+	int shift_amount;
+	uint32_t temp;
+	uint64_t off8, val, mem_crb, word[2] = {0, 0};
+
+	/*
+	 * If not MN, go check for MS or invalid.
+	 */
+
+	if (off >= QLA82XX_ADDR_QDR_NET && off <= QLA82XX_P3_ADDR_QDR_NET_MAX)
+		mem_crb = QLA82XX_CRB_QDR_NET;
+	else {
+		mem_crb = QLA82XX_CRB_DDR_NET;
+		if (qla4_8xxx_pci_mem_bound_check(ha, off, size) == 0)
+			return qla4_8xxx_pci_mem_read_direct(ha,
+					off, data, size);
+	}
+
+
+	off8 = off & 0xfffffff0;
+	off0[0] = off & 0xf;
+	sz[0] = (size < (16 - off0[0])) ? size : (16 - off0[0]);
+	shift_amount = 4;
+
+	loop = ((off0[0] + size - 1) >> shift_amount) + 1;
+	off0[1] = 0;
+	sz[1] = size - sz[0];
+
+	for (i = 0; i < loop; i++) {
+		temp = off8 + (i << shift_amount);
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_ADDR_LO, temp);
+		temp = 0;
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_ADDR_HI, temp);
+		temp = MIU_TA_CTL_ENABLE;
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_CTRL, temp);
+		temp = MIU_TA_CTL_START | MIU_TA_CTL_ENABLE;
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_CTRL, temp);
+
+		for (j = 0; j < MAX_CTL_CHECK; j++) {
+			temp = qla4_8xxx_rd_32(ha, mem_crb + MIU_TEST_AGT_CTRL);
+			if ((temp & MIU_TA_CTL_BUSY) == 0)
+				break;
+		}
+
+		if (j >= MAX_CTL_CHECK) {
+			if (printk_ratelimit())
+				ql4_err(ha, "%s: failed to read through"
+							"agent\n", __func__);
+			break;
+		}
+
+		start = off0[i] >> 2;
+		end   = (off0[i] + sz[i] - 1) >> 2;
+		for (k = start; k <= end; k++) {
+			temp = qla4_8xxx_rd_32(ha,
+				mem_crb + MIU_TEST_AGT_RDDATA(k));
+			word[i] |= ((uint64_t)temp << (32 * (k & 1)));
+		}
+	}
+
+	if (j >= MAX_CTL_CHECK)
+		return -1;
+
+	if ((off0[0] & 7) == 0) {
+		val = word[0];
+	} else {
+		val = ((word[0] >> (off0[0] * 8)) & (~(~0ULL << (sz[0] * 8)))) |
+		((word[1] & (~(~0ULL << (sz[1] * 8)))) << (sz[0] * 8));
+	}
+
+	switch (size) {
+	case 1:
+		*(uint8_t  *)data = val;
+		break;
+	case 2:
+		*(uint16_t *)data = val;
+		break;
+	case 4:
+		*(uint32_t *)data = val;
+		break;
+	case 8:
+		*(uint64_t *)data = val;
+		break;
+	}
+	return 0;
+}
+
+int
+qla4_8xxx_pci_mem_write_2M(struct scsi_qla_host *ha,
+		u64 off, void *data, int size)
+{
+	int i, j, ret = 0, loop, sz[2], off0;
+	int scale, shift_amount, startword;
+	uint32_t temp;
+	uint64_t off8, mem_crb, tmpw, word[2] = {0, 0};
+
+	/*
+	 * If not MN, go check for MS or invalid.
+	 */
+	if (off >= QLA82XX_ADDR_QDR_NET && off <= QLA82XX_P3_ADDR_QDR_NET_MAX)
+		mem_crb = QLA82XX_CRB_QDR_NET;
+	else {
+		mem_crb = QLA82XX_CRB_DDR_NET;
+		if (qla4_8xxx_pci_mem_bound_check(ha, off, size) == 0)
+			return qla4_8xxx_pci_mem_write_direct(ha,
+					off, data, size);
+	}
+
+	off0 = off & 0x7;
+	sz[0] = (size < (8 - off0)) ? size : (8 - off0);
+	sz[1] = size - sz[0];
+
+	off8 = off & 0xfffffff0;
+	loop = (((off & 0xf) + size - 1) >> 4) + 1;
+	shift_amount = 4;
+	scale = 2;
+	startword = (off & 0xf)/8;
+
+	for (i = 0; i < loop; i++) {
+		if (qla4_8xxx_pci_mem_read_2M(ha, off8 +
+		    (i << shift_amount), &word[i * scale], 8))
+			return -1;
+	}
+
+	switch (size) {
+	case 1:
+		tmpw = *((uint8_t *)data);
+		break;
+	case 2:
+		tmpw = *((uint16_t *)data);
+		break;
+	case 4:
+		tmpw = *((uint32_t *)data);
+		break;
+	case 8:
+	default:
+		tmpw = *((uint64_t *)data);
+		break;
+	}
+
+	if (sz[0] == 8)
+		word[startword] = tmpw;
+	else {
+		word[startword] &=
+		    ~((~(~0ULL << (sz[0] * 8))) << (off0 * 8));
+		word[startword] |= tmpw << (off0 * 8);
+	}
+
+	if (sz[1] != 0) {
+		word[startword+1] &= ~(~0ULL << (sz[1] * 8));
+		word[startword+1] |= tmpw >> (sz[0] * 8);
+	}
+
+	for (i = 0; i < loop; i++) {
+		temp = off8 + (i << shift_amount);
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_ADDR_LO, temp);
+		temp = 0;
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_ADDR_HI, temp);
+		temp = word[i * scale] & 0xffffffff;
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_WRDATA_LO, temp);
+		temp = (word[i * scale] >> 32) & 0xffffffff;
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_WRDATA_HI, temp);
+		temp = word[i*scale + 1] & 0xffffffff;
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_WRDATA_UPPER_LO,
+		    temp);
+		temp = (word[i*scale + 1] >> 32) & 0xffffffff;
+		qla4_8xxx_wr_32(ha, mem_crb + MIU_TEST_AGT_WRDATA_UPPER_HI,
+		    temp);
+
+		temp = MIU_TA_CTL_ENABLE | MIU_TA_CTL_WRITE;
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_CTRL, temp);
+		temp = MIU_TA_CTL_START | MIU_TA_CTL_ENABLE | MIU_TA_CTL_WRITE;
+		qla4_8xxx_wr_32(ha, mem_crb+MIU_TEST_AGT_CTRL, temp);
+
+		for (j = 0; j < MAX_CTL_CHECK; j++) {
+			temp = qla4_8xxx_rd_32(ha, mem_crb + MIU_TEST_AGT_CTRL);
+			if ((temp & MIU_TA_CTL_BUSY) == 0)
+				break;
+		}
+
+		if (j >= MAX_CTL_CHECK) {
+			if (printk_ratelimit())
+				ql4_err(ha, "%s failed to write through"
+							"agent\n", __func__);
+			ret = -1;
+			break;
+		}
+	}
+
+	return ret;
+}
+
+static int qla4_8xxx_cmdpeg_ready(struct scsi_qla_host *ha, int pegtune_val)
+{
+	u32 val = 0;
+	int retries = 60;
+
+	if (!pegtune_val) {
+		do {
+			val = qla4_8xxx_rd_32(ha, CRB_CMDPEG_STATE);
+			if ((val == PHAN_INITIALIZE_COMPLETE) ||
+			    (val == PHAN_INITIALIZE_ACK))
+				return 0;
+			set_current_state(TASK_UNINTERRUPTIBLE);
+			schedule_timeout(500);
+
+		} while (--retries);
+
+		if (!retries) {
+			pegtune_val = qla4_8xxx_rd_32(ha,
+				QLA82XX_ROMUSB_GLB_PEGTUNE_DONE);
+			ql4_warn(ha, "%s: init failed, pegtune_val = %x\n",
+				__func__, pegtune_val);
+			return -1;
+		}
+	}
+	return 0;
+}
+
+static int qla4_8xxx_rcvpeg_ready(struct scsi_qla_host *ha)
+{
+	uint32_t state = 0;
+	int loops = 0;
+
+	/* Window 1 call */
+	read_lock(&ha->hw_lock);
+	state = qla4_8xxx_rd_32(ha, CRB_RCVPEG_STATE);
+	read_unlock(&ha->hw_lock);
+
+	while ((state != PHAN_PEG_RCV_INITIALIZED) && (loops < 30000)) {
+		udelay(100);
+		/* Window 1 call */
+		read_lock(&ha->hw_lock);
+		state = qla4_8xxx_rd_32(ha, CRB_RCVPEG_STATE);
+		read_unlock(&ha->hw_lock);
+
+		loops++;
+	}
+
+	if (loops >= 30000) {
+		DEBUG2(ql4_info(ha, "Receive Peg initialization not "
+				"complete: 0x%x.\n", state));
+		return QLA_ERROR;
+	}
+
+	return QLA_SUCCESS;
+}
+
+void
+qla4_8xxx_set_drv_active(struct scsi_qla_host *ha)
+{
+	uint32_t drv_active;
+
+	drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+	drv_active |= (1 << (ha->func_num * 4));
+	ql4_info(ha, "%s(%ld): drv_active: 0x%08x\n",
+			__func__, ha->host_no, drv_active);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_ACTIVE, drv_active);
+}
+
+void
+qla4_8xxx_clear_drv_active(struct scsi_qla_host *ha)
+{
+	uint32_t drv_active;
+
+	drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+	drv_active &= ~(1 << (ha->func_num * 4));
+	ql4_info(ha, "%s(%ld): drv_active: 0x%08x\n",
+			__func__, ha->host_no, drv_active);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_ACTIVE, drv_active);
+}
+
+
+static inline int
+qla4_8xxx_need_reset(struct scsi_qla_host *ha)
+{
+	uint32_t drv_state, drv_active;
+	int rval;
+
+	drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+	drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	rval = drv_state & (1 << (ha->func_num * 4));
+	if ((test_bit(AF_EEH_BUSY, &ha->flags)) && drv_active)
+		rval = 1;
+
+	return rval;
+}
+
+static inline void
+qla4_8xxx_set_rst_ready(struct scsi_qla_host *ha)
+{
+	uint32_t drv_state;
+
+	drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	drv_state |= (1 << (ha->func_num * 4));
+	ql4_info(ha, "%s(%ld): drv_state: 0x%08x\n",
+			__func__, ha->host_no, drv_state);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_STATE, drv_state);
+}
+
+static inline void
+qla4_8xxx_clear_rst_ready(struct scsi_qla_host *ha)
+{
+	uint32_t drv_state;
+
+	drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	drv_state &= ~(1 << (ha->func_num * 4));
+	ql4_info(ha, "%s(%ld): drv_state: 0x%08x\n",
+			__func__, ha->host_no, drv_state);
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_STATE, drv_state);
+}
+
+static inline void
+qla4_8xxx_set_qsnt_ready(struct scsi_qla_host *ha)
+{
+	uint32_t qsnt_state;
+
+	qsnt_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	qsnt_state |= (2 << (ha->func_num * 4));
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_STATE, qsnt_state);
+}
+
+void
+qla4_8xxx_clear_qsnt_ready(struct scsi_qla_host *ha)
+{
+	uint32_t qsnt_state;
+
+	qsnt_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	qsnt_state &= ~(2 << (ha->func_num * 4));
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_STATE, qsnt_state);
+}
+
+static int
+qla4_8xxx_start_firmware(struct scsi_qla_host *ha, uint32_t image_start)
+{
+	int pcie_cap;
+	uint16_t lnk;
+
+	/* scrub dma mask expansion register */
+	qla4_8xxx_wr_32(ha, CRB_DMA_SHIFT, 0x55555555);
+
+	/* Overwrite stale initialization register values */
+	qla4_8xxx_wr_32(ha, CRB_CMDPEG_STATE, 0);
+	qla4_8xxx_wr_32(ha, CRB_RCVPEG_STATE, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_PEG_HALT_STATUS1, 0);
+	qla4_8xxx_wr_32(ha, QLA82XX_PEG_HALT_STATUS2, 0);
+
+	if (qla4_8xxx_load_fw(ha, image_start) != QLA_SUCCESS) {
+		ql4_info(ha, "%s: Error trying to start fw!\n", __func__);
+		return QLA_ERROR;
+	}
+
+	/* Handshake with the card before we register the devices. */
+	if (qla4_8xxx_cmdpeg_ready(ha, 0) != QLA_SUCCESS) {
+		ql4_info(ha, "%s: Error during card handshake!\n", __func__);
+		return QLA_ERROR;
+	}
+
+	/* Negotiated Link width */
+	pcie_cap = pci_find_capability(ha->pdev, PCI_CAP_ID_EXP);
+	pci_read_config_word(ha->pdev, pcie_cap + PCI_EXP_LNKSTA, &lnk);
+	ha->link_width = (lnk >> 4) & 0x3f;
+
+	/* Synchronize with Receive peg */
+	return qla4_8xxx_rcvpeg_ready(ha);
+}
+
+static int
+qla4_8xxx_try_start_fw(struct scsi_qla_host *ha)
+{
+	int rval = QLA_ERROR;
+
+	/*
+	 * FW Load priority:
+	 * 1) Operational firmware residing in flash.
+	 * 2) Fail
+	 */
+
+	ql4_info(ha, "FW: Retrieving flash offsets from FLT/FDT ...\n");
+	rval = qla4_8xxx_get_flash_info(ha);
+	if (rval != QLA_SUCCESS)
+		return rval;
+
+	ql4_info(ha, "FW: Attempting to load firmware from flash...\n");
+	rval = qla4_8xxx_start_firmware(ha, ha->hw.flt_region_fw);
+	if (rval != QLA_SUCCESS) {
+		ql4_err(ha, "FW: Load firmware from flash"
+		    " FAILED...\n");
+		return rval;
+	}
+
+	return rval;
+}
+
+static void qla4_8xxx_rom_lock_recovery(struct scsi_qla_host *ha)
+{
+	if (qla4_8xxx_rom_lock(ha)) {
+		/* Someone else is holding the lock. */
+		dev_info(&ha->pdev->dev, "Resetting rom_lock\n");
+	}
+
+	/*
+	 * Either we got the lock, or someone
+	 * else died while holding it.
+	 * In either case, unlock.
+	 */
+	qla4_8xxx_rom_unlock(ha);
+}
+
+/*
+ * Read CRB operation.
+ */
+
+static void
+qla4_8xxx_minidump_process_rdcrb(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t r_addr, r_stride, loop_cnt, i, r_value;
+	struct qla82xx_minidump_entry_crb *crb_hdr;
+	uint32_t *data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	crb_hdr = (struct qla82xx_minidump_entry_crb *)entry_hdr;
+	r_addr = crb_hdr->addr;
+	r_stride = crb_hdr->crb_strd.addr_stride;
+	loop_cnt = crb_hdr->op_count;
+
+	for (i = 0; i < loop_cnt; i++) {
+		r_value = qla4_8xxx_md_rw_32(ha, r_addr, 0, 0);
+		*data_ptr++ = cpu_to_le32(r_addr);
+		*data_ptr++ = cpu_to_le32(r_value);
+		r_addr += r_stride;
+	}
+	*d_ptr = data_ptr;
+}
+
+static int
+qla4_8xxx_minidump_process_l2tag(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t addr, r_addr, c_addr, t_r_addr;
+	uint32_t i, k, loop_count, t_value, r_cnt, r_value;
+	unsigned long p_wait, w_time, p_mask;
+	volatile uint32_t c_value_w, c_value_r;
+	struct qla82xx_minidump_entry_cache *cache_hdr;
+	int rval = QLA_ERROR;
+	uint32_t *data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	cache_hdr = (struct qla82xx_minidump_entry_cache*)entry_hdr;
+
+	loop_count = cache_hdr->op_count;
+	r_addr = cache_hdr->read_addr;
+	c_addr = cache_hdr->control_addr;
+	c_value_w = cache_hdr->cache_ctrl.write_value;
+
+	t_r_addr = cache_hdr->tag_reg_addr;
+	t_value = cache_hdr->addr_ctrl.init_tag_value;
+	r_cnt = cache_hdr->read_ctrl.read_addr_cnt;
+	p_wait = cache_hdr->cache_ctrl.poll_wait;
+	p_mask = cache_hdr->cache_ctrl.poll_mask;
+
+	for (i = 0; i < loop_count; i++) {
+		qla4_8xxx_md_rw_32(ha, t_r_addr, t_value, 1);
+
+		if (c_value_w)
+			qla4_8xxx_md_rw_32(ha, c_addr, c_value_w, 1);
+
+		if(p_mask) {
+			w_time = jiffies + p_wait;
+			do {			
+				c_value_r = qla4_8xxx_md_rw_32(ha, c_addr,
+								0, 0);
+				if ((c_value_r & p_mask) == 0)
+					break;
+				else if (time_after_eq(jiffies, w_time)) {
+					/* capturing dump failed */
+					return (rval);
+				}
+			} while(1);
+		}
+		addr = r_addr;
+		for (k = 0; k < r_cnt; k++) {
+			r_value = qla4_8xxx_md_rw_32(ha, addr, 0, 0);
+			*data_ptr++ = cpu_to_le32(r_value);
+			addr += cache_hdr->read_ctrl.read_addr_stride;
+		}
+
+		t_value += cache_hdr->addr_ctrl.tag_value_stride;
+	}
+	*d_ptr = data_ptr;
+	return QLA_SUCCESS;
+}
+
+/*
+ * Handling control entries.
+ */
+
+static int
+qla4_8xxx_minidump_process_control(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr)
+{
+	struct qla82xx_minidump_entry_crb *crb_entry;
+	uint32_t read_value, opcode, poll_time, addr, index, rval = 0;
+	uint32_t crb_addr;
+	unsigned long wtime;
+	struct qla4_8xxx_minidump_template_hdr *tmplt_hdr;
+	int i;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	tmplt_hdr = (struct qla4_8xxx_minidump_template_hdr *)
+						ha->fw_dump_tmplt_hdr;
+	crb_entry = (struct qla82xx_minidump_entry_crb*)entry_hdr;
+	crb_addr = crb_entry->addr;
+
+	for (i = 0; i < crb_entry->op_count; i++) {
+		opcode = crb_entry->crb_ctrl.opcode;
+		if (opcode & QLA82XX_DBG_OPCODE_WR) {
+			qla4_8xxx_md_rw_32(ha, crb_addr,
+					crb_entry->value_1, 1);
+			opcode &= ~QLA82XX_DBG_OPCODE_WR;
+		}
+		if (opcode & QLA82XX_DBG_OPCODE_RW) {
+			read_value = qla4_8xxx_md_rw_32(ha, crb_addr, 0, 0);
+			qla4_8xxx_md_rw_32(ha, crb_addr, read_value, 1);
+			opcode &= ~QLA82XX_DBG_OPCODE_RW;
+		}
+		if (opcode & QLA82XX_DBG_OPCODE_AND) {
+			read_value = qla4_8xxx_md_rw_32(ha, crb_addr, 0, 0);
+			read_value &= crb_entry->value_2;
+			opcode &= ~QLA82XX_DBG_OPCODE_AND;
+			if (opcode & QLA82XX_DBG_OPCODE_OR) {
+				read_value |= crb_entry->value_3;
+				opcode &= ~QLA82XX_DBG_OPCODE_OR;
+			}
+			qla4_8xxx_md_rw_32(ha, crb_addr, read_value, 1);
+		}
+		if (opcode & QLA82XX_DBG_OPCODE_OR) {
+			read_value = qla4_8xxx_md_rw_32(ha, crb_addr, 0, 0);
+			read_value |= crb_entry->value_3;
+			qla4_8xxx_md_rw_32(ha, crb_addr, read_value, 1);
+			opcode &= ~QLA82XX_DBG_OPCODE_OR;
+		}
+		if (opcode & QLA82XX_DBG_OPCODE_POLL) {
+			poll_time = crb_entry->crb_strd.poll_timeout;
+			wtime = jiffies + poll_time;
+			read_value = qla4_8xxx_md_rw_32(ha, crb_addr, 0, 0);
+
+			do {
+				if ((read_value & crb_entry->value_2)
+							== crb_entry->value_1)
+					break;
+				else if (time_after_eq(jiffies, wtime)) {
+					/* capturing dump failed */
+					rval = QLA_ERROR;
+					break;
+				} else
+					read_value = qla4_8xxx_md_rw_32(ha,
+						crb_addr, 0, 0);
+			} while (1);
+			opcode &= ~QLA82XX_DBG_OPCODE_POLL;
+		}
+
+		if (opcode & QLA82XX_DBG_OPCODE_RDSTATE) {
+			if (crb_entry->crb_strd.state_index_a) {
+				index = crb_entry->crb_strd.state_index_a;
+				addr = tmplt_hdr->saved_state_array[index];
+			} else
+				addr = crb_addr;
+
+			read_value = qla4_8xxx_md_rw_32(ha, addr, 0, 0);
+			index = crb_entry->crb_ctrl.state_index_v;
+			tmplt_hdr->saved_state_array[index] = read_value;
+			opcode &= ~QLA82XX_DBG_OPCODE_RDSTATE;
+		}
+
+		if (opcode & QLA82XX_DBG_OPCODE_WRSTATE) {
+			if (crb_entry->crb_strd.state_index_a) {
+				index = crb_entry->crb_strd.state_index_a;
+				addr = tmplt_hdr->saved_state_array[index];
+			} else
+				addr = crb_addr;
+
+			if (crb_entry->crb_ctrl.state_index_v) {
+				index = crb_entry->crb_ctrl.state_index_v;
+				read_value = tmplt_hdr->saved_state_array[index];
+			} else
+				read_value = crb_entry->value_1;
+
+			qla4_8xxx_md_rw_32(ha, addr, read_value, 1);
+			opcode &= ~QLA82XX_DBG_OPCODE_WRSTATE;
+		}
+
+		if (opcode & QLA82XX_DBG_OPCODE_MDSTATE) {
+			index = crb_entry->crb_ctrl.state_index_v;
+			read_value = tmplt_hdr->saved_state_array[index];
+			read_value <<= crb_entry->crb_ctrl.shl;
+			read_value >>= crb_entry->crb_ctrl.shr;
+			if (crb_entry->value_2)
+				read_value &= crb_entry->value_2;
+			read_value |= crb_entry->value_3;
+			read_value += crb_entry->value_1;
+			tmplt_hdr->saved_state_array[index] = read_value;
+			opcode &= ~QLA82XX_DBG_OPCODE_MDSTATE;
+		}
+		crb_addr += crb_entry->crb_strd.addr_stride;
+	}
+	DEBUG2(ql4_info(ha, "Leaving fn: %s\n", __func__));
+	return (rval);
+}
+
+/*
+ * Reading OCM memory
+ */
+static void
+qla4_8xxx_minidump_process_rdocm(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t r_addr, r_stride, loop_cnt, i, r_value;
+	struct qla82xx_minidump_entry_rdocm *ocm_hdr;
+	uint32_t * data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	ocm_hdr = (struct qla82xx_minidump_entry_rdocm *)entry_hdr;
+	r_addr = ocm_hdr->read_addr;
+	r_stride = ocm_hdr->read_addr_stride;
+	loop_cnt = ocm_hdr->op_count;
+
+	DEBUG2(ql4_info(ha, "[%s]: r_addr: 0x%x, r_stride: 0x%x, "
+		"loop_cnt: 0x%x\n", __func__, r_addr, r_stride, loop_cnt));
+
+	for ( i = 0; i < loop_cnt; i++) {
+		r_value = readl((void *)(r_addr + ha->nx_pcibase));
+		*data_ptr++ = cpu_to_le32(r_value);
+		r_addr += r_stride;
+	}
+	DEBUG2(ql4_info(ha, "Leaving fn: %s datacount: 0x%x\n", __func__,
+						(loop_cnt * 4)));
+	*d_ptr = data_ptr;
+}
+
+
+/*
+ * Read MUX data
+ */
+
+static void 
+qla4_8xxx_minidump_process_rdmux(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t r_addr, s_stride, s_addr, s_value, loop_cnt, i, r_value;
+	struct qla82xx_minidump_entry_mux *mux_hdr;
+	uint32_t * data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	mux_hdr = (struct qla82xx_minidump_entry_mux *)entry_hdr;
+	r_addr = mux_hdr->read_addr;
+	s_addr = mux_hdr->select_addr;
+	s_stride = mux_hdr->select_value_stride;
+	s_value = mux_hdr->select_value;
+	loop_cnt = mux_hdr->op_count;
+
+	for ( i = 0; i < loop_cnt; i++) {
+		qla4_8xxx_md_rw_32(ha, s_addr, s_value, 1);
+		r_value = qla4_8xxx_md_rw_32(ha, r_addr, 0, 0);
+		*data_ptr++ = cpu_to_le32(s_value);
+		*data_ptr++ = cpu_to_le32(r_value);
+		s_value += s_stride;
+	}
+
+	*d_ptr = data_ptr;
+}
+
+static void
+qla4_8xxx_minidump_process_l1cache(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t addr, r_addr, c_addr, t_r_addr;
+	uint32_t i, k, loop_count, t_value, r_cnt, r_value;
+	volatile uint32_t c_value_w;
+	struct qla82xx_minidump_entry_cache *cache_hdr;
+	uint32_t *data_ptr = *d_ptr;
+
+	cache_hdr = (struct qla82xx_minidump_entry_cache *)entry_hdr;
+	loop_count = cache_hdr->op_count;
+	r_addr = cache_hdr->read_addr;
+	c_addr = cache_hdr->control_addr;
+	c_value_w = cache_hdr->cache_ctrl.write_value;
+
+	t_r_addr = cache_hdr->tag_reg_addr;
+	t_value = cache_hdr->addr_ctrl.init_tag_value;
+	r_cnt = cache_hdr->read_ctrl.read_addr_cnt;
+
+	for (i = 0; i < loop_count; i++) {
+		qla4_8xxx_md_rw_32(ha, t_r_addr, t_value, 1);
+		qla4_8xxx_md_rw_32(ha, c_addr, c_value_w, 1);
+		addr = r_addr;
+		for (k = 0; k < r_cnt; k++) {
+			r_value = qla4_8xxx_md_rw_32(ha, addr, 0, 0);
+			*data_ptr++ = cpu_to_le32(r_value);
+			addr += cache_hdr->read_ctrl.read_addr_stride;
+		}
+		t_value += cache_hdr->addr_ctrl.tag_value_stride;
+	}
+	*d_ptr = data_ptr;
+}
+
+/*
+ * Handling Queue State Reads.
+ */
+static void 
+qla4_8xxx_minidump_process_queue(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t s_addr, r_addr;
+	uint32_t r_stride, r_value, r_cnt, qid = 0;
+	uint32_t i, k, loop_cnt;
+	struct qla82xx_minidump_entry_queue *q_hdr;
+	uint32_t *data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	q_hdr = (struct qla82xx_minidump_entry_queue *)entry_hdr;
+	s_addr = q_hdr->select_addr;
+	r_cnt = q_hdr->rd_strd.read_addr_cnt;
+	r_stride = q_hdr->rd_strd.read_addr_stride;
+	loop_cnt = q_hdr->op_count;
+
+	for ( i = 0; i < loop_cnt; i++) {
+		qla4_8xxx_md_rw_32(ha, s_addr, qid, 1);
+		r_addr = q_hdr->read_addr;
+		for ( k = 0; k < r_cnt; k++) {
+			r_value = qla4_8xxx_md_rw_32(ha, r_addr, 0, 0);
+			*data_ptr++ = cpu_to_le32(r_value);
+			r_addr += r_stride;
+		}
+		qid += q_hdr->q_strd.queue_id_stride;
+	}
+	*d_ptr = data_ptr;
+}
+
+uint32_t qla4_8xxx_validate_template_chksum(struct scsi_qla_host *ha)
+{
+	uint64_t chksum = 0;
+	uint32_t *d_ptr = (uint32_t *)ha->fw_dump_tmplt_hdr;
+	int count = ha->fw_dump_tmplt_size/sizeof(uint32_t);
+
+	while (count -- > 0)
+		chksum += *d_ptr++;
+	while (chksum >> 32)
+		chksum = (chksum & 0xFFFFFFFF) + (chksum >> 32);
+	DEBUG2(ql4_info(ha, "Check sum of template header: 0x%2llu\n", chksum));
+	return ~chksum;
+}
+
+#if 0
+/*
+ * We catch an error where driver does not read
+ * as much data as we expect from the entry.
+ */
+static void
+md_entry_err_chk(ql_minidump_entry_t * entry, uint32_t esize, int e_cnt)
+{
+	if (esize != entry->hdr.entry_capture_size) {
+		printk("%d %04x Dump write count = %d did not match entry "
+			"capture size = %d entry_count = %d\n",
+		     entry->hdr.entry_type,
+		     entry->hdr.entry_capture_mask, esize,
+		     entry->hdr.entry_capture_size, e_cnt);
+		entry->hdr.entry_capture_size = esize;
+		entry->hdr.driver_flags |= QL_DBG_SIZE_ERR_FLAG;
+	}
+	return;
+}
+#endif
+
+#define MD_DIRECT_ROM_WINDOW            0x42110030
+#define MD_DIRECT_ROM_READ_BASE         0x42150000
+static void
+qla4_8xxx_minidump_process_rdrom(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t r_addr, r_value;
+	uint32_t i, loop_cnt;
+	struct qla82xx_minidump_entry_rdrom *rom_hdr;
+	uint32_t *data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	rom_hdr = (struct qla82xx_minidump_entry_rdrom *)entry_hdr;
+	r_addr = rom_hdr->read_addr;
+	loop_cnt = rom_hdr->read_data_size/sizeof(uint32_t);
+
+	DEBUG2(ql4_info(ha, "[%s]: flash_addr: 0x%x, read_data_size: 0x%x\n",
+	    __func__, r_addr, loop_cnt));
+
+	for (i = 0; i < loop_cnt; i++) {
+		qla4_8xxx_md_rw_32(ha, MD_DIRECT_ROM_WINDOW,
+		    (r_addr & 0xFFFF0000), 1);
+		r_value = qla4_8xxx_md_rw_32(ha,
+		    MD_DIRECT_ROM_READ_BASE + (r_addr & 0x0000FFFF), 0, 0);
+		*data_ptr++ = cpu_to_le32(r_value);
+		r_addr += sizeof(uint32_t);
+	}
+	*d_ptr = data_ptr;
+}
+
+#define MD_MIU_TEST_AGT_CTRL		0x41000090
+#define MD_MIU_TEST_AGT_ADDR_LO		0x41000094
+#define MD_MIU_TEST_AGT_ADDR_HI		0x41000098
+
+//static const MD_MIU_TEST_AGT_RDDATA [ ] =
+//	{ 0x410000A8, 0x410000AC, 0x410000B8, 0x410000BC };
+
+static int
+qla4_8xxx_minidump_process_rdmem(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, uint32_t **d_ptr)
+{
+	uint32_t r_addr, r_value, r_data;
+	uint32_t i, j, loop_cnt;
+	struct qla82xx_minidump_entry_rdmem *m_hdr;
+	unsigned long flags;
+	int rval = QLA_ERROR;
+	uint32_t *data_ptr = *d_ptr;
+
+	DEBUG2(ql4_info(ha, "Entering fn: %s\n", __func__));
+	m_hdr = (struct qla82xx_minidump_entry_rdmem *)entry_hdr;
+	r_addr = m_hdr->read_addr;
+	loop_cnt = m_hdr->read_data_size/16;
+
+	DEBUG2(ql4_info(ha, "[%s]: Read addr: 0x%x, read_data_size: 0x%x\n",
+	    __func__, r_addr, m_hdr->read_data_size));
+
+	if (r_addr & 0xf) {
+		DEBUG2(ql4_info(ha, "[%s]: Read addr 0x%x not 16 bytes "
+		"alligned\n", __func__, r_addr));
+		return rval;
+	}
+
+	if (m_hdr->read_data_size % 16) {
+		DEBUG2(ql4_info(ha, "[%s]: Read data[0x%x] not multiple "
+			"of 16 bytes\n", __func__, m_hdr->read_data_size));
+		return rval;
+	}
+
+	DEBUG2(ql4_info(ha, "[%s]: rdmem_addr: 0x%x, read_data_size: 0x%x, "
+				"loop_cnt: 0x%x\n",__func__, r_addr, 
+					m_hdr->read_data_size, loop_cnt));
+
+
+	write_lock_irqsave(&ha->hw_lock, flags);
+	for (i = 0; i < loop_cnt; i++) {
+		qla4_8xxx_md_rw_32(ha, MD_MIU_TEST_AGT_ADDR_LO, r_addr, 1);
+		r_value = 0;
+		qla4_8xxx_md_rw_32(ha, MD_MIU_TEST_AGT_ADDR_HI, r_value, 1);
+		r_value = MIU_TA_CTL_ENABLE;
+		qla4_8xxx_md_rw_32(ha, MD_MIU_TEST_AGT_CTRL, r_value, 1);
+		r_value = MIU_TA_CTL_START | MIU_TA_CTL_ENABLE;
+		qla4_8xxx_md_rw_32(ha, MD_MIU_TEST_AGT_CTRL, r_value, 1);
+
+		for (j = 0; j < MAX_CTL_CHECK; j++) {
+			r_value = qla4_8xxx_md_rw_32(ha, MD_MIU_TEST_AGT_CTRL, 
+							0, 0);
+			if ((r_value & MIU_TA_CTL_BUSY) == 0)
+				break;
+		}
+
+		if (j >= MAX_CTL_CHECK) {
+			if (printk_ratelimit())
+				dev_err(&ha->pdev->dev,
+				    "%s: failed to read through"
+							"agent\n", __func__);
+			write_unlock_irqrestore(&ha->hw_lock, flags);
+			return 0;
+		}
+
+		for (j = 0; j < 4; j++) {
+			r_data = qla4_8xxx_md_rw_32(ha,
+					MD_MIU_TEST_AGT_RDDATA[j], 0, 0);
+			*data_ptr++ = cpu_to_le32(r_data);
+		}
+		r_addr += 16;
+	}
+	write_unlock_irqrestore(&ha->hw_lock, flags);
+
+	DEBUG2(ql4_info(ha, "Leaving fn: %s datacount: 0x%x\n", __func__,
+	    (loop_cnt * 16)));
+	*d_ptr = data_ptr;
+	return QLA_SUCCESS;
+}
+
+static void
+ql4_8xxx_mark_entry_skipped(struct scsi_qla_host *ha,
+    struct qla82xx_minidump_entry_hdr *entry_hdr, int index)
+{
+	entry_hdr->d_ctrl.driver_flags |= QLA82XX_DBG_SKIPPED_FLAG;
+	DEBUG2(ql4_info(ha, "scsi(%ld): Skipping entry[%d]: "
+		"ETYPE[0x%x]-ELEVEL[0x%x]\n", 
+			ha->host_no, index, entry_hdr->entry_type,
+			entry_hdr->d_ctrl.entry_capture_mask));
+}
+
+
+
+
+/*
+ * qla82xx_collect_md_data - Process minidump template and retrieve 
+ * firmware minidump data
+ * @ha: pointer to adapter structure
+ * 
+ */
+
+int
+qla4_8xxx_collect_md_data(struct scsi_qla_host *ha)
+{
+	int num_entry_hdr = 0;
+	struct qla82xx_minidump_entry_hdr *entry_hdr;
+	struct qla4_8xxx_minidump_template_hdr *tmplt_hdr;
+	uint32_t *data_ptr;
+	uint32_t data_collected = 0;
+	int i, rval = QLA_ERROR;
+	u64 now;
+	u32 timestamp;
+
+	/* make sure fw_dump memory buffers are available */	
+	if(!ha->fw_dump) {
+		ql4_info(ha, "%s(%ld) No buffer to dump\n", __func__, 
+								ha->host_no);
+		return 1;
+	}
+
+	tmplt_hdr = (struct qla4_8xxx_minidump_template_hdr *)
+						ha->fw_dump_tmplt_hdr;
+	data_ptr = (uint32_t*)((uint8_t*)ha->fw_dump + 
+						ha->fw_dump_tmplt_size);
+	data_collected += ha->fw_dump_tmplt_size;
+
+	num_entry_hdr = tmplt_hdr->num_of_entries;
+	ql4_info(ha, "[%s]: starting data ptr: %p\n", __func__, data_ptr);
+	ql4_info(ha, "[%s]: no of entry headers in Template: 0x%x\n", 
+						__func__, num_entry_hdr);
+	ql4_info(ha, "[%s]: Capture Mask obtained: 0x%x\n", __func__, 
+					ha->fw_dump_capture_mask);
+	ql4_info(ha, "[%s]: Total_data_size 0x%x, %d obtained\n", __func__, 
+					ha->fw_dump_size, ha->fw_dump_size);
+	/* Update current timestamp before taking dump */
+	now = get_jiffies_64();
+	timestamp = (u32)(jiffies_to_msecs(now)/1000);
+	tmplt_hdr->driver_timestamp = timestamp;
+
+
+	entry_hdr = (struct qla82xx_minidump_entry_hdr *) \
+	    (((uint8_t *)ha->fw_dump_tmplt_hdr) + tmplt_hdr->first_entry_offset);
+
+	/* Walk through the entry headers - validate amd perform required action */
+	for (i = 0; i < num_entry_hdr; i++) {
+
+		if (data_collected >= ha->fw_dump_size) {
+			ql4_info(ha, "Data collected: [0x%x], Total Dump size:"
+				"[0x%x]\n", data_collected, ha->fw_dump_size);
+			return 1;
+		}
+		DEBUG2(ql4_info(ha, "Data collected: [0x%x], Total Dump size:"
+				"[0x%x]\n", data_collected, ha->fw_dump_size));
+
+		if (!(entry_hdr->d_ctrl.entry_capture_mask & 
+					ha->fw_dump_capture_mask)) {
+			entry_hdr->d_ctrl.driver_flags |= 
+						QLA82XX_DBG_SKIPPED_FLAG;
+			DEBUG2(printk(KERN_WARNING "Skipping entry: EID:ETYPE:ELEVEL"
+				" --> 0x%x:0x%x:0x%x\n", i,
+					entry_hdr->entry_type, 
+					entry_hdr->d_ctrl.entry_capture_mask));
+			goto skip_nxt_entry;
+		}
+
+		DEBUG2(ql4_info(ha, "[%s]: data ptr[%d]: %p, entry_hdr: %p\n"
+		    "entry_hdr_size: 0x%x, entry_type: 0x%x, captrue_mask: 0x%x\n",
+		    __func__, i, data_ptr, entry_hdr, entry_hdr->entry_size,
+		    entry_hdr->entry_type, entry_hdr->d_ctrl.entry_capture_mask));
+
+		DEBUG2(ql4_info(ha, "Data collected: [0x%x], Dump size left:[0x%x]\n",
+		    data_collected, (ha->fw_dump_size - data_collected)));
+
+		/* Decode the entry type and take required action to capture debug data */
+		switch (entry_hdr->entry_type) {
+		case QLA82XX_RDEND:
+			ql4_8xxx_mark_entry_skipped(ha, entry_hdr, i);
+			break;
+		case QLA82XX_CNTRL:
+		    	rval = qla4_8xxx_minidump_process_control(ha, entry_hdr);
+			if (rval != QLA_SUCCESS) {
+				ql4_8xxx_mark_entry_skipped(ha, entry_hdr, i);
+				goto md_failed;				
+			}
+			break;
+		case QLA82XX_RDCRB:
+		    	qla4_8xxx_minidump_process_rdcrb(ha, entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_RDMEM:
+		    	rval = qla4_8xxx_minidump_process_rdmem(ha, entry_hdr, &data_ptr);
+			if (rval != QLA_SUCCESS) {
+				ql4_8xxx_mark_entry_skipped(ha, entry_hdr, i);
+				goto md_failed;
+			}
+			break;
+		case QLA82XX_BOARD:
+		case QLA82XX_RDROM:
+		    	qla4_8xxx_minidump_process_rdrom(ha, entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_L2DTG:
+		case QLA82XX_L2ITG:
+		case QLA82XX_L2DAT:
+		case QLA82XX_L2INS:
+			rval = qla4_8xxx_minidump_process_l2tag(ha, entry_hdr, &data_ptr);
+	               	if (rval != QLA_SUCCESS) {
+	                        ql4_8xxx_mark_entry_skipped(ha, entry_hdr, i);
+                                goto md_failed;
+                        }
+			break;
+		case QLA82XX_L1DAT:
+		case QLA82XX_L1INS:
+			qla4_8xxx_minidump_process_l1cache(ha, entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_RDOCM:
+		   	qla4_8xxx_minidump_process_rdocm(ha, entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_RDMUX:
+		    	qla4_8xxx_minidump_process_rdmux(ha, entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_QUEUE:
+			qla4_8xxx_minidump_process_queue(ha,
+						entry_hdr, &data_ptr);
+			break;
+		case QLA82XX_RDNOP:
+		default:
+			ql4_8xxx_mark_entry_skipped(ha, entry_hdr, i);
+			break;
+		}
+
+		data_collected = (uint8_t*)data_ptr -
+				((uint8_t*)((uint8_t*)ha->fw_dump + ha->fw_dump_tmplt_size));
+
+skip_nxt_entry:
+		/*  next entry in the template */
+		entry_hdr = (struct qla82xx_minidump_entry_hdr *) \
+		    (((uint8_t*)entry_hdr) + entry_hdr->entry_size);
+	}
+
+	if ((data_collected + ha->fw_dump_tmplt_size) != ha->fw_dump_size) {
+		ql4_info(ha, "Dump data mismatch: Data collected: [0x%x]"
+				", total_data_size:[0x%x]\n",
+				 data_collected, ha->fw_dump_size);
+		goto md_failed;
+	}
+	DEBUG2(ql4_info(ha, "Leaving fn: %s Last entry: 0x%x\n", __func__, i));
+md_failed:
+	return rval;
+}
+
+/**
+ * qla4_8xxx_uevent_emit - Send uevent when the firmware dump is ready.
+ * @ha: pointer to adapter structure
+ *
+ **/
+static void
+qla4_8xxx_uevent_emit(struct scsi_qla_host *ha, u32 code)
+{
+	char event_string[40];
+	char *envp[] = { event_string, NULL };
+
+	switch (code) {
+	case QL4_UEVENT_CODE_FW_DUMP:
+		snprintf(event_string, sizeof(event_string), "FW_DUMP=%ld",
+			 ha->host_no);
+		break;
+	default:
+		/*do nothing*/
+		break;
+	}
+
+	kobject_uevent_env(&(&ha->pdev->dev)->kobj, KOBJ_CHANGE, envp);
+}
+
+/**
+ * qla4_8xxx_device_bootstrap - Initialize device, set DEV_READY, start fw
+ * @ha: pointer to adapter structure
+ *
+ * Note: IDC lock must be held upon entry
+ **/
+static int
+qla4_8xxx_device_bootstrap(struct scsi_qla_host *ha)
+{
+	int rval = QLA_SUCCESS;
+	int i, timeout;
+	uint32_t old_count, count;
+	int need_reset = 0, peg_stuck = 1;
+
+	need_reset = qla4_8xxx_need_reset(ha);
+
+	old_count = qla4_8xxx_rd_32(ha, QLA82XX_PEG_ALIVE_COUNTER);
+
+	for (i = 0; i < 10; i++) {
+		timeout = msleep_interruptible(200);
+		if (timeout) {
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+			   QLA82XX_DEV_FAILED);
+			return QLA_ERROR;
+		}
+
+		count = qla4_8xxx_rd_32(ha, QLA82XX_PEG_ALIVE_COUNTER);
+		if (count != old_count)
+			peg_stuck = 0;
+	}
+
+	if (need_reset) {
+		/* We are trying to perform a recovery here. */
+		if (peg_stuck)
+			qla4_8xxx_rom_lock_recovery(ha);
+		goto dev_initialize;
+	} else  {
+		/* Start of day for this ha context. */
+		if (peg_stuck) {
+			/* Either we are the first or recovery in progress. */
+			qla4_8xxx_rom_lock_recovery(ha);
+			goto dev_initialize;
+		} else {
+			/* Firmware already running. */
+			goto dev_ready;
+		}
+	}
+
+	return rval;
+
+dev_initialize:
+	/* set to DEV_INITIALIZING */
+	ql4_info(ha, "HW State: INITIALIZING\n");
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE, QLA82XX_DEV_INITIALIZING);
+
+	/* Driver that sets device state to initializating sets IDC version */
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_IDC_VERSION, QLA82XX_IDC_VERSION);
+
+	qla4_8xxx_idc_unlock(ha);
+	/* Collect minidump after firmware reset */
+	if (ql4xenablemd && test_bit(AF_FW_RECOVERY, &ha->flags) &&
+			!test_and_set_bit(AF_82XX_FW_DUMPED, &ha->flags)) {
+		if (!qla4_8xxx_collect_md_data(ha)) {
+			qla4_8xxx_uevent_emit(ha, QL4_UEVENT_CODE_FW_DUMP);
+		} else {
+			ql4_info(ha, "Unable to collect minidump\n");
+			clear_bit(AF_82XX_FW_DUMPED, &ha->flags);
+		}
+	}
+	rval = qla4_8xxx_try_start_fw(ha);
+	qla4_8xxx_idc_lock(ha);
+
+	if (rval != QLA_SUCCESS) {
+		ql4_info(ha, "HW State: FAILED\n");
+		qla4_8xxx_clear_drv_active(ha);
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE, QLA82XX_DEV_FAILED);
+		return rval;
+	}
+
+dev_ready:
+	ql4_info(ha, "HW State: READY\n");
+	qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE, QLA82XX_DEV_READY);
+
+	return rval;
+}
+
+
+
+/**
+ * qla4_8xxx_need_reset_handler - Code to start reset sequence
+ * @ha: pointer to adapter structure
+ *
+ * Note: IDC lock must be held upon entry
+ **/
+static void
+qla4_8xxx_need_reset_handler(struct scsi_qla_host *ha)
+{
+	uint32_t dev_state, drv_state, drv_active;
+	uint32_t active_mask = 0xFFFFFFFF;
+	unsigned long reset_timeout;
+
+	ql4_info(ha, "Performing ISP error recovery\n");
+
+	if (test_and_clear_bit(AF_ONLINE, &ha->flags)) {
+		qla4_8xxx_idc_unlock(ha);
+		ha->isp_ops->disable_intrs(ha);
+		qla4_8xxx_idc_lock(ha);
+	}
+
+	if (!test_bit(AF_82XX_RST_OWNER, &ha->flags)) {
+		DEBUG2(ql4_info(ha, "%s(%ld): reset acknowledged\n",
+				__func__, ha->host_no));
+		qla4_8xxx_set_rst_ready(ha);
+	} else {
+		active_mask = (~(1 << (ha->func_num *4)));
+	}
+
+	/* wait for 10 seconds for reset ack from all functions */
+	reset_timeout = jiffies + (ha->nx_reset_timeout * HZ);
+
+	drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+
+	ql4_info(ha, "%s(%ld): drv_state = 0x%x, drv_active = 0x%x\n",
+		__func__, ha->host_no, drv_state, drv_active);
+
+	while (drv_state != (drv_active & active_mask)) {
+		if (time_after_eq(jiffies, reset_timeout)) {
+			ql4_info(ha, "%s: RESET TIMEOUT!"
+				"drv_state: 0x%08x, drv_active: 0x%08x\n",
+				DRIVER_NAME, drv_state, drv_active);
+			break;
+		}
+		/* Since RESET_OWNER will timeout first, so look at
+		 * which function ack till timeout
+		 */
+		if(test_bit(AF_82XX_RST_OWNER, &ha->flags)) {
+			ql4_info(ha, "%s(%ld): drv_state = 0x%x, drv_active"
+				" = 0x%x\n", __func__, ha->host_no, drv_state,
+				drv_active);
+		}
+		qla4_8xxx_idc_unlock(ha);
+		msleep(1000);
+		qla4_8xxx_idc_lock(ha);
+
+		drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+		drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+
+	}
+
+	/* Clear RESET OWNER as we are not going to use it any further */
+	clear_bit(AF_82XX_RST_OWNER, &ha->flags);
+
+	dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+	ql4_info(ha, "Device state is 0x%x = %s\n", dev_state,
+		dev_state < MAX_STATES ? qdev_state[dev_state] : "Unknown");
+
+	/* Force to DEV_COLD unless someone else is starting a reset */
+	if (dev_state != QLA82XX_DEV_INITIALIZING) {
+		ql4_info(ha, "HW State: COLD/RE-INIT\n");
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE, QLA82XX_DEV_COLD);
+		qla4_8xxx_set_rst_ready(ha);
+	}
+}
+
+/**
+ * qla4xxx_qsnt_state_cleanup
+ * @ha: pointer to adapter structure
+ *
+ * Stop all activity on the card.
+ * Any I/Os will be blocked when driver in HA_NEED_QUIESCENT state
+ * Wait for all pending I/Os to complete.
+ * Process all pending AENs.
+ **/
+void
+qla4xxx_qsnt_state_cleanup(struct scsi_qla_host *ha)
+{
+	qla4xxx_cmd_wait(ha, 0);
+	qla4xxx_process_aen(ha, PROCESS_ALL_AENS);
+}
+
+/**
+ * qla4_8xxx_need_qsnt_handler - Code to start qsnt
+ * @ha: pointer to adapter structure
+ *
+ * Device is set to Quiescent state through the ioctl
+ * All drivers in do_dpc() check QLA4XXX_CRB_DRV_STATE register
+ * and set the DRV_STATE to quiescent state.
+ **/
+void
+qla4_8xxx_need_qsnt_handler(struct scsi_qla_host *ha)
+{
+	unsigned long qsnt_timeout;
+	uint32_t drv_state, drv_active, dev_state;
+
+	if (test_bit(AF_ONLINE, &ha->flags))
+		qla4xxx_qsnt_state_cleanup(ha);
+	else
+		return;
+
+	qla4_8xxx_set_qsnt_ready(ha);
+
+	/* Wait for 30 secs for all functions to ack qsnt mode */
+	qsnt_timeout = jiffies + (30 * HZ);
+	drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+	drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+
+	/* drv_state is set to (2 << ha->function_number*4) */
+	drv_active = drv_active << 1;
+
+	while (drv_state != drv_active) {
+		if (time_after_eq(jiffies, qsnt_timeout)) {
+			/* Other functions did not ack, changing state to
+			 * DEV_READY
+			 */
+			clear_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+							QLA82XX_DEV_READY);
+			qla4_8xxx_clear_qsnt_ready(ha);
+			ql4_info(ha, "Timeout waiting for quiescent ack!!!\n");
+			return;
+		}
+		qla4_8xxx_idc_unlock(ha);
+		msleep(1000);
+		qla4_8xxx_idc_lock(ha);
+
+		drv_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_STATE);
+		drv_active = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);
+		/* drv_state is drv_active << 1 */
+		drv_active = drv_active << 1;
+	}
+
+	/* All functions have set the quiescent state */
+	clear_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags);
+	set_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags);
+	dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+
+	if (dev_state == QLA82XX_DEV_NEED_QUIESCENT) {
+		DEBUG2(ql4_info(ha, "%s: Set HW state to DEV_QUIESCENT "
+			"ha->flags=0x%lx ha->dpc_flags=0x%lx\n",
+			__func__, ha->flags, ha->dpc_flags));
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE, QLA82XX_DEV_QUIESCENT);
+		/* Ioctl checks DPC_QUIESCE_ACTIVE flag to see if qsnt mode
+		 * was set
+		 */
+	}
+}
+
+/**
+ * qla4_8xxx_device_state_handler - Adapter state machine
+ * @ha: pointer to host adapter structure.
+ *
+ * Note: IDC lock must be UNLOCKED upon entry
+ **/
+int qla4_8xxx_device_state_handler(struct scsi_qla_host *ha)
+{
+	uint32_t dev_state = 0;
+	int rval = QLA_SUCCESS;
+	unsigned long dev_init_timeout;
+
+	if (!test_bit(AF_INIT_DONE, &ha->flags)) {
+		qla4_8xxx_idc_lock(ha);
+		qla4_8xxx_set_drv_active(ha);
+		qla4_8xxx_idc_unlock(ha);
+	}
+
+	dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+	DEBUG2(ql4_info(ha, "Device state is 0x%x = %s\n", dev_state,
+		dev_state < MAX_STATES ? qdev_state[dev_state] : "Unknown"));
+
+	/* wait for 30 seconds for device to go ready */
+	dev_init_timeout = jiffies + (ha->nx_dev_init_timeout * HZ);
+
+	qla4_8xxx_idc_lock(ha);
+
+	while (1) {
+
+		if (time_after_eq(jiffies, dev_init_timeout)) {
+			ql4_warn(ha, "%s: Device Init Failed 0x%x ="
+				"%s\n", DRIVER_NAME, dev_state,
+				dev_state < MAX_STATES ?
+				qdev_state[dev_state] : "Unknown");
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+				QLA82XX_DEV_FAILED);
+		}
+
+		dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+		ql4_info(ha, "Device state is 0x%x = %s\n", dev_state,
+		    dev_state < MAX_STATES ? qdev_state[dev_state] : "Unknown");
+
+		/* NOTE: Make sure idc unlocked upon exit of switch statement */
+		switch (dev_state) {
+		case QLA82XX_DEV_READY:
+			goto exit;
+		case QLA82XX_DEV_COLD:
+			rval = qla4_8xxx_device_bootstrap(ha);
+			goto exit;
+		case QLA82XX_DEV_INITIALIZING:
+			qla4_8xxx_idc_unlock(ha);
+			msleep(1000);
+			qla4_8xxx_idc_lock(ha);
+			break;
+		case QLA82XX_DEV_NEED_RESET:
+			if (!ql4xdontresethba)
+				qla4_8xxx_need_reset_handler(ha);
+			else {
+				qla4_8xxx_idc_unlock(ha);
+				msleep(1000);
+				qla4_8xxx_idc_lock(ha);
+			}
+			/* Reset dev init timeout */
+			dev_init_timeout = jiffies +
+                                        (ha->nx_dev_init_timeout * HZ);
+			break;
+		case QLA82XX_DEV_NEED_QUIESCENT:
+			/* idc locked/unlocked in handler */
+			qla4_8xxx_need_qsnt_handler(ha);
+
+			/* Reset the init timeout after qsnt handler */
+			dev_init_timeout = jiffies +
+					   (ha->nx_dev_init_timeout * HZ);
+			break;
+		case QLA82XX_DEV_QUIESCENT:
+			/* Quiesce_owner will exit, other functions will wait
+			 * for device state to change to quiescent
+			 */
+			qla4_8xxx_idc_unlock(ha);
+			if (test_bit(AF_QUIESCE_OWNER, &ha->flags))
+				goto exit;
+
+			DEBUG2(ql4_dbg(ha, "%s: quiescent.. sleep\n",
+					__func__));
+			msleep(1000);
+			qla4_8xxx_idc_lock(ha);
+
+			/* Reset the init timeout after qsnt handler */
+			dev_init_timeout = jiffies +
+					   (ha->nx_dev_init_timeout * HZ);
+			break;
+		case QLA82XX_DEV_FAILED:
+			qla4_8xxx_idc_unlock(ha);
+			qla4xxx_dead_adapter_cleanup(ha);
+			rval = QLA_ERROR;
+			qla4_8xxx_idc_lock(ha);
+			goto exit;
+		default:
+			ql4_info(ha, "%s: Unknown Device State: %x\n",
+				 __func__, dev_state);
+			qla4_8xxx_idc_unlock(ha);
+			qla4xxx_dead_adapter_cleanup(ha);
+			rval = QLA_ERROR;
+			qla4_8xxx_idc_lock(ha);
+			goto exit;
+		}
+	}
+exit:
+	qla4_8xxx_idc_unlock(ha);
+	return rval;
+}
+
+int qla4_8xxx_load_risc(struct scsi_qla_host *ha)
+{
+	int retval;
+
+	/* clear the interrupt */
+	writel(0, &ha->qla4_8xxx_reg->host_int);
+	readl(&ha->qla4_8xxx_reg->host_int);
+
+	retval = qla4_8xxx_device_state_handler(ha);
+
+	if (retval == QLA_SUCCESS && !test_bit(AF_INIT_DONE, &ha->flags))
+		retval = qla4xxx_request_irqs(ha);
+
+	return retval;
+}
+
+/*****************************************************************************/
+/* Flash Manipulation Routines                                               */
+/*****************************************************************************/
+
+#define OPTROM_BURST_SIZE       0x1000
+#define OPTROM_BURST_DWORDS     (OPTROM_BURST_SIZE / 4)
+
+#define FARX_DATA_FLAG	BIT_31
+#define FARX_ACCESS_FLASH_CONF	0x7FFD0000
+#define FARX_ACCESS_FLASH_DATA	0x7FF00000
+
+static inline uint32_t
+flash_conf_addr(struct ql82xx_hw_data *hw, uint32_t faddr)
+{
+	return hw->flash_conf_off | faddr;
+}
+
+static inline uint32_t
+flash_data_addr(struct ql82xx_hw_data *hw, uint32_t faddr)
+{
+	return hw->flash_data_off | faddr;
+}
+
+static uint32_t *
+qla4_8xxx_read_flash_data(struct scsi_qla_host *ha, uint32_t *dwptr,
+    uint32_t faddr, uint32_t length)
+{
+	uint32_t i;
+	uint32_t val;
+	int loops = 0;
+	while ((qla4_8xxx_rom_lock(ha) != 0) && (loops < 50000)) {
+		udelay(100);
+		cond_resched();
+		loops++;
+	}
+	if (loops >= 50000) {
+		ql4_warn(ha, "ROM lock failed\n");
+		return dwptr;
+	}
+
+	/* Dword reads to flash. */
+	for (i = 0; i < length/4; i++, faddr += 4) {
+		if (qla4_8xxx_do_rom_fast_read(ha, faddr, &val)) {
+			ql4_warn(ha, "Do ROM fast read failed\n");
+			goto done_read;
+		}
+		dwptr[i] = __constant_cpu_to_le32(val);
+	}
+
+done_read:
+	qla4_8xxx_rom_unlock(ha);
+	return dwptr;
+}
+
+/**
+ * Address and length are byte address
+ **/
+static uint8_t *
+qla4_8xxx_read_optrom_data(struct scsi_qla_host *ha, uint8_t *buf,
+		uint32_t offset, uint32_t length)
+{
+	qla4_8xxx_read_flash_data(ha, (uint32_t *)buf, offset, length);
+	return buf;
+}
+
+static int
+qla4_8xxx_find_flt_start(struct scsi_qla_host *ha, uint32_t *start)
+{
+	const char *loc, *locations[] = { "DEF", "PCI" };
+
+	/*
+	 * FLT-location structure resides after the last PCI region.
+	 */
+
+	/* Begin with sane defaults. */
+	loc = locations[0];
+	*start = FA_FLASH_LAYOUT_ADDR_82;
+
+	DEBUG2(ql4_info(ha, "FLTL[%s] = 0x%x.\n", loc, *start));
+	return QLA_SUCCESS;
+}
+
+static void
+qla4_8xxx_get_flt_info(struct scsi_qla_host *ha, uint32_t flt_addr)
+{
+	const char *loc, *locations[] = { "DEF", "FLT" };
+	uint16_t *wptr;
+	uint16_t cnt, chksum;
+	uint32_t start;
+	struct qla_flt_header *flt;
+	struct qla_flt_region *region;
+	struct ql82xx_hw_data *hw = &ha->hw;
+
+	hw->flt_region_flt = flt_addr;
+	wptr = (uint16_t *)ha->request_ring;
+	flt = (struct qla_flt_header *)ha->request_ring;
+	region = (struct qla_flt_region *)&flt[1];
+	qla4_8xxx_read_optrom_data(ha, (uint8_t *)ha->request_ring,
+			flt_addr << 2, OPTROM_BURST_SIZE);
+	if (*wptr == __constant_cpu_to_le16(0xffff))
+		goto no_flash_data;
+	if (flt->version != __constant_cpu_to_le16(1)) {
+		DEBUG2(ql4_info(ha, "Unsupported FLT detected: "
+			"version=0x%x length=0x%x checksum=0x%x.\n",
+			le16_to_cpu(flt->version), le16_to_cpu(flt->length),
+			le16_to_cpu(flt->checksum)));
+		goto no_flash_data;
+	}
+
+	cnt = (sizeof(struct qla_flt_header) + le16_to_cpu(flt->length)) >> 1;
+	for (chksum = 0; cnt; cnt--)
+		chksum += le16_to_cpu(*wptr++);
+	if (chksum) {
+		DEBUG2(ql4_info(ha, "Inconsistent FLT detected: "
+			"version=0x%x length=0x%x checksum=0x%x.\n",
+			le16_to_cpu(flt->version), le16_to_cpu(flt->length),
+			chksum));
+		goto no_flash_data;
+	}
+
+	loc = locations[1];
+	cnt = le16_to_cpu(flt->length) / sizeof(struct qla_flt_region);
+	for ( ; cnt; cnt--, region++) {
+		/* Store addresses as DWORD offsets. */
+		start = le32_to_cpu(region->start) >> 2;
+
+		DEBUG3(ql4_debug(ha, "FLT[%02x]: start=0x%x "
+		    "end=0x%x size=0x%x.\n", le32_to_cpu(region->code), start,
+		    le32_to_cpu(region->end) >> 2, le32_to_cpu(region->size)));
+
+		switch (le32_to_cpu(region->code) & 0xff) {
+		case FLT_REG_FDT:
+			hw->flt_region_fdt = start;
+			break;
+		case FLT_REG_BOOT_CODE_82:
+			hw->flt_region_boot = start;
+			break;
+		case FLT_REG_FW_82:
+		case FLT_REG_FW_82_1:
+			hw->flt_region_fw = start;
+			break;
+		case FLT_REG_BOOTLOAD_82:
+			hw->flt_region_bootload = start;
+			break;
+		}
+	}
+	goto done;
+
+no_flash_data:
+	/* Use hardcoded defaults. */
+	loc = locations[0];
+
+	hw->flt_region_fdt      = FA_FLASH_DESCR_ADDR_82;
+	hw->flt_region_boot     = FA_BOOT_CODE_ADDR_82;
+	hw->flt_region_bootload = FA_BOOT_LOAD_ADDR_82;
+	hw->flt_region_fw       = FA_RISC_CODE_ADDR_82;
+done:
+	DEBUG2(ql4_info(ha, "FLT[%s]: flt=0x%x fdt=0x%x "
+	    "boot=0x%x bootload=0x%x fw=0x%x\n", loc, hw->flt_region_flt,
+	    hw->flt_region_fdt,	hw->flt_region_boot, hw->flt_region_bootload,
+	    hw->flt_region_fw));
+}
+
+static void
+qla4_8xxx_get_fdt_info(struct scsi_qla_host *ha)
+{
+#define FLASH_BLK_SIZE_4K       0x1000
+#define FLASH_BLK_SIZE_32K      0x8000
+#define FLASH_BLK_SIZE_64K      0x10000
+	const char *loc, *locations[] = { "MID", "FDT" };
+	uint16_t cnt, chksum;
+	uint16_t *wptr;
+	struct qla_fdt_layout *fdt;
+	uint16_t mid = 0;
+	uint16_t fid = 0;
+	struct ql82xx_hw_data *hw = &ha->hw;
+
+	hw->flash_conf_off = FARX_ACCESS_FLASH_CONF;
+	hw->flash_data_off = FARX_ACCESS_FLASH_DATA;
+
+	wptr = (uint16_t *)ha->request_ring;
+	fdt = (struct qla_fdt_layout *)ha->request_ring;
+	qla4_8xxx_read_optrom_data(ha, (uint8_t *)ha->request_ring,
+	    hw->flt_region_fdt << 2, OPTROM_BURST_SIZE);
+
+	if (*wptr == __constant_cpu_to_le16(0xffff))
+		goto no_flash_data;
+
+	if (fdt->sig[0] != 'Q' || fdt->sig[1] != 'L' || fdt->sig[2] != 'I' ||
+	    fdt->sig[3] != 'D')
+		goto no_flash_data;
+
+	for (cnt = 0, chksum = 0; cnt < sizeof(struct qla_fdt_layout) >> 1;
+	    cnt++)
+		chksum += le16_to_cpu(*wptr++);
+
+	if (chksum) {
+		DEBUG2(ql4_info(ha, "Inconsistent FDT detected: "
+		    "checksum=0x%x id=%c version=0x%x.\n", chksum, fdt->sig[0],
+		    le16_to_cpu(fdt->version)));
+		goto no_flash_data;
+	}
+
+	loc = locations[1];
+	mid = le16_to_cpu(fdt->man_id);
+	fid = le16_to_cpu(fdt->id);
+	hw->fdt_wrt_disable = fdt->wrt_disable_bits;
+	hw->fdt_erase_cmd = flash_conf_addr(hw, 0x0300 | fdt->erase_cmd);
+	hw->fdt_block_size = le32_to_cpu(fdt->block_size);
+
+	if (fdt->unprotect_sec_cmd) {
+		hw->fdt_unprotect_sec_cmd = flash_conf_addr(hw, 0x0300 |
+		    fdt->unprotect_sec_cmd);
+		hw->fdt_protect_sec_cmd = fdt->protect_sec_cmd ?
+		    flash_conf_addr(hw, 0x0300 | fdt->protect_sec_cmd) :
+		    flash_conf_addr(hw, 0x0336);
+	}
+	goto done;
+
+no_flash_data:
+	loc = locations[0];
+	hw->fdt_block_size = FLASH_BLK_SIZE_64K;
+done:
+	DEBUG2(ql4_info(ha, "FDT[%s]: (0x%x/0x%x) erase=0x%x "
+		"pro=%x upro=%x wrtd=0x%x blk=0x%x.\n", loc, mid, fid,
+		hw->fdt_erase_cmd, hw->fdt_protect_sec_cmd,
+		hw->fdt_unprotect_sec_cmd, hw->fdt_wrt_disable,
+		hw->fdt_block_size));
+}
+
+static void
+qla4_8xxx_get_idc_param(struct scsi_qla_host *ha)
+{
+#define QLA82XX_IDC_PARAM_ADDR      0x003e885c
+	uint32_t *wptr;
+
+	if (!is_qla8022(ha))
+		return;
+	wptr = (uint32_t *)ha->request_ring;
+	qla4_8xxx_read_optrom_data(ha, (uint8_t *)ha->request_ring,
+			QLA82XX_IDC_PARAM_ADDR , 8);
+
+	if (*wptr == __constant_cpu_to_le32(0xffffffff)) {
+		ha->nx_dev_init_timeout = ROM_DEV_INIT_TIMEOUT;
+		ha->nx_reset_timeout = ROM_DRV_RESET_ACK_TIMEOUT;
+	} else {
+		ha->nx_dev_init_timeout = le32_to_cpu(*wptr++);
+		ha->nx_reset_timeout = le32_to_cpu(*wptr);
+	}
+
+	DEBUG2(ql4_info(ha, "ha->nx_dev_init_timeout = %d\n",
+			 ha->nx_dev_init_timeout));
+	DEBUG2(ql4_info(ha, "ha->nx_reset_timeout = %d\n",
+			 ha->nx_reset_timeout));
+	return;
+}
+
+int
+qla4_8xxx_get_flash_info(struct scsi_qla_host *ha)
+{
+	int ret;
+	uint32_t flt_addr;
+
+	ret = qla4_8xxx_find_flt_start(ha, &flt_addr);
+	if (ret != QLA_SUCCESS)
+		return ret;
+
+	qla4_8xxx_get_flt_info(ha, flt_addr);
+	qla4_8xxx_get_fdt_info(ha);
+	qla4_8xxx_get_idc_param(ha);
+
+	return QLA_SUCCESS;
+}
+
+/**
+ * qla4_8xxx_stop_firmware - stops firmware on specified adapter instance
+ * @ha: pointer to host adapter structure.
+ *
+ * Remarks:
+ * For iSCSI, throws away all I/O and AENs into bit bucket, so they will
+ * not be available after successful return.  Driver must cleanup potential
+ * outstanding I/O's after calling this funcion.
+ **/
+int
+qla4_8xxx_stop_firmware(struct scsi_qla_host *ha)
+{
+	int status;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_STOP_FW;
+	status = qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1,
+	    &mbox_cmd[0], &mbox_sts[0]);
+
+	DEBUG2(ql4_info(ha, "%s: status = %d\n", __func__, status));
+	return status;
+}
+
+/**
+ * qla4_8xxx_isp_reset - Resets ISP and aborts all outstanding commands.
+ * @ha: pointer to host adapter structure.
+ **/
+int
+qla4_8xxx_isp_reset(struct scsi_qla_host *ha)
+{
+	int rval;
+	uint32_t dev_state;
+
+	qla4_8xxx_idc_lock(ha);
+	dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+
+	if (dev_state == QLA82XX_DEV_READY) {
+		DEBUG2(ql4_info(ha, "HW State: NEED RESET\n"));
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+		    QLA82XX_DEV_NEED_RESET);
+		set_bit(AF_82XX_RST_OWNER, &ha->flags);
+	} else
+		DEBUG2(ql4_info(ha, "HW State: 0x%d\n", dev_state));
+
+	qla4_8xxx_idc_unlock(ha);
+
+	rval = qla4_8xxx_device_state_handler(ha);
+
+	qla4_8xxx_idc_lock(ha);
+	qla4_8xxx_clear_rst_ready(ha);
+	qla4_8xxx_idc_unlock(ha);
+
+	if (rval == QLA_SUCCESS) {
+		
+		ql4_info(ha, "Clearing AF_RECOVERY in qla4_8xxx_isp_reset\n");
+
+		clear_bit(AF_FW_RECOVERY, &ha->flags);
+	}
+
+	return rval;
+}
+
+/**
+ * qla4_8xxx_get_sys_info - get adapter MAC address(es) and serial number
+ * @ha: pointer to host adapter structure.
+ *
+ **/
+void qla4_8xxx_get_sys_info(struct scsi_qla_host *ha)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct mbx_sys_info *sys_info;
+	dma_addr_t sys_info_dma;
+
+	sys_info = dma_alloc_coherent(&ha->pdev->dev, sizeof(*sys_info),
+				      &sys_info_dma, GFP_KERNEL);
+	if (sys_info == NULL) {
+		DEBUG2(ql4_info(ha, "%s: Unable to allocate dma buffer.\n",
+				__func__));
+		goto exit_get_sys_info;
+	}
+
+	memset(sys_info, 0, sizeof(*sys_info));
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_SYS_INFO;
+	mbox_cmd[1] = LSDW(sys_info_dma);
+	mbox_cmd[2] = MSDW(sys_info_dma);
+	mbox_cmd[4] = sizeof(*sys_info);
+
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 6, &mbox_cmd[0],
+	    &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: GET_SYS_INFO failed\n", __func__));
+		goto exit_validate_mac82;
+	}
+
+	/* Make sure we receive the minimum required data to cache internally */
+	if (mbox_sts[4] < offsetof(struct mbx_sys_info, reserved)) {
+		DEBUG2(ql4_info(ha, "%s: GET_SYS_INFO data receive"
+		    " error (%x)\n", __func__, mbox_sts[4]));
+		goto exit_validate_mac82;
+	}
+
+	/* Save M.A.C. address & serial_number */
+	memcpy(ha->my_mac, &sys_info->mac_addr[0],
+	    min(sizeof(ha->my_mac), sizeof(sys_info->mac_addr)));
+	memcpy(ha->serial_number, &sys_info->serial_number,
+	    min(sizeof(ha->serial_number), sizeof(sys_info->serial_number)));
+
+exit_validate_mac82:
+	dma_free_coherent(&ha->pdev->dev, sizeof(*sys_info), sys_info,
+			  sys_info_dma);
+exit_get_sys_info:
+	DEBUG2(ql4_info(ha, "%s: mac %02x:%02x:%02x:%02x:%02x:%02x "
+	    "serial %s\n", __func__, ha->my_mac[0], ha->my_mac[1],
+	    ha->my_mac[2], ha->my_mac[3], ha->my_mac[4], ha->my_mac[5],
+	    ha->serial_number));
+
+	return;
+}
+
+/* Interrupt handling helpers. */
+
+static int
+qla4_8xxx_mbx_intr_enable(struct scsi_qla_host *ha)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+
+	DEBUG2(ql4_info(ha, "%s\n", __func__));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_ENABLE_INTRS;
+	mbox_cmd[1] = INTR_ENABLE;
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0],
+		&mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_ENABLE_INTRS failed "
+				"(0x%04x)\n", __func__, mbox_sts[0]));
+		return QLA_ERROR;
+	}
+	return QLA_SUCCESS;
+}
+
+static int
+qla4_8xxx_mbx_intr_disable(struct scsi_qla_host *ha)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+
+	DEBUG2(ql4_info(ha, "%s\n", __func__));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_ENABLE_INTRS;
+	mbox_cmd[1] = INTR_DISABLE;
+	if (qla4xxx_mailbox_command(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0],
+	    &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_ENABLE_INTRS failed "
+				"(0x%04x)\n", __func__, mbox_sts[0]));
+		return QLA_ERROR;
+	}
+
+	return QLA_SUCCESS;
+}
+
+void
+qla4_8xxx_enable_intrs(struct scsi_qla_host *ha)
+{
+	qla4_8xxx_mbx_intr_enable(ha);
+
+	spin_lock_irq(&ha->hardware_lock);
+	/* BIT 10 - reset */
+	qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_mask_reg, 0xfbff);
+	spin_unlock_irq(&ha->hardware_lock);
+	set_bit(AF_INTERRUPTS_ON, &ha->flags);
+}
+
+void
+qla4_8xxx_disable_intrs(struct scsi_qla_host *ha)
+{
+	if (test_and_clear_bit(AF_INTERRUPTS_ON, &ha->flags))
+		qla4_8xxx_mbx_intr_disable(ha);
+
+	spin_lock_irq(&ha->hardware_lock);
+	/* BIT 10 - set */
+	qla4_8xxx_wr_32(ha, ha->nx_legacy_intr.tgt_mask_reg, 0x0400);
+	spin_unlock_irq(&ha->hardware_lock);
+}
+
+struct ql4_init_msix_entry {
+	uint16_t entry;
+	uint16_t index;
+	const char *name;
+	irq_handler_t handler;
+};
+
+static struct ql4_init_msix_entry qla4_8xxx_msix_entries[QLA_MSIX_ENTRIES] = {
+	{ QLA_MSIX_DEFAULT, QLA_MIDX_DEFAULT,
+	    "qla4xxx (default)",
+	    (irq_handler_t)qla4_8xxx_default_intr_handler },
+	{ QLA_MSIX_RSP_Q, QLA_MIDX_RSP_Q,
+	    "qla4xxx (rsp_q)", (irq_handler_t)qla4_8xxx_msix_rsp_q },
+};
+
+void
+qla4_8xxx_disable_msix(struct scsi_qla_host *ha)
+{
+	int i;
+	struct ql4_msix_entry *qentry;
+
+	for (i = 0; i < QLA_MSIX_ENTRIES; i++) {
+		qentry = &ha->msix_entries[qla4_8xxx_msix_entries[i].index];
+		if (qentry->have_irq) {
+			free_irq(qentry->msix_vector, ha);
+			DEBUG2(ql4_info(ha, "%s: %s\n", __func__,
+					qla4_8xxx_msix_entries[i].name));
+		}
+	}
+	pci_disable_msix(ha->pdev);
+	clear_bit(AF_MSIX_ENABLED, &ha->flags);
+}
+
+int
+qla4_8xxx_enable_msix(struct scsi_qla_host *ha)
+{
+	int i, ret;
+	struct msix_entry entries[QLA_MSIX_ENTRIES];
+	struct ql4_msix_entry *qentry;
+
+	for (i = 0; i < QLA_MSIX_ENTRIES; i++)
+		entries[i].entry = qla4_8xxx_msix_entries[i].entry;
+
+	ret = pci_enable_msix(ha->pdev, entries, ARRAY_SIZE(entries));
+	if (ret) {
+		ql4_info(ha, "MSI-X: Failed to enable support -- %d/%d\n",
+			 QLA_MSIX_ENTRIES, ret);
+		goto msix_out;
+	}
+	set_bit(AF_MSIX_ENABLED, &ha->flags);
+
+	for (i = 0; i < QLA_MSIX_ENTRIES; i++) {
+		qentry = &ha->msix_entries[qla4_8xxx_msix_entries[i].index];
+		qentry->msix_vector = entries[i].vector;
+		qentry->msix_entry = entries[i].entry;
+		qentry->have_irq = 0;
+		ret = request_irq(qentry->msix_vector,
+		    qla4_8xxx_msix_entries[i].handler, 0,
+		    qla4_8xxx_msix_entries[i].name, ha);
+		if (ret) {
+			ql4_warn(ha, "MSI-X: Unable to register handler -- "
+				 "%x/%d.\n", qla4_8xxx_msix_entries[i].index,
+				 ret);
+			qla4_8xxx_disable_msix(ha);
+			goto msix_out;
+		}
+		qentry->have_irq = 1;
+		DEBUG2(ql4_info(ha, "%s: %s\n", __func__,
+				qla4_8xxx_msix_entries[i].name));
+	}
+msix_out:
+	return ret;
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_nx.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4_nx.h
@@ -0,0 +1,1080 @@
+/*
+ * QLogic Fibre Channel HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla2xxx for copyright and licensing details.
+ */
+#ifndef __QLA_NX_H
+#define __QLA_NX_H
+
+/*
+ * Following are the states of the Phantom. Phantom will set them and
+ * Host will read to check if the fields are correct.
+*/
+#define PHAN_INITIALIZE_FAILED		0xffff
+#define PHAN_INITIALIZE_COMPLETE	0xff01
+
+/* Host writes the following to notify that it has done the init-handshake */
+#define PHAN_INITIALIZE_ACK		0xf00f
+#define PHAN_PEG_RCV_INITIALIZED	0xff01
+
+/*CRB_RELATED*/
+#define QLA82XX_CRB_BASE	QLA82XX_CAM_RAM(0x200)
+#define QLA82XX_REG(X)		(QLA82XX_CRB_BASE+(X))
+#define CRB_TEMP_STATE		(QLA82XX_REG(0x1b4))
+
+#define qla82xx_get_temp_val(x)		((x) >> 16)
+#define qla82xx_get_temp_state(x)	((x) & 0xffff)
+
+/*
+ * Temperature control.
+ */
+enum {
+	QLA82XX_TEMP_NORMAL = 0x1,      /* Normal operating range */
+	QLA82XX_TEMP_WARN,      	/* Sound alert, temperature getting high */
+	QLA82XX_TEMP_PANIC      	/* Fatal error, hardware has shut down. */
+};
+
+#define CRB_NIU_XG_PAUSE_CTL_P0		0x1
+#define CRB_NIU_XG_PAUSE_CTL_P1		0x8
+
+#define CRB_CMDPEG_STATE		QLA82XX_REG(0x50)
+#define CRB_RCVPEG_STATE		QLA82XX_REG(0x13c)
+#define CRB_DMA_SHIFT			QLA82XX_REG(0xcc)
+
+#define QLA82XX_HW_H0_CH_HUB_ADR	0x05
+#define QLA82XX_HW_H1_CH_HUB_ADR	0x0E
+#define QLA82XX_HW_H2_CH_HUB_ADR	0x03
+#define QLA82XX_HW_H3_CH_HUB_ADR	0x01
+#define QLA82XX_HW_H4_CH_HUB_ADR	0x06
+#define QLA82XX_HW_H5_CH_HUB_ADR	0x07
+#define QLA82XX_HW_H6_CH_HUB_ADR	0x08
+
+/*  Hub 0 */
+#define QLA82XX_HW_MN_CRB_AGT_ADR	0x15
+#define QLA82XX_HW_MS_CRB_AGT_ADR	0x25
+
+/*  Hub 1 */
+#define QLA82XX_HW_PS_CRB_AGT_ADR	0x73
+#define QLA82XX_HW_QMS_CRB_AGT_ADR	0x00
+#define QLA82XX_HW_RPMX3_CRB_AGT_ADR	0x0b
+#define QLA82XX_HW_SQGS0_CRB_AGT_ADR	0x01
+#define QLA82XX_HW_SQGS1_CRB_AGT_ADR	0x02
+#define QLA82XX_HW_SQGS2_CRB_AGT_ADR	0x03
+#define QLA82XX_HW_SQGS3_CRB_AGT_ADR	0x04
+#define QLA82XX_HW_C2C0_CRB_AGT_ADR	0x58
+#define QLA82XX_HW_C2C1_CRB_AGT_ADR	0x59
+#define QLA82XX_HW_C2C2_CRB_AGT_ADR	0x5a
+#define QLA82XX_HW_RPMX2_CRB_AGT_ADR	0x0a
+#define QLA82XX_HW_RPMX4_CRB_AGT_ADR	0x0c
+#define QLA82XX_HW_RPMX7_CRB_AGT_ADR	0x0f
+#define QLA82XX_HW_RPMX9_CRB_AGT_ADR	0x12
+#define QLA82XX_HW_SMB_CRB_AGT_ADR	0x18
+
+/*  Hub 2 */
+#define QLA82XX_HW_NIU_CRB_AGT_ADR	0x31
+#define QLA82XX_HW_I2C0_CRB_AGT_ADR	0x19
+#define QLA82XX_HW_I2C1_CRB_AGT_ADR	0x29
+
+#define QLA82XX_HW_SN_CRB_AGT_ADR	0x10
+#define QLA82XX_HW_I2Q_CRB_AGT_ADR	0x20
+#define QLA82XX_HW_LPC_CRB_AGT_ADR	0x22
+#define QLA82XX_HW_ROMUSB_CRB_AGT_ADR   0x21
+#define QLA82XX_HW_QM_CRB_AGT_ADR	0x66
+#define QLA82XX_HW_SQG0_CRB_AGT_ADR	0x60
+#define QLA82XX_HW_SQG1_CRB_AGT_ADR	0x61
+#define QLA82XX_HW_SQG2_CRB_AGT_ADR	0x62
+#define QLA82XX_HW_SQG3_CRB_AGT_ADR	0x63
+#define QLA82XX_HW_RPMX1_CRB_AGT_ADR    0x09
+#define QLA82XX_HW_RPMX5_CRB_AGT_ADR    0x0d
+#define QLA82XX_HW_RPMX6_CRB_AGT_ADR    0x0e
+#define QLA82XX_HW_RPMX8_CRB_AGT_ADR    0x11
+
+/*  Hub 3 */
+#define QLA82XX_HW_PH_CRB_AGT_ADR	0x1A
+#define QLA82XX_HW_SRE_CRB_AGT_ADR	0x50
+#define QLA82XX_HW_EG_CRB_AGT_ADR	0x51
+#define QLA82XX_HW_RPMX0_CRB_AGT_ADR	0x08
+
+/*  Hub 4 */
+#define QLA82XX_HW_PEGN0_CRB_AGT_ADR	0x40
+#define QLA82XX_HW_PEGN1_CRB_AGT_ADR	0x41
+#define QLA82XX_HW_PEGN2_CRB_AGT_ADR	0x42
+#define QLA82XX_HW_PEGN3_CRB_AGT_ADR	0x43
+#define QLA82XX_HW_PEGNI_CRB_AGT_ADR	0x44
+#define QLA82XX_HW_PEGND_CRB_AGT_ADR	0x45
+#define QLA82XX_HW_PEGNC_CRB_AGT_ADR	0x46
+#define QLA82XX_HW_PEGR0_CRB_AGT_ADR	0x47
+#define QLA82XX_HW_PEGR1_CRB_AGT_ADR	0x48
+#define QLA82XX_HW_PEGR2_CRB_AGT_ADR	0x49
+#define QLA82XX_HW_PEGR3_CRB_AGT_ADR	0x4a
+#define QLA82XX_HW_PEGN4_CRB_AGT_ADR	0x4b
+
+/*  Hub 5 */
+#define QLA82XX_HW_PEGS0_CRB_AGT_ADR	0x40
+#define QLA82XX_HW_PEGS1_CRB_AGT_ADR	0x41
+#define QLA82XX_HW_PEGS2_CRB_AGT_ADR	0x42
+#define QLA82XX_HW_PEGS3_CRB_AGT_ADR	0x43
+
+#define QLA82XX_HW_PEGSI_CRB_AGT_ADR	0x44
+#define QLA82XX_HW_PEGSD_CRB_AGT_ADR	0x45
+#define QLA82XX_HW_PEGSC_CRB_AGT_ADR	0x46
+
+/*  Hub 6 */
+#define QLA82XX_HW_CAS0_CRB_AGT_ADR	0x46
+#define QLA82XX_HW_CAS1_CRB_AGT_ADR	0x47
+#define QLA82XX_HW_CAS2_CRB_AGT_ADR	0x48
+#define QLA82XX_HW_CAS3_CRB_AGT_ADR	0x49
+#define QLA82XX_HW_NCM_CRB_AGT_ADR	0x16
+#define QLA82XX_HW_TMR_CRB_AGT_ADR	0x17
+#define QLA82XX_HW_XDMA_CRB_AGT_ADR	0x05
+#define QLA82XX_HW_OCM0_CRB_AGT_ADR	0x06
+#define QLA82XX_HW_OCM1_CRB_AGT_ADR	0x07
+
+/*  This field defines PCI/X adr [25:20] of agents on the CRB */
+/*  */
+#define QLA82XX_HW_PX_MAP_CRB_PH	0
+#define QLA82XX_HW_PX_MAP_CRB_PS	1
+#define QLA82XX_HW_PX_MAP_CRB_MN	2
+#define QLA82XX_HW_PX_MAP_CRB_MS	3
+#define QLA82XX_HW_PX_MAP_CRB_SRE	5
+#define QLA82XX_HW_PX_MAP_CRB_NIU	6
+#define QLA82XX_HW_PX_MAP_CRB_QMN	7
+#define QLA82XX_HW_PX_MAP_CRB_SQN0	8
+#define QLA82XX_HW_PX_MAP_CRB_SQN1	9
+#define QLA82XX_HW_PX_MAP_CRB_SQN2	10
+#define QLA82XX_HW_PX_MAP_CRB_SQN3	11
+#define QLA82XX_HW_PX_MAP_CRB_QMS	12
+#define QLA82XX_HW_PX_MAP_CRB_SQS0	13
+#define QLA82XX_HW_PX_MAP_CRB_SQS1	14
+#define QLA82XX_HW_PX_MAP_CRB_SQS2	15
+#define QLA82XX_HW_PX_MAP_CRB_SQS3	16
+#define QLA82XX_HW_PX_MAP_CRB_PGN0	17
+#define QLA82XX_HW_PX_MAP_CRB_PGN1	18
+#define QLA82XX_HW_PX_MAP_CRB_PGN2	19
+#define QLA82XX_HW_PX_MAP_CRB_PGN3	20
+#define QLA82XX_HW_PX_MAP_CRB_PGN4	QLA82XX_HW_PX_MAP_CRB_SQS2
+#define QLA82XX_HW_PX_MAP_CRB_PGND	21
+#define QLA82XX_HW_PX_MAP_CRB_PGNI	22
+#define QLA82XX_HW_PX_MAP_CRB_PGS0	23
+#define QLA82XX_HW_PX_MAP_CRB_PGS1	24
+#define QLA82XX_HW_PX_MAP_CRB_PGS2	25
+#define QLA82XX_HW_PX_MAP_CRB_PGS3	26
+#define QLA82XX_HW_PX_MAP_CRB_PGSD	27
+#define QLA82XX_HW_PX_MAP_CRB_PGSI	28
+#define QLA82XX_HW_PX_MAP_CRB_SN	29
+#define QLA82XX_HW_PX_MAP_CRB_EG	31
+#define QLA82XX_HW_PX_MAP_CRB_PH2	32
+#define QLA82XX_HW_PX_MAP_CRB_PS2	33
+#define QLA82XX_HW_PX_MAP_CRB_CAM	34
+#define QLA82XX_HW_PX_MAP_CRB_CAS0	35
+#define QLA82XX_HW_PX_MAP_CRB_CAS1	36
+#define QLA82XX_HW_PX_MAP_CRB_CAS2	37
+#define QLA82XX_HW_PX_MAP_CRB_C2C0	38
+#define QLA82XX_HW_PX_MAP_CRB_C2C1	39
+#define QLA82XX_HW_PX_MAP_CRB_TIMR	40
+#define QLA82XX_HW_PX_MAP_CRB_RPMX1	42
+#define QLA82XX_HW_PX_MAP_CRB_RPMX2	43
+#define QLA82XX_HW_PX_MAP_CRB_RPMX3	44
+#define QLA82XX_HW_PX_MAP_CRB_RPMX4	45
+#define QLA82XX_HW_PX_MAP_CRB_RPMX5	46
+#define QLA82XX_HW_PX_MAP_CRB_RPMX6	47
+#define QLA82XX_HW_PX_MAP_CRB_RPMX7	48
+#define QLA82XX_HW_PX_MAP_CRB_XDMA	49
+#define QLA82XX_HW_PX_MAP_CRB_I2Q	50
+#define QLA82XX_HW_PX_MAP_CRB_ROMUSB    51
+#define QLA82XX_HW_PX_MAP_CRB_CAS3	52
+#define QLA82XX_HW_PX_MAP_CRB_RPMX0	53
+#define QLA82XX_HW_PX_MAP_CRB_RPMX8	54
+#define QLA82XX_HW_PX_MAP_CRB_RPMX9	55
+#define QLA82XX_HW_PX_MAP_CRB_OCM0	56
+#define QLA82XX_HW_PX_MAP_CRB_OCM1	57
+#define QLA82XX_HW_PX_MAP_CRB_SMB	58
+#define QLA82XX_HW_PX_MAP_CRB_I2C0	59
+#define QLA82XX_HW_PX_MAP_CRB_I2C1	60
+#define QLA82XX_HW_PX_MAP_CRB_LPC	61
+#define QLA82XX_HW_PX_MAP_CRB_PGNC	62
+#define QLA82XX_HW_PX_MAP_CRB_PGR0	63
+#define QLA82XX_HW_PX_MAP_CRB_PGR1	4
+#define QLA82XX_HW_PX_MAP_CRB_PGR2	30
+#define QLA82XX_HW_PX_MAP_CRB_PGR3	41
+
+/*  This field defines CRB adr [31:20] of the agents */
+/*  */
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_MN	((QLA82XX_HW_H0_CH_HUB_ADR << 7) | \
+					QLA82XX_HW_MN_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PH	((QLA82XX_HW_H0_CH_HUB_ADR << 7) | \
+					QLA82XX_HW_PH_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_MS	((QLA82XX_HW_H0_CH_HUB_ADR << 7) | \
+					QLA82XX_HW_MS_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PS	((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					QLA82XX_HW_PS_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SS	((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					QLA82XX_HW_SS_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX3    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX3_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_QMS	    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_QMS_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQS0     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQGS0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQS1     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQGS1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQS2     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQGS2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQS3     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQGS3_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_C2C0     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_C2C0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_C2C1     ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_C2C1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX2    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX4    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX4_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX7    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX7_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX9    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX9_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SMB	    ((QLA82XX_HW_H1_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SMB_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_NIU      ((QLA82XX_HW_H2_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_NIU_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_I2C0     ((QLA82XX_HW_H2_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_I2C0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_I2C1     ((QLA82XX_HW_H2_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_I2C1_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SRE      ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SRE_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_EG       ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_EG_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX0    ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_QMN      ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_QM_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQN0     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQG0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQN1     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQG1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQN2     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQG2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SQN3     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SQG3_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX1    ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX5    ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX5_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX6    ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX6_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_RPMX8    ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_RPMX8_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_CAS0     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_CAS0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_CAS1     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_CAS1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_CAS2     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_CAS2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_CAS3     ((QLA82XX_HW_H3_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_CAS3_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGNI     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGNI_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGND     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGND_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGN0     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGN0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGN1     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGN1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGN2     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGN2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGN3     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGN3_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGN4     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGN4_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGNC     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGNC_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGR0     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGR0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGR1     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGR1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGR2     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGR2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGR3     ((QLA82XX_HW_H4_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGR3_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGSI     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGSI_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGSD     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGSD_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGS0     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGS0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGS1     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGS1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGS2     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGS2_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGS3     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGS3_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_PGSC     ((QLA82XX_HW_H5_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_PEGSC_CRB_AGT_ADR)
+
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_CAM      ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_NCM_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_TIMR     ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_TMR_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_XDMA     ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_XDMA_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_SN       ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_SN_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_I2Q      ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_I2Q_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_ROMUSB   ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_ROMUSB_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_OCM0     ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_OCM0_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_OCM1     ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_OCM1_CRB_AGT_ADR)
+#define QLA82XX_HW_CRB_HUB_AGT_ADR_LPC      ((QLA82XX_HW_H6_CH_HUB_ADR << 7) | \
+					    QLA82XX_HW_LPC_CRB_AGT_ADR)
+
+#define ROMUSB_GLB	(QLA82XX_CRB_ROMUSB + 0x00000)
+#define QLA82XX_ROMUSB_GLB_PEGTUNE_DONE		(ROMUSB_GLB + 0x005c)
+#define QLA82XX_ROMUSB_GLB_STATUS		(ROMUSB_GLB + 0x0004)
+#define QLA82XX_ROMUSB_GLB_SW_RESET		(ROMUSB_GLB + 0x0008)
+#define QLA82XX_ROMUSB_ROM_ADDRESS		(ROMUSB_ROM + 0x0008)
+#define QLA82XX_ROMUSB_ROM_WDATA		(ROMUSB_ROM + 0x000c)
+#define QLA82XX_ROMUSB_ROM_ABYTE_CNT		(ROMUSB_ROM + 0x0010)
+#define QLA82XX_ROMUSB_ROM_DUMMY_BYTE_CNT	(ROMUSB_ROM + 0x0014)
+#define QLA82XX_ROMUSB_ROM_RDATA		(ROMUSB_ROM + 0x0018)
+
+#define ROMUSB_ROM	(QLA82XX_CRB_ROMUSB + 0x10000)
+#define QLA82XX_ROMUSB_ROM_INSTR_OPCODE	(ROMUSB_ROM + 0x0004)
+#define QLA82XX_ROMUSB_GLB_CAS_RST	(ROMUSB_GLB + 0x0038)
+
+/* Lock IDs for ROM lock */
+#define ROM_LOCK_DRIVER		0x0d417340
+
+#define QLA82XX_PCI_CRB_WINDOWSIZE	0x00100000    /* all are 1MB windows */
+#define QLA82XX_PCI_CRB_WINDOW(A)	(QLA82XX_PCI_CRBSPACE + \
+					(A)*QLA82XX_PCI_CRB_WINDOWSIZE)
+
+#define QLA82XX_CRB_C2C_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_C2C0)
+#define QLA82XX_CRB_C2C_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_C2C1)
+#define QLA82XX_CRB_C2C_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_C2C2)
+#define QLA82XX_CRB_CAM	\
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_CAM)
+#define QLA82XX_CRB_CASPER \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_CAS)
+#define QLA82XX_CRB_CASPER_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_CAS0)
+#define QLA82XX_CRB_CASPER_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_CAS1)
+#define QLA82XX_CRB_CASPER_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_CAS2)
+#define QLA82XX_CRB_DDR_MD \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_MS)
+#define QLA82XX_CRB_DDR_NET \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_MN)
+#define QLA82XX_CRB_EPG \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_EG)
+#define QLA82XX_CRB_I2Q \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_I2Q)
+#define QLA82XX_CRB_NIU	\
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_NIU)
+/* HACK upon HACK upon HACK (for PCIE builds) */
+#define QLA82XX_CRB_PCIX_HOST \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PH)
+#define QLA82XX_CRB_PCIX_HOST2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PH2)
+#define QLA82XX_CRB_PCIX_MD \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PS)
+#define QLA82XX_CRB_PCIE	QLA82XX_CRB_PCIX_MD
+/* window 1 pcie slot */
+#define QLA82XX_CRB_PCIE2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PS2)
+
+#define QLA82XX_CRB_PEG_MD_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGS0)
+#define QLA82XX_CRB_PEG_MD_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGS1)
+#define QLA82XX_CRB_PEG_MD_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGS2)
+#define QLA82XX_CRB_PEG_MD_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGS3)
+#define QLA82XX_CRB_PEG_MD_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGS3)
+#define QLA82XX_CRB_PEG_MD_D \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGSD)
+#define QLA82XX_CRB_PEG_MD_I \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGSI)
+#define QLA82XX_CRB_PEG_NET_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGN0)
+#define QLA82XX_CRB_PEG_NET_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGN1)
+#define QLA82XX_CRB_PEG_NET_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGN2)
+#define QLA82XX_CRB_PEG_NET_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGN3)
+#define QLA82XX_CRB_PEG_NET_4 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGN4)
+#define QLA82XX_CRB_PEG_NET_D \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGND)
+#define QLA82XX_CRB_PEG_NET_I \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_PGNI)
+#define QLA82XX_CRB_PQM_MD \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_QMS)
+#define QLA82XX_CRB_PQM_NET \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_QMN)
+#define QLA82XX_CRB_QDR_MD \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SS)
+#define QLA82XX_CRB_QDR_NET \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SN)
+#define QLA82XX_CRB_ROMUSB \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_ROMUSB)
+#define QLA82XX_CRB_RPMX_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX0)
+#define QLA82XX_CRB_RPMX_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX1)
+#define QLA82XX_CRB_RPMX_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX2)
+#define QLA82XX_CRB_RPMX_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX3)
+#define QLA82XX_CRB_RPMX_4 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX4)
+#define QLA82XX_CRB_RPMX_5 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX5)
+#define QLA82XX_CRB_RPMX_6 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX6)
+#define QLA82XX_CRB_RPMX_7 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_RPMX7)
+#define QLA82XX_CRB_SQM_MD_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQS0)
+#define QLA82XX_CRB_SQM_MD_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQS1)
+#define QLA82XX_CRB_SQM_MD_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQS2)
+#define QLA82XX_CRB_SQM_MD_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQS3)
+#define QLA82XX_CRB_SQM_NET_0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQN0)
+#define QLA82XX_CRB_SQM_NET_1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQN1)
+#define QLA82XX_CRB_SQM_NET_2 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQN2)
+#define QLA82XX_CRB_SQM_NET_3 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SQN3)
+#define QLA82XX_CRB_SRE \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SRE)
+#define QLA82XX_CRB_TIMER \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_TIMR)
+#define QLA82XX_CRB_XDMA \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_XDMA)
+#define QLA82XX_CRB_I2C0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_I2C0)
+#define QLA82XX_CRB_I2C1 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_I2C1)
+#define QLA82XX_CRB_OCM0 \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_OCM0)
+#define QLA82XX_CRB_SMB \
+	QLA82XX_PCI_CRB_WINDOW(QLA82XX_HW_PX_MAP_CRB_SMB)
+
+#define QLA82XX_CRB_MAX		QLA82XX_PCI_CRB_WINDOW(64)
+
+/*
+ * ====================== BASE ADDRESSES ON-CHIP ======================
+ * Base addresses of major components on-chip.
+ * ====================== BASE ADDRESSES ON-CHIP ======================
+ */
+#define QLA82XX_ADDR_DDR_NET		(0x0000000000000000ULL)
+#define QLA82XX_ADDR_DDR_NET_MAX	(0x000000000fffffffULL)
+
+/* Imbus address bit used to indicate a host address. This bit is
+ * eliminated by the pcie bar and bar select before presentation
+ * over pcie. */
+/* host memory via IMBUS */
+#define QLA82XX_P2_ADDR_PCIE	(0x0000000800000000ULL)
+#define QLA82XX_P3_ADDR_PCIE	(0x0000008000000000ULL)
+#define QLA82XX_ADDR_PCIE_MAX	(0x0000000FFFFFFFFFULL)
+#define QLA82XX_ADDR_OCM0	(0x0000000200000000ULL)
+#define QLA82XX_ADDR_OCM0_MAX	(0x00000002000fffffULL)
+#define QLA82XX_ADDR_OCM1	(0x0000000200400000ULL)
+#define QLA82XX_ADDR_OCM1_MAX	(0x00000002004fffffULL)
+#define QLA82XX_ADDR_QDR_NET	(0x0000000300000000ULL)
+
+#define QLA82XX_P2_ADDR_QDR_NET_MAX	(0x00000003001fffffULL)
+#define QLA82XX_P3_ADDR_QDR_NET_MAX	(0x0000000303ffffffULL)
+
+#define QLA82XX_PCI_CRBSPACE		(unsigned long)0x06000000
+#define QLA82XX_PCI_DIRECT_CRB		(unsigned long)0x04400000
+#define QLA82XX_PCI_CAMQM		(unsigned long)0x04800000
+#define QLA82XX_PCI_CAMQM_MAX		(unsigned long)0x04ffffff
+#define QLA82XX_PCI_DDR_NET		(unsigned long)0x00000000
+#define QLA82XX_PCI_QDR_NET		(unsigned long)0x04000000
+#define QLA82XX_PCI_QDR_NET_MAX		(unsigned long)0x043fffff
+
+/*
+ *   Register offsets for MN
+ */
+#define MIU_CONTROL			(0x000)
+#define MIU_TAG				(0x004)
+#define MIU_TEST_AGT_CTRL		(0x090)
+#define MIU_TEST_AGT_ADDR_LO		(0x094)
+#define MIU_TEST_AGT_ADDR_HI		(0x098)
+#define MIU_TEST_AGT_WRDATA_LO		(0x0a0)
+#define MIU_TEST_AGT_WRDATA_HI		(0x0a4)
+#define MIU_TEST_AGT_WRDATA(i)		(0x0a0+(4*(i)))
+#define MIU_TEST_AGT_RDDATA_LO		(0x0a8)
+#define MIU_TEST_AGT_RDDATA_HI		(0x0ac)
+#define MIU_TEST_AGT_RDDATA(i)		(0x0a8+(4*(i)))
+#define MIU_TEST_AGT_ADDR_MASK		0xfffffff8
+#define MIU_TEST_AGT_UPPER_ADDR(off)	(0)
+
+/* MIU_TEST_AGT_CTRL flags. work for SIU as well */
+#define MIU_TA_CTL_START	1
+#define MIU_TA_CTL_ENABLE	2
+#define MIU_TA_CTL_WRITE	4
+#define MIU_TA_CTL_BUSY		8
+
+/*CAM RAM */
+# define QLA82XX_CAM_RAM_BASE	(QLA82XX_CRB_CAM + 0x02000)
+# define QLA82XX_CAM_RAM(reg)	(QLA82XX_CAM_RAM_BASE + (reg))
+
+#define QLA82XX_PORT_MODE_ADDR		(QLA82XX_CAM_RAM(0x24))
+#define QLA82XX_PEG_HALT_STATUS1	(QLA82XX_CAM_RAM(0xa8))
+#define QLA82XX_PEG_HALT_STATUS2	(QLA82XX_CAM_RAM(0xac))
+#define QLA82XX_PEG_ALIVE_COUNTER	(QLA82XX_CAM_RAM(0xb0))
+#define QLA82XX_CAM_RAM_DB1		(QLA82XX_CAM_RAM(0x1b0))
+#define QLA82XX_CAM_RAM_DB2		(QLA82XX_CAM_RAM(0x1b4))
+
+#define HALT_STATUS_UNRECOVERABLE	0x80000000
+#define HALT_STATUS_RECOVERABLE		0x40000000
+
+
+
+#define QLA82XX_ROM_LOCK_ID		(QLA82XX_CAM_RAM(0x100))
+#define QLA82XX_CRB_WIN_LOCK_ID		(QLA82XX_CAM_RAM(0x124))
+#define QLA82XX_FW_VERSION_MAJOR	(QLA82XX_CAM_RAM(0x150))
+#define QLA82XX_FW_VERSION_MINOR	(QLA82XX_CAM_RAM(0x154))
+#define QLA82XX_FW_VERSION_SUB		(QLA82XX_CAM_RAM(0x158))
+#define QLA82XX_PCIE_REG(reg)		(QLA82XX_CRB_PCIE + (reg))
+
+/* Driver Coexistence Defines */
+#define QLA82XX_CRB_DRV_ACTIVE		(QLA82XX_CAM_RAM(0x138))
+#define QLA82XX_CRB_DEV_STATE		(QLA82XX_CAM_RAM(0x140))
+#define QLA82XX_CRB_DEV_PART_INFO	(QLA82XX_CAM_RAM(0x14c))
+#define QLA82XX_CRB_DRV_IDC_VERSION	(QLA82XX_CAM_RAM(0x174))
+#define QLA82XX_CRB_DRV_STATE		(QLA82XX_CAM_RAM(0x144))
+#define QLA82XX_CRB_DRV_SCRATCH		(QLA82XX_CAM_RAM(0x148))
+#define QLA82XX_CRB_DEV_PART_INFO	(QLA82XX_CAM_RAM(0x14c))
+
+/* Every driver should use these Device State */
+#define QLA82XX_DEV_COLD		1
+#define QLA82XX_DEV_INITIALIZING	2
+#define QLA82XX_DEV_READY		3
+#define QLA82XX_DEV_NEED_RESET		4
+#define QLA82XX_DEV_NEED_QUIESCENT	5
+#define QLA82XX_DEV_FAILED		6
+#define QLA82XX_DEV_QUIESCENT		7
+#define MAX_STATES			8 /* Increment if new state added */
+
+#define QLA82XX_IDC_VERSION		0x1
+#define ROM_DEV_INIT_TIMEOUT		30
+#define ROM_DRV_RESET_ACK_TIMEOUT	10
+
+#define PCIE_SETUP_FUNCTION		(0x12040)
+#define PCIE_SETUP_FUNCTION2		(0x12048)
+
+#define QLA82XX_PCIX_PS_REG(reg)	(QLA82XX_CRB_PCIX_MD + (reg))
+#define QLA82XX_PCIX_PS2_REG(reg)	(QLA82XX_CRB_PCIE2 + (reg))
+
+#define PCIE_SEM2_LOCK		(0x1c010)  /* Flash lock   */
+#define PCIE_SEM2_UNLOCK	(0x1c014)  /* Flash unlock */
+#define PCIE_SEM5_LOCK		(0x1c028)  /* Coexistence lock   */
+#define PCIE_SEM5_UNLOCK	(0x1c02c)  /* Coexistence unlock */
+#define PCIE_SEM7_LOCK		(0x1c038)  /* crb win lock */
+#define PCIE_SEM7_UNLOCK	(0x1c03c)  /* crbwin unlock*/
+
+/*
+ * The PCI VendorID and DeviceID for our board.
+ */
+#define QLA82XX_MSIX_TBL_SPACE		8192
+#define QLA82XX_PCI_REG_MSIX_TBL	0x44
+#define QLA82XX_PCI_MSIX_CONTROL	0x40
+
+struct crb_128M_2M_sub_block_map {
+	unsigned valid;
+	unsigned start_128M;
+	unsigned end_128M;
+	unsigned start_2M;
+};
+
+struct crb_128M_2M_block_map {
+	struct crb_128M_2M_sub_block_map sub_block[16];
+};
+
+struct crb_addr_pair {
+	long addr;
+	long data;
+};
+
+#define ADDR_ERROR	((unsigned long) 0xffffffff)
+#define MAX_CTL_CHECK	1000
+
+/***************************************************************************
+ *		PCI related defines.
+ **************************************************************************/
+
+/*
+ * Interrupt related defines.
+ */
+#define PCIX_TARGET_STATUS	(0x10118)
+#define PCIX_TARGET_STATUS_F1	(0x10160)
+#define PCIX_TARGET_STATUS_F2	(0x10164)
+#define PCIX_TARGET_STATUS_F3	(0x10168)
+#define PCIX_TARGET_STATUS_F4	(0x10360)
+#define PCIX_TARGET_STATUS_F5	(0x10364)
+#define PCIX_TARGET_STATUS_F6	(0x10368)
+#define PCIX_TARGET_STATUS_F7	(0x1036c)
+
+#define PCIX_TARGET_MASK	(0x10128)
+#define PCIX_TARGET_MASK_F1	(0x10170)
+#define PCIX_TARGET_MASK_F2	(0x10174)
+#define PCIX_TARGET_MASK_F3	(0x10178)
+#define PCIX_TARGET_MASK_F4	(0x10370)
+#define PCIX_TARGET_MASK_F5	(0x10374)
+#define PCIX_TARGET_MASK_F6	(0x10378)
+#define PCIX_TARGET_MASK_F7	(0x1037c)
+
+/*
+ * Message Signaled Interrupts
+ */
+#define PCIX_MSI_F0		(0x13000)
+#define PCIX_MSI_F1		(0x13004)
+#define PCIX_MSI_F2		(0x13008)
+#define PCIX_MSI_F3		(0x1300c)
+#define PCIX_MSI_F4		(0x13010)
+#define PCIX_MSI_F5		(0x13014)
+#define PCIX_MSI_F6		(0x13018)
+#define PCIX_MSI_F7		(0x1301c)
+#define PCIX_MSI_F(FUNC)	(0x13000 + ((FUNC) * 4))
+
+/*
+ *
+ */
+#define PCIX_INT_VECTOR		(0x10100)
+#define PCIX_INT_MASK		(0x10104)
+
+/*
+ * Interrupt state machine and other bits.
+ */
+#define PCIE_MISCCFG_RC		(0x1206c)
+
+
+#define ISR_INT_TARGET_STATUS \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS))
+#define ISR_INT_TARGET_STATUS_F1 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F1))
+#define ISR_INT_TARGET_STATUS_F2 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F2))
+#define ISR_INT_TARGET_STATUS_F3 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F3))
+#define ISR_INT_TARGET_STATUS_F4 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F4))
+#define ISR_INT_TARGET_STATUS_F5 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F5))
+#define ISR_INT_TARGET_STATUS_F6 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F6))
+#define ISR_INT_TARGET_STATUS_F7 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_STATUS_F7))
+
+#define ISR_INT_TARGET_MASK \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK))
+#define ISR_INT_TARGET_MASK_F1 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F1))
+#define ISR_INT_TARGET_MASK_F2 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F2))
+#define ISR_INT_TARGET_MASK_F3 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F3))
+#define ISR_INT_TARGET_MASK_F4 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F4))
+#define ISR_INT_TARGET_MASK_F5 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F5))
+#define ISR_INT_TARGET_MASK_F6 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F6))
+#define ISR_INT_TARGET_MASK_F7 \
+	(QLA82XX_PCIX_PS_REG(PCIX_TARGET_MASK_F7))
+
+#define ISR_INT_VECTOR			(QLA82XX_PCIX_PS_REG(PCIX_INT_VECTOR))
+#define ISR_INT_MASK			(QLA82XX_PCIX_PS_REG(PCIX_INT_MASK))
+#define ISR_INT_STATE_REG		(QLA82XX_PCIX_PS_REG(PCIE_MISCCFG_RC))
+
+#define	ISR_MSI_INT_TRIGGER(FUNC)	(QLA82XX_PCIX_PS_REG(PCIX_MSI_F(FUNC)))
+
+
+#define	ISR_IS_LEGACY_INTR_IDLE(VAL)		(((VAL) & 0x300) == 0)
+#define	ISR_IS_LEGACY_INTR_TRIGGERED(VAL)	(((VAL) & 0x300) == 0x200)
+
+/*
+ * PCI Interrupt Vector Values.
+ */
+#define	PCIX_INT_VECTOR_BIT_F0	0x0080
+#define	PCIX_INT_VECTOR_BIT_F1	0x0100
+#define	PCIX_INT_VECTOR_BIT_F2	0x0200
+#define	PCIX_INT_VECTOR_BIT_F3	0x0400
+#define	PCIX_INT_VECTOR_BIT_F4	0x0800
+#define	PCIX_INT_VECTOR_BIT_F5	0x1000
+#define	PCIX_INT_VECTOR_BIT_F6	0x2000
+#define	PCIX_INT_VECTOR_BIT_F7	0x4000
+
+/* struct qla4_8xxx_legacy_intr_set defined in ql4_def.h */
+
+#define QLA82XX_LEGACY_INTR_CONFIG                                      \
+{                                                                       \
+	{                                                               \
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F0,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS,          \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK,            \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(0) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F1,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F1,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F1,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(1) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F2,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F2,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F2,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(2) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F3,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F3,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F3,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(3) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F4,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F4,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F4,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(4) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F5,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F5,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F5,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(5) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F6,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F6,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F6,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(6) },       \
+									\
+	{								\
+		.int_vec_bit    =	PCIX_INT_VECTOR_BIT_F7,         \
+		.tgt_status_reg =	ISR_INT_TARGET_STATUS_F7,       \
+		.tgt_mask_reg   =	ISR_INT_TARGET_MASK_F7,         \
+		.pci_int_reg    =	ISR_MSI_INT_TRIGGER(7) },       \
+}
+
+/* Magic number to let user know flash is programmed */
+#define	QLA82XX_BDINFO_MAGIC	0x12345678
+#define FW_SIZE_OFFSET		(0x3e840c)
+
+/* QLA82XX additions */
+#define MIU_TEST_AGT_WRDATA_UPPER_LO	(0x0b0)
+#define	MIU_TEST_AGT_WRDATA_UPPER_HI	(0x0b4)
+
+#ifndef readq
+static inline u64 readq(void __iomem *addr)
+{
+	return readl(addr) | (((u64) readl(addr + 4)) << 32LL);
+}
+#endif
+
+#ifndef writeq
+static inline void writeq(u64 val, void __iomem *addr)
+{
+	writel(((u32) (val)), (addr));
+	writel(((u32) (val >> 32)), (addr + 4));
+}
+#endif
+
+/* Minidump related */
+
+/*
+ * Version of the template
+ * 4 Bytes
+ * X.Major.Minor.RELEASE
+ */
+#define QLA82XX_MINIDUMP_VERSION         0x10101
+#define QLA82XX_DEFAULT_CAPTURE_LEVEL    0x0F
+#define QLA82XX_DBG_MAX_PRIORITY         8
+
+/*
+ * Entry Type Defines
+ */
+#define QLA82XX_RDNOP                   0
+#define QLA82XX_RDCRB                   1
+#define QLA82XX_RDMUX                   2
+#define QLA82XX_QUEUE                   3
+#define QLA82XX_BOARD                   4
+#define QLA82XX_RDSRE                   5
+#define QLA82XX_RDOCM                   6
+#define QLA82XX_PREGS                   7
+#define QLA82XX_L1DTG                   8
+#define QLA82XX_L1ITG                   9
+#define QLA82XX_CACHE                  10
+
+#define QLA82XX_L1DAT                  11
+#define QLA82XX_L1INS                  12
+#define QLA82XX_RDSTK                  13
+#define QLA82XX_RDCON                  14
+
+#define QLA82XX_L2DTG                  21
+#define QLA82XX_L2ITG                  22
+#define QLA82XX_L2DAT                  23
+#define QLA82XX_L2INS                  24
+#define QLA82XX_RDOC3                  25
+
+#define QLA82XX_MEMBK                  32
+
+#define QLA82XX_RDROM                  71
+#define QLA82XX_RDMEM                  72
+
+#define QLA82XX_INFOR                  81
+#define QLA82XX_CNTRL                  98
+
+#define QLA82XX_RDEND                  255
+
+#define QLA82XX_PRIMQ                  103
+#define QLA82XX_SQG2Q                  104
+#define QLA82XX_SQG3Q                  105
+
+/*
+ * Opcodes for Control Entries.
+ * These Flags are bit fields.
+ */
+#define QLA82XX_DBG_OPCODE_WR        0x01
+#define QLA82XX_DBG_OPCODE_RW        0x02
+#define QLA82XX_DBG_OPCODE_AND       0x04
+#define QLA82XX_DBG_OPCODE_OR        0x08
+#define QLA82XX_DBG_OPCODE_POLL      0x10
+#define QLA82XX_DBG_OPCODE_RDSTATE   0x20
+#define QLA82XX_DBG_OPCODE_WRSTATE   0x40
+#define QLA82XX_DBG_OPCODE_MDSTATE   0x80
+
+
+/*
+ * Entry Header definitions start here.
+ */
+
+/*
+ * Entry Header:  Common to All Entry Types
+ */
+
+/*
+ * Driver Flags
+ */
+#define QLA82XX_DBG_SKIPPED_FLAG     0x80	/*  driver skipped this entry  */
+#define QLA82XX_DBG_SIZE_ERR_FLAG    0x40	/*  entry size vs capture size mismatch */
+
+/*
+ * Driver Code is for driver to write some info about the entry.
+ * Currently not used.
+ */
+struct qla82xx_minidump_entry_hdr {
+	uint32_t entry_type;
+	uint32_t entry_size;
+	uint32_t entry_capture_size;
+	struct {
+		uint8_t entry_capture_mask;
+		uint8_t entry_code;
+		uint8_t driver_code;
+		uint8_t driver_flags;
+	} d_ctrl;
+};
+
+/*
+ *  Read CRB entry header
+ */
+struct qla82xx_minidump_entry_crb {
+	struct qla82xx_minidump_entry_hdr h;
+	uint32_t addr;
+	struct {
+		uint8_t addr_stride;
+		uint8_t state_index_a;
+		uint16_t poll_timeout;
+	} crb_strd;
+	uint32_t data_size;
+	uint32_t op_count;
+
+	struct {
+		uint8_t opcode;
+		uint8_t state_index_v;
+		uint8_t shl;
+		uint8_t shr;
+	} crb_ctrl;
+	
+	uint32_t value_1;
+	uint32_t value_2;
+	uint32_t value_3;
+};
+
+/*
+ * Cache entry header
+ */
+struct qla82xx_minidump_entry_cache {
+	struct qla82xx_minidump_entry_hdr h;
+
+	uint32_t tag_reg_addr;
+
+	struct {
+		uint16_t tag_value_stride;
+		uint16_t init_tag_value;
+	} addr_ctrl;
+
+	uint32_t data_size;
+	uint32_t op_count;
+
+	uint32_t control_addr;
+	struct {
+		uint16_t write_value;
+		uint8_t poll_mask;
+		uint8_t poll_wait;
+	} cache_ctrl;
+	uint32_t read_addr;
+	struct {	
+		uint8_t read_addr_stride;
+		uint8_t read_addr_cnt;
+		uint16_t rsvd_1;
+	} read_ctrl;
+};
+
+/*
+ * Read OCM 
+ */
+struct qla82xx_minidump_entry_rdocm {
+	struct qla82xx_minidump_entry_hdr h;
+
+	uint32_t rsvd_0;
+	uint32_t rsvd_1;
+		
+	uint32_t data_size;
+	uint32_t op_count;
+
+	uint32_t rsvd_2;
+	uint32_t rsvd_3;
+
+	uint32_t read_addr;
+	uint32_t read_addr_stride;
+	uint32_t read_addr_cntrl;
+};
+
+/*
+ * Read Memory 
+ */
+struct qla82xx_minidump_entry_rdmem {
+	struct qla82xx_minidump_entry_hdr h;
+	
+	uint32_t rsvd[6];
+	uint32_t read_addr;
+	uint32_t read_data_size;
+};
+
+/*
+ * Read ROm
+ */
+struct qla82xx_minidump_entry_rdrom {
+	struct qla82xx_minidump_entry_hdr h;
+
+	uint32_t rsvd[6];
+	uint32_t read_addr;
+	uint32_t read_data_size;
+};
+
+/*
+ * Mux entry
+ */
+
+struct qla82xx_minidump_entry_mux {
+	struct qla82xx_minidump_entry_hdr h;
+
+	uint32_t select_addr;
+
+	uint32_t rsvd_0;
+	uint32_t data_size;
+	uint32_t op_count;
+
+	uint32_t select_value;
+	uint32_t select_value_stride;
+
+	uint32_t read_addr;
+	uint32_t rsvd_1;
+
+};
+
+/*
+ * Queue entry
+ */
+
+struct qla82xx_minidump_entry_queue {
+	struct qla82xx_minidump_entry_hdr h;
+
+	uint32_t select_addr;
+
+	struct {
+		uint16_t queue_id_stride;
+		uint16_t rsvd_0;
+	} q_strd;
+	uint32_t data_size;
+	uint32_t op_count;
+
+	uint32_t rsvd_1;
+	uint32_t rsvd_2;
+
+	uint32_t read_addr;
+	struct {
+		uint8_t read_addr_stride;
+		uint8_t read_addr_cnt;
+		uint16_t rsvd_3;
+	} rd_strd;
+
+};
+
+#define QLA82XX_MINIDUMP_OCM0_SIZE		256 * 1024
+#define QLA82XX_MINIDUMP_L1C_SIZE		256 * 1024
+#define QLA82XX_MINIDUMP_L2C_SIZE		1572864
+#define QLA82XX_MINIDUMP_COMMON_STR_SIZE	0
+#define QLA82XX_MINIDUMP_FCOE_STR_SIZE		0
+#define QLA82XX_MINIDUMP_MEM_SIZE		0
+#define QLA82XX_MAX_ENTRY_HDR			4
+
+struct qla82xx_minidump {
+	uint32_t md_ocm0_data[QLA82XX_MINIDUMP_OCM0_SIZE];
+	uint32_t md_l1c_data[QLA82XX_MINIDUMP_L1C_SIZE];
+	uint32_t md_l2c_data[QLA82XX_MINIDUMP_L2C_SIZE];
+	uint32_t md_cs_data[QLA82XX_MINIDUMP_COMMON_STR_SIZE];
+	uint32_t md_fcoes_data[QLA82XX_MINIDUMP_FCOE_STR_SIZE];
+	uint32_t md_mem_data[QLA82XX_MINIDUMP_MEM_SIZE];
+};
+
+#define MBC_DIAGNOSTIC_MINIDUMP_TEMPLATE 0x129
+#define RQST_TMPLT_SIZE	0x0
+#define RQST_TMPLT 0x1
+#define MD_DIRECT_ROM_WINDOW	0x42110030
+#define MD_DIRECT_ROM_READ_BASE	0x42150000
+#define MD_MIU_TEST_AGT_CTRL		0x41000090
+#define MD_MIU_TEST_AGT_ADDR_LO		0x41000094
+#define MD_MIU_TEST_AGT_ADDR_HI		0x41000098
+
+static const int MD_MIU_TEST_AGT_RDDATA [ ] =
+	{ 0x410000A8, 0x410000AC, 0x410000B8, 0x410000BC };
+#endif
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_os.c
--- a/drivers/scsi/qla4xxx/ql4_os.c
+++ b/drivers/scsi/qla4xxx/ql4_os.c
@@ -1,15 +1,14 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
 #include <linux/moduleparam.h>
+#include <linux/slab.h>
 
 #include <scsi/scsi_tcq.h>
 #include <scsi/scsicam.h>
-#include <scsi/iscsi_proto.h>
-#include <scsi/scsi_eh.h>
 
 #include "ql4_def.h"
 #include "ql4_version.h"
@@ -21,18 +20,17 @@
  * Driver version
  */
 char qla4xxx_version_str[40];
-EXPORT_SYMBOL_GPL(qla4xxx_version_str);
 
 /*
  * List of host adapters
  */
 struct klist qla4xxx_hostlist;
 
-struct klist *qla4xxx_hostlist_ptr = &qla4xxx_hostlist;
-EXPORT_SYMBOL_GPL(qla4xxx_hostlist_ptr);
-
 static atomic_t qla4xxx_hba_count;
 
+extern  int ql4im_init(void);
+extern  int ql4im_exit(void);
+
 /*
  * SRB allocation cache
  */
@@ -41,26 +39,64 @@ static struct kmem_cache *srb_cachep;
 /*
  * Module parameter information and variables
  */
-int ql4xdiscoverywait = 60;
-module_param_named(ql4xdiscoverywait, ql4xdiscoverywait, int, S_IRUGO | S_IWUSR);
-MODULE_PARM_DESC(ql4xdiscoverywait, "Discovery wait time");
-
 int ql4xdontresethba = 0;
-module_param_named(ql4xdontresethba, ql4xdontresethba, int, S_IRUGO | S_IWUSR);
+module_param(ql4xdontresethba, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(ql4xdontresethba,
-		 "Dont reset the HBA when the driver gets 0x8002 AEN "
-		 " default it will reset hba :0"
-		 " set to 1 to avoid resetting HBA");
+		"Don't reset the HBA for driver recovery \n"
+		"\t\t 0 - It will reset HBA (Default)\n"
+		"\t\t 1 - It will NOT reset HBA\n"
+		"\t\t 2 - Only reset in eh_host_reset");
+
+int ql4xmdcapmask = 0x1F;
+module_param(ql4xmdcapmask, int, S_IRUGO);
+MODULE_PARM_DESC(ql4xmdcapmask,
+		"\t\t Set the Minidump driver capture mask level.\n"
+		"\t\t Default is 0x1F.\n"
+		"\t\t Set to 0 for firmware default capture mask.\n"
+		"\t\t Can be set to 0x3, 0x7, 0xF, 0x1F, 0x3F, 0x7F.\n");
+
+int ql4xenablemd = 1;
+module_param(ql4xenablemd, int, S_IRUGO | S_IWUSR);
+MODULE_PARM_DESC(ql4xenablemd,
+		"Set to enable minidump.\n"
+		"\t\t 0 - disable minidump\n"
+		"\t\t 1 - enable minidump (Default)\n");
 
 int ql4xextended_error_logging = 0; /* 0 = off, 1 = log errors */
-module_param_named(ql4xextended_error_logging, ql4xextended_error_logging, int, S_IRUGO | S_IWUSR);
+module_param(ql4xextended_error_logging, int, S_IRUGO | S_IWUSR);
 MODULE_PARM_DESC(ql4xextended_error_logging,
-		 "Option to enable extended error logging, "
-		 "Default is 0 - no logging, 1 - debug logging");
-
-int ql4_mod_unload = 0;
-
-#define QL4_DEF_QDEPTH 32
+		 "Option to enable extended error logging \n"
+		 "\t\t 0 - no logging (Default)\n"
+		 "\t\t 1 - debug logging");
+
+int ql4xenablemsix = 1;
+module_param(ql4xenablemsix, int, S_IRUGO|S_IWUSR);
+MODULE_PARM_DESC(ql4xenablemsix,
+		"Set to enable MSI or MSI-X interrupt mechanism\n"
+		"\t\t 0 - enable INTx interrupt mechanism\n"
+		"\t\t 1 - enable MSI-X interrupt mechanism (Default)\n"
+		"\t\t 2 - enable MSI interrupt mechanism");
+
+int ql4xkeepalive=0xDEAD;
+module_param(ql4xkeepalive, int, S_IRUGO|S_IWUSR);
+MODULE_PARM_DESC(ql4xkeepalive,
+		"Keep Alive Timeout - Target Session Recovery Timeout\n"
+		"\t\t 0xDEAD - retrieved from firmware DDB. (Default)\n"
+		"\t\t other  - override for all sessions.");
+
+static int ql4xmaxqdepth = MAX_Q_DEPTH;
+module_param(ql4xmaxqdepth, int, S_IRUGO|S_IWUSR);
+MODULE_PARM_DESC(ql4xmaxqdepth,
+		"Maximum queue depth to report for target devices\n"
+		"\t\t Default - 32");
+
+int ql4xmaxcmds = 0;
+module_param(ql4xmaxcmds, int, S_IRUGO|S_IWUSR);
+MODULE_PARM_DESC(ql4xmaxcmds,
+		"Maximum outstanding commands per host adapter\n"
+		"\t\t 0 - uses driver default of 1024\n"
+		"\t\t Range for ISP4xxx - 64 to 1024\n"
+		"\t\t Range for ISP8xxx - 64 to 1024\n");
 
 /*
  * SCSI host template entry points
@@ -95,6 +131,12 @@ static int qla4xxx_slave_alloc(struct sc
 static int qla4xxx_slave_configure(struct scsi_device *device);
 static void qla4xxx_slave_destroy(struct scsi_device *sdev);
 static void qla4xxx_scan_start(struct Scsi_Host *shost);
+#ifdef QL4_RHEL62
+static mode_t ql4_attr_is_visible(int param_type, int param);
+#endif
+
+static struct qla4_8xxx_legacy_intr_set legacy_intr[] =
+    QLA82XX_LEGACY_INTR_CONFIG;
 
 static struct scsi_host_template qla4xxx_driver_template = {
 	.module			= THIS_MODULE,
@@ -111,7 +153,6 @@ static struct scsi_host_template qla4xxx
 	.slave_configure	= qla4xxx_slave_configure,
 	.slave_alloc		= qla4xxx_slave_alloc,
 	.slave_destroy		= qla4xxx_slave_destroy,
-	.target_destroy		= NULL,
 
 	.scan_finished		= iscsi_scan_finished,
 	.scan_start		= qla4xxx_scan_start,
@@ -122,6 +163,7 @@ static struct scsi_host_template qla4xxx
 	.sg_tablesize		= SG_ALL,
 
 	.max_sectors		= 0xFFFF,
+	.shost_attrs		= qla4xxx_host_attrs,
 };
 
 static struct iscsi_transport qla4xxx_iscsi_transport = {
@@ -129,11 +171,15 @@ static struct iscsi_transport qla4xxx_is
 	.name			= DRIVER_NAME,
 	.caps			= CAP_FW_DB | CAP_SENDTARGETS_OFFLOAD |
 				  CAP_DATA_PATH_OFFLOAD,
-	.param_mask		= ISCSI_CONN_PORT | ISCSI_CONN_ADDRESS |
+#ifdef QL4_RHEL62
+	.attr_is_visible        = ql4_attr_is_visible,
+#else
+	.param_mask             = ISCSI_CONN_PORT | ISCSI_CONN_ADDRESS |
 				  ISCSI_TARGET_NAME | ISCSI_TPGT,
 	.host_param_mask	= ISCSI_HOST_HWADDRESS |
 				  ISCSI_HOST_IPADDRESS |
 				  ISCSI_HOST_INITIATOR_NAME,
+#endif
 	.tgt_dscvr		= qla4xxx_tgt_dscvr,
 	.get_conn_param		= qla4xxx_conn_get_param,
 	.get_session_param	= qla4xxx_sess_get_param,
@@ -143,6 +189,35 @@ static struct iscsi_transport qla4xxx_is
 
 static struct scsi_transport_template *qla4xxx_scsi_transport;
 
+#ifdef QL4_RHEL62
+static mode_t ql4_attr_is_visible(int param_type, int param)
+{
+        switch (param_type) {
+        case ISCSI_HOST_PARAM:
+                switch (param) {
+                case ISCSI_HOST_PARAM_HWADDRESS:
+                case ISCSI_HOST_PARAM_IPADDRESS:
+                case ISCSI_HOST_PARAM_INITIATOR_NAME:
+                        return S_IRUGO;
+                default:
+                        return 0;
+                }
+        case ISCSI_PARAM:
+                switch (param) {
+                case ISCSI_PARAM_CONN_ADDRESS:
+                case ISCSI_PARAM_CONN_PORT:
+                case ISCSI_PARAM_TARGET_NAME:
+                case ISCSI_PARAM_TPGT:
+                        return S_IRUGO;
+                default:
+                        return 0;
+                }
+        }
+
+        return 0;
+}
+#endif
+
 static enum blk_eh_timer_return qla4xxx_eh_cmd_timed_out(struct scsi_cmnd *sc)
 {
 	struct iscsi_cls_session *session;
@@ -161,20 +236,17 @@ static enum blk_eh_timer_return qla4xxx_
 static void qla4xxx_recovery_timedout(struct iscsi_cls_session *session)
 {
 	struct ddb_entry *ddb_entry = session->dd_data;
+#if defined(QL_DEBUG_LEVEL_2)
 	struct scsi_qla_host *ha = ddb_entry->ha;
+#endif
 
 	if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE) {
 		atomic_set(&ddb_entry->state, DDB_STATE_DEAD);
 
-		DEBUG2(printk("scsi%ld: %s: index [%d] port down retry count "
+		DEBUG2(ql4_info(ha, "%s: ddb [%d] session recovery timeout "
 			      "of (%d) secs exhausted, marking device DEAD.\n",
-			      ha->host_no, __func__, ddb_entry->fw_ddb_index,
-			      ha->port_down_retry_count));
-
-		DEBUG2(printk("scsi%ld: %s: scheduling dpc routine - dpc "
-			      "flags = 0x%lx\n",
-			      ha->host_no, __func__, ha->dpc_flags));
-		queue_work(ha->dpc_thread, &ha->dpc_work);
+			      __func__, ddb_entry->fw_ddb_index,
+			      ddb_entry->sess->recovery_tmo));
 	}
 }
 
@@ -189,9 +261,18 @@ static int qla4xxx_host_get_param(struct
 		len = sysfs_format_mac(buf, ha->my_mac, MAC_ADDR_LEN);
 		break;
 	case ISCSI_HOST_PARAM_IPADDRESS:
-		len = sprintf(buf, "%d.%d.%d.%d\n", ha->ip_address[0],
-			      ha->ip_address[1], ha->ip_address[2],
-			      ha->ip_address[3]);
+		len = sprintf(buf, "%pI4\n", &ha->ip_address);
+		if (!is_ipv4_enabled(ha) && is_ipv6_enabled(ha)) {
+			if (ha->ipv6_addr0_state == ACB_STATE_VALID)
+				len = sprintf(buf, "%pI6\n",
+							&ha->ipv6_addr0);
+			else if (ha->ipv6_addr1_state == ACB_STATE_VALID)
+				len = sprintf(buf, "%pI6\n",
+							&ha->ipv6_addr1);
+			else if (ha->ipv6_link_local_state == ACB_STATE_VALID)
+				len = sprintf(buf, "%pI6\n",
+					&ha->ipv6_link_local_addr);
+		}
 		break;
 	case ISCSI_HOST_PARAM_INITIATOR_NAME:
 		len = sprintf(buf, "%s\n", ha->name_string);
@@ -239,8 +320,13 @@ static int qla4xxx_conn_get_param(struct
 		len = sprintf(buf, "%hu\n", ddb_entry->port);
 		break;
 	case ISCSI_PARAM_CONN_ADDRESS:
-		/* TODO: what are the ipv6 bits */
-		len = sprintf(buf, "%pI4\n", &ddb_entry->ip_addr);
+		if (is_ipv6_ddb(ddb_entry))
+			len = sprintf(buf, NIP6_FMT"\n",
+				NIP6(ddb_entry->ipv6_addr));
+		else
+			len = sprintf(buf, NIPQUAD_FMT"\n",
+				NIPQUAD(ddb_entry->ipv6_addr));
+
 		break;
 	default:
 		return -ENOSYS;
@@ -284,36 +370,72 @@ static int qla4xxx_tgt_dscvr(struct Scsi
 	return ret;
 }
 
+static int ql4_alloc_osindex(struct scsi_qla_host *ha)
+{
+        unsigned int idx;
+
+get_idx:
+	idx = find_first_zero_bit(ha->os_map, MAX_DDB_ENTRIES);
+	if (idx >= MAX_DDB_ENTRIES)
+		return -1;
+
+	if (test_and_set_bit(idx, ha->os_map))
+		goto get_idx;
+
+	return idx;
+}
+
+static void ql4_free_osindex(struct scsi_qla_host *ha, uint32_t idx)
+{
+	clear_bit(idx, ha->os_map);
+}
+
 void qla4xxx_destroy_sess(struct ddb_entry *ddb_entry)
 {
 	if (!ddb_entry->sess)
 		return;
 
-	if (ddb_entry->conn)
+	ql4_free_osindex(ddb_entry->ha, ddb_entry->os_target_id);
+
+	if (ddb_entry->conn) {
+		/* Mark device DEAD */
+                ql4_info(ddb_entry->ha, "%s: ddb[%d] os[%d] DEAD\n",
+                         __func__, ddb_entry->fw_ddb_index,
+                         ddb_entry->os_target_id);
+		atomic_set(&ddb_entry->state, DDB_STATE_DEAD);
 		iscsi_remove_session(ddb_entry->sess);
+	}
 	iscsi_free_session(ddb_entry->sess);
 }
 
 int qla4xxx_add_sess(struct ddb_entry *ddb_entry)
 {
 	int err;
-
-	ddb_entry->sess->recovery_tmo = ddb_entry->ka_timeout;
-	err = iscsi_add_session(ddb_entry->sess, ddb_entry->fw_ddb_index);
+	struct scsi_qla_host *ha = ddb_entry->ha;
+
+	err = iscsi_add_session(ddb_entry->sess, ddb_entry->os_target_id);
 	if (err) {
-		DEBUG2(printk(KERN_ERR "Could not add session.\n"));
+		DEBUG2(ql4_err(ha, "Could not add session.\n"));
 		return err;
 	}
 
 	ddb_entry->conn = iscsi_create_conn(ddb_entry->sess, 0, 0);
 	if (!ddb_entry->conn) {
 		iscsi_remove_session(ddb_entry->sess);
-		DEBUG2(printk(KERN_ERR "Could not add connection.\n"));
+		DEBUG2(ql4_err(ha, "Could not add connection.\n"));
 		return -ENOMEM;
 	}
 
+	ddb_entry->sess->recovery_tmo = (ql4xkeepalive != 0xDEAD)
+			?ql4xkeepalive:ddb_entry->ka_timeout;
+
 	/* finally ready to go */
 	iscsi_unblock_session(ddb_entry->sess);
+	DEBUG2(ql4_info(ha, "%s: iscsi_unblock_session "
+			"ddb[%d] os[%d] sess 0x%p conn 0x%p\n", __func__,
+			ddb_entry->fw_ddb_index, ddb_entry->os_target_id,
+			ddb_entry->sess, ddb_entry->conn));
+
 	return 0;
 }
 
@@ -321,14 +443,24 @@ struct ddb_entry *qla4xxx_alloc_sess(str
 {
 	struct ddb_entry *ddb_entry;
 	struct iscsi_cls_session *sess;
+	int os_idx;
+
+        os_idx = ql4_alloc_osindex(ha);
+	if (os_idx == -1) {
+		DEBUG2(ql4_info(ha, "%s: os_idx=%d\n", __func__, os_idx));
+                return NULL;
+	}
 
 	sess = iscsi_alloc_session(ha->host, &qla4xxx_iscsi_transport,
 				   sizeof(struct ddb_entry));
-	if (!sess)
+	if (!sess) {
+		ql4_free_osindex(ha, os_idx);
 		return NULL;
+	}
 
 	ddb_entry = sess->dd_data;
 	memset(ddb_entry, 0, sizeof(*ddb_entry));
+	ddb_entry->os_target_id = os_idx;
 	ddb_entry->ha = ha;
 	ddb_entry->sess = sess;
 	return ddb_entry;
@@ -353,8 +485,8 @@ static void qla4xxx_scan_start(struct Sc
 static void qla4xxx_start_timer(struct scsi_qla_host *ha, void *func,
 				unsigned long interval)
 {
-	DEBUG(printk("scsi: %s: Starting timer thread for adapter %d\n",
-		     __func__, ha->host->host_no));
+	DEBUG(ql4_info(ha, "scsi: %s: Starting timer thread for adapter\n",
+		     __func__));
 	init_timer(&ha->timer);
 	ha->timer.expires = jiffies + interval * HZ;
 	ha->timer.data = (unsigned long)ha;
@@ -374,28 +506,38 @@ static void qla4xxx_stop_timer(struct sc
  * @ha: Pointer to host adapter structure.
  * @ddb_entry: Pointer to device database entry
  *
- * This routine marks a device missing and resets the relogin retry count.
+ * This routine marks a device missing and close connection.
  **/
 void qla4xxx_mark_device_missing(struct scsi_qla_host *ha,
 				 struct ddb_entry *ddb_entry)
 {
-	atomic_set(&ddb_entry->state, DDB_STATE_MISSING);
-	DEBUG2(printk("scsi%ld: index [%d] marked MISSING\n",
-		      ha->host_no, ddb_entry->fw_ddb_index));
+	if ((atomic_read(&ddb_entry->state) != DDB_STATE_DEAD)) {
+		atomic_set(&ddb_entry->state, DDB_STATE_MISSING);
+		DEBUG2(ql4_info(ha, "ddb[%d] os[%d] marked MISSING\n",
+				ddb_entry->fw_ddb_index,
+				ddb_entry->os_target_id));
+	} else
+		DEBUG2(ql4_info(ha, "ddb[%d] os[%d] DEAD\n",
+				ddb_entry->fw_ddb_index,
+				ddb_entry->os_target_id));
+
 	iscsi_block_session(ddb_entry->sess);
-	iscsi_conn_error_event(ddb_entry->conn, ISCSI_ERR_CONN_FAILED);
 }
 
-/***
- * qla4xxx_get_new_srb - Allocate memory for a local srb.
+/**
+ * qla4xxx_mark_all_devices_missing - mark all devices as missing.
  * @ha: Pointer to host adapter structure.
- * @ddb_entry: Pointer to device database entry
- * @cmd: Pointer to Linux's SCSI command structure
- * @done: Pointer to Linux's SCSI mid-layer done function
  *
- * NOTE: Sets te ref_count for non-NULL srb to one,
- *       and initializes some fields.
+ * This routine marks a device missing and resets the relogin retry count.
  **/
+void qla4xxx_mark_all_devices_missing(struct scsi_qla_host *ha)
+{
+	struct ddb_entry *ddb_entry, *ddbtemp;
+	list_for_each_entry_safe(ddb_entry, ddbtemp, &ha->ddb_list, list) {
+		qla4xxx_mark_device_missing(ha, ddb_entry);
+	}
+}
+
 static struct srb* qla4xxx_get_new_srb(struct scsi_qla_host *ha,
 				       struct ddb_entry *ddb_entry,
 				       struct scsi_cmnd *cmd,
@@ -407,12 +549,12 @@ static struct srb* qla4xxx_get_new_srb(s
 	if (!srb)
 		return srb;
 
-	atomic_set(&srb->ref_count, 1);
+	kref_init(&srb->srb_ref);
 	srb->ha = ha;
 	srb->ddb = ddb_entry;
 	srb->cmd = cmd;
 	srb->flags = 0;
-	cmd->SCp.ptr = (void *)srb;
+	CMD_SP(cmd) = (void *)srb;
 	cmd->scsi_done = done;
 
 	return srb;
@@ -426,49 +568,23 @@ static void qla4xxx_srb_free_dma(struct 
 		scsi_dma_unmap(cmd);
 		srb->flags &= ~SRB_DMA_VALID;
 	}
-	cmd->SCp.ptr = NULL;
+	CMD_SP(cmd) = NULL;
 }
 
-void qla4xxx_srb_compl(struct scsi_qla_host *ha, struct srb *srb)
+void qla4xxx_srb_compl(struct kref *ref)
 {
+	struct srb *srb = container_of(ref, struct srb, srb_ref);
 	struct scsi_cmnd *cmd = srb->cmd;
+	struct scsi_qla_host *ha = srb->ha;
 
 	if (!(srb->flags & SRB_SCSI_PASSTHRU)) {
 		qla4xxx_srb_free_dma(ha, srb);
 		mempool_free(srb, ha->srb_mempool);
 	}
-
 	cmd->scsi_done(cmd);
 }
 
 /**
- * sp_put - Decrement reference count and call callback.
- * @ha: Pointer to host adapter structure.
- * @sp: Pointer to srb structure
- **/
-void sp_put(struct scsi_qla_host *ha, struct srb *sp)
-{
-	if (atomic_read(&sp->ref_count) == 0) {
-		DEBUG2(printk("%s: SP->ref_count ZERO\n", __func__));
-		DEBUG2(BUG());
-		return;
-	}
-	if (!atomic_dec_and_test(&sp->ref_count)) {
-		return;
-	}
-	qla4xxx_srb_compl(ha, sp);
-}
-
-/**
- * sp_get - Increment reference count of the specified sp.
- * @sp: Pointer to srb structure
- **/
-void sp_get(struct srb *sp)
-{
-	atomic_inc(&sp->ref_count);
-}
-
-/**
  * qla4xxx_queuecommand - scsi layer issues scsi command to driver.
  * @cmd: Pointer to Linux's SCSI command structure
  * @done_fn: Function that the driver calls to notify the SCSI mid-layer
@@ -491,6 +607,14 @@ static int qla4xxx_queuecommand(struct s
 	struct srb *srb;
 	int rval;
 
+	if (test_bit(AF_EEH_BUSY, &ha->flags)) {
+		if (test_bit(AF_PCI_CHANNEL_IO_PERM_FAILURE, &ha->flags))
+			cmd->result = DID_NO_CONNECT << 16;
+		else
+			cmd->result = DID_REQUEUE << 16;
+		goto qc_fail_command;
+	}
+
 	if (!sess) {
 		cmd->result = DID_IMM_RETRY << 16;
 		goto qc_fail_command;
@@ -503,14 +627,22 @@ static int qla4xxx_queuecommand(struct s
 	}
 
 	if (atomic_read(&ddb_entry->state) != DDB_STATE_ONLINE) {
-		if ((atomic_read(&ddb_entry->state) == DDB_STATE_DEAD)) {
+		if (atomic_read(&ddb_entry->state) == DDB_STATE_DEAD) {
 			cmd->result = DID_NO_CONNECT << 16;
 			goto qc_fail_command;
 		}
 		return SCSI_MLQUEUE_TARGET_BUSY;
 	}
 
-	if (test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags))
+	if (test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags) ||
+	    test_bit(DPC_RESET_ACTIVE, &ha->dpc_flags) ||
+	    test_bit(DPC_RESET_HA, &ha->dpc_flags) ||
+	    test_bit(DPC_HA_UNRECOVERABLE, &ha->dpc_flags) ||
+	    test_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags) ||
+	    test_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags) ||
+	    test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags) ||
+	    !test_bit(AF_ONLINE, &ha->flags) ||
+	    test_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags))
 		goto qc_host_busy;
 
 	spin_unlock_irq(ha->host->host_lock);
@@ -559,7 +691,7 @@ static void qla4xxx_mem_free(struct scsi
 
 	if (ha->gen_req_rsp_iocb)
 		dma_free_coherent(&ha->pdev->dev, PAGE_SIZE,
-				ha->gen_req_rsp_iocb, ha->gen_req_rsp_iocb_dma);
+			ha->gen_req_rsp_iocb, ha->gen_req_rsp_iocb_dma);
 
 	while (!list_empty(&ha->async_iocb_list)) {
 		ptr = ha->async_iocb_list.next;
@@ -568,6 +700,9 @@ static void qla4xxx_mem_free(struct scsi
 		kfree(apdu_iocb);
 	}
 
+	if(ha->fw_dump)
+		vfree(ha->fw_dump);
+
 	ha->queues_len = 0;
 	ha->queues = NULL;
 	ha->queues_dma = 0;
@@ -577,6 +712,8 @@ static void qla4xxx_mem_free(struct scsi
 	ha->response_dma = 0;
 	ha->shadow_regs = NULL;
 	ha->shadow_regs_dma = 0;
+	ha->fw_dump = NULL;
+	ha->fw_dump_size = 0;
 
 	/* Free srb pool. */
 	if (ha->srb_mempool)
@@ -584,9 +721,20 @@ static void qla4xxx_mem_free(struct scsi
 
 	ha->srb_mempool = NULL;
 
+	/* Free DMA Pool for Passthru IOCBs */
+	if (ha->pt_iocb_dmapool) {
+		dma_pool_destroy(ha->pt_iocb_dmapool);
+		ha->pt_iocb_dmapool = NULL;
+	}
+
 	/* release io space registers  */
-	if (ha->reg)
+	if (is_qla8022(ha)) {
+		if (ha->nx_pcibase)
+			iounmap(
+			    (struct device_reg_82xx __iomem *)ha->nx_pcibase);
+	} else if (ha->reg)
 		iounmap(ha->reg);
+
 	pci_release_regions(ha->pdev);
 }
 
@@ -600,18 +748,17 @@ static void qla4xxx_mem_free(struct scsi
 static int qla4xxx_mem_alloc(struct scsi_qla_host *ha)
 {
 	unsigned long align;
+	__u8 name[24];
 
 	/* Allocate contiguous block of DMA memory for queues. */
-	ha->queues_len = ((REQUEST_QUEUE_DEPTH * QUEUE_SIZE) +
-			  (RESPONSE_QUEUE_DEPTH * QUEUE_SIZE) +
-			  sizeof(struct shadow_regs) +
-			  MEM_ALIGN_VALUE +
-			  (PAGE_SIZE - 1)) & ~(PAGE_SIZE - 1);
+	ha->queues_len = ((ha->maxcmds * QUEUE_SIZE) +
+		(ha->response_qdepth * QUEUE_SIZE) +
+		sizeof(struct shadow_regs) +
+		(PAGE_SIZE - 1)) & ~(PAGE_SIZE - 1);
 	ha->queues = dma_alloc_coherent(&ha->pdev->dev, ha->queues_len,
 					&ha->queues_dma, GFP_KERNEL);
 	if (ha->queues == NULL) {
-		dev_warn(&ha->pdev->dev,
-			"Memory Allocation failed - queues.\n");
+		ql4_warn(ha, "Memory Allocation failed - queues.\n");
 
 		goto mem_alloc_error_exit;
 	}
@@ -622,43 +769,54 @@ static int qla4xxx_mem_alloc(struct scsi
 	 * multiple of the request-ring size (in bytes).
 	 */
 	align = 0;
-	if ((unsigned long)ha->queues_dma & (MEM_ALIGN_VALUE - 1))
-		align = MEM_ALIGN_VALUE - ((unsigned long)ha->queues_dma &
-					   (MEM_ALIGN_VALUE - 1));
+	if (!is_qla8022(ha)) {
+		if ((unsigned long)ha->queues_dma & (MEM_ALIGN_VALUE - 1))
+			align = MEM_ALIGN_VALUE - ((unsigned long)ha->queues_dma &
+					(MEM_ALIGN_VALUE - 1));
+	}
 
 	/* Update request and response queue pointers. */
 	ha->request_dma = ha->queues_dma + align;
 	ha->request_ring = (struct queue_entry *) (ha->queues + align);
+
 	ha->response_dma = ha->queues_dma + align +
-		(REQUEST_QUEUE_DEPTH * QUEUE_SIZE);
+		(ha->maxcmds * QUEUE_SIZE);
 	ha->response_ring = (struct queue_entry *) (ha->queues + align +
-						    (REQUEST_QUEUE_DEPTH *
-						     QUEUE_SIZE));
+		(ha->maxcmds * QUEUE_SIZE));
+
 	ha->shadow_regs_dma = ha->queues_dma + align +
-		(REQUEST_QUEUE_DEPTH * QUEUE_SIZE) +
-		(RESPONSE_QUEUE_DEPTH * QUEUE_SIZE);
+		(ha->maxcmds * QUEUE_SIZE) +
+		(ha->response_qdepth * QUEUE_SIZE);
 	ha->shadow_regs = (struct shadow_regs *) (ha->queues + align +
-						  (REQUEST_QUEUE_DEPTH *
-						   QUEUE_SIZE) +
-						  (RESPONSE_QUEUE_DEPTH *
-						   QUEUE_SIZE));
+		(ha->maxcmds * QUEUE_SIZE) +
+		(ha->response_qdepth * QUEUE_SIZE));
 
 	/* Allocate memory for srb pool. */
 	ha->srb_mempool = mempool_create(SRB_MIN_REQ, mempool_alloc_slab,
 					 mempool_free_slab, srb_cachep);
 	if (ha->srb_mempool == NULL) {
-		dev_warn(&ha->pdev->dev,
-			"Memory Allocation failed - SRB Pool.\n");
-
+		ql4_warn(ha, "Memory Allocation failed - SRB Pool.\n");
 		goto mem_alloc_error_exit;
 	}
 
+	/* Allocate memory for async pdus. */
 	ha->gen_req_rsp_iocb = dma_alloc_coherent(&ha->pdev->dev, PAGE_SIZE,
-					&ha->gen_req_rsp_iocb_dma, GFP_KERNEL);
+		&ha->gen_req_rsp_iocb_dma, GFP_KERNEL);
 	if (ha->gen_req_rsp_iocb == NULL) {
 		dev_warn(&ha->pdev->dev,
-				"Memory Allocation failed - gen_req_rsp_iocb.\n");
-
+			"Memory Allocation failed - gen_req_rsp_iocb.\n");
+		goto mem_alloc_error_exit;
+	}
+	
+	/* Create DMA pool for Passthru IOCBs */
+	snprintf(name, sizeof(name), "%s_iocb_%d", DRIVER_NAME, 
+							ha->pdev->device);
+	ha->pt_iocb_dmapool = dma_pool_create(name, &ha->pdev->dev, PAGE_SIZE,
+					sizeof(struct passthru0), 0);
+
+	if (ha->pt_iocb_dmapool == NULL) {
+		dev_warn(&ha->pdev->dev,
+			"Memory Allocation failed - Passthru IOCB dmapool.\n");
 		goto mem_alloc_error_exit;
 	}
 
@@ -670,13 +828,201 @@ mem_alloc_error_exit:
 }
 
 /**
+ * qla4_8xxx_check_fw_alive  - Check firmware health
+ * @ha: Pointer to host adapter structure.
+ *
+ * Context: Interrupt
+ **/
+void qla4_8xxx_check_fw_alive(struct scsi_qla_host *ha)
+{
+	uint32_t fw_heartbeat_counter, halt_status;
+
+	fw_heartbeat_counter = qla4_8xxx_rd_32(ha, QLA82XX_PEG_ALIVE_COUNTER);
+	/* If PEG_ALIVE_COUNTER is 0xffffffff, AER/EEH is in progress, ignore */
+	if (fw_heartbeat_counter == 0xffffffff) {
+		DEBUG2(ql4_warn(ha, "%s: Device in frozen "
+		    "state, QLA82XX_PEG_ALIVE_COUNTER is 0xffffffff\n",
+		    __func__));
+		return;
+	}
+
+	if (ha->fw_heartbeat_counter == fw_heartbeat_counter) {
+		ha->seconds_since_last_heartbeat++;
+		/* FW not alive after 2 seconds */
+		if (ha->seconds_since_last_heartbeat == 2) {
+			ha->seconds_since_last_heartbeat = 0;
+			ql4_info(ha,
+				"disabling pause transmit on port 0 & 1.\n");
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x98,
+			    CRB_NIU_XG_PAUSE_CTL_P0|CRB_NIU_XG_PAUSE_CTL_P1);
+			halt_status = qla4_8xxx_rd_32(ha,
+			    QLA82XX_PEG_HALT_STATUS1);
+
+			ql4_printk(KERN_INFO, ha,
+			    "scsi(%ld): %s, Dumping hw/fw registers:\n "
+			    " PEG_HALT_STATUS1: 0x%x, PEG_HALT_STATUS2: 0x%x,\n "
+			    " PEG_NET_0_PC: 0x%x, PEG_NET_1_PC: 0x%x,\n "
+			    " PEG_NET_2_PC: 0x%x, PEG_NET_3_PC: 0x%x,\n "
+			    " PEG_NET_4_PC: 0x%x\n",
+			    ha->host_no, __func__, halt_status,
+			    qla4_8xxx_rd_32(ha, QLA82XX_PEG_HALT_STATUS2),
+			    qla4_8xxx_rd_32(ha, QLA82XX_CRB_PEG_NET_0 + 0x3c),
+			    qla4_8xxx_rd_32(ha, QLA82XX_CRB_PEG_NET_1 + 0x3c),
+			    qla4_8xxx_rd_32(ha, QLA82XX_CRB_PEG_NET_2 + 0x3c),
+			    qla4_8xxx_rd_32(ha, QLA82XX_CRB_PEG_NET_3 + 0x3c),
+			    qla4_8xxx_rd_32(ha, QLA82XX_CRB_PEG_NET_4 + 0x3c));
+
+			if (LSW(MSB(halt_status)) == 0x67)
+				ql4_printk(KERN_ERR, ha, "scsi%ld: %s: "
+					"Firmware aborted with error "
+					"code 0x00006700. Device is "
+					"being reset\n", ha->host_no,
+					__func__);
+
+			/* Since we cannot change dev_state in interrupt
+			 * context, set appropriate DPC flag then wakeup
+			 * DPC */
+			if (halt_status & HALT_STATUS_UNRECOVERABLE)
+				set_bit(DPC_HA_UNRECOVERABLE, &ha->dpc_flags);
+			else {
+				ql4_info(ha, "%s: detect abort needed!\n",
+				    	__func__);
+				set_bit(DPC_RESET_HA, &ha->dpc_flags);
+			}
+			qla4xxx_wake_dpc(ha);
+			qla4xxx_mailbox_premature_completion(ha);
+		}
+	} else
+		ha->seconds_since_last_heartbeat = 0;
+
+	ha->fw_heartbeat_counter = fw_heartbeat_counter;
+}
+
+/*
+ * qla4_8xxx_check_temp
+ * Check the ISP82XX temperature.
+ * Input:
+ *	ha  = adapter block pointer.
+ * Note: The caller should not hold the idc lock.
+ *
+ */
+
+int
+qla4_8xxx_check_temp(struct scsi_qla_host *ha)
+{
+	uint32_t temp, temp_state, temp_val;
+	int status = 0;
+
+	temp = qla4_8xxx_rd_32(ha, CRB_TEMP_STATE);
+
+	temp_state = qla82xx_get_temp_state(temp);
+	temp_val = qla82xx_get_temp_val(temp);
+
+	if (temp_state == QLA82XX_TEMP_PANIC) {
+		ql4_info(ha,
+			"Device temperature %d degrees C exceeds"
+			" maximum allowed. Hardware has been shut down.\n",
+			temp_val);
+		status = 1;
+	} else if (temp_state == QLA82XX_TEMP_WARN) {
+		if (ha->temperature == QLA82XX_TEMP_NORMAL) {
+			ql4_info(ha,
+				"Device temperature %d degrees C "
+				"exceeds operating range."
+				" Immediate action needed.\n",
+				temp_val);
+		}
+	} else {
+		if (ha->temperature == QLA82XX_TEMP_WARN) {
+			ql4_info(ha,
+				"Device temperature is now %d degrees C"
+				" in normal range.\n",
+				temp_val);
+		}
+	}
+	ha->temperature = temp_state;
+	return status;
+}
+
+/**
+ * qla4_8xxx_watchdog - Poll dev state
+ * @ha: Pointer to host adapter structure.
+ *
+ * Context: Interrupt
+ **/
+void qla4_8xxx_watchdog(struct scsi_qla_host *ha)
+{
+	uint32_t dev_state;
+
+	dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+
+	/* don't poll if reset is going on */
+	if (!(test_bit(DPC_RESET_ACTIVE, &ha->dpc_flags) ||
+		test_bit(DPC_RESET_HA, &ha->dpc_flags) ||
+		test_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags))) {
+		if (qla4_8xxx_check_temp(ha)) {
+			ql4_info(ha,
+				"disabling pause transmit on port 0 & 1.\n");
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_NIU + 0x98,
+			    CRB_NIU_XG_PAUSE_CTL_P0|CRB_NIU_XG_PAUSE_CTL_P1);
+			set_bit(DPC_HA_UNRECOVERABLE, &ha->dpc_flags);
+			qla4xxx_wake_dpc(ha);
+		} else if (dev_state == QLA82XX_DEV_NEED_RESET) {
+			if (!ql4xdontresethba) {
+				ql4_info(ha, "%s: HW State: NEED RESET!\n",
+					__func__);
+				set_bit(DPC_RESET_HA, &ha->dpc_flags);
+				qla4xxx_wake_dpc(ha);
+				qla4xxx_mailbox_premature_completion(ha);
+			}
+		} else if (dev_state == QLA82XX_DEV_NEED_QUIESCENT &&
+		    !test_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags)) {
+			ql4_err(ha, "%s: HW State: NEED QUIESCENT detected "
+					"flags=0x%lx, dpc_flags=0x%lx\n",
+					__func__, ha->flags, ha->dpc_flags);
+			set_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags);
+			qla4xxx_wake_dpc(ha);
+		} else if ((dev_state == QLA82XX_DEV_QUIESCENT) &&
+			    test_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags)) {
+			qla4xxx_wake_dpc(ha);
+			
+		} else  {
+			/* Check firmware health */
+			qla4_8xxx_check_fw_alive(ha);
+		}
+	}
+}
+
+/**
  * qla4xxx_timer - checks every second for work to do.
  * @ha: Pointer to host adapter structure.
  **/
-static void qla4xxx_timer(struct scsi_qla_host *ha)
+void qla4xxx_timer(struct scsi_qla_host *ha)
 {
 	struct ddb_entry *ddb_entry, *dtemp;
 	int start_dpc = 0;
+	uint16_t w;
+
+	/* If we are in the middle of AER/EEH processing
+	 * skip any processing and reschedule the timer
+	 */
+	if (test_bit(AF_EEH_BUSY, &ha->flags)) {
+		mod_timer(&ha->timer, jiffies + HZ);
+		return;
+	}
+
+	/* Hardware read to trigger an EEH error during mailbox waits. */
+	if (!pci_channel_offline(ha->pdev))
+		pci_read_config_word(ha->pdev, PCI_VENDOR_ID, &w);
+
+	if (test_bit(AF_HA_REMOVAL, &ha->flags)) {
+		DEBUG2(ql4_info(ha, "%s exited. HBA GOING AWAY\n", __func__));
+		return;
+	}
+
+	if (is_qla8022(ha)) {
+		qla4_8xxx_watchdog(ha);
+	}
 
 	/* Search for relogin's to time-out and port down retry. */
 	list_for_each_entry_safe(ddb_entry, dtemp, &ha->ddb_list, list) {
@@ -687,16 +1033,16 @@ static void qla4xxx_timer(struct scsi_ql
 			if (atomic_read(&ddb_entry->retry_relogin_timer) !=
 			    INVALID_ENTRY) {
 				if (atomic_read(&ddb_entry->retry_relogin_timer)
-				    		== 0) {
+						== 0) {
 					atomic_set(&ddb_entry->
 						retry_relogin_timer,
 						INVALID_ENTRY);
 					set_bit(DPC_RELOGIN_DEVICE,
 						&ha->dpc_flags);
 					set_bit(DF_RELOGIN, &ddb_entry->flags);
-					DEBUG2(printk("scsi%ld: %s: index [%d]"
+					DEBUG2(ql4_info(ha, "%s: ddb [%d]"
 						      " login device\n",
-						      ha->host_no, __func__,
+						      __func__,
 						      ddb_entry->fw_ddb_index));
 				} else
 					atomic_dec(&ddb_entry->
@@ -717,20 +1063,17 @@ static void qla4xxx_timer(struct scsi_ql
 			    DDB_DS_SESSION_FAILED) {
 				/* Reset retry relogin timer */
 				atomic_inc(&ddb_entry->relogin_retry_count);
-				DEBUG2(printk("scsi%ld: index[%d] relogin"
+				DEBUG2(ql4_info(ha, "ddb [%d] relogin"
 					      " timed out-retrying"
 					      " relogin (%d)\n",
-					      ha->host_no,
 					      ddb_entry->fw_ddb_index,
 					      atomic_read(&ddb_entry->
 							  relogin_retry_count))
 					);
 				start_dpc++;
-				DEBUG(printk("scsi%ld:%d:%d: index [%d] "
+				DEBUG(ql4_info(ha, "ddb [%d] "
 					     "initate relogin after"
 					     " %d seconds\n",
-					     ha->host_no, ddb_entry->bus,
-					     ddb_entry->target,
 					     ddb_entry->fw_ddb_index,
 					     ddb_entry->default_time2wait + 4)
 					);
@@ -741,33 +1084,81 @@ static void qla4xxx_timer(struct scsi_ql
 		}
 	}
 
-	/* Check for heartbeat interval. */
-	if (ha->firmware_options & FWOPT_HEARTBEAT_ENABLE &&
-	    ha->heartbeat_interval != 0) {
-		ha->seconds_since_last_heartbeat++;
-		if (ha->seconds_since_last_heartbeat >
-		    ha->heartbeat_interval + 2)
-			set_bit(DPC_RESET_HA, &ha->dpc_flags);
+	if (!is_qla8022(ha)) {
+		/* Check for heartbeat interval. */
+		if (ha->firmware_options & FWOPT_HEARTBEAT_ENABLE &&
+		    ha->heartbeat_interval != 0) {
+			ha->seconds_since_last_heartbeat++;
+			if (ha->seconds_since_last_heartbeat >
+			    ha->heartbeat_interval + 2)
+				set_bit(DPC_RESET_HA, &ha->dpc_flags);
+		}
 	}
 
+	/* Check for iSNS actions */
+	if (adapter_up(ha)) {
+		/* Re-register with the iSNS server if two times
+		 * the esi interval has elapsed-- to prevent
+		 * iSNS server from de-registering us. */
+		if (test_bit(ISNS_FLAG_ISNS_SRV_REGISTERED,
+		    &ha->isns.flags) &&
+		    atomic_read(&ha->isns.esi_timer)) {
+			if (atomic_dec_and_test(&ha->isns.esi_timer)) {
+				ql4_info(ha, "ESI timer expired. "
+				    "Re-register with iSNS server\n");
+				set_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags);
+			}
+		}
+
+		/* Decrement the restart timer.  When it has elapsed,
+		 * start the iSNS server */
+		if ((atomic_read(&ha->isns.state) ==
+		    ISNS_STATE_RESTART_SRV_WAIT) &&
+		    atomic_read(&ha->isns.restart_timer) != 0) {
+			if (atomic_dec_and_test(&ha->isns.restart_timer)) {
+				set_bit(DPC_ISNS_START, &ha->dpc_flags);
+			}
+		}
+		else if (test_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+		    &ha->isns.flags) &&
+		    atomic_read(&ha->isns.state) ==
+		    ISNS_STATE_TCP_DISCONNECTED &&
+		    !test_bit(DPC_ISNS_RESTART, &ha->dpc_flags) &&
+		    !test_bit(DPC_ISNS_START, &ha->dpc_flags)) {
+			/* If iSNS is enabled in ISP, but no TCP connection
+			 * with an iSNS server has been established,
+			 * periodically poll for an iSNS server connection. */
+			ql4_isns_restart_timer(ha, ISNS_POLL_SVR_TOV);
+		}
+	}
 
 	/* Wakeup the dpc routine for this adapter, if needed. */
 	if ((start_dpc ||
 	     test_bit(DPC_RESET_HA, &ha->dpc_flags) ||
 	     test_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags) ||
 	     test_bit(DPC_RELOGIN_DEVICE, &ha->dpc_flags) ||
-	     test_bit(DPC_RESET_HA_DESTROY_DDB_LIST, &ha->dpc_flags) ||
+	     test_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags) ||
 	     test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags) ||
 	     test_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags) ||
+	     test_bit(DPC_LINK_CHANGED, &ha->dpc_flags) ||
+	     test_bit(DPC_HA_UNRECOVERABLE, &ha->dpc_flags) ||
+	     test_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags) ||
+	     test_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags) ||
+	     test_bit(DPC_ASYNC_ISCSI_PDU, &ha->dpc_flags) ||
+	     test_bit(DPC_DYNAMIC_LUN_SCAN, &ha->dpc_flags) ||
 	     test_bit(DPC_REMOVE_DEVICE, &ha->dpc_flags) ||
-	     test_bit(DPC_LINK_CHANGED, &ha->dpc_flags) ||
-	     test_bit(DPC_ASYNC_MSG_PDU, &ha->dpc_flags) ||
+	     test_bit(DPC_ISNS_RESTART, &ha->dpc_flags) ||
+	     test_bit(DPC_ISNS_START, &ha->dpc_flags) ||
+	     test_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags) ||
+	     test_bit(DPC_ISNS_DEREGISTER, &ha->dpc_flags) ||
+	     test_bit(DPC_ISNS_STOP, &ha->dpc_flags) ||
 	     test_bit(DPC_AEN, &ha->dpc_flags)) &&
+	     !test_bit(AF_DPC_SCHEDULED, &ha->flags) &&
 	     ha->dpc_thread) {
-		DEBUG2(printk("scsi%ld: %s: scheduling dpc routine"
+		DEBUG2(ql4_info(ha, "%s: scheduling dpc routine"
 			      " - dpc flags = 0x%lx\n",
-			      ha->host_no, __func__, ha->dpc_flags));
-		queue_work(ha->dpc_thread, &ha->dpc_work);
+			      __func__, ha->dpc_flags));
+		qla4xxx_wake_dpc(ha);
 	}
 
 	/* Reschedule timer thread to call us back in one second */
@@ -783,51 +1174,49 @@ static void qla4xxx_timer(struct scsi_ql
  * This routine stalls the driver until all outstanding commands are returned.
  * Caller must release the Hardware Lock prior to calling this routine.
  **/
-static int qla4xxx_cmd_wait(struct scsi_qla_host *ha)
+int qla4xxx_cmd_wait(struct scsi_qla_host *ha, uint32_t timeout)
 {
 	uint32_t index = 0;
-	int stat = QLA_SUCCESS;
 	unsigned long flags;
-	int wait_cnt = WAIT_CMD_TOV;	/*
-					 * Initialized for 30 seconds as we
-					 * expect all commands to retuned
-					 * ASAP.
-					 */
-
-	while (wait_cnt) {
+	unsigned long wtime;
+
+	if (timeout)
+		wtime = jiffies + (timeout * HZ);
+	else
+		wtime = jiffies + (WAIT_CMD_TOV * HZ);
+
+	DEBUG2(ql4_info(ha, "Wait up to %d seconds for cmds to "
+	    "complete\n", timeout ? timeout : WAIT_CMD_TOV));
+
+	while (!time_after_eq(jiffies, wtime)) {
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 		/* Find a command that hasn't completed. */
 		for (index = 1; index < MAX_SRBS; index++) {
-			if (ha->active_srb_array[index] != NULL)
+                        if (ha->active_srb_array[index] != NULL)
 				break;
 		}
 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 
 		/* If No Commands are pending, wait is complete */
-		if (index == ha->host->can_queue) {
-			break;
-		}
-
-		/* If we timed out on waiting for commands to come back
-		 * return ERROR.
-		 */
-		wait_cnt--;
-		if (wait_cnt == 0)
-			stat = QLA_ERROR;
-		else {
-			msleep(1000);
-		}
-	}			/* End of While (wait_cnt) */
-
-	return stat;
+		if (index == MAX_SRBS)
+			return QLA_SUCCESS;
+
+		msleep(1000);
+	}
+	/* If we timed out on waiting for commands to come back
+	 * return ERROR. */
+	return QLA_ERROR;
 }
 
-void qla4xxx_hw_reset(struct scsi_qla_host *ha)
+int qla4xxx_hw_reset(struct scsi_qla_host *ha)
 {
 	uint32_t ctrl_status;
 	unsigned long flags = 0;
 
-	DEBUG2(printk(KERN_ERR "scsi%ld: %s\n", ha->host_no, __func__));
+	DEBUG2(ql4_err(ha, "%s\n", __func__));
+
+	if (ql4xxx_lock_drvr_wait(ha) != QLA_SUCCESS)
+		return QLA_ERROR;
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 
@@ -844,6 +1233,7 @@ void qla4xxx_hw_reset(struct scsi_qla_ho
 	readl(&ha->reg->ctrl_status);
 
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+	return QLA_SUCCESS;
 }
 
 /**
@@ -854,11 +1244,14 @@ int qla4xxx_soft_reset(struct scsi_qla_h
 {
 	uint32_t max_wait_time;
 	unsigned long flags = 0;
-	int status = QLA_ERROR;
+	int status;
 	uint32_t ctrl_status;
 
-	qla4xxx_hw_reset(ha);
-
+	status = qla4xxx_hw_reset(ha);
+	if (status != QLA_SUCCESS)
+		return status;
+
+	status = QLA_ERROR;
 	/* Wait until the Network Reset Intr bit is cleared */
 	max_wait_time = RESET_INTR_TOV;
 	do {
@@ -873,10 +1266,8 @@ int qla4xxx_soft_reset(struct scsi_qla_h
 	} while ((--max_wait_time));
 
 	if ((ctrl_status & CSR_NET_RESET_INTR) != 0) {
-		DEBUG2(printk(KERN_WARNING
-			      "scsi%ld: Network Reset Intr not cleared by "
-			      "Network function, clearing it now!\n",
-			      ha->host_no));
+		DEBUG2(ql4_warn(ha, "Network Reset Intr not cleared by "
+			      "Network function, clearing it now!\n"));
 		spin_lock_irqsave(&ha->hardware_lock, flags);
 		writel(set_rmask(CSR_NET_RESET_INTR), &ha->reg->ctrl_status);
 		readl(&ha->reg->ctrl_status);
@@ -942,15 +1333,16 @@ int qla4xxx_soft_reset(struct scsi_qla_h
 }
 
 /**
- * qla4xxx_flush_active_srbs - returns all outstanding i/o requests to O.S.
+ * qla4xxx_abort_active_cmds - returns all outstanding i/o requests to O.S.
  * @ha: Pointer to host adapter structure.
+ * @res: returned scsi status
  *
  * This routine is called just prior to a HARD RESET to return all
  * outstanding commands back to the Operating System.
  * Caller should make sure that the following locks are released
  * before this calling routine: Hardware lock, and io_request_lock.
  **/
-static void qla4xxx_flush_active_srbs(struct scsi_qla_host *ha)
+static void qla4xxx_abort_active_cmds(struct scsi_qla_host *ha, int res)
 {
 	struct srb *srb;
 	int i;
@@ -958,77 +1350,127 @@ static void qla4xxx_flush_active_srbs(st
 
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 	for (i = 1; i < MAX_SRBS; i++) {
-		if ((srb = ha->active_srb_array[i]) != NULL) {
+		srb = ha->active_srb_array[i];	
+		if (srb != NULL) {
 			qla4xxx_del_from_active_array(ha, i);
-			srb->cmd->result = DID_RESET << 16;
-			sp_put(ha, srb);
+			srb->cmd->result = res;
+			kref_put(&srb->srb_ref, qla4xxx_srb_compl);
 		}
 	}
 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
-
+}
+
+void qla4xxx_dead_adapter_cleanup(struct scsi_qla_host *ha)
+{
+	clear_bit(AF_ONLINE, &ha->flags);
+
+	/* Disable the board */
+	ql4_info(ha, "Disabling the board\n");
+	qla4xxx_abort_active_cmds(ha, DID_NO_CONNECT << 16);
+	qla4xxx_mark_all_devices_missing(ha);
+	clear_bit(AF_INIT_DONE, &ha->flags);
 }
 
 /**
  * qla4xxx_recover_adapter - recovers adapter after a fatal error
  * @ha: Pointer to host adapter structure.
- * @renew_ddb_list: Indicates what to do with the adapter's ddb list
- *
- * renew_ddb_list value can be 0=preserve ddb list, 1=destroy and rebuild
- * ddb list.
  **/
-static int qla4xxx_recover_adapter(struct scsi_qla_host *ha,
-				uint8_t renew_ddb_list)
+static int qla4xxx_recover_adapter(struct scsi_qla_host *ha)
 {
-	int status;
+	int status = QLA_ERROR;
+	uint8_t reset_chip = 0;
 
 	/* Stall incoming I/O until we are done */
 	scsi_block_requests(ha->host);
+
+	DEBUG2(ql4_info(ha, "%s: Adapter OFFLINE\n", __func__));
 	clear_bit(AF_ONLINE, &ha->flags);
-	DEBUG2(dev_info(&ha->pdev->dev, "%s: adapter OFFLINE\n", __func__));
-
-	/* Wait for outstanding commands to complete.
-	 * Stalls the driver for max 30 secs
+
+	set_bit(DPC_RESET_ACTIVE, &ha->dpc_flags);
+
+	/* Block all sessions, so qla4xxx_iscsi_block_scsi_eh()
+	 * blocks device_reset and target_reset error handlers
+	 * till sessions become ACTIVE
 	 */
-	status = qla4xxx_cmd_wait(ha);
-
-	qla4xxx_disable_intrs(ha);
+	qla4xxx_mark_all_devices_missing(ha);
+
+	if (test_bit(DPC_RESET_HA, &ha->dpc_flags))
+		reset_chip = 1;
+
+	/* For the DPC_RESET_HA_INTR case (ISP-4xxx specific)
+	 * do not reset adapter, jump to initialize_adapter */
+	if (test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags)) {
+		status = QLA_SUCCESS;
+		goto recover_ha_init_adapter;
+	}
+
+	/* For the ISP-82xx adapter, issue a stop_firmware if invoked
+	 * from eh_host_reset or ioctl module */
+	if (is_qla8022(ha) && !reset_chip &&
+	    test_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags)) {
+
+		DEBUG2(ql4_info(ha, "%s - Performing stop_firmware...\n",
+				__func__));
+		status = ha->isp_ops->reset_firmware(ha);
+		if (status == QLA_SUCCESS) {
+			if (!test_bit(AF_FW_RECOVERY, &ha->flags))
+				qla4xxx_cmd_wait(ha, 5);
+			ha->isp_ops->disable_intrs(ha);
+			qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
+			qla4xxx_abort_active_cmds(ha, DID_RESET << 16);
+		} else {
+			/* If the stop_firmware fails then
+			 * reset the entire chip */
+			reset_chip = 1;
+			clear_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+			set_bit(DPC_RESET_HA, &ha->dpc_flags);
+		}
+	}
+
+	/* Issue full chip reset if recovering from a catastrophic error,
+	 * or if stop_firmware fails for ISP-82xx.
+	 * This is the default case for ISP-4xxx */
+	if (!is_qla8022(ha) || reset_chip) {
+		if (!test_bit(AF_FW_RECOVERY, &ha->flags))
+			qla4xxx_cmd_wait(ha, 5);
+		qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
+		qla4xxx_abort_active_cmds(ha, DID_RESET << 16);
+		DEBUG2(ql4_info(ha, "%s - Performing chip reset..\n",
+				__func__));
+		status = ha->isp_ops->reset_chip(ha);
+	}
 
 	/* Flush any pending ddb changed AENs */
 	qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
 
-	qla4xxx_flush_active_srbs(ha);
-
-	/* Reset the firmware.	If successful, function
-	 * returns with ISP interrupts enabled.
-	 */
-	DEBUG2(printk("scsi%ld: %s - Performing soft reset..\n",
-		      ha->host_no, __func__));
-	if (ql4xxx_lock_drvr_wait(ha) == QLA_SUCCESS)
-		status = qla4xxx_soft_reset(ha);
-	else
-		status = QLA_ERROR;
-
-	/* Flush any pending ddb changed AENs */
-	qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
-
-	/* Re-initialize firmware. If successful, function returns
-	 * with ISP interrupts enabled */
+recover_ha_init_adapter:
+	/* Upon successful firmware/chip reset, re-initialize the adapter */
 	if (status == QLA_SUCCESS) {
-		/* If successful, AF_ONLINE flag set in
-		 * qla4xxx_initialize_adapter */
-		status = qla4xxx_initialize_adapter(ha, renew_ddb_list);
+		/* For ISP-4xxx, force function 1 to always initialize
+		 * before function 3 to prevent both funcions from
+		 * stepping on top of the other */
+		if (!is_qla8022(ha) && (ha->mac_index == 3))
+			ssleep(6);
+
+		/* NOTE: AF_ONLINE flag set upon successful completion of
+		 *       qla4xxx_initialize_adapter */
+		status = qla4xxx_initialize_adapter(ha, PRESERVE_DDB_LIST);
 	}
 
-	/* Failed adapter initialization?
-	 * Retry reset_ha only if invoked via DPC (DPC_RESET_HA) */
-	if ((test_bit(AF_ONLINE, &ha->flags) == 0) &&
-	    (test_bit(DPC_RESET_HA, &ha->dpc_flags))) {
+	/* Retry failed adapter initialization, if necessary
+	 * Do not retry initialize_adapter for RESET_HA_INTR (ISP-4xxx specific)
+	 * case to prevent ping-pong resets between functions */
+	if (!test_bit(AF_ONLINE, &ha->flags) &&
+	    !test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags)) {
 		/* Adapter initialization failed, see if we can retry
-		 * resetting the ha */
+		 * resetting the ha.
+		 * Since we don't want to block the DPC for too long
+		 * with multiple resets in the same thread,
+		 * utilize DPC to retry */
 		if (!test_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags)) {
 			ha->retry_reset_ha_cnt = MAX_RESET_HA_RETRIES;
-			DEBUG2(printk("scsi%ld: recover adapter - retrying "
-				      "(%d) more times\n", ha->host_no,
+			DEBUG2(ql4_info(ha, "recover adapter - retrying "
+				      "(%d) more times\n",
 				      ha->retry_reset_ha_cnt));
 			set_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags);
 			status = QLA_ERROR;
@@ -1036,9 +1478,8 @@ static int qla4xxx_recover_adapter(struc
 			if (ha->retry_reset_ha_cnt > 0) {
 				/* Schedule another Reset HA--DPC will retry */
 				ha->retry_reset_ha_cnt--;
-				DEBUG2(printk("scsi%ld: recover adapter - "
+				DEBUG2(ql4_info(ha, "recover adapter - "
 					      "retry remaining %d\n",
-					      ha->host_no,
 					      ha->retry_reset_ha_cnt));
 				status = QLA_ERROR;
 			}
@@ -1046,42 +1487,43 @@ static int qla4xxx_recover_adapter(struc
 			if (ha->retry_reset_ha_cnt == 0) {
 				/* Recover adapter retries have been exhausted.
 				 * Adapter DEAD */
-				DEBUG2(printk("scsi%ld: recover adapter "
-					      "failed - board disabled\n",
-					      ha->host_no));
-				qla4xxx_flush_active_srbs(ha);
+				DEBUG2(ql4_info(ha, "recover adapter "
+					      "failed - board disabled\n"));
+				qla4xxx_dead_adapter_cleanup(ha);
 				clear_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags);
 				clear_bit(DPC_RESET_HA, &ha->dpc_flags);
-				clear_bit(DPC_RESET_HA_DESTROY_DDB_LIST,
+				clear_bit(DPC_RESET_HA_FW_CONTEXT,
 					  &ha->dpc_flags);
 				status = QLA_ERROR;
 			}
 		}
 	} else {
 		clear_bit(DPC_RESET_HA, &ha->dpc_flags);
-		clear_bit(DPC_RESET_HA_DESTROY_DDB_LIST, &ha->dpc_flags);
+		clear_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
 		clear_bit(DPC_RETRY_RESET_HA, &ha->dpc_flags);
 	}
 
 	ha->adapter_error_count++;
 
-	if (status == QLA_SUCCESS) {
-		qla4xxx_enable_intrs(ha);
-		scsi_unblock_requests(ha->host);
-	}
-
-	DEBUG2(printk("scsi%ld: recover adapter: %s\n", ha->host_no,
-			status == QLA_ERROR ? "FAILED" : "SUCCEDED"));
+	if (test_bit(AF_ONLINE, &ha->flags))
+		ha->isp_ops->enable_intrs(ha);
+
+	scsi_unblock_requests(ha->host);
+
+	clear_bit(DPC_RESET_ACTIVE, &ha->dpc_flags);
+	DEBUG2(ql4_info(ha, "recover adapter: %s\n",
+	    status == QLA_ERROR ? "FAILED" : "SUCCEDED"));
+
 	return status;
 }
 
 /*
- * qla4xxx_async_iocbs - processes ASYNC PDU IOCBS, if they are greater in
+ * qla4xxx_process_async_pdu_iocb - processes ASYNC PDU IOCBS, if they are greater in
  * length than 48 bytes (i.e., more than just the iscsi header). Used for
  * unsolicited pdus received from target.
  */
-static void qla4xxx_async_iocbs(struct scsi_qla_host *ha,
-				 struct async_msg_pdu_iocb *amsg_pdu_iocb)
+static void qla4xxx_process_async_iscsi_pdu_iocb(struct scsi_qla_host *ha,
+                        struct async_msg_pdu_iocb *amsg_pdu_iocb)
 {
 	struct iscsi_hdr *hdr;
 	struct async_pdu_iocb *apdu;
@@ -1091,7 +1533,7 @@ static void qla4xxx_async_iocbs(struct s
 	uint32_t offset;
 	struct passthru0 *pthru0_iocb;
 	struct ddb_entry *ddb_entry = NULL;
-	ASYNC_PDU_SENSE *pdu_sense;
+	struct async_pdu_sense *pdu_sense;
 
 	uint8_t using_prealloc = 1;
 	uint8_t async_event_type;
@@ -1099,110 +1541,121 @@ static void qla4xxx_async_iocbs(struct s
 	apdu = (struct async_pdu_iocb *)amsg_pdu_iocb->iocb;
 	hdr = (struct iscsi_hdr *)apdu->iscsi_pdu_hdr;
 	len = hdr->hlength + hdr->dlength[2] +
-	       (hdr->dlength[1]<<8) + (hdr->dlength[0]<<16);
+		(hdr->dlength[1]<<8) + (hdr->dlength[0]<<16);
 
 	offset = sizeof(struct passthru0) + sizeof(struct passthru_status);
 	if (len <= (PAGE_SIZE - offset)) {
-	       buf_addr_dma = ha->gen_req_rsp_iocb_dma + offset;
-	       buf_addr = (uint8_t *)ha->gen_req_rsp_iocb + offset;
+		buf_addr_dma = ha->gen_req_rsp_iocb_dma + offset;
+		buf_addr = (uint8_t *)ha->gen_req_rsp_iocb + offset;
 	} else {
-	       using_prealloc = 0;
-	       buf_addr = dma_alloc_coherent(&ha->pdev->dev, len,
-				       &buf_addr_dma, GFP_KERNEL);
-	       if (!buf_addr) {
-		       dev_info(&ha->pdev->dev,
-			       "%s: dma_alloc_coherent failed\n", __func__);
-		       return;
-	       }
+		using_prealloc = 0;
+		buf_addr = dma_alloc_coherent(&ha->pdev->dev, len,
+			&buf_addr_dma, GFP_KERNEL);
+		if (!buf_addr) {
+			dev_info(&ha->pdev->dev,
+				"%s: dma_alloc_coherent failed\n", __func__);
+			return;
+		}
 	}
 	/* Create the pass-thru0 iocb */
 	pthru0_iocb = ha->gen_req_rsp_iocb;
 	memset(pthru0_iocb, 0, offset);
-	pthru0_iocb->hdr.entryType = ET_PASSTHRU0;
-	pthru0_iocb->hdr.entryCount = 1;
+
+	pthru0_iocb->hdr.entry_type = ET_PASSTHRU0;
+	pthru0_iocb->hdr.entry_count = 1;
 	pthru0_iocb->target = cpu_to_le16(apdu->target_id);
-	pthru0_iocb->controlFlags =
-	       cpu_to_le16(PT_FLAG_ISCSI_PDU | PT_FLAG_WAIT_4_RESPONSE);
+	pthru0_iocb->ctrl_flags =
+		cpu_to_le16(PT_FLAG_ISCSI_PDU | PT_FLAG_WAIT_4_RESPONSE);
 	pthru0_iocb->timeout = cpu_to_le16(PT_DEFAULT_TIMEOUT);
-	pthru0_iocb->inDataSeg64.base.addrHigh =
-	       cpu_to_le32(MSDW(buf_addr_dma));
-	pthru0_iocb->inDataSeg64.base.addrLow =
-	       cpu_to_le32(LSDW(buf_addr_dma));
-	pthru0_iocb->inDataSeg64.count = cpu_to_le32(len);
+	pthru0_iocb->in_data_seg64.base.addr_hi =
+		cpu_to_le32(MSDW(buf_addr_dma));
+	pthru0_iocb->in_data_seg64.base.addr_lo =
+		cpu_to_le32(LSDW(buf_addr_dma));
+	pthru0_iocb->in_data_seg64.count = cpu_to_le32(len);
 	pthru0_iocb->async_pdu_handle = cpu_to_le32(apdu->async_pdu_handle);
 
 	dev_info(&ha->pdev->dev,
-		       "%s: qla4xxx_issue_iocb\n", __func__);
+		"%s: qla4xxx_issue_iocb\n", __func__);
 
 	if (qla4xxx_issue_iocb(ha, sizeof(struct passthru0),
-	       ha->gen_req_rsp_iocb_dma) != QLA_SUCCESS) {
-	       dev_info(&ha->pdev->dev,
-		       "%s: qla4xxx_issue_iocb failed\n", __func__);
-	       goto exit_async_pdu_iocb;
+	    ha->gen_req_rsp_iocb_dma) != QLA_SUCCESS) {
+		dev_info(&ha->pdev->dev,
+			"%s: qla4xxx_issue_iocb failed\n", __func__);
+		goto exit_async_pdu_iocb;
 	}
 
 	async_event_type = ((struct iscsi_async *)hdr)->async_event;
-	pdu_sense = (ASYNC_PDU_SENSE *)buf_addr;
+	pdu_sense = (struct async_pdu_sense *)buf_addr;
 
 	switch (async_event_type) {
 	case ISCSI_ASYNC_MSG_SCSI_EVENT:
-	       dev_info(&ha->pdev->dev,
-			       "%s: async msg event 0x%x processed\n"
-			       , __func__, async_event_type);
-
-	       qla4xxx_dump_buffer(buf_addr, len);
+		dev_info(&ha->pdev->dev,
+			"%s: async msg event 0x%x processed\n"
+			, __func__, async_event_type);
 
 		if (pdu_sense->sense_data[12] == 0x3F) {
 			if (pdu_sense->sense_data[13] == 0x0E) {
 				/* reported luns data has changed */
 				uint16_t fw_index = apdu->target_id;
 
-				ddb_entry = qla4xxx_lookup_ddb_by_fw_index(ha, fw_index);
+				ddb_entry =
+					qla4xxx_lookup_ddb_by_fw_index(ha,
+								fw_index);
 				if (ddb_entry == NULL) {
 					dev_info(&ha->pdev->dev,
-						 "%s: No DDB entry for index [%d]\n"
-						 , __func__, fw_index);
+						"%s: No DDB entry for index "
+						"[%d]\n" , __func__, fw_index);
 					goto exit_async_pdu_iocb;
 				}
-				if (ddb_entry->fw_ddb_device_state != DDB_DS_SESSION_ACTIVE) {
+				if (ddb_entry->fw_ddb_device_state !=
+							DDB_DS_SESSION_ACTIVE) {
 					dev_info(&ha->pdev->dev,
-						"scsi%ld: %s: No Active Session for index [%d]\n",
-						ha->host_no, __func__, fw_index);
+						"scsi%ld: %s: No Active Session"
+						" for index [%d]\n",
+						ha->host_no, __func__,
+						fw_index);
 					goto exit_async_pdu_iocb;
 				}
 
 				/* report new lun to kernel */
-				scsi_scan_target(&ddb_entry->sess->dev, 0,
-						 ddb_entry->sess->target_id,
-						 SCAN_WILD_CARD, 0);
+				if (test_bit(AF_ONLINE, &ha->flags))
+					scsi_scan_target(&ddb_entry->sess->dev, 0,
+						ddb_entry->sess->target_id,
+						SCAN_WILD_CARD, 0);
 			}
 		}
-
 		break;
 	case ISCSI_ASYNC_MSG_REQUEST_LOGOUT:
 	case ISCSI_ASYNC_MSG_DROPPING_CONNECTION:
 	case ISCSI_ASYNC_MSG_DROPPING_ALL_CONNECTIONS:
 	case ISCSI_ASYNC_MSG_PARAM_NEGOTIATION:
-	       dev_info(&ha->pdev->dev,
-			       "%s: async msg event 0x%x processed\n"
-			       , __func__, async_event_type);
-	       qla4xxx_conn_close_sess_logout(ha, apdu->target_id, 0, 0);
-	       break;
+		dev_info(&ha->pdev->dev,
+			"%s: async msg event 0x%x processed\n"
+			, __func__, async_event_type);
+		qla4xxx_conn_close_sess_logout(ha, apdu->target_id, 0);
+		break;
 	default:
-	       dev_info(&ha->pdev->dev,
-		       "%s: async msg event 0x%x not processed\n",
-		       __func__, async_event_type);
-	       break;
+		dev_info(&ha->pdev->dev,
+			"%s: async msg event 0x%x not processed\n",
+			__func__, async_event_type);
+		break;
 	};
-
-	exit_async_pdu_iocb:
+exit_async_pdu_iocb:
 	if (!using_prealloc)
-	       dma_free_coherent(&ha->pdev->dev, len,
-		       buf_addr, buf_addr_dma);
-
+		dma_free_coherent(&ha->pdev->dev, len,
+				buf_addr, buf_addr_dma);
 	return;
 }
 
+void qla4xxx_wake_dpc(struct scsi_qla_host *ha)
+{
+	if (ha->dpc_thread &&
+	    !test_bit(AF_DPC_SCHEDULED, &ha->flags)) {
+		set_bit(AF_DPC_SCHEDULED, &ha->flags);
+		queue_work(ha->dpc_thread, &ha->dpc_work);
+	}
+}
+
 /**
  * qla4xxx_do_dpc - dpc routine
  * @data: in our case pointer to adapter structure
@@ -1214,30 +1667,85 @@ static void qla4xxx_async_iocbs(struct s
  * the mid-level tries to sleep when it reaches the driver threshold
  * "host->can_queue". This can cause a panic if we were in our interrupt code.
  **/
-static void qla4xxx_do_dpc(struct work_struct *work)
+static void qla4xxx_do_dpc(struct work_struct *data)
 {
 	struct scsi_qla_host *ha =
-		container_of(work, struct scsi_qla_host, dpc_work);
+		container_of(data, struct scsi_qla_host, dpc_work);
 	struct ddb_entry *ddb_entry, *dtemp;
 	struct async_msg_pdu_iocb *apdu_iocb, *apdu_iocb_tmp;
 	int status = QLA_ERROR;
 
-	DEBUG2(printk("scsi%ld: %s: DPC handler waking up."
-		"flags = 0x%08lx, dpc_flags = 0x%08lx ctrl_stat = 0x%08x\n",
-		ha->host_no, __func__, ha->flags, ha->dpc_flags,
-		readw(&ha->reg->ctrl_status)));
+	DEBUG2(ql4_info(ha, "%s: DPC handler waking up."
+	    "flags = 0x%08lx, dpc_flags = 0x%08lx\n", __func__, ha->flags,
+	    ha->dpc_flags))
 
 	/* Initialization not yet finished. Don't do anything yet. */
 	if (!test_bit(AF_INIT_DONE, &ha->flags))
+		goto do_dpc_exit;
+
+	if (test_bit(AF_EEH_BUSY, &ha->flags)) {
+		DEBUG2(ql4_info(ha, "%s: flags = %lx\n", __func__, ha->flags));
+		goto do_dpc_exit;
+	}
+
+	/* HBA is in the process of being permanently disabled.
+	 * Don't process anything */
+	if (test_bit(AF_HA_REMOVAL, &ha->flags))
 		return;
 
-	if (adapter_up(ha) ||
-	    test_bit(DPC_RESET_HA, &ha->dpc_flags) ||
+	if (is_qla8022(ha)) {
+		if (test_bit(DPC_HA_UNRECOVERABLE, &ha->dpc_flags)) {
+			qla4_8xxx_idc_lock(ha);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+			    QLA82XX_DEV_FAILED);
+			qla4_8xxx_idc_unlock(ha);
+			ql4_info(ha, "HW State: FAILED\n");
+			qla4_8xxx_device_state_handler(ha);
+		}
+		if (test_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags)) {
+			qla4_8xxx_idc_lock(ha);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+					QLA82XX_DEV_NEED_QUIESCENT);
+			qla4_8xxx_idc_unlock(ha);
+			qla4_8xxx_device_state_handler(ha);
+			/* Clear quiescent state of all functions except
+			 * quiesce owner quiescent state is cleared for owner
+			 * during reset qsnt
+			 */
+			if (!test_bit(AF_QUIESCE_OWNER, &ha->flags)) {
+				qla4_8xxx_idc_lock(ha);
+				qla4_8xxx_clear_qsnt_ready(ha);
+				clear_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags);
+				qla4_8xxx_idc_unlock(ha);
+			}
+		}
+		if (test_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags)) {
+			if (test_bit(AF_QUIESCE_OWNER, &ha->flags)) {
+				qla4_8xxx_idc_lock(ha);
+				qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+							QLA82XX_DEV_READY);
+				qla4_8xxx_clear_qsnt_ready(ha);
+				clear_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags);
+				qla4_8xxx_idc_unlock(ha);
+			}
+			clear_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags);
+		}
+	}
+
+	if (!test_bit(DPC_RESET_ACTIVE, &ha->dpc_flags) &&
+	    (test_bit(DPC_RESET_HA, &ha->dpc_flags) ||
 	    test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags) ||
-	    test_bit(DPC_RESET_HA_DESTROY_DDB_LIST, &ha->dpc_flags)) {
-		if (test_bit(DPC_RESET_HA_DESTROY_DDB_LIST, &ha->dpc_flags) ||
-			test_bit(DPC_RESET_HA, &ha->dpc_flags))
-			qla4xxx_recover_adapter(ha, PRESERVE_DDB_LIST);
+	    test_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags))) {
+		if (ql4xdontresethba) {
+			DEBUG2(ql4_info(ha, "%s: Don't Reset HBA\n", __func__));
+			clear_bit(DPC_RESET_HA, &ha->dpc_flags);
+			clear_bit(DPC_RESET_HA_INTR, &ha->dpc_flags);
+			clear_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+			goto dpc_post_reset_ha;
+		}
+		if (test_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags) ||
+		    test_bit(DPC_RESET_HA, &ha->dpc_flags))
+			qla4xxx_recover_adapter(ha);
 
 		if (test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags)) {
 			uint8_t wait_time = RESET_INTR_TOV;
@@ -1249,32 +1757,68 @@ static void qla4xxx_do_dpc(struct work_s
 				msleep(1000);
 			}
 			if (wait_time == 0)
-				DEBUG2(printk("scsi%ld: %s: SR|FSR "
+				DEBUG2(ql4_info(ha, "%s: SR|FSR "
 					      "bit not cleared-- resetting\n",
-					      ha->host_no, __func__));
-			qla4xxx_flush_active_srbs(ha);
+					      __func__));
+			qla4xxx_abort_active_cmds(ha, DID_RESET << 16);
 			if (ql4xxx_lock_drvr_wait(ha) == QLA_SUCCESS) {
 				qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
-				status = qla4xxx_initialize_adapter(ha,
-						PRESERVE_DDB_LIST);
+				status = qla4xxx_recover_adapter(ha);
 			}
 			clear_bit(DPC_RESET_HA_INTR, &ha->dpc_flags);
-			if (status == QLA_SUCCESS) {
-				qla4xxx_enable_intrs(ha);
-				scsi_unblock_requests(ha->host);
+			if (status == QLA_SUCCESS)
+				ha->isp_ops->enable_intrs(ha);
+		}
+	}
+
+dpc_post_reset_ha:
+
+	/* ---- process AEN? --- */
+	if (test_and_clear_bit(DPC_AEN, &ha->dpc_flags))
+		qla4xxx_process_aen(ha, PROCESS_ALL_AENS);
+
+	/* ---- Get DHCP IP Address? --- */
+	if (test_and_clear_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags))
+		qla4xxx_get_dhcp_ip_address(ha);
+
+	/* ---- link change? --- */
+	/* Check for AF_LINK after, adapter initialization is complete.
+	 * If adapter initialization is not complete, relogin to devices
+	 * will fail and since DPC_LINK_CHANGED flag is reset, driver
+	 * will not relogin to the device.
+	 */
+	if (test_bit(AF_ONLINE, &ha->flags)) {
+		if (test_and_clear_bit(DPC_LINK_CHANGED, &ha->dpc_flags)) {
+			if (!test_bit(AF_LINK_UP, &ha->flags)) {
+				/* ---- link down? --- */
+				qla4xxx_mark_all_devices_missing(ha);
+			} else {
+				/* ---- link up? --- *
+				 * F/W will auto login to all devices ONLY ONCE
+				 * after link up during driver initialization and
+				 * runtime fatal error recovery.  Therefore, the
+				 * driver must manually relogin to devices when
+				 * recovering from connection failures, logouts,
+				 * expired KATO, etc.
+				 */
+				qla4xxx_relogin_all_devices(ha);
 			}
 		}
 	}
 
-	/* ---- process AEN? --- */
-	if (test_and_clear_bit(DPC_AEN, &ha->dpc_flags))
-		qla4xxx_process_aen(ha, PROCESS_ALL_AENS);
-
-	/* ---- Get DHCP IP Address? --- */
-	if (test_and_clear_bit(DPC_GET_DHCP_IP_ADDR, &ha->dpc_flags))
-		qla4xxx_get_dhcp_ip_address(ha);
-
-	qla4xxx_remove_device(ha);
+	/* ---- remove device ? ---- */
+	if (test_and_clear_bit(DPC_REMOVE_DEVICE, &ha->dpc_flags)) {
+		list_for_each_entry_safe(ddb_entry, dtemp,
+		    &ha->ddb_list, list) {
+			if (test_and_clear_bit(DF_REMOVE, &ddb_entry->flags)) {
+				dev_info(&ha->pdev->dev,
+					"%s: ddb[%d] os[%d] - removed\n",
+					__func__, ddb_entry->fw_ddb_index,
+					ddb_entry->os_target_id);
+				qla4xxx_free_ddb(ha, ddb_entry);
+			}
+		}
+	}
 
 	/* ---- relogin device? --- */
 	if (adapter_up(ha) &&
@@ -1292,94 +1836,200 @@ static void qla4xxx_do_dpc(struct work_s
 			 * the system.
 			 */
 			if (test_bit(DPC_RESET_HA, &ha->dpc_flags)) {
-				printk(KERN_WARNING "scsi%ld: %s: "
-				       "need to reset hba\n",
-				       ha->host_no, __func__);
+				ql4_warn(ha, "%s: need to reset hba\n",
+				       __func__);
 				break;
 			}
 		}
 	}
 
-	if (test_and_clear_bit(DPC_LINK_CHANGED, &ha->dpc_flags)) {
-		if (!test_bit(AF_LINK_UP, &ha->flags)) {
-			/* ---- link down? --- */
-			list_for_each_entry_safe(ddb_entry, dtemp, &ha->ddb_list, list) {
-				if (atomic_read(&ddb_entry->state) == DDB_STATE_ONLINE)
-					qla4xxx_mark_device_missing(ha, ddb_entry);
-			}
-		} else {
-			/* ---- link up? --- *
-			 * F/W will auto login to all devices ONLY ONCE after
-			 * link up during driver initialization and runtime
-			 * fatal error recovery.  Therefore, the driver must
-			 * manually relogin to devices when recovering from
-			 * connection failures, logouts, expired KATO, etc. */
-
-			list_for_each_entry_safe(ddb_entry, dtemp, &ha->ddb_list, list) {
-				if ((atomic_read(&ddb_entry->state) == DDB_STATE_MISSING) ||
-						(atomic_read(&ddb_entry->state) == DDB_STATE_DEAD)) {
-					if (ddb_entry->fw_ddb_device_state == DDB_DS_SESSION_ACTIVE) {
-						atomic_set(&ddb_entry->state, DDB_STATE_ONLINE);
-						dev_info(&ha->pdev->dev,
-							"scsi%ld: %s: ddb[%d] os[%d] marked ONLINE\n",
-							ha->host_no, __func__, ddb_entry->fw_ddb_index,
-							ddb_entry->os_target_id);
-
-						iscsi_unblock_session(ddb_entry->sess);
-					} else
-						qla4xxx_relogin_device(ha, ddb_entry);
-				}
+	/* ---- perform dynamic lun scan? --- */
+	if (adapter_up(ha) &&
+	    test_and_clear_bit(DPC_DYNAMIC_LUN_SCAN, &ha->dpc_flags)) {
+		list_for_each_entry_safe(ddb_entry, dtemp,
+		    &ha->ddb_list, list) {
+			if (test_and_clear_bit(DF_DYNAMIC_LUN_SCAN_NEEDED,
+			    &ddb_entry->flags)) {
+				dev_info(&ha->pdev->dev,"%s: ddb[%d] os[%d] "
+					"perform dynamic lun scan\n",
+					__func__, ddb_entry->fw_ddb_index,
+					ddb_entry->os_target_id);
+				/* report new lun to kernel */
+				scsi_scan_target(&ddb_entry->sess->dev, 0,
+					ddb_entry->sess->target_id,
+					SCAN_WILD_CARD, 0);
+				/* report new lun to GUI */
+				qla4xxx_queue_lun_change_aen(ha,
+					ddb_entry->fw_ddb_index);
 			}
 		}
 	}
 
-	/* Check for ASYNC PDU IOCBs */
+	/* iSNS Server Actions */
+	if (adapter_up(ha)) {
+		/* Error Recovery Case:
+		 * The driver detected some sort of iSNS error.
+		 * Stop the TCP connection then reschedule
+		 */
+		if (test_and_clear_bit(DPC_ISNS_RESTART, &ha->dpc_flags))
+			ql4_isns_restart_service(ha);
+
+		/* IP Address Change Case:
+		 * If the initiator's IP address changes, we
+		 * stop the TCP connection using the old source IP address. */
+		if (test_and_clear_bit(DPC_ISNS_STOP, &ha->dpc_flags))
+			ql4_isns_stop_service(ha);
+
+		/* AEN 8021 iSNS Service Connection FAILED Case:
+		 * We already have a TCP connection to iSNS server, but the
+		 * iSNS Server closes the connection, so de-register.
+		 * A future attempt will be made to re-register with iSNS
+		 * server after the ISNS_STATE_RESTART_SRV_WAIT wait-time
+		 * has expired. */
+		if (test_and_clear_bit(DPC_ISNS_DEREGISTER, &ha->dpc_flags)) {
+			ql4_isns_deregister_isns_server(ha);
+		}
+
+		/* ESI Timeout Case:
+		 * We already have a TCP connection to iSNS server.
+		 * De-register then attempt to re-register with iSNS server. */
+		if (test_bit(DPC_ISNS_REREGISTER, &ha->dpc_flags) &&
+			ql4_is_isns_active(ha)) {
+			ql4_isns_register_isns_server(ha);
+		}
+
+		/* No Current TCP Connection --
+		 * Polling, IP Address Change and Rescheduled Start Cases: */
+		if (test_and_clear_bit(DPC_ISNS_START, &ha->dpc_flags))
+			ql4_isns_start_service(ha);
+	}
+
+	/* Check for ASYNC iSCSI PDU IOCBs */
 	if (adapter_up(ha) &&
-		test_bit(DPC_ASYNC_MSG_PDU, &ha->dpc_flags)) {
+	    test_bit(DPC_ASYNC_ISCSI_PDU, &ha->dpc_flags)) {
 
 		list_for_each_entry_safe(apdu_iocb, apdu_iocb_tmp,
-					 &ha->async_iocb_list, list) {
-			qla4xxx_async_iocbs(ha, apdu_iocb);
+		    &ha->async_iocb_list, list) {
+			qla4xxx_process_async_iscsi_pdu_iocb(ha, apdu_iocb);
 			list_del_init(&apdu_iocb->list);
 			kfree(apdu_iocb);
 		}
-		clear_bit(DPC_ASYNC_MSG_PDU, &ha->dpc_flags);
+		clear_bit(DPC_ASYNC_ISCSI_PDU, &ha->dpc_flags);
 	}
+do_dpc_exit:
+	clear_bit(AF_DPC_SCHEDULED, &ha->flags);
 }
 
 /**
  * qla4xxx_free_adapter - release the adapter
  * @ha: pointer to adapter structure
  **/
-static void qla4xxx_free_adapter(struct scsi_qla_host *ha)
+static void qla4xxx_free_adapter(struct scsi_qla_host *ha, int rm_host)
 {
+	/* Deregister with the iSNS Server */
+	/* NOTE: On 4xxx dual port adapters, if one port unloads and resets the
+	 *       chip, the other port will no longer be able to communicate
+	 *       with the chip.  Thus, iSNS will not deregister or get
+	 *       disabled on the second port.  The iSNS server will deregister
+	 *       the second port (no ESI notification) in approximately 15
+	 *       minutes.  But, if driver re-loads within that time, the driver
+	 *       will first de-register with the iSNS server, then register
+	 *       with it to prevent multiple registration errors.
+	 */
+	if (test_bit(AF_ONLINE, &ha->flags) &&
+	    test_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: Stop iSNS service\n", __func__));
+		ql4_isns_stop_service(ha);
+	}
 
 	if (test_bit(AF_INTERRUPTS_ON, &ha->flags)) {
 		/* Turn-off interrupts on the card. */
-		qla4xxx_disable_intrs(ha);
+		ha->isp_ops->disable_intrs(ha);
 	}
 
-	/* Kill the kernel thread for this host */
-	if (ha->dpc_thread)
-		destroy_workqueue(ha->dpc_thread);
-
-	/* Issue Soft Reset to put firmware in unknown state */
-	if (ql4xxx_lock_drvr_wait(ha) == QLA_SUCCESS)
-		qla4xxx_hw_reset(ha);
-
 	/* Remove timer thread, if present */
 	if (ha->timer_active)
 		qla4xxx_stop_timer(ha);
 
+	/* Kill the kernel thread for this host */
+	if (ha->pt_thread)
+		destroy_workqueue(ha->pt_thread);
+	if (ha->dpc_thread)
+		destroy_workqueue(ha->dpc_thread);
+
+	if (rm_host ) {
+		/* remove devs from iscsi_sessions to scsi_devices */
+		qla4xxx_free_ddb_list(ha);
+
+		scsi_remove_host(ha->host);
+	}
+
+	/* Put firmware in known state */
+	ha->isp_ops->reset_firmware(ha);
+
+	if (is_qla8022(ha)) {
+		qla4_8xxx_idc_lock(ha);
+		qla4_8xxx_clear_drv_active(ha);
+		qla4_8xxx_idc_unlock(ha);
+	}
+
 	/* Detach interrupts */
 	if (test_and_clear_bit(AF_IRQ_ATTACHED, &ha->flags))
-		free_irq(ha->pdev->irq, ha);
+		qla4xxx_free_irqs(ha);
 
 	/* free extra memory */
 	qla4xxx_mem_free(ha);
-
-	pci_disable_device(ha->pdev);
-
+}
+
+int qla4_8xxx_iospace_config(struct scsi_qla_host *ha)
+{
+	int status = 0;
+	uint8_t revision_id;
+	unsigned long mem_base, mem_len, db_base, db_len;
+	struct pci_dev *pdev = ha->pdev;
+
+	status = pci_request_regions(pdev, DRIVER_NAME);
+	if (status) {
+		ql4_warn(ha, "Failed to reserve PIO regions (%s) status=%d\n",
+			pci_name(pdev), status);
+		goto iospace_error_exit;
+	}
+
+	pci_read_config_byte(pdev, PCI_REVISION_ID, &revision_id);
+	DEBUG2(ql4_info(ha, "%s: revision-id=%d\n", __func__, revision_id));
+	ha->revision_id = revision_id;
+
+	/* remap phys address */
+	mem_base = pci_resource_start(pdev, 0); /* 0 is for BAR 0 */
+	mem_len = pci_resource_len(pdev, 0);
+	DEBUG2(ql4_info(ha, "%s: ioremap from %lx a size of %lx\n",
+	    __func__, mem_base, mem_len));
+
+	/* mapping of pcibase pointer */
+	ha->nx_pcibase = (unsigned long)ioremap(mem_base, mem_len);
+	if (!ha->nx_pcibase) {
+		ql4_err(ha, "cannot remap MMIO (%s), aborting\n",
+			pci_name(pdev));
+		pci_release_regions(ha->pdev);
+		goto iospace_error_exit;
+	}
+
+	/* Mapping of IO base pointer, door bell read and write pointer */
+
+	/* mapping of IO base pointer */
+	ha->qla4_8xxx_reg =
+	    (struct device_reg_82xx  __iomem *)((uint8_t *)ha->nx_pcibase +
+	    0xbc000 + (ha->pdev->devfn << 11));
+
+	db_base = pci_resource_start(pdev, 4);  /* doorbell is on bar 4 */
+	db_len = pci_resource_len(pdev, 4);
+
+	ha->nx_db_wr_ptr = (ha->pdev->devfn == 4 ? QLA82XX_CAM_RAM_DB1 :
+				QLA82XX_CAM_RAM_DB2);
+
+	return 0;
+iospace_error_exit:
+	return -ENOMEM;
 }
 
 /***
@@ -1389,7 +2039,7 @@ static void qla4xxx_free_adapter(struct 
  * This routines maps HBA's registers from the pci address space
  * into the kernel virtual address space for memory mapped i/o.
  **/
-static int qla4xxx_iospace_config(struct scsi_qla_host *ha)
+int qla4xxx_iospace_config(struct scsi_qla_host *ha)
 {
 	unsigned long pio, pio_len, pio_flags;
 	unsigned long mmio, mmio_len, mmio_flags;
@@ -1399,12 +2049,11 @@ static int qla4xxx_iospace_config(struct
 	pio_flags = pci_resource_flags(ha->pdev, 0);
 	if (pio_flags & IORESOURCE_IO) {
 		if (pio_len < MIN_IOBASE_LEN) {
-			dev_warn(&ha->pdev->dev,
-				"Invalid PCI I/O region size\n");
+			ql4_warn(ha, "Invalid PCI I/O region size\n");
 			pio = 0;
 		}
 	} else {
-		dev_warn(&ha->pdev->dev, "region #0 not a PIO resource\n");
+		ql4_warn(ha, "region #0 not a PIO resource\n");
 		pio = 0;
 	}
 
@@ -1414,20 +2063,18 @@ static int qla4xxx_iospace_config(struct
 	mmio_flags = pci_resource_flags(ha->pdev, 1);
 
 	if (!(mmio_flags & IORESOURCE_MEM)) {
-		dev_err(&ha->pdev->dev,
-			"region #0 not an MMIO resource, aborting\n");
+		ql4_err(ha, "region #0 not an MMIO resource, aborting\n");
 
 		goto iospace_error_exit;
 	}
+
 	if (mmio_len < MIN_IOBASE_LEN) {
-		dev_err(&ha->pdev->dev,
-			"Invalid PCI mem region size, aborting\n");
+		ql4_err(ha, "Invalid PCI mem region size, aborting\n");
 		goto iospace_error_exit;
 	}
 
 	if (pci_request_regions(ha->pdev, DRIVER_NAME)) {
-		dev_warn(&ha->pdev->dev,
-			"Failed to reserve PIO/MMIO regions\n");
+		ql4_warn(ha, "Failed to reserve PIO/MMIO regions\n");
 
 		goto iospace_error_exit;
 	}
@@ -1436,8 +2083,7 @@ static int qla4xxx_iospace_config(struct
 	ha->pio_length = pio_len;
 	ha->reg = ioremap(mmio, MIN_IOBASE_LEN);
 	if (!ha->reg) {
-		dev_err(&ha->pdev->dev,
-			"cannot remap MMIO, aborting\n");
+		ql4_err(ha, "cannot remap MMIO, aborting\n");
 
 		goto iospace_error_exit;
 	}
@@ -1448,6 +2094,82 @@ iospace_error_exit:
 	return -ENOMEM;
 }
 
+static struct isp_operations qla4xxx_isp_ops = {
+	.iospace_config         = qla4xxx_iospace_config,
+	.pci_config             = qla4xxx_pci_config,
+	.disable_intrs          = qla4xxx_disable_intrs,
+	.enable_intrs           = qla4xxx_enable_intrs,
+	.start_firmware         = qla4xxx_start_firmware,
+	.intr_handler           = qla4xxx_intr_handler,
+	.interrupt_service_routine = qla4xxx_interrupt_service_routine,
+	.reset_chip             = qla4xxx_soft_reset,
+	.reset_firmware         = qla4xxx_hw_reset,
+	.queue_iocb             = qla4xxx_queue_iocb,
+	.complete_iocb          = qla4xxx_complete_iocb,
+	.rd_shdw_req_q_out      = qla4xxx_rd_shdw_req_q_out,
+	.rd_shdw_rsp_q_in       = qla4xxx_rd_shdw_rsp_q_in,
+	.get_sys_info           = qla4xxx_get_sys_info,
+};
+
+static struct isp_operations qla4_8xxx_isp_ops = {
+	.iospace_config         = qla4_8xxx_iospace_config,
+	.pci_config             = qla4_8xxx_pci_config,
+	.disable_intrs          = qla4_8xxx_disable_intrs,
+	.enable_intrs           = qla4_8xxx_enable_intrs,
+	.start_firmware         = qla4_8xxx_load_risc,
+	.intr_handler           = qla4_8xxx_intr_handler,
+	.interrupt_service_routine = qla4_8xxx_interrupt_service_routine,
+	.reset_chip             = qla4_8xxx_isp_reset,
+	.reset_firmware         = qla4_8xxx_stop_firmware,
+	.queue_iocb             = qla4_8xxx_queue_iocb,
+	.complete_iocb          = qla4_8xxx_complete_iocb,
+	.rd_shdw_req_q_out      = qla4_8xxx_rd_shdw_req_q_out,
+	.rd_shdw_rsp_q_in       = qla4_8xxx_rd_shdw_rsp_q_in,
+	.get_sys_info           = qla4_8xxx_get_sys_info,
+};
+
+uint16_t qla4xxx_rd_shdw_req_q_out(struct scsi_qla_host *ha)
+{
+	return (uint16_t)le32_to_cpu(ha->shadow_regs->req_q_out);
+}
+
+uint16_t qla4_8xxx_rd_shdw_req_q_out(struct scsi_qla_host *ha)
+{
+	return (uint16_t)le32_to_cpu(readl(&ha->qla4_8xxx_reg->req_q_out));
+}
+
+uint16_t qla4xxx_rd_shdw_rsp_q_in(struct scsi_qla_host *ha)
+{
+	return (uint16_t)le32_to_cpu(ha->shadow_regs->rsp_q_in);
+}
+
+uint16_t qla4_8xxx_rd_shdw_rsp_q_in(struct scsi_qla_host *ha)
+{
+	return (uint16_t)le32_to_cpu(readl(&ha->qla4_8xxx_reg->rsp_q_in));
+}
+
+static void ql4_get_aen_log(struct scsi_qla_host *ha, struct ql4_aen_log *aenl)
+{
+	if (aenl) {
+		memcpy(aenl, &ha->aen_log, sizeof (ha->aen_log));
+		ha->aen_log.count = 0;
+	}
+}
+
+static inline int qla4xxx_ioctl_init(struct scsi_qla_host *ha)
+{
+	ha->ql4mbx = qla4xxx_mailbox_command;
+	ha->ql4cmd = qla4xxx_send_command_to_isp;
+	ha->ql4getaenlog = ql4_get_aen_log;
+	ha->ql4_isns_start_svc = ql4_isns_start_service;
+	ha->ql4_isns_stop_svc = ql4_isns_stop_service;
+	ha->ql4_isns_populate_server_ip = ql4_isns_populate_server_ip;
+	ha->ql4_isns_send_dev_get_next = ql4_isns_send_dev_get_next;
+	ha->ql4_isns_send_dev_attr_qry = ql4_isns_send_dev_attr_qry;
+	ha->ql4_is_isns_active = ql4_is_isns_active;
+	return 0;
+}
+
 /**
  * qla4xxx_probe_adapter - callback function to probe HBA
  * @pdev: pointer to pci_dev structure
@@ -1465,14 +2187,16 @@ static int __devinit qla4xxx_probe_adapt
 	struct scsi_qla_host *ha;
 	uint8_t init_retry_count = 0;
 	char buf[34];
+	struct qla4_8xxx_legacy_intr_set *nx_legacy_intr;
+	int rm_host = 0;
+	uint32_t dev_state;
 
 	if (pci_enable_device(pdev))
 		return -1;
 
 	host = scsi_host_alloc(&qla4xxx_driver_template, sizeof(*ha));
 	if (host == NULL) {
-		printk(KERN_WARNING
-		       "qla4xxx: Couldn't allocate host from scsi layer!\n");
+		printk("qla4xxx: Couldn't allocate host from scsi layer!\n");
 		goto probe_disable_device;
 	}
 
@@ -1484,13 +2208,59 @@ static int __devinit qla4xxx_probe_adapt
 	ha->pdev = pdev;
 	ha->host = host;
 	ha->host_no = host->host_no;
+	ha->func_num = PCI_FUNC(ha->pdev->devfn);
+
+	if (is_qla8022(ha)) {
+		if (ql4xmaxcmds)
+			ha->maxcmds = clamp_t(int, ql4xmaxcmds,
+					MIN_IOCBS,
+					MAX_IOCBS);
+		else
+			ha->maxcmds = REQUEST_QUEUE_DEPTH;
+		ha->response_qdepth = RESPONSE_QUEUE_DEPTH_ISP8XXX;
+
+	} else {
+		if (ql4xmaxcmds)
+			ha->maxcmds = clamp_t(int, ql4xmaxcmds,
+					MIN_IOCBS,
+					MAX_IOCBS);
+		else
+			ha->maxcmds = REQUEST_QUEUE_DEPTH;
+		ha->response_qdepth = RESPONSE_QUEUE_DEPTH;
+	}
+
+	pci_enable_pcie_error_reporting(pdev);
+
+	/* Setup Runtime configurable options */
+	if (is_qla8022(ha)) {
+		ha->isp_ops = &qla4_8xxx_isp_ops;
+		rwlock_init(&ha->hw_lock);
+		ha->qdr_sn_window = -1;
+		ha->ddr_mn_window = -1;
+		ha->curr_window = 255;
+		ha->func_num = PCI_FUNC(ha->pdev->devfn);
+		nx_legacy_intr = &legacy_intr[ha->func_num];
+		ha->nx_legacy_intr.int_vec_bit = nx_legacy_intr->int_vec_bit;
+		ha->nx_legacy_intr.tgt_status_reg =
+			nx_legacy_intr->tgt_status_reg;
+		ha->nx_legacy_intr.tgt_mask_reg = nx_legacy_intr->tgt_mask_reg;
+		ha->nx_legacy_intr.pci_int_reg = nx_legacy_intr->pci_int_reg;
+	} else {
+		ha->isp_ops = &qla4xxx_isp_ops;
+	}
+
+#if defined (QL4_SLES11_SP1) || defined (QL4_RHEL6) || defined (QL4_UEK56)
+	/* Set EEH reset type to fundamental if required by hba */
+	if (is_qla8022(ha))
+		pdev->needs_freset = 1;
+#endif
 
 	/* Configure PCI I/O space. */
-	ret = qla4xxx_iospace_config(ha);
+	ret = ha->isp_ops->iospace_config(ha);
 	if (ret)
-		goto probe_failed;
-
-	dev_info(&ha->pdev->dev, "Found an ISP%04x, irq %d, iobase 0x%p\n",
+		goto probe_failed_ioconfig;
+
+	ql4_info(ha, "Found an ISP%04x, irq %d, iobase 0x%p\n",
 		   pdev->device, pdev->irq, ha->reg);
 
 	qla4xxx_config_dma_addressing(ha);
@@ -1499,34 +2269,74 @@ static int __devinit qla4xxx_probe_adapt
 	INIT_LIST_HEAD(&ha->ddb_list);
 	INIT_LIST_HEAD(&ha->free_srb_q);
 	INIT_LIST_HEAD(&ha->async_iocb_list);
-
+	INIT_LIST_HEAD(&ha->isns.rcvd_pdu_list);
+
+	mutex_init(&ha->pt_sem);
 	mutex_init(&ha->mbox_sem);
+	init_completion(&ha->mbx_intr_comp);
 
 	spin_lock_init(&ha->hardware_lock);
 
 	/* Allocate dma buffers */
 	if (qla4xxx_mem_alloc(ha)) {
-		dev_warn(&ha->pdev->dev,
-			   "[ERROR] Failed to allocate memory for adapter\n");
+		ql4_warn(ha, "[ERROR] Failed to allocate memory for adapter\n");
 
 		ret = -ENOMEM;
 		goto probe_failed;
 	}
 
+	if (is_qla8022(ha))
+		(void) qla4_8xxx_get_flash_info(ha);
+
+	DEBUG2(ql4_info(ha, "scsi: %s: Starting kernel thread for "
+		      "qla4xxx_ptc\n", __func__));
+	sprintf(buf, "qla4xxx_%lu_pt", ha->host_no);
+	ha->pt_thread = create_singlethread_workqueue(buf);
+	if (!ha->pt_thread) {
+		dev_warn(&ha->pdev->dev, "Unable to start pt thread!\n");
+		ret = -ENODEV;
+		goto probe_failed;
+	}
+	INIT_WORK(&ha->pt_work, ql4_isns_dequeue_passthru_sts_iocb);
+
 	/*
 	 * Initialize the Host adapter request/response queues and
 	 * firmware
 	 * NOTE: interrupts enabled upon successful completion
 	 */
 	status = qla4xxx_initialize_adapter(ha, REBUILD_DDB_LIST);
-	while (status == QLA_ERROR && init_retry_count++ < MAX_INIT_RETRIES) {
-		DEBUG2(printk("scsi: %s: retrying adapter initialization "
+	while ((!test_bit(AF_ONLINE, &ha->flags)) &&
+	    init_retry_count++ < MAX_INIT_RETRIES) {
+		if (is_qla8022(ha)) {
+			qla4_8xxx_idc_lock(ha);
+			dev_state = qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE);
+			qla4_8xxx_idc_unlock(ha);
+			if (dev_state == QLA82XX_DEV_FAILED) {
+				dev_info(&ha->pdev->dev, "%s: don't retry "
+					"adapter init. H/W is in Failed state\n",
+					__func__);
+				break;
+			}
+		}
+
+		DEBUG2(ql4_info(ha, "scsi: %s: retrying adapter initialization "
 			      "(%d)\n", __func__, init_retry_count));
-		qla4xxx_soft_reset(ha);
+
+		if (ha->isp_ops->reset_chip(ha) == QLA_ERROR)
+			continue;
+
 		status = qla4xxx_initialize_adapter(ha, REBUILD_DDB_LIST);
 	}
-	if (status == QLA_ERROR) {
-		dev_warn(&ha->pdev->dev, "Failed to initialize adapter\n");
+
+	if (!test_bit(AF_ONLINE, &ha->flags)) {
+		ql4_warn(ha, "Failed to initialize adapter\n");
+		if (is_qla8022(ha) && ql4xdontresethba) {
+			qla4_8xxx_idc_lock(ha);
+			DEBUG2(ql4_info(ha, "HW State: Setting to failed\n"));
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+					QLA82XX_DEV_FAILED);
+			qla4_8xxx_idc_unlock(ha);
+		}
 
 		ret = -ENODEV;
 		goto probe_failed;
@@ -1537,39 +2347,43 @@ static int __devinit qla4xxx_probe_adapt
 	host->max_lun = MAX_LUNS - 1;
 	host->max_id = MAX_TARGETS;
 	host->max_cmd_len = IOCB_MAX_CDB_LEN;
-	host->can_queue = MAX_SRBS ;
 	host->transportt = qla4xxx_scsi_transport;
 
-        ret = scsi_init_shared_tag_map(host, MAX_SRBS);
-        if (ret) {
-                dev_warn(&ha->pdev->dev, "scsi_init_shared_tag_map failed\n");
-                goto probe_failed;
-        }
+	host->can_queue = (ha->maxcmds + 128);
+
+	DEBUG2(ql4_info(ha, "%s: ql4xmaxcmds = %d\n",
+		__func__, ha->maxcmds));
+	DEBUG2(ql4_info(ha, "%s: CAN Q = %d\n",
+		__func__, host->can_queue));
 
 	/* Startup the kernel thread for this host adapter. */
-	DEBUG2(printk("scsi: %s: Starting kernel thread for "
+	DEBUG2(ql4_info(ha, "scsi: %s: Starting kernel thread for "
 		      "qla4xxx_dpc\n", __func__));
 	sprintf(buf, "qla4xxx_%lu_dpc", ha->host_no);
 	ha->dpc_thread = create_singlethread_workqueue(buf);
 	if (!ha->dpc_thread) {
-		dev_warn(&ha->pdev->dev, "Unable to start DPC thread!\n");
+		ql4_warn(ha, "Unable to start DPC thread!\n");
 		ret = -ENODEV;
 		goto probe_failed;
 	}
 	INIT_WORK(&ha->dpc_work, qla4xxx_do_dpc);
 
-	ret = request_irq(pdev->irq, qla4xxx_intr_handler,
-			  IRQF_DISABLED | IRQF_SHARED, "qla4xxx", ha);
-	if (ret) {
-		dev_warn(&ha->pdev->dev, "Failed to reserve interrupt %d"
-			" already in use.\n", pdev->irq);
-		goto probe_failed;
+	/* For ISP-82XX, request_irqs is called in qla4_8xxx_load_risc
+	 * (which is called indirectly by qla4xxx_initialize_adapter),
+	 * so that irqs will be registered after crbinit but before
+	 * mbx_intr_enable.
+	 */
+	if (!is_qla8022(ha)) {
+		ret = qla4xxx_request_irqs(ha);
+		if (ret) {
+			ql4_warn(ha, "Failed to reserve "
+			    "interrupt %d already in use.\n", pdev->irq);
+			goto probe_failed;
+		}
 	}
-	set_bit(AF_IRQ_ATTACHED, &ha->flags);
-	host->irq = pdev->irq;
-	DEBUG(printk("scsi%d: irq %d attached\n", ha->host_no, ha->pdev->irq));
-
-	qla4xxx_enable_intrs(ha);
+
+	pci_save_state(ha->pdev);
+	ha->isp_ops->enable_intrs(ha);
 
 	/* Start timer thread. */
 	qla4xxx_start_timer(ha, qla4xxx_timer, 1);
@@ -1580,35 +2394,37 @@ static int __devinit qla4xxx_probe_adapt
 	if (ret)
 		goto probe_failed;
 
-	printk(KERN_INFO
-	       " QLogic iSCSI HBA Driver version: %s\n"
-	       "  QLogic ISP%04x @ %s, host#=%ld, fw=%02d.%02d.%02d.%02d\n",
+	qla4_8xxx_alloc_sysfs_attr(ha);
+
+	ql4_info(ha, " QLogic iSCSI HBA Driver version: %s\n"
+	       "  QLogic ISP%04x @ %s, fw=%02d.%02d.%02d.%02d\n",
 	       qla4xxx_version_str, ha->pdev->device, pci_name(ha->pdev),
-	       ha->host_no, ha->firmware_version[0], ha->firmware_version[1],
+	       ha->firmware_version[0], ha->firmware_version[1],
 	       ha->patch_number, ha->build_number);
 
 	scsi_scan_host(host);
 
 	/* Insert new entry into the list of adapters. */
-        klist_add_tail(&ha->node, &qla4xxx_hostlist);
-        ha->instance = atomic_inc_return(&qla4xxx_hba_count) - 1;
-
-        if (qla4xxx_ioctl_init(ha)) {
-                dev_info(&ha->pdev->dev, "ioctl init failed\n");
-                goto remove_host;
-        }
+	klist_add_tail(&ha->node, &qla4xxx_hostlist);
+	ha->instance = atomic_inc_return(&qla4xxx_hba_count) - 1;
+
+	if (qla4xxx_ioctl_init(ha)) {
+		dev_warn(&ha->pdev->dev, "ioctl init failed\n");
+		goto remove_host;
+	}
 
 	set_bit(AF_INIT_DONE, &ha->flags);
 	dev_info(&ha->pdev->dev, "%s: AF_INIT_DONE\n", __func__);
-
 	return 0;
 
 remove_host:
-	qla4xxx_free_ddb_list(ha);
-	scsi_remove_host(host);
+	rm_host = 1;
 
 probe_failed:
-	qla4xxx_free_adapter(ha);
+	qla4xxx_free_adapter(ha, rm_host);
+
+probe_failed_ioconfig:
+	pci_disable_pcie_error_reporting(pdev);
 	scsi_host_put(ha->host);
 
 probe_disable_device:
@@ -1618,34 +2434,65 @@ probe_disable_device:
 }
 
 /**
+ * qla4xxx_prevent_other_port_reinit - Mark the other ISP-4xxx port to indicate
+ * that the driver is being removed, so that the other port will not
+ * re-initialize while in the process of removing the ha due to driver unload
+ * or hba hotplug.
+ * @ha: pointer to adapter structure
+ **/
+static void qla4xxx_prevent_other_port_reinit(struct scsi_qla_host *ha)
+{
+        struct scsi_qla_host *ha_listp;
+	struct klist_iter i;
+	struct klist_node *n;
+
+	klist_iter_init(&qla4xxx_hostlist, &i);
+	while ((n = klist_next(&i)) != NULL) {
+		ha_listp = container_of(n, struct scsi_qla_host, node);
+                if (ha == ha_listp)
+                        continue;
+
+                if ((pci_domain_nr(ha->pdev->bus) ==
+                     pci_domain_nr(ha_listp->pdev->bus)) &&
+                    (ha->pdev->bus->number ==
+                     ha_listp->pdev->bus->number) &&
+                    (PCI_SLOT(ha->pdev->devfn) ==
+                     PCI_SLOT(ha_listp->pdev->devfn)) ) {
+
+                        set_bit(AF_HA_REMOVAL, &ha_listp->flags);
+			DEBUG2(ql4_info(ha, "%s: Prevent %s reinit\n",
+				__func__, dev_name(&((ha_listp)->pdev->dev))));
+                }
+        }
+
+	klist_iter_exit(&i);
+}
+
+/**
  * qla4xxx_remove_adapter - calback function to remove adapter.
  * @pci_dev: PCI device pointer
  **/
 static void __devexit qla4xxx_remove_adapter(struct pci_dev *pdev)
 {
 	struct scsi_qla_host *ha;
+	int rm_host = 1;
 
 	ha = pci_get_drvdata(pdev);
 
-	qla4xxx_disable_intrs(ha);
-
-	while (test_bit(DPC_RESET_HA_INTR, &ha->dpc_flags))
-		ssleep(1);
+	if (!is_qla8022(ha))
+		qla4xxx_prevent_other_port_reinit(ha);
 
 	klist_remove(&ha->node);
 	atomic_dec(&qla4xxx_hba_count);
 
-	/* remove devs from iscsi_sessions to scsi_devices */
-	qla4xxx_free_ddb_list(ha);
-
-	scsi_remove_host(ha->host);
-
-	qla4xxx_ioctl_exit(ha);
-
-	qla4xxx_free_adapter(ha);
+	qla4xxx_free_adapter(ha, rm_host);
 
 	scsi_host_put(ha->host);
 
+	qla4_8xxx_free_sysfs_attr(ha);
+
+	pci_disable_pcie_error_reporting(pdev);
+	pci_disable_device(pdev);
 	pci_set_drvdata(pdev, NULL);
 }
 
@@ -1677,10 +2524,14 @@ static int qla4xxx_slave_alloc(struct sc
 {
 	struct iscsi_cls_session *sess = starget_to_session(sdev->sdev_target);
 	struct ddb_entry *ddb = sess->dd_data;
+	int queue_depth = MAX_Q_DEPTH;
+
+	if (ql4xmaxqdepth != 0 && ql4xmaxqdepth <= 0xffffU)
+		queue_depth = ql4xmaxqdepth;
 
 	sdev->hostdata = ddb;
 	sdev->tagged_supported = 1;
-	scsi_activate_tcq(sdev, QL4_DEF_QDEPTH);
+	scsi_activate_tcq(sdev, queue_depth);
 	return 0;
 }
 
@@ -1692,7 +2543,12 @@ static int qla4xxx_slave_configure(struc
 
 static void qla4xxx_slave_destroy(struct scsi_device *sdev)
 {
-	scsi_deactivate_tcq(sdev, 1);
+	int queue_depth = MAX_Q_DEPTH;
+
+	if (ql4xmaxqdepth != 0 && ql4xmaxqdepth <= 0xffffU)
+		queue_depth = ql4xmaxqdepth;
+
+	scsi_deactivate_tcq(sdev, queue_depth);
 }
 
 /**
@@ -1702,7 +2558,8 @@ static void qla4xxx_slave_destroy(struct
  *
  * This routine removes and returns the srb at the specified index
  **/
-struct srb * qla4xxx_del_from_active_array(struct scsi_qla_host *ha, uint32_t index)
+struct srb *qla4xxx_del_from_active_array(struct scsi_qla_host *ha,
+    uint32_t index)
 {
 	struct srb *srb = NULL;
 
@@ -1720,45 +2577,47 @@ struct srb * qla4xxx_del_from_active_arr
 		ha->req_q_count += srb->iocb_cnt;
 		ha->iocb_cnt -= srb->iocb_cnt;
 		if (srb->cmd)
-			srb->cmd->host_scribble = NULL;
+			srb->cmd->host_scribble =
+				(unsigned char *)(unsigned long) MAX_SRBS;
 	}
 	return srb;
 }
 
 /**
  * qla4xxx_eh_wait_on_command - waits for command to be returned by firmware
- * @ha: actual ha whose done queue will contain the comd returned by firmware.
+ * @ha: Pointer to host adapter structure.
  * @cmd: Scsi Command to wait on.
- * @got_ref: Additional reference retrieved by caller.
  *
  * This routine waits for the command to be returned by the Firmware
  * for some max time.
  **/
 static int qla4xxx_eh_wait_on_command(struct scsi_qla_host *ha,
-				      struct scsi_cmnd *cmd, int got_ref)
+				      struct scsi_cmnd *cmd)
 {
-#define ABORT_POLLING_PERIOD	1000
-#define ABORT_WAIT_ITER		1
-
 	int done = 0;
 	struct srb *rp;
-	unsigned long wait_iter = ABORT_WAIT_ITER;
+	uint32_t max_wait_time = EH_WAIT_CMD_TOV;
+	int ret = SUCCESS;
+
+	/* Dont wait on command if PCI error is being handled
+	 * by PCI AER driver
+	 */
+	if (unlikely(pci_channel_offline(ha->pdev)) ||
+	    (test_bit(AF_EEH_BUSY, &ha->flags))) {
+		ql4_warn(ha, "Return from %s\n", __func__);
+		return ret;
+	}
 
 	do {
 		/* Checking to see if its returned to OS */
-		rp = (struct srb *) cmd->SCp.ptr;
+		rp = (struct srb *) CMD_SP(cmd);
 		if (rp == NULL) {
 			done++;
 			break;
 		}
 
-		if (got_ref && (atomic_read(&rp->ref_count) == 1)) {
-			done++;
-			break;
-		}
-
-		msleep(ABORT_POLLING_PERIOD);
-	} while (!(--wait_iter));
+		msleep(2000);
+	} while (max_wait_time--);
 
 	return done;
 }
@@ -1771,13 +2630,11 @@ static int qla4xxx_wait_for_hba_online(s
 {
 	unsigned long wait_online;
 
-	wait_online = jiffies + (30 * HZ);
+	wait_online = jiffies + (HBA_ONLINE_TOV * HZ);
 	while (time_before(jiffies, wait_online)) {
 
 		if (adapter_up(ha))
 			return QLA_SUCCESS;
-		else if (ha->retry_reset_ha_cnt == 0)
-			return QLA_ERROR;
 
 		msleep(2000);
 	}
@@ -1814,9 +2671,9 @@ static int qla4xxx_eh_wait_for_commands(
 		if (sp) {
 			cmd = sp->cmd;
 			spin_unlock_irqrestore(&ha->hardware_lock, flags);
-			if (cmd && stgt == scsi_target(cmd->device) &&
-			   (!sdev || sdev == cmd->device)) {
-				if (!qla4xxx_eh_wait_on_command(ha, cmd, 0)) {
+			if (cmd && stgt==scsi_target(cmd->device) &&
+				(!sdev || sdev==cmd->device)) {
+				if (!qla4xxx_eh_wait_on_command(ha, cmd)) {
 					status++;
 					break;
 				}
@@ -1825,6 +2682,7 @@ static int qla4xxx_eh_wait_for_commands(
 			spin_unlock_irqrestore(&ha->hardware_lock, flags);
 		}
 	}
+
 	return status;
 }
 
@@ -1837,114 +2695,86 @@ static int qla4xxx_eh_wait_for_commands(
  **/
 static int qla4xxx_eh_abort(struct scsi_cmnd *cmd)
 {
-	struct scsi_qla_host *ha;
+	struct scsi_qla_host *ha = to_qla_host(cmd->device->host);
+	unsigned int id = cmd->device->id;
+	unsigned int lun = cmd->device->lun;
+	unsigned long serial = cmd->serial_number;
+	unsigned long flags;
 	struct srb *srb = NULL;
-	struct ddb_entry *ddb_entry;
-	int ret = FAILED;
-	unsigned int channel;
-	unsigned int id;
-	unsigned int lun;
-	unsigned long serial;
-	unsigned long flags = 0;
-	int i = 0;
-	int got_ref = 0;
-
-	if (cmd == NULL) {
-		DEBUG2(printk("ABORT - **** SCSI mid-layer passing in NULL cmd\n"));
+	int ret = SUCCESS;
+	int wait = 0;
+
+	ql4_info(ha, "%d:%d: Abort command issued cmd=%p, pid=%ld\n",
+		 id, lun, cmd, serial);
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	srb = (struct srb *) CMD_SP(cmd);
+
+	if (!srb) {
+		DEBUG2(ql4_info(ha, "ABORT - cmd already completed.\n"));
+		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 		return SUCCESS;
 	}
 
-	ha = to_qla_host(cmd->device->host);
-	ddb_entry = cmd->device->hostdata;
-	channel = cmd->device->channel;
-	id = cmd->device->id;
-	lun = cmd->device->lun;
-	serial = cmd->serial_number;
-
-	if (!ddb_entry) {
-		DEBUG2(printk("scsi%ld: ABORT - NULL ddb entry.\n", ha->host_no));
-		return FAILED;
+	kref_get(&srb->srb_ref);
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+
+	if (qla4xxx_abort_task(ha, srb) != QLA_SUCCESS) {
+		DEBUG3(ql4_info(ha, "%d:%d: Abort_task mbx failed.\n",
+				id, lun));
+		ret = FAILED;
+	} else {
+		DEBUG3(ql4_info(ha, "%d:%d: Abort_task mbx success.\n",
+				id, lun));
+		wait = 1;
 	}
 
-	if (!cmd->SCp.ptr) {
-		DEBUG2(printk("scsi%ld: ABORT - cmd already completed.\n",
-			      ha->host_no));
-		return SUCCESS;
+	kref_put(&srb->srb_ref, qla4xxx_srb_compl);
+
+	/* Wait for command to complete */
+	if (wait) {
+		if (!qla4xxx_eh_wait_on_command(ha, cmd)) {
+			DEBUG2(ql4_info(ha, "%d:%d: Abort handler timed out\n",
+					id, lun));
+			ret = FAILED;
+		}
 	}
 
-
-
-	srb = (struct srb *) cmd->SCp.ptr;
-
-	dev_info(&ha->pdev->dev, "scsi%ld:%d:%d:%d: ABORT ISSUED "
-		 "cmd=%p, pid=%ld, ref=%d\n", ha->host_no, channel, id, lun,
-		 cmd, serial, atomic_read(&srb->ref_count));
-
-	if (qla4xxx_wait_for_hba_online(ha) != QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld:%d: %s: Unable to abort task. Adapter "
-				"DEAD.\n", ha->host_no, cmd->device->channel
-				, __func__));
-
-		return FAILED;
-	}
-
-	/* Check active list for command */
-	spin_lock_irqsave(&ha->hardware_lock, flags);
-	for (i = 1; i < MAX_SRBS; i++) {
-		srb =  ha->active_srb_array[i];
-
-		if (srb == NULL)
-			continue;
-
-		if (srb->cmd != cmd)
-			continue;
-
-		DEBUG2(printk("scsi%ld:%d:%d:%d %s: aborting srb %p from RISC. "
-			      "pid=%ld.\n", ha->host_no, channel, id, lun,
-			      __func__, srb, serial));
-		DEBUG3(qla4xxx_print_scsi_cmd(cmd));
-
-		/* Get a reference to the sp and drop the lock.*/
-		sp_get(srb);
-		got_ref++;
-
-		spin_unlock_irqrestore(&ha->hardware_lock, flags);
-
-		if (qla4xxx_abort_task(ha, srb) != QLA_SUCCESS) {
-			dev_info(&ha->pdev->dev,
-				"scsi%ld:%d:%d:%d: ABORT TASK - FAILED.\n",
-				ha->host_no, channel, id, lun);
-		} else {
-			dev_info(&ha->pdev->dev,
-				"scsi%ld:%d:%d:%d: ABORT TASK - mbx success.\n",
-				ha->host_no, channel, id, lun);
-		}
-		spin_lock_irqsave(&ha->hardware_lock, flags);
-		break;
-	}
-	spin_unlock_irqrestore(&ha->hardware_lock, flags);
-
-	/* Wait for command to complete */
-	if (qla4xxx_eh_wait_on_command(ha, cmd, got_ref)) {
-		dev_info(&ha->pdev->dev,
-			"scsi%ld:%d:%d:%d: ABORT SUCCEEDED - "
-			 "cmd returned back to OS.\n",
-			 ha->host_no, channel, id, lun);
-		ret = SUCCESS;
-	}
-
-	DEBUG2(printk("scsi%ld:%d:%d:%d: ABORT cmd=%p, pid=%ld, ref=%d, "
-		      "ret=%x\n", ha->host_no, channel, id, lun, cmd,
-		      serial, atomic_read(&srb->ref_count), ret));
-
-	if (got_ref)
-		sp_put(ha, srb);
+	ql4_info(ha, "%d:%d: Abort command - %s\n", id, lun,
+		(ret == SUCCESS) ? "succeded" : "failed");
 
 	return ret;
 }
 
-
-
+/**
+ * iscsi_block_scsi_eh - block scsi eh until session state has transistioned
+ * @cmd: scsi cmd passed to scsi eh handler
+ *
+ * If the session is down this function will wait for the recovery
+ * timer to fire or for the session to be logged back in. If the
+ * recovery timer fires then FAST_IO_FAIL is returned. The caller
+ * should pass this error value to the scsi eh.
+ */
+static int qla4xxx_iscsi_block_scsi_eh(struct scsi_cmnd *cmd)
+{
+	struct iscsi_cls_session *session =
+		starget_to_session(scsi_target(cmd->device));
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&session->lock, flags);
+	while (session->state != ISCSI_SESSION_LOGGED_IN) {
+		if (session->state == ISCSI_SESSION_FREE) {
+			ret = FAST_IO_FAIL;
+			break;
+		}
+		spin_unlock_irqrestore(&session->lock, flags);
+		msleep(1000);
+		spin_lock_irqsave(&session->lock, flags);
+	}
+	spin_unlock_irqrestore(&session->lock, flags);
+	return ret;
+}
 
 /**
  * qla4xxx_eh_device_reset - callback for target reset.
@@ -1955,71 +2785,56 @@ static int qla4xxx_eh_abort(struct scsi_
  **/
 static int qla4xxx_eh_device_reset(struct scsi_cmnd *cmd)
 {
-	struct scsi_qla_host *ha;
-	struct ddb_entry *ddb_entry;
-	int stat;
-	struct Scsi_Host *h;
-	unsigned int b, t, l;
-
-	if (cmd == NULL) {
-		DEBUG2(printk("%s: **** SCSI mid-layer passing in NULL cmd"
-				"DEVICE RESET - cmd already completed.\n",
-				__func__));
-		return SUCCESS;
-	}
-
-	h = cmd->device->host;
-	b = cmd->device->channel;
-	t = cmd->device->id;
-	l = cmd->device->lun;
-	ha = to_qla_host(h);
-	ddb_entry = cmd->device->hostdata;
-
-	if (!ddb_entry) {
-		DEBUG2(printk("scsi%ld: DEVICE RESET - NULL ddb entry.\n"
-				, ha->host_no));
-		return FAILED;
-	}
-
-	dev_info(&ha->pdev->dev, "scsi%ld:%d:%d:%d: DEVICE RESET ISSUED.\n"
-				 , ha->host_no, b, t, l);
-
-	DEBUG2(printk(KERN_INFO
-		      "scsi%ld: DEVICE_RESET cmd=%p jiffies = 0x%lx, to=%x,"
-		      "dpc_flags=%lx, status=%x allowed=%d\n", ha->host_no,
+	struct scsi_qla_host *ha = to_qla_host(cmd->device->host);
+	struct ddb_entry *ddb_entry = cmd->device->hostdata;
+	int ret = FAILED, stat;
+
+	if (!ddb_entry)
+		return ret;
+
+	/* If the iscsi_session is not logged in, qla4xxx_isci_block_scsi_eh()
+	 * waits for session to log back in and returns FAST_IO_FAIL after session
+	 * recovery timeout, so SML finishes the command and doenst call eh_host_reset.
+	 */
+	ret = qla4xxx_iscsi_block_scsi_eh(cmd);
+	if (ret)
+		return ret;
+
+	ql4_info(ha, "%d:%d:%d: DEVICE RESET ISSUED.\n",
+		   cmd->device->channel, cmd->device->id, cmd->device->lun);
+
+	DEBUG2(ql4_info(ha, "DEVICE_RESET cmd=%p jiffies = 0x%lx, to=%x,"
+		      "dpc_flags=%lx, status=%x allowed=%d\n",
 		      cmd, jiffies, cmd->request->timeout / HZ,
 		      ha->dpc_flags, cmd->result, cmd->allowed));
 
-	/* wait for hba to go online */
-	if (qla4xxx_wait_for_hba_online(ha) != QLA_SUCCESS) {
-		dev_info(&ha->pdev->dev, "%s: DEVICE RESET."
-			 "Adapter Offline.\n", __func__);
-                return FAILED;
-        }
-	stat = qla4xxx_reset_lun(ha, ddb_entry, l);
+	/* FIXME: wait for hba to go online */
+	stat = qla4xxx_reset_lun(ha, ddb_entry, cmd->device->lun);
 	if (stat != QLA_SUCCESS) {
-		dev_info(&ha->pdev->dev, "DEVICE RESET FAILED. %d\n", stat);
-		return FAILED;
+		ql4_info(ha, "DEVICE RESET FAILED. %d\n", stat);
+		goto eh_dev_reset_done;
 	}
 
 	if (qla4xxx_eh_wait_for_commands(ha, scsi_target(cmd->device),
 					 cmd->device)) {
-		dev_info(&ha->pdev->dev,
-			   "DEVICE RESET FAILED - waiting for "
+		ql4_info(ha, "DEVICE RESET FAILED - waiting for "
 			   "commands.\n");
-		return FAILED;
+		goto eh_dev_reset_done;
 	}
 
 	/* Send marker. */
-	if (qla4xxx_send_marker_iocb(ha, ddb_entry, l, MM_LUN_RESET)
-		!= QLA_SUCCESS)
-		return FAILED;
-
-	dev_info(&ha->pdev->dev,
-		   "scsi(%ld:%d:%d:%d): DEVICE RESET SUCCEEDED.\n",
-		   ha->host_no, b, t, l);
-
-	return SUCCESS;
+	if (qla4xxx_send_marker_iocb(ha, ddb_entry, cmd->device->lun,
+		MM_LUN_RESET) != QLA_SUCCESS)
+		goto eh_dev_reset_done;
+
+	ql4_info(ha, "%d:%d:%d): DEVICE RESET SUCCEEDED.\n",
+		   cmd->device->channel, cmd->device->id, cmd->device->lun);
+
+	ret = SUCCESS;
+
+eh_dev_reset_done:
+
+	return ret;
 }
 
 /**
@@ -2032,25 +2847,25 @@ static int qla4xxx_eh_target_reset(struc
 {
 	struct scsi_qla_host *ha = to_qla_host(cmd->device->host);
 	struct ddb_entry *ddb_entry = cmd->device->hostdata;
-	int stat;
+	int stat, ret;
 
 	if (!ddb_entry)
 		return FAILED;
 
+	/* If the iscsi_session is not logged in, qla4xxx_isci_block_scsi_eh()
+	 * waits for session to log back in and returns FAST_IO_FAIL after session
+	 * recovery timeout, so SML finishes the command and doenst call eh_host_reset.
+	 */
+	ret = qla4xxx_iscsi_block_scsi_eh(cmd);
+	if (ret)
+		return ret;
+
 	starget_printk(KERN_INFO, scsi_target(cmd->device),
 		       "WARM TARGET RESET ISSUED.\n");
 
-	/* wait for hba to go online */
-	if (qla4xxx_wait_for_hba_online(ha) != QLA_SUCCESS) {
-		dev_info(&ha->pdev->dev, "%s: TARGET RESET."
-			 "Adapter Offline.\n", __func__);
-		return FAILED;
-	}
-
-	DEBUG2(printk(KERN_INFO
-		      "scsi%ld: TARGET_DEVICE_RESET cmd=%p jiffies = 0x%lx, "
+	DEBUG2(ql4_info(ha, "TARGET_DEVICE_RESET cmd=%p jiffies = 0x%lx, "
 		      "to=%x,dpc_flags=%lx, status=%x allowed=%d\n",
-		      ha->host_no, cmd, jiffies, cmd->request->timeout / HZ,
+		      cmd, jiffies, cmd->request->timeout / HZ,
 		      ha->dpc_flags, cmd->result, cmd->allowed));
 
 	stat = qla4xxx_reset_target(ha, ddb_entry);
@@ -2082,6 +2897,20 @@ static int qla4xxx_eh_target_reset(struc
 	return SUCCESS;
 }
 
+/* qla4xxx_is_eh_active: Find if host reset is issue from sg_reset or EH
+ * @cmd: Pointer to Linux's SCSI Host struct
+ *
+ * Function  check if host reset is issued from Error handling or
+ * sg_reset. In case of sg_reset, we return false, as we don't want to abort
+ * active commands.
+ */
+static int qla4xxx_is_eh_active(struct Scsi_Host *shost)
+{
+        if (shost->shost_state == SHOST_RECOVERY)
+                return 1;
+        return 0;
+}
+
 /**
  * qla4xxx_eh_host_reset - kernel callback
  * @cmd: Pointer to Linux's SCSI command structure
@@ -2094,40 +2923,291 @@ static int qla4xxx_eh_host_reset(struct 
 	int return_status = FAILED;
 	struct scsi_qla_host *ha;
 
-	if (cmd == NULL) {
-		DEBUG2(printk("%s: **** SCSI mid-layer passing in NULL cmd"
-			      "HOST RESET - cmd already completed.\n",
-			      __func__));
-		return SUCCESS;
-	}
-
 	ha = (struct scsi_qla_host *) cmd->device->host->hostdata;
 
-	dev_info(&ha->pdev->dev,
-		   "scsi(%ld:%d:%d:%d): HOST RESET ISSUED.\n", ha->host_no,
-		   cmd->device->channel, cmd->device->id, cmd->device->lun);
-
-	if (qla4xxx_wait_for_hba_online(ha) != QLA_SUCCESS) {
-		DEBUG2(printk("scsi%ld:%d: %s: Unable to reset host.  Adapter "
-			      "DEAD.\n", ha->host_no, cmd->device->channel,
-			      __func__));
-
+	if (ql4xdontresethba == 1) {
+		DEBUG2(ql4_info(ha, "%s: Don't Reset HBA\n", __func__));
+		/* Clear outstanding srb in queues ONLY if host reset
+		 * is issued from EH scenario
+		 */
+		if(qla4xxx_is_eh_active(cmd->device->host))
+			qla4xxx_abort_active_cmds(ha, DID_ABORT << 16);
 		return FAILED;
 	}
 
-	/* make sure the dpc thread is stopped while we reset the hba */
-	clear_bit(AF_ONLINE, &ha->flags);
-	flush_workqueue(ha->dpc_thread);
-
-	if (qla4xxx_recover_adapter(ha, PRESERVE_DDB_LIST) == QLA_SUCCESS)
+	ql4_info(ha, "%d:%d:%d: HOST RESET ISSUED.\n",
+		   cmd->device->channel, cmd->device->id, cmd->device->lun);
+
+	if (qla4xxx_wait_for_hba_online(ha) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%d: %s: Unable to reset host.  Adapter "
+			      "DEAD.\n", cmd->device->channel, __func__));
+
+		return FAILED;
+	}
+
+	if (!test_bit(DPC_RESET_HA, &ha->dpc_flags)) {
+		if (is_qla8022(ha))
+			set_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+		else
+			set_bit(DPC_RESET_HA, &ha->dpc_flags);
+	}
+
+	if (qla4xxx_recover_adapter(ha) == QLA_SUCCESS)
 		return_status = SUCCESS;
 
-	dev_info(&ha->pdev->dev, "HOST RESET %s.\n",
+	ql4_info(ha, "HOST RESET %s.\n",
 		   return_status == FAILED ? "FAILED" : "SUCCEDED");
 
 	return return_status;
 }
 
+/* PCI AER driver recovers from all correctable errors w/o
+ * driver intervention. For uncorrectable errors PCI AER
+ * driver calls the following device driver's callbacks
+ *
+ * - Fatal Errors - link_reset
+ * - Non-Fatal Errors - driver's pci_error_detected() which
+ * returns CAN_RECOVER, NEED_RESET or DISCONNECT.
+ *
+ * PCI AER driver calls
+ * CAN_RECOVER - driver's pci_mmio_enabled(), mmio_enabled
+ *               returns RECOVERED or NEED_RESET if fw_hung
+ * NEED_RESET - driver's slot_reset()
+ * DISCONNECT - device is dead & cannot recover
+ * RECOVERED - driver's pci_resume()
+ */
+static pci_ers_result_t
+qla4xxx_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)
+{
+	struct scsi_qla_host *ha = pci_get_drvdata(pdev);
+
+	ql4_warn(ha, "%s: error detected:state %x\n", __func__, state);
+
+	if (!is_aer_supported(ha))
+		return PCI_ERS_RESULT_NONE;
+
+	switch (state) {
+	case pci_channel_io_normal:
+		clear_bit(AF_EEH_BUSY, &ha->flags);
+		return PCI_ERS_RESULT_CAN_RECOVER;
+	case pci_channel_io_frozen:
+		set_bit(AF_EEH_BUSY, &ha->flags);
+		qla4xxx_mailbox_premature_completion(ha);
+		qla4xxx_free_irqs(ha);
+		pci_disable_device(pdev);
+		/* Return back all IOs */
+		qla4xxx_abort_active_cmds(ha, DID_RESET << 16);
+		return PCI_ERS_RESULT_NEED_RESET;
+	case pci_channel_io_perm_failure:
+		set_bit(AF_EEH_BUSY, &ha->flags);
+		set_bit(AF_PCI_CHANNEL_IO_PERM_FAILURE, &ha->flags);
+		qla4xxx_abort_active_cmds(ha, DID_NO_CONNECT << 16);
+		return PCI_ERS_RESULT_DISCONNECT;
+	}
+	return PCI_ERS_RESULT_NEED_RESET;
+}
+
+/**
+ * qla4xxx_pci_mmio_enabled() gets called if
+ * qla4xxx_pci_error_detected() returns PCI_ERS_RESULT_CAN_RECOVER
+ * and read/write to the device still works.
+ **/
+static pci_ers_result_t
+qla4xxx_pci_mmio_enabled(struct pci_dev *pdev)
+{
+	struct scsi_qla_host *ha = pci_get_drvdata(pdev);
+
+	if (!is_aer_supported(ha))
+		return PCI_ERS_RESULT_NONE;
+
+	return PCI_ERS_RESULT_RECOVERED;
+}
+
+static uint32_t qla4_8xxx_error_recovery(struct scsi_qla_host *ha)
+{
+	uint32_t rval = QLA_ERROR;
+	uint32_t ret = 0;
+	int fn;
+	struct pci_dev *other_pdev = NULL;
+
+	ql4_warn(ha, "In %s\n", __func__);
+
+	set_bit(DPC_RESET_ACTIVE, &ha->dpc_flags);
+
+	if (test_bit(AF_ONLINE, &ha->flags)) {
+		clear_bit(AF_ONLINE, &ha->flags);
+		qla4xxx_mark_all_devices_missing(ha);
+		qla4xxx_process_aen(ha, FLUSH_DDB_CHANGED_AENS);
+	}
+
+	fn = PCI_FUNC(ha->pdev->devfn);
+	while (fn > 0) {
+		fn--;
+		ql4_info(ha, "%s: Finding PCI device at func %x\n",
+			 __func__, fn);
+		/* Get the pci device given the domain, bus,
+		 * slot/function number */
+		other_pdev =
+		    pci_get_domain_bus_and_slot(pci_domain_nr(ha->pdev->bus),
+		    ha->pdev->bus->number, PCI_DEVFN(PCI_SLOT(ha->pdev->devfn),
+		    fn));
+
+		if (!other_pdev)
+			continue;
+
+		if (atomic_read(&other_pdev->enable_cnt)) {
+			ql4_info(ha, "%s: Found PCI func in enabled state%x\n",
+			    __func__, fn);
+			pci_dev_put(other_pdev);
+			break;
+		}
+		pci_dev_put(other_pdev);
+	}
+
+	/* The first function on the card, the reset owner will
+	 * start & initialize the firmware. The other functions
+	 * on the card will reset the firmware context
+	 */
+	if (!fn) {
+		ql4_info(ha, "%s: devfn being reset 0x%x is the owner\n",
+			__func__, ha->pdev->devfn);
+
+		qla4_8xxx_idc_lock(ha);
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+		    QLA82XX_DEV_COLD);
+
+		qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_IDC_VERSION,
+		    QLA82XX_IDC_VERSION);
+
+		qla4_8xxx_idc_unlock(ha);
+		ql4_info(ha, "Clearing AF_FW_RECOVERY in qla4_8xxx_error_recovery\n");
+		clear_bit(AF_FW_RECOVERY, &ha->flags);
+		rval = qla4xxx_initialize_adapter(ha, PRESERVE_DDB_LIST);
+		qla4_8xxx_idc_lock(ha);
+
+		if (rval != QLA_SUCCESS) {
+			ql4_info(ha, "%s: HW State: FAILED\n", __func__);
+			qla4_8xxx_clear_drv_active(ha);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+			    QLA82XX_DEV_FAILED);
+		} else {
+			ql4_info(ha, "%s: HW State: READY\n", __func__);
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DEV_STATE,
+			    QLA82XX_DEV_READY);
+			/* Clear driver state register */
+			qla4_8xxx_wr_32(ha, QLA82XX_CRB_DRV_STATE, 0);
+			qla4_8xxx_set_drv_active(ha);
+			ret = qla4xxx_request_irqs(ha);
+			if (ret) {
+				ql4_warn(ha, "Failed to reserve interrupt %d "
+					"already in use.\n", ha->pdev->irq);
+				rval = QLA_ERROR;
+			} else {
+				ha->isp_ops->enable_intrs(ha);
+				rval = QLA_SUCCESS;
+			}
+		}
+		qla4_8xxx_idc_unlock(ha);
+	} else {
+		ql4_info(ha, "%s: devfn 0x%x is not the reset owner\n",
+				__func__, ha->pdev->devfn);
+		if ((qla4_8xxx_rd_32(ha, QLA82XX_CRB_DEV_STATE) ==
+		    QLA82XX_DEV_READY)) {
+			ql4_info(ha, "Clearing AF_FW_RECOVERY in qla4_8xxx_error_recovery in else\n");
+			clear_bit(AF_FW_RECOVERY, &ha->flags);
+			rval = qla4xxx_initialize_adapter(ha,
+			    PRESERVE_DDB_LIST);
+			if (rval == QLA_SUCCESS) {
+				ret = qla4xxx_request_irqs(ha);
+				if (ret) {
+					ql4_warn(ha, "Failed to"
+					    " reserve interrupt %d already in"
+					    " use.\n", ha->pdev->irq);
+					rval = QLA_ERROR;
+				} else {
+					ha->isp_ops->enable_intrs(ha);
+					rval = QLA_SUCCESS;
+				}
+			}
+			qla4_8xxx_idc_lock(ha);
+			qla4_8xxx_set_drv_active(ha);
+			qla4_8xxx_idc_unlock(ha);
+		}
+	}
+	clear_bit(DPC_RESET_ACTIVE, &ha->dpc_flags);
+	return rval;
+}
+
+static pci_ers_result_t
+qla4xxx_pci_slot_reset(struct pci_dev *pdev)
+{
+	pci_ers_result_t ret = PCI_ERS_RESULT_DISCONNECT;
+	struct scsi_qla_host *ha = pci_get_drvdata(pdev);
+	int rc;
+
+	ql4_warn(ha, "%s: slot_reset\n", __func__);
+
+	if (!is_aer_supported(ha))
+		return PCI_ERS_RESULT_NONE;
+
+	/* Restore the saved state of PCIe device -
+	 * BAR registers, PCI Config space, PCIX, MSI,
+	 * IOV states
+	 */
+	pci_restore_state(pdev);
+
+	/* pci_restore_state() clears the saved_state flag of the device
+	 * save restored state which resets saved_state flag
+	 */
+	pci_save_state(pdev);
+
+	/* Initialize device or resume if in suspended state */
+	rc = pci_enable_device(pdev);
+	if (rc) {
+		ql4_warn(ha, "%s: Cant re-enable device after reset\n",
+				 __func__);
+		goto exit_slot_reset;
+	}
+
+	ha->isp_ops->disable_intrs(ha);
+
+	if (is_qla8022(ha)) {
+		if (qla4_8xxx_error_recovery(ha) == QLA_SUCCESS) {
+			ret = PCI_ERS_RESULT_RECOVERED;
+			goto exit_slot_reset;
+		} else
+			goto exit_slot_reset;
+	}
+
+exit_slot_reset:
+	ql4_warn(ha, "%s: Return=%x\n device after reset\n", __func__, ret);
+	return ret;
+}
+
+static void
+qla4xxx_pci_resume(struct pci_dev *pdev)
+{
+	struct scsi_qla_host *ha = pci_get_drvdata(pdev);
+	int ret;
+
+	printk("%s: pci_resume\n", __func__);
+
+	ret = qla4xxx_wait_for_hba_online(ha);
+	if (ret != QLA_SUCCESS) {
+		printk("%s: the device failed to resume I/O from "
+			"slot/link_reset\n", __func__);
+	}
+
+	pci_cleanup_aer_uncorrect_error_status(pdev);
+	clear_bit(AF_EEH_BUSY, &ha->flags);
+}
+
+static struct pci_error_handlers qla4xxx_err_handler = {
+	.error_detected = qla4xxx_pci_error_detected,
+	.mmio_enabled = qla4xxx_pci_mmio_enabled,
+	.slot_reset = qla4xxx_pci_slot_reset,
+	.resume = qla4xxx_pci_resume,
+};
 
 static struct pci_device_id qla4xxx_pci_tbl[] = {
 	{
@@ -2148,6 +3228,12 @@ static struct pci_device_id qla4xxx_pci_
 		.subvendor	= PCI_ANY_ID,
 		.subdevice	= PCI_ANY_ID,
 	},
+	{
+		.vendor         = PCI_VENDOR_ID_QLOGIC,
+		.device         = PCI_DEVICE_ID_QLOGIC_ISP8022,
+		.subvendor      = PCI_ANY_ID,
+		.subdevice      = PCI_ANY_ID,
+	},
 	{0, 0},
 };
 MODULE_DEVICE_TABLE(pci, qla4xxx_pci_tbl);
@@ -2157,6 +3243,7 @@ static struct pci_driver qla4xxx_pci_dri
 	.id_table	= qla4xxx_pci_tbl,
 	.probe		= qla4xxx_probe_adapter,
 	.remove		= qla4xxx_remove_adapter,
+	.err_handler = &qla4xxx_err_handler,
 };
 
 static int __init qla4xxx_module_init(void)
@@ -2165,13 +3252,11 @@ static int __init qla4xxx_module_init(vo
 
 	atomic_set(&qla4xxx_hba_count, 0);
 	klist_init(&qla4xxx_hostlist, NULL, NULL);
-
 	/* Allocate cache for SRBs. */
 	srb_cachep = kmem_cache_create("qla4xxx_srbs", sizeof(struct srb), 0,
 				       SLAB_HWCACHE_ALIGN, NULL);
 	if (srb_cachep == NULL) {
-		printk(KERN_ERR
-		       "%s: Unable to allocate SRB cache..."
+		printk("%s: Unable to allocate SRB cache..."
 		       "Failing load!\n", DRIVER_NAME);
 		ret = -ENOMEM;
 		goto no_srp_cache;
@@ -2193,7 +3278,9 @@ static int __init qla4xxx_module_init(vo
 	if (ret)
 		goto unregister_transport;
 
-	printk(KERN_INFO "QLogic iSCSI HBA Driver\n");
+	ql4im_init();
+
+	printk("QLogic iSCSI HBA Driver\n");
 	return 0;
 
 unregister_transport:
@@ -2206,7 +3293,7 @@ no_srp_cache:
 
 static void __exit qla4xxx_module_exit(void)
 {
-	ql4_mod_unload = 1;
+	ql4im_exit();
 	pci_unregister_driver(&qla4xxx_pci_driver);
 	iscsi_unregister_transport(&qla4xxx_iscsi_transport);
 	kmem_cache_destroy(srb_cachep);
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4_version.h
--- a/drivers/scsi/qla4xxx/ql4_version.h
+++ b/drivers/scsi/qla4xxx/ql4_version.h
@@ -1,9 +1,32 @@
 /*
  * QLogic iSCSI HBA Driver
- * Copyright (c)  2003-2006 QLogic Corporation
+ * Copyright (c)  2003-2011 QLogic Corporation
  *
  * See LICENSE.qla4xxx for copyright and licensing details.
  */
 
-#define QLA4XXX_DRIVER_VERSION	"5.01.00.00.11.01-k14"
+#define QLA4XXX_DRIVER_VERSION	"5.02.14.01.05.06-c0"
 
+/*
+ * Driver Versioning Scheme:
+ * Major.Minor.Patch.Subminor.Distro.DistroLevel-SuffixBeta
+ *
+ * - Major#: Denotes driver family
+ *           (i.e. 5=iSCSI 2.6, 3=iSCSI 2.4, etc.)
+ * - Minor#: Denotes which iSCSI chip is supported
+ *           (i.e. 5.01=Add 4032, 5.02=Add P3P, etc.)
+ * - Patch#: Major Feature or structure (common w/ IOCTL) change.
+ *           Must match patch# in corresponding qisioctl.
+ *           **************************************************
+ *           ***   Also used to distinguish inbox vs OOT    ***
+ *           ***   (Inbox = even number, OOT = odd number)  ***
+ *           **************************************************
+ * - Subminor#: Updated per external release if the above numbers remain
+ *           unchanged. Set to 0 if above numbers are changed.
+ * - Beta#:  To be used for internal/test/EVT builds.
+ *           Set to 0 for release to DVT or external users.
+ * - Suffix [-k/-c/-d]:
+ *           -k: upstream or sysfs based drivers,
+ *           -d: ioctl based,
+ *           -c: Citrix XenServer based
+ */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_dbg.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_dbg.c
@@ -0,0 +1,108 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/klist.h>
+
+#include "ql4_def.h"
+#include "ql4im_def.h"
+
+void dprt_hba_iscsi_portal(PEXT_HBA_ISCSI_PORTAL port)
+{
+	printk("\tIPAddr\t\t%d.%d.%d.%d\n",
+		port->IPAddr.IPAddress[0],
+		port->IPAddr.IPAddress[1],
+		port->IPAddr.IPAddress[2],
+		port->IPAddr.IPAddress[3]);
+
+	printk("\tMACAddr\t\t%02x.%02x.%02x.%02x.%02x.%02x\n",
+		port->MacAddr[0],
+		port->MacAddr[1],
+		port->MacAddr[2],
+		port->MacAddr[3],
+		port->MacAddr[4],
+		port->MacAddr[5]);
+	printk("\tSerialNum\t0x%x\n", port->SerialNum);
+	printk("\tManufacturer\t%s\n", port->Manufacturer);
+	printk("\tModel\t\t%s\n", port->Model);
+	printk("\tDriverVersion\t%s\n", port->DriverVersion);
+	printk("\tFWVersion\t%s\n", port->FWVersion);
+	printk("\tOptRomVersion\t%s\n", port->OptRomVersion);
+	printk("\tState\t\t0x%x\n", port->State);
+	printk("\tType\t\t0x%x\n", port->Type);
+	printk("\tOptRomVersion\t0x%x\n", port->DriverAttr);
+	printk("\tFWAttr\t\t0x%x\n", port->FWAttr);
+	printk("\tDiscTargetCount\t0x%x\n", port->DiscTargetCount);
+}
+
+void dprt_chip_info(PEXT_CHIP_INFO pcinfo)
+{
+	printk("\tVendorId\t0x%x\n", pcinfo->VendorId);
+	printk("\tDeviceId\t0x%x\n", pcinfo->DeviceId);
+	printk("\tSubVendorId\t0x%x\n", pcinfo->SubVendorId);
+	printk("\tSubSystemId\t0x%x\n", pcinfo->SubSystemId);
+	printk("\tBoardID\t0x%x\n", pcinfo->BoardID);
+}
+
+void dprt_rw_flash(int rd, uint32_t offset, uint32_t len, uint32_t options)
+{
+	printk("\tDataLen 0x%08x", len);
+	if (!rd)
+		printk(" Options 0x%08x", options);
+	printk(" DataOffset 0x%08x", offset);
+	if (offset & INT_ISCSI_ACCESS_RAM)
+		printk(" RAM");
+	else
+		printk(" FLASH");
+	switch ((offset & INT_ISCSI_PAGE_MASK)) {
+		case INT_ISCSI_FW_IMAGE2_FLASH_OFFSET:
+		printk(" FW Image 2\n");
+		break;
+		case INT_ISCSI_SYSINFO_FLASH_OFFSET:
+		printk(" sysInfo\n");
+		break;
+		case INT_ISCSI_DRIVER_FLASH_OFFSET:
+		printk(" driver\n");
+		break;
+		case INT_ISCSI_INITFW_FLASH_OFFSET:
+		printk(" initfw\n");
+		break;
+		case INT_ISCSI_DDB_FLASH_OFFSET:
+		printk(" ddb\n");
+		break;
+		case INT_ISCSI_CHAP_FLASH_OFFSET:
+		printk(" CHAP\n");
+		break;
+		case INT_ISCSI_FW_IMAGE1_FLASH_OFFSET:
+		printk(" FW Image 1\n");
+		break;
+		case INT_ISCSI_BIOS_FLASH_OFFSET:
+		printk(" BIOS\n");
+		break;
+		default:
+		printk(" Illegal 0x%x\n",
+			(offset & INT_ISCSI_PAGE_MASK));
+		break;
+	}
+}
+
+void ql4_dump_buffer(unsigned char *buf, uint32_t len)
+{
+        uint32_t i;
+	uint32_t j, k;
+
+        for (i=0; i < len; i+=16) {
+                printk("0x%08x:", i);
+		k = len - i;
+		if (k >= 16) k = 16;
+		for (j = 0; j < k; j++) printk(" %02x", buf[i+j]);
+		printk("\n");
+        }
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_dbg.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_dbg.h
@@ -0,0 +1,114 @@
+/*
+ * QLogic iSCSI HBA Driver ioctl module
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef _QL4IM_DBG_H_
+#define _QL4IM_DBG_H_
+
+extern unsigned dbg_level;
+
+/*
+ * Driver debug definitions.
+ */
+#if 1
+#define ql4_printk(level, ha, format, arg...)                           \
+        printk("%s(%ld): %s: " format ,                                 \
+                dev_driver_string(&((ha)->pdev->dev)),                  \
+                (ha)->host_no, dev_name(&((ha)->pdev->dev)), ## arg)
+#else
+#define ql4_printk(level, ha, format, arg...) \
+        dev_printk(level , &((ha)->pdev->dev) , format , ## arg)
+#endif
+
+#define ql4_info(ha, format, arg...)    \
+        ql4_printk(KERN_INFO, ha, format, ## arg)
+#define ql4_warn(ha, format, arg...)    \
+        ql4_printk(KERN_WARNING, ha, format, ## arg)
+#define ql4_err(ha, format, arg...)     \
+        ql4_printk(KERN_ERR, ha, format, ## arg)
+#define ql4_dbg(ha, format, arg...)     \
+        ql4_printk(KERN_DEBUG, ha, format, ## arg)
+
+#define QL_DBG_1	(1 << 0)
+#define QL_DBG_2	(1 << 1)
+#define QL_DBG_3	(1 << 2)
+#define QL_DBG_4	(1 << 3)
+#define QL_DBG_5	(1 << 4)
+#define QL_DBG_6	(1 << 5)
+#define QL_DBG_7	(1 << 6)
+#define QL_DBG_8	(1 << 7)
+#define QL_DBG_9	(1 << 8)
+#define QL_DBG_10	(1 << 9)
+#define QL_DBG_11	(1 << 10)
+#define QL_DBG_12	(1 << 11)
+
+#define QL_DEBUG
+
+#ifdef QL_DEBUG
+
+extern void dprt_hba_iscsi_portal(PEXT_HBA_ISCSI_PORTAL port);
+
+extern void dprt_chip_info(PEXT_CHIP_INFO pcinfo);
+extern void dprt_rw_flash(int rd, uint32_t offset, uint32_t len, uint32_t options);
+
+
+#define DEBUG1(x)	if (dbg_level & QL_DBG_1) {x;}
+#define DEBUG2(x)	if (dbg_level & QL_DBG_2) {x;}
+#define DEBUG3(x)	if (dbg_level & QL_DBG_3) {x;}
+#define DEBUG4(x)	if (dbg_level & QL_DBG_4) {x;}
+#define DEBUG5(x)	if (dbg_level & QL_DBG_5) {x;}
+#define DEBUG6(x)	if (dbg_level & QL_DBG_6) {x;}
+#define DEBUG7(x)	if (dbg_level & QL_DBG_7) {x;}
+#define DEBUG8(x)	if (dbg_level & QL_DBG_8) {x;}
+#define DEBUG9(x)	if (dbg_level & QL_DBG_9) {x;}
+#define DEBUG10(x)	if (dbg_level & QL_DBG_10) {x;}
+#define DEBUG11(x)	if (dbg_level & QL_DBG_11) {x;}
+#define DEBUG12(x)	if (dbg_level & QL_DBG_12) {x;}
+
+#define ENTER(x)	DEBUG12(printk("qisioctl: Entering %s()\n", x))
+#define LEAVE(x)	DEBUG12(printk("qisioctl: Leaving  %s()\n", x))
+
+#define ENTER_IOCTL(x,n)	\
+	DEBUG12(printk("qisioctl(%d): Entering %s()\n", (int)n, x))
+
+#define LEAVE_IOCTL(x,n)	\
+	DEBUG12(printk("qisioctl(%d): Leaving %s()\n", (int)n, x))
+
+#define DUMP_HBA_ISCSI_PORTAL(port) if (dbg_level & QL_DBG_11) \
+		dprt_hba_iscsi_portal(port);
+#define DUMP_CHIP_INFO(pcinfo) if (dbg_level & QL_DBG_11) \
+		dprt_chip_info(pcinfo);
+#define DUMP_SET_FLASH(a,b,c) if (dbg_level & QL_DBG_11) \
+		dprt_rw_flash(0, a, b, c);
+#define DUMP_GET_FLASH(a,b) if (dbg_level & QL_DBG_11) \
+		dprt_rw_flash(1, a, b, 0);
+
+#else
+
+#define DEBUG1(x)
+#define DEBUG2(x)
+#define DEBUG3(x)
+#define DEBUG4(x)
+#define DEBUG5(x)
+#define DEBUG6(x)
+#define DEBUG7(x)
+#define DEBUG8(x)
+#define DEBUG9(x)
+#define DEBUG10(x)
+#define DEBUG11(x)
+#define DEBUG12(x)
+
+#define ENTER(x)
+#define LEAVE(x)
+
+#define DUMP_HBA_ISCSI_PORTAL(port)
+#define DUMP_CHIP_INFO(pcinfo)
+#define DUMP_GET_FLASH(a,b,c)
+#define DUMP_SET_FLASH(a,b)
+
+#endif
+
+#endif /* #ifndef _QL4IM_DBG_H_ */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_def.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_def.h
@@ -0,0 +1,75 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef __QIM_DEF_H__
+#define __QIM_DEF_H__
+
+#include <linux/blkdev.h>
+#include "qlisioct.h"
+#include "qlinioct.h"
+#include "ql4im_dbg.h"
+#include "ql4im_version.h"
+
+#define QL_TMP_BUF_SIZE		PAGE_SIZE * 2
+/*
+ * INT_DEF_FLASH_BLK_SIZE is which is the maximum flash transfer that can
+ * happen is the maximum dma size that could ever happen
+ */
+#define QL_DMA_BUF_SIZE		PAGE_ALIGN(INT_DEF_FLASH_BLK_SIZE)
+//	(((INT_DEF_FLASH_BLK_SIZE + PAGE_SIZE -1)/PAGE_SIZE) * PAGE_SIZE)
+
+struct hba_ioctl {
+	uint32_t		flag;
+#define HBA_IOCTL_BUSY		0x0001
+
+	struct mutex		ioctl_sem;
+	uint32_t		aen_reg_mask;
+	struct scsi_qla_host	*ha;
+	void			*dma_v;
+	dma_addr_t		dma_p;
+	int			dma_len;
+	uint16_t		aen_read;
+	uint16_t		pt_in_progress;
+	struct scsi_cmnd	pt_scsi_cmd;
+	struct srb		pt_srb;
+	struct scsi_device	pt_scsi_device;
+	struct request		pt_request;
+	struct semaphore	pt_cmpl_sem;
+	struct timer_list	pt_cmpl_timer;
+	struct ql4_aen_log	aen_log;
+	unsigned char		cmnd[32];
+	unsigned char		sense_buffer[SCSI_SENSE_BUFFERSIZE];
+	void			*core; /* ptr for core dump image */
+	char			tmp_buf[QL_TMP_BUF_SIZE];
+};
+
+#define IOCTL_INVALID_STATUS			0xffff
+
+#define SCSI_PT_CMD_TOV			55
+
+#define MIN(x,y)            ((x)<(y)?(x):(y))
+#define MAX(x,y)            ((x)>(y)?(x):(y))
+#define LSB(x)  ((uint8_t)(x))
+#define MSB(x)  ((uint8_t)((uint16_t)(x) >> 8))
+
+#define SCSI_GOOD                         0x00
+
+#include "ql4im_glbl.h"
+
+static inline struct ddb_entry *get_ddb_from_osid(struct scsi_qla_host *ha,
+		uint16_t os_id)
+{
+	struct ddb_entry *ddb_entry;
+
+	list_for_each_entry(ddb_entry, &ha->ddb_list, list)
+		if (ddb_entry->os_target_id == os_id)
+			return ddb_entry;
+
+	return NULL;
+}
+
+#endif /* ifndef __QIM_DEF_H__ */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_dump.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_dump.c
@@ -0,0 +1,720 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/klist.h>
+#include "ql4_def.h"
+#include "ql4im_def.h"
+#include "ql4im_dump.h"
+#include <scsi/scsi_dbg.h>
+
+static void ql4_dump_header(struct scsi_qla_host *ha, struct dump_image_header *hdr)
+{
+	extern char drvr_ver[];
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	memset(hdr, 0, sizeof(struct dump_image_header));
+
+	hdr->cookie = QLGC_COOKIE;
+	sprintf((char *)&hdr->dump_id_string,"%4x Dump", ha->pdev->device);
+	hdr->time_stamp = get_jiffies_64();
+	hdr->total_image_size  = DUMP_IMAGE_SIZE;
+	hdr->core_dump_offset  = CORE_DUMP_OFFSET;
+	hdr->probe_dump_offset = PROBE_DUMP_OFFSET;
+	sprintf((char *)&hdr->driver,"qla4xxx_%d v%s", ha->instance, drvr_ver);
+	sprintf((char *)&hdr->ioctlmod,"qisioctl_%d v%s",
+		    ha->instance, QL4IM_VERSION);
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+/************************************************************
+ *
+ *                  Core Dump Routines
+ *
+ ************************************************************/
+
+/*
+ * Perform a Write operation via the MADI registers
+ */
+static int qla4_write_MADI(struct scsi_qla_host *ha, uint32_t addr,
+				uint32_t data)
+{
+	int done = 0;
+	int count = 10000;
+	unsigned long flags;
+	int status = QLA_SUCCESS;
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+
+	if (((readl(&ha->reg->arc_madi_cmd) & MADI_STAT_MASK) >> 27) ==
+		MADI_STAT_COMMAND_BUSY) {
+		status = QLA_ERROR;
+		goto exit_write_MADI;
+	}
+
+	writel(addr, &ha->reg->arc_madi_cmd);
+	writel(data, &ha->reg->arc_madi_data);
+
+	while (!done && count--) {
+		switch ((readl(&ha->reg->arc_madi_cmd) & MADI_STAT_MASK) >> 27) {
+		case MADI_STAT_DATA_VALID:
+			done = 1;
+			break;
+
+		case MADI_STAT_DATA_INVALID:
+			writel(addr, &ha->reg->arc_madi_cmd);
+			writel(data, &ha->reg->arc_madi_data);
+			break;
+
+		default:
+			break;
+		}
+	}
+	if (!count)
+		status = QLA_ERROR;
+
+exit_write_MADI:
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+	return status;
+}
+
+/*
+ * Perform a Read operation via the MADI registers
+ */
+static int qla4_read_MADI(struct scsi_qla_host *ha, uint32_t addr,
+			uint32_t *data)
+{
+	int done = 0;
+	int count = 10000;
+	unsigned long flags;
+	int status = QLA_SUCCESS;
+
+	spin_lock_irqsave(&ha->hardware_lock, flags);
+	writel((MADI_READ_CMD | addr), &ha->reg->arc_madi_cmd);
+
+	while (!done && count--) {
+		switch ((readl(&ha->reg->arc_madi_cmd) & MADI_STAT_MASK) >> 27){
+		case MADI_STAT_DATA_VALID:
+			done = 1;
+			break;
+
+		case MADI_STAT_DATA_INVALID:
+			writel((MADI_READ_CMD | addr), &ha->reg->arc_madi_cmd);
+			break;
+
+		default:
+			break;
+		}
+	}
+
+	if (!count)
+		status = QLA_ERROR;
+
+	*data = readl(&ha->reg->arc_madi_data);
+	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+
+	return status;
+}
+
+static void
+ql4_dump_core(struct scsi_qla_host *ha, struct core_dump *core_dump)
+{
+	uint32_t		addr, data, rval;
+	volatile uint32_t	 __iomem *reg_ptr;
+	unsigned long		flags;
+	uint8_t			page, num_pci_pages;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	/* 1 - Select OAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000000) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 1 - Select OAP Processor "
+			"Failed1\n", __func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 2 - Halt the OAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_AUX_REG | 0x00000005, 0x00000002)
+		!= QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 2 - Halt OAP Processor "
+			"Failed\n", __func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 3 - Disable SRAM Parity */
+	if (qla4_write_MADI(ha, MADI_DEST_AUX_REG | 0x00000020, 0x00000001)
+		!= QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 3 - Disable SRAM Parity "
+			"Failed\n", __func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 4 - Select IAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000001)
+		!= QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 4 - Select IAP Processor "
+			"Failed\n", __func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 5 - Halt IAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_AUX_REG | 0x00000005, 0x00000002)
+		!= QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 5 - Halt IAP Processor Failed\n",
+			__func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 6 - Select OAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000000)
+		!= QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 6 - Select OAP Processor Failed\n",
+			__func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 7 - PCI Registers from Processor's Perspective */
+	for (addr = (PCI_START >> 2); (addr <= (PCI_END >> 2)) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD) , &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 7 - PCI Registers "
+				"from Processor's Perspective Failed\n",
+				__func__, (int)ha->host_no));
+			DEBUG2(ql4_info(ha, "%s(%d): PCIReg 0 addr = 0x%08x "
+				"Failed0\n", __func__, (int)ha->host_no,
+				(addr << 2)));
+			goto core_dump_exit;
+		}
+		core_dump->PCIRegProc[(addr & (0xFFC >> 2))] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 7 - PCI Registers from Processor's "
+			"Perspective:\n", __func__, (int)ha->host_no));
+
+
+	/* 8 - SRAM Content */
+	for (addr = (RAM_START >> 2); (addr <= (RAM_END >> 2)) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD) , &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 8 - SRAM Content Failed, "
+					" addr = 0x%08x\n", __func__,
+					(int)ha->host_no, (addr << 2)));
+			goto core_dump_exit;
+		}
+		core_dump->SRAM[addr] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 8 - SRAM Content:\n", __func__,
+			(int)ha->host_no));
+
+
+	/* 9 - OAP Core Registers */
+	for (addr = CORE_START; (addr <= CORE_END) ; addr++) {
+		rval = qla4_read_MADI(ha,
+			(addr | MADI_READ_CMD | MADI_DEST_CORE_REG), &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 9 - OAP Core Reg Failed, "
+					"addr = 0x%08x\n", __func__,
+					(int)ha->host_no, (addr)));
+			goto core_dump_exit;
+		}
+		core_dump->OAPCoreReg[addr] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 9 - OAP Core Register:\n", __func__,
+			(int)ha->host_no));
+
+
+	/* 10 - OAP Auxiliary Registers */
+	for (addr = 0; (addr <= 0x309) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD | MADI_DEST_AUX_REG) , &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 10 - OAP Aux Reg Failed, "
+				"addr = 0x%08x\n", __func__, (int)ha->host_no, (addr)));
+			goto core_dump_exit;
+		}
+		core_dump->OAPAuxReg[addr] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 10 - OAP Auxiliary Registers:\n", __func__, (int)ha->host_no));
+
+
+	/* 11 - Select IAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000001) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 11 - Select IAP Processor Failed\n",
+			__func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 12 - IAP Core Registers */
+	for (addr = 0; (addr <= 0x3F) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD | MADI_DEST_CORE_REG), &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 12 - IAP Core Reg Failed, "
+				"addr = 0x%08x \n", __func__, (int)ha->host_no, addr));
+			goto core_dump_exit;
+		}
+		core_dump->IAPCoreReg[addr] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 12 - IAP Core Registers:\n", __func__, (int)ha->host_no));
+
+
+	/* 13 - IAP Auxiliary Registers */
+	for (addr = 0; (addr <= 0x309) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD | MADI_DEST_AUX_REG), &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 13 - IAP Aux Reg Failed, "
+				"addr = 0x%08x\n", __func__, (int)ha->host_no, (addr)));
+			goto core_dump_exit;
+		}
+		core_dump->IAPAuxReg[addr] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 13 - IAP Auxiliary Registers:\n", __func__, (int)ha->host_no));
+
+	/* 14 - Save IAP load/store RAM */
+	for (addr = (LDST_START >> 2); (addr <= (LDST_END >> 2)) ; addr++) {
+		rval = qla4_read_MADI(ha, (addr | MADI_READ_CMD), &data);
+		if (rval != QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s(%d): 14 - IAP SRAM Content Failed, "
+				"addr = 0x%08x\n", __func__, (int)ha->host_no, (addr << 2)));
+			goto core_dump_exit;
+		}
+		core_dump->IAPSRAM[(addr & (0x1FFC >> 2))] = data;
+	}
+	DEBUG10(ql4_info(ha, "%s(%d): 14 - IAP Load/Store RAM\n", __func__, (int)ha->host_no));
+
+
+	/* 15 - Select OAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000000) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 15 - Select OAP Processor Failed3\n",
+			__func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+
+	/* 16 - Save Host PCI Registers */
+	if (is_qla4010(ha))
+                num_pci_pages = 4;
+	else
+                num_pci_pages = 3;
+
+	for (page = 0; page < num_pci_pages; page++) {
+		spin_lock_irqsave(&ha->hardware_lock, flags);
+		writel((clr_rmask(CSR_SCSI_PAGE_SELECT) | page), &ha->reg->ctrl_status);
+		reg_ptr = &ha->reg->mailbox[0];
+		for (addr = 0; addr < 64; addr++) {
+			core_dump->HostPCIRegPage[page][addr] = readl(reg_ptr);
+			reg_ptr++;
+		}
+		spin_unlock_irqrestore(&ha->hardware_lock, flags);
+		DEBUG10(ql4_info(ha, "%s(%d): 16 - Host PCI Registers Page %d:\n",
+			__func__, (int)ha->host_no, page));
+	}
+
+	/* 17 - Save statistics registers */
+	if (is_qla4010(ha)) {
+		/* Statistics registers were saved from page 3 registers above */
+	}
+	else {
+		spin_lock_irqsave(&ha->hardware_lock, flags);
+		writel(clr_rmask(CSR_SCSI_PAGE_SELECT), &ha->reg->ctrl_status);
+		writel(0, &ha->reg->u2.isp4022.p0.stats_index);
+		for (addr = 0; addr < 64; addr++) {
+			data = readl(&ha->reg->u2.isp4022.p0.stats_read_data_inc);
+			core_dump->HostPCIRegPage[PROT_STAT_PAGE][addr] = data;
+		}
+		DEBUG10(ql4_info(ha, "%s(%d): 17 - Statistics Registers:\n",
+			__func__, (int)ha->host_no));
+		spin_unlock_irqrestore(&ha->hardware_lock, flags);
+	}
+
+	/* Select OAP Processor */
+	if (qla4_write_MADI(ha, MADI_DEST_ARC_DEBUG, 0x00000000) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 18 - Select OAP Processor Failed\n",
+			__func__, (int)ha->host_no));
+		goto core_dump_exit;
+	}
+	/* Enable SRAM Parity */
+	if (qla4_write_MADI(ha, MADI_DEST_AUX_REG | 0x00000020, 0x00000000) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s(%d): 19 - Enable SRAM Parity Failed\n",
+			__func__, (int)ha->host_no));
+	}
+
+core_dump_exit:
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+
+/************************************************************
+ *
+ *                  Probe Dump Routines
+ *
+ ************************************************************/
+//
+// 4010 ProbeMux table
+//
+static PROBEMUX_INFO  probeModuleInfo4010[] = {
+     {"0"        , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"DA"       , CLK_BIT(SYSCLK) | CLK_BIT(PCICLK)    , MUX_SELECT_MAX}
+   , {"NRM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ODE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SRM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SCM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"NCM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"PRD"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RBM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"TDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RA"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ERM"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"RMI"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"OAP"      ,                   CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"ECM"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"NPF"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"IAP"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"OTP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"TTM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ITP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"MAM"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"BLM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ILM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IFP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IPV"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"OIP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"OFB"      , CLK_BIT(SYSCLK) | CLK_BIT(NRXCLK)    , MUX_SELECT_MAX}
+   , {"MAC"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IFB"      , CLK_BIT(SYSCLK) | CLK_BIT(NRXCLK)    , MUX_SELECT_MAX}
+   , {"PCORE"    , CLK_BIT(PCICLK)                      , MUX_SELECT_MAX}
+   , {"20"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"21"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"22"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"23"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"24"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"25"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"26"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"27"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"28"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"29"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2A"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2B"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2C"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2D"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2E"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2F"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"30"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"31"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"32"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"33"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"34"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"35"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"36"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"37"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"38"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"39"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3a"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3b"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3c"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3d"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3e"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3f"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+};
+
+//
+// 4022/4032 ProbeMux table
+//
+
+static PROBEMUX_INFO  probeModuleInfo4022[] = {
+     {"0"        , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"DA"       , CLK_BIT(SYSCLK) | CLK_BIT(PCICLK)    , MUX_SELECT_MAX}
+   , {"BPM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ODE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SRM0"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SRM1"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"PMD"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"PRD"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RMD"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"TDE"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RA"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"REG"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RMI"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"OAP"      ,                   CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"ECM"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"NPF"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"IAP"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"OTP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"TTM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ITP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"MAM"      , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"BLM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ILM"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IFP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IPV"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"OIP"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"OFB"      , CLK_BIT(SYSCLK) | CLK_BIT(NRXCLK)    , MUX_SELECT_MAX}
+   , {"MAC"      , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"IFB"      , CLK_BIT(SYSCLK) | CLK_BIT(NRXCLK)    , MUX_SELECT_MAX}
+   , {"PCORE"    , CLK_BIT(PCICLK)                      , MUX_SELECT_MAX}
+   , {"NRM0"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"NRM1"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SCM0"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"SCM1"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"NCM0"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"NCM1"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RBM0"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RBM1"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RBM2"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"RBM3"     , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"ERM0"     , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"ERM1"     , CLK_BIT(SYSCLK) | CLK_BIT(CPUCLK)    , MUX_SELECT_MAX}
+   , {"PERF0"    , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"PERF1"    , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2E"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"2F"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"30"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"31"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"32"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"33"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"34"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"35"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"36"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"37"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"38"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"39"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3a"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3b"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3c"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3d"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3e"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+   , {"3f"       , CLK_BIT(SYSCLK)                      , MUX_SELECT_MAX}
+};
+
+static void
+ql4_probe_dump(struct scsi_qla_host *ha, struct probe_dump *probe_dump)
+{
+	uint32_t   probeModule;
+	uint32_t   probeClock;
+	uint32_t   muxSelect;
+	uint32_t   oldPage;
+	unsigned long	flags;
+	uint32_t   probeAddr;
+	struct probe_data *pd;
+
+	PROBEMUX_INFO  *probeModuleInfo;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	probeModuleInfo = (is_qla4010(ha)) ? probeModuleInfo4010 : probeModuleInfo4022;
+	pd = (struct probe_data *)probe_dump;
+
+	for (probeModule = probe_DA; probeModule <= probe_PERF1; probeModule++) {
+		for (probeClock = 0; probeClock < 4; probeClock++) {
+			if (probeModuleInfo[probeModule].clocks & (1 << probeClock)) {
+				probeAddr = (probeModule << 8) | (probeClock << 6);
+				for (muxSelect = 0;
+					muxSelect < probeModuleInfo[probeModule].maxSelect;
+					muxSelect++) {
+					spin_lock_irqsave(&ha->hardware_lock, flags);
+					oldPage = readl(&ha->reg->ctrl_status) & 0x0003;
+					writel(0x00030000, &ha->reg->ctrl_status);  // Set to page 0
+
+					writel((u_long)(probeAddr | PROBE_RE | PROBE_UP | muxSelect),
+						isp_probe_mux_addr(ha));
+					pd->high = (readl(isp_probe_mux_data(ha)) >> 24) & 0xff;
+
+					writel((u_long)(probeAddr | PROBE_RE | PROBE_LO | muxSelect),
+						isp_probe_mux_addr(ha));
+					pd->low = readl(isp_probe_mux_data(ha));
+
+					writel((u_long)(0x00030000 | oldPage), &ha->reg->ctrl_status); // Reset page
+					spin_unlock_irqrestore(&ha->hardware_lock, flags);
+					pd++;
+				}
+			}
+		}
+	}
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+void ql4_core_dump(struct scsi_qla_host *ha, void *pdump)
+{
+	struct dump_image *image = (struct dump_image *)pdump;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ql4_dump_header(ha, &image->dump_header);
+	if(!(is_qla8022(ha))) {
+		ql4_dump_core(ha, &image->core_dump);
+		ql4_probe_dump(ha, &image->probe_dump);
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+char *probe_clk_names[] = {
+	"SYSCLK",
+	"PCICLK",
+	"NRXCLK",
+	"CPUCLK"
+};
+
+#if 0
+static void ql4_print_probe_dump(struct scsi_qla_host *ha,
+		struct probe_dump *p_dump)
+{
+	uint32_t   probeModule;
+	uint32_t   probeClock;
+	uint32_t   muxSelect;
+	uint32_t   probeAddr;
+	struct probe_data *pd;
+	PROBEMUX_INFO  *probeModuleInfo;
+
+	probeModuleInfo =
+		(is_qla4010(ha)) ? probeModuleInfo4010 : probeModuleInfo4022;
+	pd = (struct probe_data *)p_dump;
+
+	for (probeModule = probe_DA; probeModule <= probe_PERF1;
+		probeModule++) {
+		for (probeClock = 0; probeClock < 4; probeClock++) {
+			if (probeModuleInfo[probeModule].clocks &
+				(1 << probeClock)) {
+				probeAddr = (probeModule << 8) |
+						(probeClock << 6);
+
+				dev_info(&ha->pdev->dev,
+					"%s: %s ModuleSelect:0x%x "
+					"Clock:0x%x (%s)"
+					" StartProbeAddr:0x%x\n",
+					__func__,
+					probeModuleInfo[probeModule].moduleName,
+					probeModule,
+					probeClock,
+					probe_clk_names[probeClock],
+					probeAddr);
+
+				for (muxSelect = 0;
+					muxSelect <
+					probeModuleInfo[probeModule].maxSelect;) {
+					dev_info(&ha->pdev->dev,
+						"%s %s %s:\t 0x%04x: "
+						"%02x_%08x %02x_%08x "
+						"%02x_%08x %02x_%08x\n",
+						__func__,
+						probeModuleInfo[probeModule].moduleName,
+						probe_clk_names[probeClock],
+						(probeAddr | muxSelect),
+						pd->high, pd->low,
+						(pd + 1)->high, (pd + 1)->low,
+						(pd + 2)->high, (pd + 2)->low,
+						(pd + 3)->high, (pd + 3)->low);
+
+					muxSelect = muxSelect + 4;
+					pd = pd + 4;
+				}
+			}
+		}
+	}
+
+}
+
+static void ql4_print_core_dump(struct scsi_qla_host *ha,
+	struct core_dump *c_dump)
+{
+	uint32_t i;
+	uint32_t addr, page;
+
+	/* print Proc PCI Registers */
+	dev_info(&ha->pdev->dev, "%s : Proc PCI Registers \n", __func__);
+
+	for (i = 0 ; i < 1024; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, (PCI_START | i),
+			c_dump->PCIRegProc[i], c_dump->PCIRegProc[i+1],
+			c_dump->PCIRegProc[i+2], c_dump->PCIRegProc[i+3]);
+		i += 4;
+	}
+
+	/* print OAP Core  Registers */
+	dev_info(&ha->pdev->dev, "%s : OAP Core Registers \n", __func__);
+
+	for (i = 0 ; i < 64; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, i,
+			c_dump->OAPCoreReg[i], c_dump->OAPCoreReg[i+1],
+			c_dump->OAPCoreReg[i+2], c_dump->OAPCoreReg[i+3]);
+		i += 4;
+	}
+
+	/* print OAP Aux  Registers */
+	dev_info(&ha->pdev->dev, "%s : OAP Aux Registers \n", __func__);
+
+	for (i = 0 ; i < 778; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, i,
+			c_dump->OAPAuxReg[i], c_dump->OAPAuxReg[i+1],
+			c_dump->OAPAuxReg[i+2], c_dump->OAPAuxReg[i+3]);
+		i += 4;
+	}
+
+	/* print IAP Core  Registers */
+	dev_info(&ha->pdev->dev, "%s : IAP Core Registers \n", __func__);
+
+	for (i = 0 ; i < 64; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, i,
+			c_dump->IAPCoreReg[i], c_dump->IAPCoreReg[i+1],
+			c_dump->IAPCoreReg[i+2], c_dump->IAPCoreReg[i+3]);
+		i += 4;
+	}
+
+	/* print IAP Aux  Registers */
+	dev_info(&ha->pdev->dev, "%s : IAP Aux Registers \n", __func__);
+
+	for (i = 0 ; i < 778; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, i,
+			c_dump->IAPAuxReg[i], c_dump->IAPAuxReg[i+1],
+			c_dump->IAPAuxReg[i+2], c_dump->IAPAuxReg[i+3]);
+		i += 4;
+	}
+
+	/* print IAP SRAM  Registers */
+	dev_info(&ha->pdev->dev, "%s : IAP SRAM Registers \n", __func__);
+
+	for (i = 0 ; i < 2048; ) {
+		dev_info(&ha->pdev->dev, "%s : 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, i,
+			c_dump->IAPSRAM[i], c_dump->IAPSRAM[i+1],
+			c_dump->IAPSRAM[i+2], c_dump->IAPSRAM[i+3]);
+		i += 4;
+	}
+
+	/* print Host PCI Registers */
+	dev_info(&ha->pdev->dev, "%s : Host PCI Registers \n", __func__);
+	for (page = 0; page < 4; page++) {
+		for (addr = 0; addr < 64; ) {
+			dev_info(&ha->pdev->dev, "%s : 0x%04x: 0x%08x:"
+			"  0x%08x 0x%08x 0x%08x 0x%08x \n",
+			__func__, page, i,
+			c_dump->HostPCIRegPage[page][addr],
+			c_dump->HostPCIRegPage[page][addr+1],
+			c_dump->HostPCIRegPage[page][addr+2],
+			c_dump->HostPCIRegPage[page][addr+3]);
+
+			addr += 4;
+		}
+	}
+}
+#endif
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_dump.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_dump.h
@@ -0,0 +1,193 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef __QL4IM_DUMP_H_
+#define __QL4IM_DUMP_H_
+/*
+ * Dump Image Header
+ */
+struct dump_image_header {
+	uint32_t cookie;                /* 0x00  QLGC		*/
+	uint8_t  dump_id_string[12];    /* 0x04  "40xx Dump   "	*/
+	uint64_t time_stamp;		/* 0x10  timeb struct used by ftime() */
+	uint32_t total_image_size;      /* 0x18  image size excluding header  */
+	uint32_t core_dump_offset;      /* 0x1c  also represents size of header */
+	uint32_t probe_dump_offset;     /* 0x20  */
+	uint32_t queue_dump_offset;     /* 0x24  */
+	uint32_t reserved1[6];          /* 0x28  */
+	uint8_t driver[0x30];           /* 0x40  "qla4xxx_x vx.xx.xx-dx" */
+	uint8_t ioctlmod[0x30];         /* 0x70  "qisioctl_x vx.xx.xx-dx" */
+	uint8_t reserved2[0x60];        /* 0xA0  */
+};                  /* 0x100 (256) bytes */
+
+#define DUMP_IMAGE_HEADER_SIZE   (sizeof(struct dump_image_header))
+#define DUMP_IMAGE_HEADER_OFFSET 0
+
+#define QLGC_COOKIE     0x43474C51
+
+
+/*
+ * Core Dump
+ */
+struct core_dump {
+	uint32_t PCIRegProc[1024];      /* 4096    bytes */
+	uint32_t SRAM[524288];          /* 2097152 bytes */
+	uint32_t OAPCoreReg[64];        /* 256     bytes */
+	uint32_t OAPAuxReg[778];        /* 3112    bytes */
+	uint32_t IAPCoreReg[64];        /* 256     bytes */
+	uint32_t IAPAuxReg[778];        /* 3112    bytes */
+	uint32_t IAPSRAM[2048];         /* 8192    bytes */
+	uint32_t HostPCIRegPage[4][64];   /* 4 * 256     bytes */
+};                            /* 2117200 total */
+
+#define CORE_DUMP_SIZE   (sizeof(struct core_dump))
+#define CORE_DUMP_OFFSET (0 + DUMP_IMAGE_HEADER_SIZE)
+
+
+/*
+ * Probe Dump
+ */
+struct probe_dump {
+	uint8_t  data[28416];/* actually 28160 = 0x40x55x8 */
+};
+
+#define PROBE_DUMP_SIZE   (sizeof(struct probe_dump))
+#define PROBE_DUMP_OFFSET (CORE_DUMP_OFFSET + CORE_DUMP_SIZE)
+
+
+/*
+ * Dump Image
+ */
+struct dump_image{
+	struct dump_image_header	dump_header;
+	struct core_dump		core_dump;
+	struct probe_dump		probe_dump;
+};
+
+#define DUMP_IMAGE_SIZE (sizeof(struct dump_image))
+
+/****************************************************************
+ *
+ *                      Core Dump Defines
+ *
+ ****************************************************************/
+
+/* Defines used when accessing MADI */
+#define MADI_STAT_DATA_VALID   0
+#define MADI_STAT_DATA_INVALID 1
+#define MADI_STAT_COMMAND_BUSY 3
+
+#define MADI_DEST_SRAM         0x00000000
+#define MADI_DEST_CORE_REG     0x40000000
+#define MADI_DEST_AUX_REG      0x80000000
+#define MADI_DEST_ARC_DEBUG    0xc0000000
+
+#define MADI_STAT_MASK         0x18000000
+#define MADI_READ_CMD          0x20000000
+
+#define PROC_OAP 1
+#define PROC_IAP 2
+
+#define RAM_START  0
+#define RAM_END    0x1fffff
+#define CORE_START 0
+#define CORE_END   63
+#define AUX_START  0
+#define AUX_END    0x309
+#define LDST_START 0x07f00000
+#define LDST_END   0x07f01fff
+#define PCI_START  0x08000000
+#define PCI_END    0x08000fff
+
+
+/****************************************************************
+ *
+ *                      Probe Dump Defines
+ *
+ ****************************************************************/
+
+#define MUX_SELECT_MAX  0x40
+#define MAX_MODULE      0x40
+#define MAX_CLOCK       0x4
+
+#define  SYSCLK   0
+#define  PCICLK   1
+#define  NRXCLK   2
+#define  CPUCLK   3
+
+#define  CLK_BIT(x)  (1<<x)
+
+
+typedef enum
+{
+     probe_DA = 1
+   , probe_BPM
+   , probe_ODE
+   , probe_SRM0
+   , probe_SRM1
+   , probe_PMD
+   , probe_PRD
+   , probe_SDE
+   , probe_RMD
+   , probe_IDE
+   , probe_TDE
+   , probe_RA
+   , probe_REG
+   , probe_RMI
+   , probe_OAP
+   , probe_ECM
+   , probe_NPF
+   , probe_IAP
+   , probe_OTP
+   , probe_TTM
+   , probe_ITP
+   , probe_MAM
+   , probe_BLM
+   , probe_ILM
+   , probe_IFP
+   , probe_IPV
+   , probe_OIP
+   , probe_OFB
+   , probe_MAC
+   , probe_IFB
+   , probe_PCORE
+   , probe_NRM0
+   , probe_NRM1
+   , probe_SCM0
+   , probe_SCM1
+   , probe_NCM0
+   , probe_NCM1
+   , probe_RBM0
+   , probe_RBM1
+   , probe_RBM2
+   , probe_RBM3
+   , probe_ERM0
+   , probe_ERM1
+   , probe_PERF0
+   , probe_PERF1
+} probe_Module;
+
+typedef struct
+{
+   char     *moduleName;
+   uint32_t   clocks;
+   uint32_t   maxSelect;
+} PROBEMUX_INFO;
+
+
+#define PROBE_RE  0x8000
+#define PROBE_UP  0x4000
+#define PROBE_LO  0x0000
+
+struct probe_data {
+   uint32_t   high;
+   uint32_t   low;
+};
+
+extern void ql4_core_dump(struct scsi_qla_host *ha, void *pdump);
+
+#endif
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_glbl.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_glbl.h
@@ -0,0 +1,36 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+/*
+ * Global include file.
+ */
+#ifndef __QL4IM_GBL_H
+#define	__QL4IM_GBL_H
+
+extern uint8_t drvr_major;
+extern uint8_t drvr_minor;
+extern uint8_t drvr_patch;
+extern uint8_t drvr_beta;
+extern char drvr_ver[];
+
+/*
+ * Defined in ql4im_os.c
+ */
+extern uint32_t ql4im_get_hba_count(void);
+
+/*
+ * Defined in ql4im_ioctl.c
+ */
+extern int qla4xxx_ioctl(int cmd, void *arg);
+extern struct hba_ioctl *ql4im_get_adapter_handle(uint16_t instance);
+
+/*
+ * Defined in ql4im_dbg.c
+ */
+extern void ql4_dump_buffer(unsigned char *buf, uint32_t len);
+
+#endif /* _QL4IM_GBL_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_ioctl.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_ioctl.c
@@ -0,0 +1,4687 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+/*
+ * ioctl support functions
+ */
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/klist.h>
+
+#include "ql4_def.h"
+#include "ql4im_def.h"
+#include "ql4im_dump.h"
+#include <scsi/scsi_dbg.h>
+
+
+static void *
+Q64BIT_TO_PTR(uint64_t buf_addr, uint16_t addr_mode)
+{
+#if defined(CONFIG_COMPAT) || !defined(CONFIG_IA64) || !defined(CONFIG_64BIT)
+	union ql_doublelong {
+		struct {
+			uint32_t        lsl;
+			uint32_t        msl;
+		} longs;
+		uint64_t        dl;
+	};
+
+	union ql_doublelong tmpval;
+
+	tmpval.dl = buf_addr;
+
+#if defined(CONFIG_COMPAT) && !defined(CONFIG_IA64)
+	/* 32bit user - 64bit kernel */
+	if (addr_mode == EXT_DEF_ADDR_MODE_32) {
+		DEBUG9(printk("%s: got 32bit user address.\n", __func__));
+		return((void *)(uint64_t)(tmpval.longs.lsl));
+	} else {
+		DEBUG9(printk("%s: got 64bit user address.\n", __func__));
+		return((void *)buf_addr);
+	}
+#else
+	return((void *)(tmpval.longs.lsl));
+#endif
+#else
+	return((void *)buf_addr);
+#endif
+}
+
+#include "ql4im_os.h"
+
+/* Start of External ioctls */
+
+static int ql4_reg_aen(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	EXT_REG_AEN_ISCSI reg_aen;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ioctl->RequestLen > sizeof(EXT_REG_AEN_ISCSI)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_reg_aen;
+	}
+
+	if ((status = copy_from_user((void *)&reg_aen,
+	    Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+				     sizeof(EXT_REG_AEN_ISCSI))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_reg_aen;
+	}
+
+	ql4im_ha->aen_reg_mask = reg_aen.Enable;
+
+	DEBUG4(ql4_info(ha, "%s: mask = 0x%x\n",
+		__func__, ql4im_ha->aen_reg_mask));
+
+	ioctl->Status = EXT_STATUS_OK;
+
+exit_reg_aen:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_get_rhel5_aen(struct hba_ioctl *ql4im_ha,
+	EXT_ASYNC_EVENT *async_event)
+{
+	struct scsi_qla_host *ha;
+	uint32_t num_aens = 0;
+	uint16_t i, aen_in;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	aen_in = ha->aen_in;
+	if (ql4im_ha->aen_read < aen_in) {
+		for (i = ql4im_ha->aen_read;
+			((i < aen_in)&&(num_aens < EXT_DEF_MAX_AEN_QUEUE));
+			i++) {
+			async_event[num_aens].AsyncEventCode =
+				ha->aen_q[i].mbox_sts[0];
+			async_event[num_aens].Payload[0] =
+				ha->aen_q[i].mbox_sts[1];
+			async_event[num_aens].Payload[1] =
+				ha->aen_q[i].mbox_sts[2];
+			async_event[num_aens].Payload[2] =
+				ha->aen_q[i].mbox_sts[3];
+			async_event[num_aens].Payload[3] =
+				ha->aen_q[i].mbox_sts[4];
+			num_aens++;
+		}
+	} else if (ql4im_ha->aen_read > aen_in) {
+		for (i = ql4im_ha->aen_read;
+			((i < MAX_AEN_ENTRIES)&&
+				(num_aens < EXT_DEF_MAX_AEN_QUEUE));
+			i++) {
+			async_event[num_aens].AsyncEventCode =
+				ha->aen_q[i].mbox_sts[0];
+			async_event[num_aens].Payload[0] =
+				ha->aen_q[i].mbox_sts[1];
+			async_event[num_aens].Payload[1] =
+				ha->aen_q[i].mbox_sts[2];
+			async_event[num_aens].Payload[2] =
+				ha->aen_q[i].mbox_sts[3];
+			async_event[num_aens].Payload[3] =
+				ha->aen_q[i].mbox_sts[4];
+			num_aens++;
+		}
+		for (i = 0;
+			((i < aen_in)&&
+				(num_aens < EXT_DEF_MAX_AEN_QUEUE));
+			i++) {
+			async_event[num_aens].AsyncEventCode =
+				ha->aen_q[i].mbox_sts[0];
+			async_event[num_aens].Payload[0] =
+				ha->aen_q[i].mbox_sts[1];
+			async_event[num_aens].Payload[1] =
+				ha->aen_q[i].mbox_sts[2];
+			async_event[num_aens].Payload[2] =
+				ha->aen_q[i].mbox_sts[3];
+			async_event[num_aens].Payload[3] =
+				ha->aen_q[i].mbox_sts[4];
+			num_aens++;
+		}
+	}
+	ql4im_ha->aen_read = aen_in;
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return num_aens;
+}
+
+static int ql4_get_aen(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	EXT_ASYNC_EVENT *async_event;
+	uint32_t num_aens = 0;
+	uint16_t i, j;
+	int status = 0;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	DEBUG4(ql4_info(ha, "%s: mask = 0x%x\n", __func__,
+		ql4im_ha->aen_reg_mask));
+
+	if (ql4im_ha->aen_reg_mask == EXT_DEF_ENABLE_NO_AENS) {
+		DEBUG2(ql4_info(ha, "%s: AEN mask not enabled\n", __func__));
+		ioctl->Status = EXT_STATUS_OK;
+		return 0;
+	}
+	if (ioctl->ResponseLen <
+		(sizeof(EXT_ASYNC_EVENT) * EXT_DEF_MAX_AEN_QUEUE)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_get_gen;
+	}
+	async_event = (EXT_ASYNC_EVENT *)ql4im_ha->tmp_buf;
+	memset(async_event, 0,
+		MIN(sizeof(ql4im_ha->tmp_buf),
+		    sizeof(EXT_ASYNC_EVENT) * EXT_DEF_MAX_AEN_QUEUE));
+
+	if ((drvr_major == 5)&&(drvr_minor == 0)){
+		num_aens = ql4_get_rhel5_aen(ql4im_ha, async_event);
+	} else {
+		ha->ql4getaenlog(ha, &ql4im_ha->aen_log);
+		if (ql4im_ha->aen_log.count) {
+			for (i = 0; (i < ql4im_ha->aen_log.count); i++) {
+				async_event[i].AsyncEventCode =
+					ql4im_ha->aen_log.entry[i].mbox_sts[0];
+				for (j = 0; j < MBOX_AEN_REG_COUNT - 1; j++)
+					async_event[i].Payload[j] =
+						ql4im_ha->aen_log.entry[i].mbox_sts[j+1];
+				num_aens++;
+			}
+		}
+	}
+
+	ioctl->ResponseLen = sizeof(EXT_ASYNC_EVENT) * num_aens;
+	ioctl->Status = EXT_STATUS_OK;
+
+	/*
+	 * Copy the IOCTL EXT_ASYNC_EVENT buffer to the user's data space
+	 */
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), async_event,
+				   ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+exit_get_gen:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+
+
+static int
+ql4_query_hba_iscsi_node(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	EXT_HBA_ISCSI_NODE	*phba_node = NULL;
+	struct init_fw_ctrl_blk	*init_fw_cb;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	phba_node = (EXT_HBA_ISCSI_NODE *)ql4im_ha->tmp_buf;
+
+	if (!ioctl->ResponseAdr ||
+		ioctl->ResponseLen < sizeof(EXT_HBA_ISCSI_NODE)) {
+		DEBUG2(ql4_info(ha, "%s: rsp buffer too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_hba_node;
+	}
+
+	/*
+	 * Send mailbox command
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_INIT_FW_CTRL_BLOCK;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	if (ha->acb_version == ACB_SUPPORTED) {
+		mbox_cmd[4] = ha->ifcb_size;
+	}
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) == QLA_ERROR) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+
+		goto exit_query_hba_node;
+	}
+
+	/*
+	 * Transfer data from Fw's DEV_DB_ENTRY buffer to IOCTL's
+	 * EXT_HBA_ISCSI_NODE buffer
+	 */
+	init_fw_cb = (struct init_fw_ctrl_blk *) ql4im_ha->dma_v;
+
+	memset(phba_node, 0, sizeof(EXT_HBA_ISCSI_NODE));
+	phba_node->PortNumber = le16_to_cpu(init_fw_cb->pri.ipv4_port);
+	phba_node->NodeInfo.PortalCount = 1;
+
+	memcpy(phba_node->NodeInfo.IPAddr.IPAddress, init_fw_cb->pri.ipv4_addr,
+	    sizeof(init_fw_cb->pri.ipv4_addr));
+	memcpy(phba_node->NodeInfo.iSCSIName, init_fw_cb->pri.iscsi_name,
+	    sizeof(init_fw_cb->pri.iscsi_name));
+
+	sprintf(phba_node->DeviceName, "/proc/scsi/qla4xxx/%ld", ha->host_no);
+
+	/*
+	 * Copy the IOCTL EXT_HBA_ISCSI_NODE buffer to the user's data space
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   phba_node, ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_query_hba_node:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int
+ql4_get_flash_sys_info(struct scsi_qla_host *ha,
+		   struct flash_sys_info *sys_info,
+		   dma_addr_t sys_info_dma,
+		   uint32_t *mbox_status)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_READ_FLASH;
+	mbox_cmd[1] = LSDW(sys_info_dma);
+	mbox_cmd[2] = MSDW(sys_info_dma);
+	mbox_cmd[3] = INT_ISCSI_SYSINFO_FLASH_OFFSET;
+	mbox_cmd[4] = sizeof(*sys_info);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		*mbox_status = mbox_sts[0];
+                return QLA_ERROR;
+	}
+	return QLA_SUCCESS;
+}
+
+static int
+ql4_get_mbx_sys_info(struct scsi_qla_host *ha,
+                 struct mbx_sys_info *sys_info,
+                 dma_addr_t sys_info_dma,
+                 uint32_t *mbox_status)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_SYS_INFO;
+	mbox_cmd[1] = LSDW(sys_info_dma);
+	mbox_cmd[2] = MSDW(sys_info_dma);
+	mbox_cmd[4] = sizeof(*sys_info);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 6, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		*mbox_status = mbox_sts[0];
+                return QLA_ERROR;
+	}
+
+	/* Make sure we receive the minimum required data */
+        if (mbox_sts[4] < offsetof(struct mbx_sys_info, reserved)) {
+                DEBUG2(ql4_info(ha, "%s: GET_SYS_INFO data receive err (%x)\n",
+                        __func__, mbox_sts[4]));
+		*mbox_status = mbox_sts[0];
+                return QLA_ERROR;
+        }
+
+	return QLA_SUCCESS;
+}
+
+static int
+ql4_query_hba_iscsi_portal(struct hba_ioctl *ql4im_ha,
+                           EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	EXT_HBA_ISCSI_PORTAL *phba_portal;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(*phba_portal))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_hba_portal;
+	}
+
+	phba_portal = (EXT_HBA_ISCSI_PORTAL *)ql4im_ha->tmp_buf;
+	memset(phba_portal, 0, sizeof(EXT_HBA_ISCSI_PORTAL));
+
+	strcpy(phba_portal->DriverVersion, drvr_ver);
+	sprintf(phba_portal->FWVersion, "%02d.%02d Patch %02d Build %02d",
+		ha->firmware_version[0], ha->firmware_version[1],
+		ha->patch_number, ha->build_number);
+
+	/* Get firmware state information */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_FW_STATE;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 4, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_GET_FW_STATE "
+		    "failed w/ status %04x\n", __func__, mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_query_hba_portal;
+	}
+
+	switch (mbox_sts[1]) {
+	case FW_STATE_READY:
+		phba_portal->State = EXT_DEF_CARD_STATE_READY;
+		break;
+	case FW_STATE_CONFIG_WAIT:
+		phba_portal->State = EXT_DEF_CARD_STATE_CONFIG_WAIT;
+		break;
+	case 0x0002: /*case FW_STATE_WAIT_LOGIN:*/
+		phba_portal->State = EXT_DEF_CARD_STATE_LOGIN;
+		break;
+	case FW_STATE_ERROR:
+		phba_portal->State = EXT_DEF_CARD_STATE_ERROR;
+		break;
+	}
+
+	switch (mbox_sts[3] & 0x0001) {
+	case 0:/* case FW_ADDSTATE_COPPER_MEDIA:*/
+		phba_portal->Type = EXT_DEF_TYPE_COPPER;
+		break;
+	case FW_ADDSTATE_OPTICAL_MEDIA:
+		phba_portal->Type = EXT_DEF_TYPE_OPTICAL;
+		break;
+	}
+
+	/* Get ddb entry information */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY;
+	mbox_cmd[1] = 0;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: GET_DATABASE_ENTRY failed!\n",
+		    __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->RequestLen = 0;
+		ioctl->DetailStatus = ioctl->Instance;
+
+		goto exit_query_hba_portal;
+	}
+
+	phba_portal->DiscTargetCount = (uint16_t) mbox_sts[2];
+
+	if (is_qla8022(ha)) {
+		/* Get Sys Info from Mailbox */
+		struct mbx_sys_info *sys_info;
+		sys_info = (struct mbx_sys_info *) ql4im_ha->dma_v;
+
+		status = ql4_get_mbx_sys_info(ha, sys_info, ql4im_ha->dma_p, &mbox_sts[0]);
+		if (status == QLA_SUCCESS) {
+			memcpy(phba_portal->IPAddr.IPAddress, ha->ip_address,
+			    MIN(sizeof(phba_portal->IPAddr.IPAddress),
+				sizeof(ha->ip_address)));
+			memcpy(phba_portal->MacAddr, sys_info->mac_addr,
+			    MIN(sizeof(phba_portal->MacAddr),
+				sizeof(sys_info->mac_addr)));
+			memcpy(phba_portal->Model, sys_info->board_id_str,
+			    MIN(sizeof(phba_portal->Model),
+				sizeof(sys_info->board_id_str)));
+			#if 0 //FIXME:
+			phba_portal->SerialNum = le32_to_cpu(sys_info->serial_number);
+			memcpy(phba_portal->Manufacturer, sys_info->vendorId,
+			    sizeof(phba_portal->Manufacturer));
+			#endif
+		}
+	} else {
+		/* Get Sys Info from Flash */
+		struct flash_sys_info *sys_info;
+		sys_info = (struct flash_sys_info *) ql4im_ha->dma_v;
+
+		status = ql4_get_flash_sys_info(ha, sys_info, ql4im_ha->dma_p, &mbox_sts[0]);
+		if (status == QLA_SUCCESS) {
+			phba_portal->SerialNum = le32_to_cpu(sys_info->serialNumber);
+			memcpy(phba_portal->IPAddr.IPAddress, ha->ip_address,
+			    MIN(sizeof(phba_portal->IPAddr.IPAddress),
+				sizeof(ha->ip_address)));
+			memcpy(phba_portal->MacAddr, sys_info->physAddr[0].address,
+			    sizeof(phba_portal->MacAddr));
+			memcpy(phba_portal->Manufacturer, sys_info->vendorId,
+			    sizeof(phba_portal->Manufacturer));
+			memcpy(phba_portal->Model, sys_info->productId,
+			    sizeof(phba_portal->Model));
+		}
+	}
+	if (status != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: Get SYS_INFO failed w/"
+		    " status %04X\n", __func__, mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_query_hba_portal;
+	}
+
+	/*
+	 * Copy the IOCTL EXT_HBA_ISCSI_PORTAL buffer to the user's data space
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   phba_portal, ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+	DUMP_HBA_ISCSI_PORTAL(phba_portal);
+exit_query_hba_portal:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_query_disc_iscsi_node(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	struct dev_db_entry *fw_ddb_entry = (struct dev_db_entry *)ql4im_ha->dma_v;
+	EXT_DISC_ISCSI_NODE *pdisc_node;
+	struct ddb_entry *ddb_entry = NULL;
+	struct scsi_qla_host *ha;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(*pdisc_node))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_disc_node;
+	}
+
+	pdisc_node = (EXT_DISC_ISCSI_NODE *)ql4im_ha->tmp_buf;
+
+	/* get device database entry info from firmware */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY;
+	mbox_cmd[1] = (uint32_t)ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: failed to get DEV_DB_ENTRY\n",
+		    __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->RequestLen = 0;
+		ioctl->DetailStatus = ioctl->Instance;
+		goto exit_disc_node;
+	}
+
+	/* --- Transfer data from Fw's DEV_DB_ENTRY buffer to
+	*      IOCTL's EXT_DISC_ISCSI_PORTAL buffer --- */
+	memset(pdisc_node, 0, sizeof(EXT_DISC_ISCSI_NODE));
+	pdisc_node->NodeInfo.PortalCount = 1;
+	pdisc_node->NodeInfo.IPAddr.Type = EXT_DEF_TYPE_ISCSI_IP;
+	memcpy(pdisc_node->NodeInfo.IPAddr.IPAddress, fw_ddb_entry->ip_addr,
+	    MIN(sizeof(pdisc_node->NodeInfo.IPAddr.IPAddress),
+	    sizeof(fw_ddb_entry->ip_addr)));
+	strncpy(pdisc_node->NodeInfo.Alias, fw_ddb_entry->iscsi_alias,
+	    MIN(sizeof(pdisc_node->NodeInfo.Alias),
+	    sizeof(fw_ddb_entry->iscsi_alias)));
+	strncpy(pdisc_node->NodeInfo.iSCSIName, fw_ddb_entry->iscsi_name,
+	    MIN(sizeof(pdisc_node->NodeInfo.iSCSIName),
+	    sizeof(fw_ddb_entry->iscsi_name)));
+
+	if (ioctl->Instance < MAX_DDB_ENTRIES){
+		ddb_entry = ha->fw_ddb_index_map[ioctl->Instance];
+		if ((ddb_entry == NULL) ||
+			(ddb_entry == (struct ddb_entry *)INVALID_ENTRY))
+			ddb_entry = NULL;
+	}
+
+	if (ddb_entry == NULL) {
+		DEBUG2(ql4_info(ha, "%s: device index [%d] not logged "
+		    "in. Dummy target info returned.\n", __func__,
+		    ioctl->Instance));
+
+		pdisc_node->SessionID	    = 0xDEAD;
+		pdisc_node->ConnectionID    = 0xDEAD;
+		pdisc_node->PortalGroupID   = 0xDEAD;
+		pdisc_node->ScsiAddr.Bus    = 0xFF;
+		pdisc_node->ScsiAddr.Target = 0xFF;
+		pdisc_node->ScsiAddr.Lun    = 0xFF;
+	}
+	else {
+		pdisc_node->SessionID	    = ddb_entry->target_session_id;
+		pdisc_node->ConnectionID    = ddb_entry->connection_id;
+		pdisc_node->PortalGroupID   = 0;
+		pdisc_node->ScsiAddr.Bus    = 0;
+		pdisc_node->ScsiAddr.Target = QL4_DDB_TO_TGTID(ddb_entry);
+		pdisc_node->ScsiAddr.Lun    = 0;
+	}
+
+	/* --- Copy Results to user space --- */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   pdisc_node,
+				   sizeof(EXT_DISC_ISCSI_NODE))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_disc_node:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_query_disc_iscsi_portal(struct hba_ioctl *ql4im_ha,
+					EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	struct dev_db_entry *fw_ddb_entry;
+	EXT_DISC_ISCSI_PORTAL *pdisc_portal;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(*pdisc_portal))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_disc_portal;
+	}
+
+	pdisc_portal = (EXT_DISC_ISCSI_PORTAL *)ql4im_ha->tmp_buf;
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	fw_ddb_entry = (struct dev_db_entry *) ql4im_ha->dma_v;
+
+	mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY;
+	mbox_cmd[1] = (uint32_t)ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: failed to get DEV_DB_ENTRY\n",
+		    __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->RequestLen = 0;
+		ioctl->DetailStatus = ioctl->Instance;
+		goto exit_disc_portal;
+	}
+
+	memset(pdisc_portal, 0, sizeof(EXT_DISC_ISCSI_PORTAL));
+	memcpy(pdisc_portal->IPAddr.IPAddress, fw_ddb_entry->ip_addr,
+	    MIN(sizeof(pdisc_portal->IPAddr.IPAddress),
+	    sizeof(fw_ddb_entry->ip_addr)));
+
+	pdisc_portal->PortNumber = le16_to_cpu(fw_ddb_entry->port);
+	pdisc_portal->IPAddr.Type = EXT_DEF_TYPE_ISCSI_IP;
+	pdisc_portal->NodeCount = 0;
+
+	strncpy(pdisc_portal->HostName, fw_ddb_entry->iscsi_name,
+	    MIN(sizeof(pdisc_portal->HostName),
+	    sizeof(fw_ddb_entry->iscsi_name)));
+
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   pdisc_portal,
+				   sizeof(EXT_DISC_ISCSI_PORTAL))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+exit_disc_portal:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_query_driver(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	EXT_DRIVER_INFO *pdinfo;
+	struct scsi_qla_host *ha;
+	int status = 0;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || (ioctl->ResponseLen < sizeof(*pdinfo))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_driver;
+	}
+
+	pdinfo = (EXT_DRIVER_INFO *)ql4im_ha->tmp_buf;
+
+	memset(pdinfo, 0, sizeof(EXT_DRIVER_INFO));
+	strcpy(pdinfo->Version, drvr_ver);
+
+	pdinfo->NumOfBus	= EXT_DEF_MAX_HBA;
+	pdinfo->TargetsPerBus	= EXT_DEF_MAX_TARGET;
+	pdinfo->LunPerTarget	= EXT_DEF_MAX_LUN;
+	pdinfo->LunPerTargetOS	= EXT_DEF_MAX_BUS;
+
+	if (sizeof(dma_addr_t) > 4)
+		pdinfo->DmaBitAddresses = 1;  /* 64-bit */
+	else
+		pdinfo->DmaBitAddresses = 0;  /* 32-bit */
+
+	pdinfo->IoMapType	= 1;
+
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pdinfo,
+				   sizeof(EXT_DRIVER_INFO))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_query_driver:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_query_fw(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	EXT_FW_INFO *pfw_info;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+	int status = 0;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || (ioctl->ResponseLen < sizeof(*pfw_info))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_fw;
+	}
+
+	pfw_info = (EXT_FW_INFO *)ql4im_ha->tmp_buf;
+	memset(pfw_info, 0, sizeof(EXT_FW_INFO));
+
+	/* ----- Get firmware version information ---- */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_ABOUT_FW;
+
+	/*
+	 * NOTE: In QLA4010, mailboxes 2 & 3 may hold an address for data.
+	 * Make sure that we write 0 to those mailboxes, if unused.
+	 */
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_ABOUT_FW failed w/ "
+		    "status %04X\n", __func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_query_fw;
+	}
+
+	sprintf(pfw_info->Version, "FW Version %d.%d Patch %d Build %d",
+	    mbox_sts[1], mbox_sts[2], mbox_sts[3], mbox_sts[4]);
+
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pfw_info,
+				sizeof(EXT_FW_INFO))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_query_fw:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_query_chip(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	EXT_CHIP_INFO	*pchip_info;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(EXT_CHIP_INFO))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+				 __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_chip;
+	}
+
+	pchip_info = (EXT_CHIP_INFO *)ql4im_ha->tmp_buf;
+	memset(pchip_info, 0, sizeof(EXT_CHIP_INFO));
+
+	if(is_qla8022(ha)) {
+		pchip_info->VendorId	= ha->pdev->vendor;
+		pchip_info->DeviceId	= ha->pdev->device;
+		pchip_info->SubVendorId = ha->pdev->subsystem_vendor;
+		pchip_info->SubSystemId = ha->pdev->subsystem_device;
+		pchip_info->BoardID	= ha->board_id;
+		pchip_info->ChipRevision = CHIP_REVISION_VALID |
+					   ha->revision_id;
+	} else {
+		uint32_t mbox_status;
+		struct flash_sys_info *sys_info;
+		sys_info = (struct flash_sys_info *) ql4im_ha->dma_v;
+
+		status = ql4_get_flash_sys_info(ha, sys_info, ql4im_ha->dma_p, &mbox_status);
+		if (status == QLA_SUCCESS) {
+			pchip_info->VendorId	= le32_to_cpu(sys_info->pciDeviceVendor);
+			pchip_info->DeviceId	= le32_to_cpu(sys_info->pciDeviceId);
+			pchip_info->SubVendorId = le32_to_cpu(sys_info->pciSubsysVendor);
+			pchip_info->SubSystemId = le32_to_cpu(sys_info->pciSubsysId);
+			pchip_info->BoardID	= ha->board_id;
+		} else {
+			DEBUG2(ql4_info(ha, "%s: MBOX_CMD_READ_FLASH failed w/"
+			    " status %04X\n", __func__, mbox_status));
+
+			ioctl->Status = EXT_STATUS_MAILBOX;
+			ioctl->DetailStatus = mbox_status;
+			goto exit_query_chip;
+		}
+	}
+
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(
+		Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+		pchip_info, sizeof(EXT_CHIP_INFO))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+	DUMP_CHIP_INFO(pchip_info);
+
+exit_query_chip:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_query_ipstate(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	EXT_QUERY_IP_STATE *ip_state;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(EXT_QUERY_IP_STATE))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_ipstate;
+	}
+
+	ip_state = (EXT_QUERY_IP_STATE *)ql4im_ha->tmp_buf;
+	memset(ip_state, 0, sizeof(EXT_QUERY_IP_STATE));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_IP_ADDR_STATE;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = ioctl->Reserved1;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 8, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD 0x91 failed w/"
+		    " status 0x%04x\n", __func__, mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_query_ipstate;
+	}
+
+	memcpy(ip_state->IP_ACBState, &mbox_sts[1],
+		MIN(sizeof(ip_state->IP_ACBState), sizeof(mbox_sts[1])));
+
+	ip_state->ValidLifetime = le32_to_cpu(mbox_sts[2]);
+	ip_state->PreferredLifetime = le32_to_cpu(mbox_sts[3]);
+
+	memcpy(ip_state->IPAddressInfo1, &mbox_sts[4],
+		MIN(sizeof(ip_state->IPAddressInfo1), sizeof(mbox_sts[4])));
+	memcpy(ip_state->IPAddressInfo2, &mbox_sts[5],
+		MIN(sizeof(ip_state->IPAddressInfo2), sizeof(mbox_sts[5])));
+	memcpy(ip_state->IPAddressInfo3, &mbox_sts[6],
+		MIN(sizeof(ip_state->IPAddressInfo3), sizeof(mbox_sts[6])));
+	memcpy(ip_state->IPAddressInfo4, &mbox_sts[7],
+		MIN(sizeof(ip_state->IPAddressInfo4), sizeof(mbox_sts[7])));
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if ((status = copy_to_user(
+		Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+		ip_state, sizeof(EXT_QUERY_IP_STATE))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_query_ipstate:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_query_cur_ip(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	EXT_QUERY_DEVICE_CURRENT_IP *ip;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr ||
+		(ioctl->ResponseLen < sizeof(EXT_QUERY_DEVICE_CURRENT_IP))) {
+		DEBUG2(ql4_info(ha, "%s: no response buffer found.\n",
+		    __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_query_ipstate;
+	}
+
+	ip = (EXT_QUERY_DEVICE_CURRENT_IP *)ql4im_ha->tmp_buf;
+	memset(ip, 0, sizeof(EXT_QUERY_DEVICE_CURRENT_IP));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_DB_ENTRY_CURRENT_IP_ADDR;
+	mbox_cmd[1] = ioctl->Instance;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 8, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD 0x93 failed w/"
+		    " status 0x%04x\n", __func__, mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+
+		goto exit_query_ipstate;
+	}
+
+	memcpy(&ip->Addr.IPAddress[0], &mbox_sts[3], sizeof(mbox_sts[3]));
+	memcpy(&ip->Addr.IPAddress[4], &mbox_sts[4], sizeof(mbox_sts[4]));
+	memcpy(&ip->Addr.IPAddress[8], &mbox_sts[5], sizeof(mbox_sts[5]));
+	memcpy(&ip->Addr.IPAddress[12], &mbox_sts[6], sizeof(mbox_sts[6]));
+
+	if (mbox_sts[2] & 0x10)
+		ip->Addr.Type = EXT_DEF_TYPE_ISCSI_IPV6;
+
+	ip->DeviceState = le16_to_cpu((mbox_sts[1] >> 16));
+	ip->TCPPort	= le16_to_cpu((mbox_sts[2] >> 16));
+	memcpy(&ip->Flags[0], &mbox_sts[2], sizeof(ip->Flags));
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if ((status = copy_to_user(
+		Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+		ip, sizeof(EXT_QUERY_DEVICE_CURRENT_IP))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: copy_to_user failed\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_query_ipstate:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_query(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+
+	switch (ioctl->SubCode) {
+	case EXT_SC_QUERY_HBA_ISCSI_NODE:
+		status = ql4_query_hba_iscsi_node(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_HBA_ISCSI_PORTAL:
+		status = ql4_query_hba_iscsi_portal(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_DISC_ISCSI_NODE:
+		status = ql4_query_disc_iscsi_node(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_DISC_ISCSI_PORTAL:
+		status = ql4_query_disc_iscsi_portal(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_DRIVER:
+		status = ql4_query_driver(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_FW:
+		status = ql4_query_fw(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_CHIP:
+		status = ql4_query_chip(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_IP_STATE:
+		status = ql4_query_ipstate(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_QUERY_DEVICE_CURRENT_IP:
+		status = ql4_query_cur_ip(ql4im_ha, ioctl);
+		break;
+	default:
+		DEBUG2(printk("%s: unsupported qry sub-code(%x)\n",
+			__func__, ioctl->SubCode));
+
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+	}
+	return(status);
+}
+
+static int ql4_get_statistics_gen(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	EXT_HBA_PORT_STAT_GEN	*pstat_gen;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ioctl->ResponseLen < sizeof(EXT_HBA_PORT_STAT_GEN)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_get_stat_gen;
+	}
+
+	pstat_gen = (EXT_HBA_PORT_STAT_GEN *)ql4im_ha->tmp_buf;
+	memset(pstat_gen, 0, sizeof(EXT_HBA_PORT_STAT_GEN));
+
+	pstat_gen->HBAPortErrorCount	 = ha->adapter_error_count;
+	pstat_gen->DevicePortErrorCount  = ha->device_error_count;
+	pstat_gen->IoCount		 = ha->total_io_count;
+	pstat_gen->MBytesCount		 = ha->total_mbytes_xferred;
+	pstat_gen->InterruptCount	 = ha->isr_count;
+	pstat_gen->LinkFailureCount	 = ha->link_failure_count;
+	pstat_gen->InvalidCrcCount	 = ha->invalid_crc_count;
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pstat_gen,
+				   ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_stat_gen:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_statistics_iscsi(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	EXT_HBA_PORT_STAT_ISCSI *pstat_local;
+	EXT_HBA_PORT_STAT_ISCSI *pstat_user;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen < sizeof(EXT_HBA_PORT_STAT_ISCSI))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_stats_iscsi;
+	}
+
+	pstat_user = (EXT_HBA_PORT_STAT_ISCSI *)ql4im_ha->tmp_buf;
+
+	/*
+	 * Make the mailbox call
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_MANAGEMENT_DATA;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: get mngmt data for index [%d] failed "
+		    "w/ mailbox ststus 0x%x\n", __func__, ioctl->Instance,
+		    mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_stats_iscsi;
+	}
+
+	pstat_local = (EXT_HBA_PORT_STAT_ISCSI *) ql4im_ha->dma_v;
+	memset(pstat_user, 0, sizeof(EXT_HBA_PORT_STAT_ISCSI));
+	pstat_user->MACTxFramesCount	      =
+	    le64_to_cpu(pstat_local->MACTxFramesCount);
+	pstat_user->MACTxBytesCount	      =
+	    le64_to_cpu(pstat_local->MACTxBytesCount);
+	pstat_user->MACRxFramesCount	      =
+	    le64_to_cpu(pstat_local->MACRxFramesCount);
+	pstat_user->MACRxBytesCount	      =
+	    le64_to_cpu(pstat_local->MACRxBytesCount);
+	pstat_user->MACCRCErrorCount	      =
+	    le64_to_cpu(pstat_local->MACCRCErrorCount);
+	pstat_user->MACEncodingErrorCount     =
+	    le64_to_cpu(pstat_local->MACEncodingErrorCount);
+	pstat_user->IPTxPacketsCount	      =
+	    le64_to_cpu(pstat_local->IPTxPacketsCount);
+	pstat_user->IPTxBytesCount	      =
+	    le64_to_cpu(pstat_local->IPTxBytesCount);
+	pstat_user->IPTxFragmentsCount	      =
+	    le64_to_cpu(pstat_local->IPTxFragmentsCount);
+	pstat_user->IPRxPacketsCount	      =
+	    le64_to_cpu(pstat_local->IPRxPacketsCount);
+	pstat_user->IPRxBytesCount	      =
+	    le64_to_cpu(pstat_local->IPRxBytesCount);
+	pstat_user->IPRxFragmentsCount	      =
+	    le64_to_cpu(pstat_local->IPRxFragmentsCount);
+	pstat_user->IPDatagramReassemblyCount =
+	    le64_to_cpu(pstat_local->IPDatagramReassemblyCount);
+	pstat_user->IPv6RxPacketsCount	      =
+	    le64_to_cpu(pstat_local->IPv6RxPacketsCount);
+	pstat_user->IPRxPacketErrorCount      =
+	    le64_to_cpu(pstat_local->IPRxPacketErrorCount);
+	pstat_user->IPReassemblyErrorCount    =
+	    le64_to_cpu(pstat_local->IPReassemblyErrorCount);
+	pstat_user->TCPTxSegmentsCount	      =
+	    le64_to_cpu(pstat_local->TCPTxSegmentsCount);
+	pstat_user->TCPTxBytesCount	      =
+	    le64_to_cpu(pstat_local->TCPTxBytesCount);
+	pstat_user->TCPRxSegmentsCount	      =
+	    le64_to_cpu(pstat_local->TCPRxSegmentsCount);
+	pstat_user->TCPRxBytesCount	      =
+	    le64_to_cpu(pstat_local->TCPRxBytesCount);
+	pstat_user->TCPTimerExpiredCount      =
+	    le64_to_cpu(pstat_local->TCPTimerExpiredCount);
+	pstat_user->TCPRxACKCount	      =
+	    le64_to_cpu(pstat_local->TCPRxACKCount);
+	pstat_user->TCPTxACKCount	      =
+	    le64_to_cpu(pstat_local->TCPTxACKCount);
+	pstat_user->TCPRxErrorSegmentCount    =
+	    le64_to_cpu(pstat_local->TCPRxErrorSegmentCount);
+	pstat_user->TCPWindowProbeUpdateCount =
+	    le64_to_cpu(pstat_local->TCPWindowProbeUpdateCount);
+	pstat_user->iSCSITxPDUCount	      =
+	    le64_to_cpu(pstat_local->iSCSITxPDUCount);
+	pstat_user->iSCSITxBytesCount	      =
+	    le64_to_cpu(pstat_local->iSCSITxBytesCount);
+	pstat_user->iSCSIRxPDUCount	      =
+	    le64_to_cpu(pstat_local->iSCSIRxPDUCount);
+	pstat_user->iSCSIRxBytesCount	      =
+	    le64_to_cpu(pstat_local->iSCSIRxBytesCount);
+	pstat_user->iSCSICompleteIOsCount     =
+	    le64_to_cpu(pstat_local->iSCSICompleteIOsCount);
+	pstat_user->iSCSIUnexpectedIORxCount  =
+	    le64_to_cpu(pstat_local->iSCSIUnexpectedIORxCount);
+	pstat_user->iSCSIFormatErrorCount     =
+	    le64_to_cpu(pstat_local->iSCSIFormatErrorCount);
+	pstat_user->iSCSIHeaderDigestCount    =
+	    le64_to_cpu(pstat_local->iSCSIHeaderDigestCount);
+	pstat_user->iSCSIDataDigestErrorCount =
+	    le64_to_cpu(pstat_local->iSCSIDataDigestErrorCount);
+	pstat_user->iSCSISeqErrorCount	      =
+	    le64_to_cpu(pstat_local->iSCSISeqErrorCount);
+
+	/*
+	 * Copy the data from the dma buffer to the user's data space
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   pstat_user, ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_stats_iscsi:
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_get_device_entry_iscsi(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	struct dev_db_entry	*pfw_ddb_entry;
+	EXT_DEVICE_ENTRY_ISCSI	*pdev_entry;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen < sizeof(EXT_DEVICE_ENTRY_ISCSI))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_dev_entry;
+	}
+
+	/*
+	 * Make the mailbox call
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	if (ioctl->SubCode == EXT_SC_GET_DEVICE_ENTRY_ISCSI)
+		mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY;
+	else
+		mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY_DEFAULTS;
+
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: get ddb entry for index [%d] failed "
+		    "w/ mailbox ststus 0x%x\n", __func__, ioctl->Instance,
+		    mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_dev_entry;
+	}
+
+	pdev_entry = (EXT_DEVICE_ENTRY_ISCSI *)ql4im_ha->tmp_buf;
+	memset(pdev_entry, 0, sizeof(EXT_DEVICE_ENTRY_ISCSI));
+	/*
+	 * Transfer data from Fw's DEV_DB_ENTRY buffer to IOCTL's
+	 * EXT_DEVICE_ENTRY_ISCSI buffer
+	 */
+	pfw_ddb_entry = (struct dev_db_entry *) ql4im_ha->dma_v;
+
+	pdev_entry->NumValid	 = mbox_sts[2];
+	pdev_entry->NextValid	 = mbox_sts[3];
+	pdev_entry->DeviceState  = mbox_sts[4];
+	pdev_entry->Options	 = pfw_ddb_entry->options;
+	pdev_entry->TargetSessID = le16_to_cpu(pfw_ddb_entry->tsid);
+	memcpy(pdev_entry->InitiatorSessID, pfw_ddb_entry->isid,
+	    sizeof(pfw_ddb_entry->isid));
+
+	pdev_entry->DeviceInfo.DeviceType = le16_to_cpu(EXT_DEF_ISCSI_REMOTE);
+	pdev_entry->DeviceInfo.ExeThrottle =
+	    le16_to_cpu(pfw_ddb_entry->exec_throttle);
+	pdev_entry->DeviceInfo.InitMarkerlessInt =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_max_snd_data_seg_len);
+	pdev_entry->DeviceInfo.iSCSIOptions =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_options);
+	pdev_entry->DeviceInfo.TCPOptions =
+	    le16_to_cpu(pfw_ddb_entry->tcp_options);
+	pdev_entry->DeviceInfo.IPOptions =
+	    le16_to_cpu(pfw_ddb_entry->ip_options);
+	pdev_entry->DeviceInfo.MaxPDUSize =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_max_rcv_data_seg_len);
+	pdev_entry->DeviceInfo.FirstBurstSize =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_first_burst_len);
+	pdev_entry->DeviceInfo.LogoutMinTime =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_def_time2wait);
+	pdev_entry->DeviceInfo.LogoutMaxTime =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_def_time2retain);
+	pdev_entry->DeviceInfo.MaxOutstandingR2T =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_max_outsnd_r2t);
+	pdev_entry->DeviceInfo.KeepAliveTimeout =
+	    le16_to_cpu(pfw_ddb_entry->ka_timeout);
+	pdev_entry->DeviceInfo.PortNumber =
+	    le16_to_cpu(pfw_ddb_entry->port);
+	pdev_entry->DeviceInfo.MaxBurstSize =
+	    le16_to_cpu(pfw_ddb_entry->iscsi_max_burst_len);
+	pdev_entry->DeviceInfo.TaskMgmtTimeout =
+	    le16_to_cpu(pfw_ddb_entry->def_timeout);
+	pdev_entry->EntryInfo.PortalCount = mbox_sts[2];
+	pdev_entry->ExeCount = le16_to_cpu(pfw_ddb_entry->exec_count);
+	pdev_entry->DDBLink = le16_to_cpu(pfw_ddb_entry->ddb_link);
+
+	memcpy(pdev_entry->DeviceInfo.TargetAddr, pfw_ddb_entry->tgt_addr,
+	    MIN(sizeof(pdev_entry->DeviceInfo.TargetAddr),
+		sizeof(pfw_ddb_entry->tgt_addr)));
+	memcpy(pdev_entry->EntryInfo.IPAddr.IPAddress, pfw_ddb_entry->ip_addr,
+	    MIN(sizeof(pdev_entry->EntryInfo.IPAddr.IPAddress),
+		sizeof(pfw_ddb_entry->ip_addr)));
+	memcpy(pdev_entry->EntryInfo.iSCSIName, pfw_ddb_entry->iscsi_name,
+	    MIN(sizeof(pdev_entry->EntryInfo.iSCSIName),
+		sizeof(pfw_ddb_entry->iscsi_name)));
+	memcpy(pdev_entry->EntryInfo.Alias, pfw_ddb_entry->iscsi_alias,
+	    MIN(sizeof(pdev_entry->EntryInfo.Alias),
+		sizeof(pfw_ddb_entry->iscsi_alias)));
+
+	/*
+	 * Copy the IOCTL EXT_DEVICE_ENTRY_ISCSI buffer to the user's data space
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+				   pdev_entry, ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_dev_entry:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+
+static int ql4_get_init_fw_iscsi(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	EXT_INIT_FW_ISCSI *pinit_fw;
+	struct addr_ctrl_blk *acb;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen < sizeof(EXT_DEVICE_ENTRY_ISCSI))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_init_fw;
+	}
+
+	/*
+	 * Send mailbox command
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	switch (ioctl->SubCode) {
+	case EXT_SC_GET_INIT_FW_ISCSI:
+		mbox_cmd[0] = MBOX_CMD_GET_INIT_FW_CTRL_BLOCK;
+		break;
+	case EXT_SC_GET_INIT_FW_DEFAULTS_ISCSI:
+		mbox_cmd[0] = MBOX_CMD_GET_INIT_FW_CTRL_BLOCK_DEFAULTS;
+		break;
+	default:
+		DEBUG2(ql4_info(ha, "%s: invalid subcode (0x%04X)"
+			" speficied\n", __func__, ioctl->SubCode));
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_init_fw;
+	}
+
+	mbox_cmd[1] = 0;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	if (ha->acb_version == ACB_SUPPORTED) {
+		mbox_cmd[4] = ha->ifcb_size;
+	}
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_init_fw;
+	}
+
+	pinit_fw = (EXT_INIT_FW_ISCSI *)ql4im_ha->tmp_buf;
+	memset(pinit_fw, 0, sizeof(EXT_INIT_FW_ISCSI));
+	/*
+	 * Transfer Data from DMA buffer to Local buffer
+	 */
+	acb = (struct addr_ctrl_blk *)ql4im_ha->dma_v;
+
+	pinit_fw->Version	  = acb->version;
+	pinit_fw->FWOptions	  = le16_to_cpu(acb->fw_options);
+	pinit_fw->AddFWOptions	  = le16_to_cpu(acb->add_fw_options);
+	//FIXME: pinit_fw->WakeupThreshold = le16_to_cpu(acb->WakeupThreshold);
+	memcpy(&pinit_fw->IPAddr.IPAddress, &acb->ipv4_addr,
+	    MIN(sizeof(pinit_fw->IPAddr.IPAddress),
+	    sizeof(acb->ipv4_addr)));
+	memcpy(&pinit_fw->SubnetMask.IPAddress, &acb->ipv4_subnet,
+	    MIN(sizeof(pinit_fw->SubnetMask.IPAddress),
+	    sizeof(acb->ipv4_subnet)));
+	memcpy(&pinit_fw->Gateway.IPAddress, &acb->ipv4_gw_addr,
+	    MIN(sizeof(pinit_fw->Gateway.IPAddress),
+	    sizeof(acb->ipv4_gw_addr)));
+	memcpy(&pinit_fw->DNSConfig.IPAddr.IPAddress,
+	    &acb->pri_dns_srvr_ip,
+	    MIN(sizeof(pinit_fw->DNSConfig.IPAddr.IPAddress),
+	    sizeof(acb->pri_dns_srvr_ip)));
+	memcpy(&pinit_fw->Alias, &acb->iscsi_alias,
+	    MIN(sizeof(pinit_fw->Alias), sizeof(acb->iscsi_alias)));
+	memcpy(&pinit_fw->iSCSIName, &acb->iscsi_name,
+	    MIN(sizeof(pinit_fw->iSCSIName),
+	    sizeof(acb->iscsi_name)));
+
+	pinit_fw->DeviceInfo.DeviceType = le16_to_cpu(EXT_DEF_ISCSI_LOCAL);
+	pinit_fw->DeviceInfo.ExeThrottle =
+	    le16_to_cpu(acb->exec_throttle);
+	pinit_fw->DeviceInfo.iSCSIOptions =
+	    le16_to_cpu(acb->iscsi_opts);
+	pinit_fw->DeviceInfo.TCPOptions = le16_to_cpu(acb->ipv4_tcp_opts);
+	pinit_fw->DeviceInfo.IPOptions = le16_to_cpu(acb->ipv4_ip_opts);
+	pinit_fw->DeviceInfo.MaxPDUSize = le16_to_cpu(acb->iscsi_max_pdu_size);
+	pinit_fw->DeviceInfo.FirstBurstSize =
+	    le16_to_cpu(acb->iscsi_fburst_len);
+	pinit_fw->DeviceInfo.LogoutMinTime =
+	    le16_to_cpu(acb->iscsi_def_time2wait);
+	pinit_fw->DeviceInfo.LogoutMaxTime =
+	    le16_to_cpu(acb->iscsi_def_time2retain);
+	pinit_fw->DeviceInfo.LogoutMaxTime =
+	    le16_to_cpu(acb->iscsi_def_time2retain);
+	pinit_fw->DeviceInfo.MaxOutstandingR2T =
+	    le16_to_cpu(acb->iscsi_max_outstnd_r2t);
+	pinit_fw->DeviceInfo.KeepAliveTimeout =
+	    le16_to_cpu(acb->conn_ka_timeout);
+	pinit_fw->DeviceInfo.PortNumber = le16_to_cpu(acb->ipv4_port);
+	pinit_fw->DeviceInfo.MaxBurstSize =
+	    le16_to_cpu(acb->iscsi_max_burst_len);
+
+	/*
+	 * Copy the local data to the user's buffer
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pinit_fw,
+				   sizeof(EXT_INIT_FW_ISCSI))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_init_fw:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_acb(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	EXT_ACB		*pacb;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ha->firmware_version[0] == 2) {
+                DEBUG2(ql4_info(ha, "%s: Not supported by 2-series "
+				"firmware.\n", __func__));
+
+                ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+                ioctl->ResponseLen = 0;
+                goto exit_get_acb;
+        }
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen < sizeof(EXT_ACB))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_acb;
+	}
+
+	pacb = (EXT_ACB *)ql4im_ha->dma_v;
+	memset(pacb, 0, sizeof(EXT_ACB));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_ACB;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	mbox_cmd[4] = ioctl->ResponseLen;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_acb;
+	}
+
+	/*
+	 * Copy the local data to the user's buffer
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pacb,
+				   sizeof(EXT_ACB))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_acb:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_cache(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl, uint32_t cache_cmd)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	EXT_NEIGHBOR_CACHE	cache;
+	EXT_NEIGHBOR_CACHE	*pcache, *pu_cache;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen > QL_DMA_BUF_SIZE)) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_cache;
+	}
+
+	memset(&cache, 0, sizeof(EXT_NEIGHBOR_CACHE));
+
+	/*
+	 * Copy the IOCTL EXT_DEVICE_ENTRY_ISCSI buffer from the user's
+	 * data space
+	 */
+	if ((status = copy_from_user((uint8_t *)&cache,
+				     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     ioctl->RequestLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from user's "
+		    "memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_cache;
+	}
+
+	/*
+	 * Transfer data from IOCTL's EXT_DEVICE_ENTRY_ISCSI buffer to
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = cache_cmd;
+
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	mbox_cmd[4] = ioctl->Reserved1;
+	mbox_cmd[5] = cache.CacheBufferSize;
+
+	pcache = ql4im_ha->dma_v;
+	memset(pcache, 0, cache.CacheBufferSize);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_cache;
+	}
+
+	ioctl->VendorSpecificStatus[0] = mbox_sts[0];
+	ioctl->VendorSpecificStatus[1] = mbox_sts[1];
+	ioctl->VendorSpecificStatus[2] = mbox_sts[2];
+	ioctl->VendorSpecificStatus[3] = mbox_sts[3];
+	ioctl->VendorSpecificStatus[4] = mbox_sts[4];
+	ioctl->VendorSpecificStatus[5] = mbox_sts[5];
+	ioctl->VendorSpecificStatus[6] = mbox_sts[6];
+
+	/*
+	 * Copy the local data to the user's buffer
+	 */
+	pu_cache = Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode);
+	/*
+	 * Copy local DMA buffer to user's response data area
+	 */
+	if ((status = copy_to_user(pu_cache,
+                                   &cache,
+				   sizeof(EXT_NEIGHBOR_CACHE))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: FlashData to user failed\n",
+			__func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_cache;
+	}
+
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(&pu_cache->Buffer[0], pcache,
+				   cache.CacheBufferSize)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_cache;
+	}
+
+exit_get_cache:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int
+ql4_read_flash_ifcb(struct scsi_qla_host *ha,
+		   dma_addr_t flash_ifcb_dma,
+		   uint32_t flash_ifcb_size,
+		   uint32_t *mbox_status)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_READ_FLASH;
+	mbox_cmd[1] = LSDW(flash_ifcb_dma);
+	mbox_cmd[2] = MSDW(flash_ifcb_dma);
+	mbox_cmd[3] = INT_ISCSI_INITFW_FLASH_OFFSET;
+	mbox_cmd[4] = flash_ifcb_size;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		*mbox_status = mbox_sts[0];
+                return QLA_ERROR;
+	}
+	return QLA_SUCCESS;
+}
+
+static int
+ql4_write_flash_ifcb(struct scsi_qla_host *ha,
+		   dma_addr_t flash_ifcb_dma,
+		   uint32_t flash_ifcb_size,
+		   uint32_t *mbox_status)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_WRITE_FLASH;
+	mbox_cmd[1] = LSDW(flash_ifcb_dma);
+	mbox_cmd[2] = MSDW(flash_ifcb_dma);
+	mbox_cmd[3] = INT_ISCSI_INITFW_FLASH_OFFSET;
+	mbox_cmd[4] = flash_ifcb_size;
+	mbox_cmd[5] = WRITE_FLASH_OPTION_COMMIT_DATA;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		*mbox_status = mbox_sts[0];
+                return QLA_ERROR;
+	}
+	return QLA_SUCCESS;
+}
+
+static int ql4_get_isns_server(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_status = 0;
+	EXT_ISNS_SERVER		*isns;
+	struct addr_ctrl_blk	*flash_ifcb;
+	struct scsi_qla_host	*ha;
+	uint16_t		tcp_options = 0;
+	uint16_t		ipv6_tcp_options = 0;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+	    !ioctl->RequestAdr || !ioctl->RequestLen |
+		(ioctl->ResponseLen < sizeof(EXT_ISNS_SERVER))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_isns;
+	}
+
+	isns = (EXT_ISNS_SERVER *) ql4im_ha->tmp_buf;
+	memset(isns, 0, sizeof(EXT_ISNS_SERVER));
+
+	/*
+	 * Copy iSNS Server info from the user's buffer
+	 */
+	if ((status = copy_from_user((void *)isns,
+                Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+                        sizeof(EXT_ISNS_SERVER))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_isns;
+	}
+
+	flash_ifcb = (struct addr_ctrl_blk *) ql4im_ha->dma_v;
+	memset(flash_ifcb, 0, sizeof(*flash_ifcb));
+	status = ql4_read_flash_ifcb(ha, ql4im_ha->dma_p, sizeof(*flash_ifcb),
+					&mbox_status);
+	if (status == QLA_ERROR) {
+		DEBUG2(ql4_info(ha, "%s: READ FLASH command failed \n",
+		    __func__));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_status;
+		goto exit_get_isns;
+	}
+
+	/*
+	 * Copy Flash IFCB info to the iSNS_Server structure
+	 */
+	tcp_options = cpu_to_le16(flash_ifcb->ipv4_tcp_opts);
+	ipv6_tcp_options = cpu_to_le16(flash_ifcb->ipv6_tcp_opts);
+
+	if (tcp_options & TOPT_ISNSv4_ENABLE) {
+		isns->IPAddr.Type = EXT_DEF_TYPE_ISCSI_IP;
+		isns->AutomaticiSNSDiscovery = 0;
+		isns->PerformiSNSDiscovery = 1;
+		isns->PortNumber =
+			cpu_to_le16(flash_ifcb->isns_svr_port);
+		memcpy(isns->IPAddr.IPAddress,
+		       flash_ifcb->ipv4_isns_svr_ip,
+		       sizeof(flash_ifcb->ipv4_isns_svr_ip));
+		memcpy(isns->InitiatorName,
+		       flash_ifcb->iscsi_name,
+		       MIN(sizeof(isns->InitiatorName),
+			   sizeof(flash_ifcb->iscsi_name)));
+	}
+	else if (ipv6_tcp_options & IPV6_TCPOPT_ISNSv6_ENABLE) {
+		isns->IPAddr.Type = EXT_DEF_TYPE_ISCSI_IPV6;
+		isns->PerformiSNSDiscovery = 1;
+		isns->AutomaticiSNSDiscovery = 0;
+		isns->PortNumber =
+			cpu_to_le16(flash_ifcb->isns_svr_port);
+		memcpy(isns->IPAddr.IPAddress,
+		       flash_ifcb->ipv6_isns_svr_ip,
+		       sizeof(flash_ifcb->ipv6_isns_svr_ip));
+		memcpy(isns->InitiatorName,
+		       flash_ifcb->iscsi_name,
+		       MIN(sizeof(isns->InitiatorName),
+			   sizeof(flash_ifcb->iscsi_name)));
+	}
+
+	/*
+	 * Notify application layer which features bits are supported.
+	 */
+	isns->FeaturesResponse |=
+		EXT_DEF_RETURN_ISNS_CONN_STATUS | EXT_DEF_IMMEDIATE_ISNS_CONFIG;
+
+	/*
+	 * Return iSNS Connection Status , if requested.
+	 */
+	if ((isns->FeaturesRequest & EXT_DEF_RETURN_ISNS_CONN_STATUS) != 0) {
+		uint8_t is_isns_active = ha->ql4_is_isns_active(ha);
+		isns->iSNSServerConnOpen =
+			(is_isns_active == ISNS_STATUS_ACTIVE);
+		DEBUG2(ql4_info(ha, "%s: "
+			"ISNS SERVICE CONNECTION STATUS = \"%s\"\n", __func__,
+			(is_isns_active == ISNS_STATUS_ACTIVE)
+			? "Connected" : "Not Connected"));
+	}
+
+	/*
+	 * Copy the local data to the user's buffer
+	 */
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+                ioctl->AddrMode), isns, sizeof(EXT_ISNS_SERVER))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		status = (-EFAULT);
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		ioctl->ResponseLen = 0;
+		goto exit_get_isns;
+	}
+
+	ioctl->Status = EXT_STATUS_OK;
+	ioctl->ResponseLen = sizeof(EXT_ISNS_SERVER);
+
+exit_get_isns:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static uint8_t
+ql4_get_next_isns_tgt_name(struct scsi_qla_host *ha,
+			 EXT_ISNS_TARGETS_BUFFER *isns_tgts)
+{
+	uint8_t status = QLA_SUCCESS;
+	unsigned long   wait_cnt;
+	struct isnsp_response *rsp;
+
+	set_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY, &ha->isns.flags);
+
+	/* Given a pointer to the last_iscsi_name, the dev_get_next function
+	 * will return the next_iscsi_name.  The next iscsi_name will be
+	 * NULL if there are no more targets */
+	ha->ql4_isns_send_dev_get_next(ha, &isns_tgts->LastIscsiName[0],
+		&isns_tgts->Buffer[0], NULL);
+
+	wait_cnt = jiffies + PDU_WAIT_TOV * HZ;
+	while (!time_after_eq(jiffies, wait_cnt)) {
+		if (!test_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY,
+			&ha->isns.flags))
+			break;
+
+		DEBUG7(printk("."));
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(10);
+	}
+
+	if (test_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: Timed Out\n", __func__));
+		status = QLA_ERROR;
+		goto exit_get_next_isns_tgt;
+	}
+
+	rsp = (struct isnsp_response *) isns_tgts->Buffer;
+	if (rsp) {
+		switch (ntohl(rsp->status_code)) {
+		case ISNS_STS_SUCCESS:
+		case ISNS_STS_NO_SUCH_ENTRY:
+			break;
+		default:
+                        status = QLA_ERROR;
+			break;
+		}
+	}
+
+exit_get_next_isns_tgt:
+	return status;
+}
+
+static uint8_t
+ql4_get_isns_tgt_attrs(struct scsi_qla_host *ha,
+		     EXT_ISNS_TARGETS_BUFFER *isns_tgts)
+{
+	uint8_t status = QLA_SUCCESS;
+	unsigned long   wait_cnt;
+	struct isnsp_response *rsp;
+
+	set_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY, &ha->isns.flags);
+
+	ha->ql4_isns_send_dev_attr_qry(ha, &isns_tgts->LastIscsiName[0],
+		&isns_tgts->Buffer[0], &isns_tgts->BufferSize);
+
+	wait_cnt = jiffies + PDU_WAIT_TOV * HZ;
+	while (!time_after_eq(jiffies, wait_cnt)) {
+		if (!test_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY,
+			&ha->isns.flags))
+			break;
+
+		DEBUG7(printk("."));
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(10);
+	}
+
+	if (test_bit(ISNS_FLAG_IOCTL_INVOKED_QUERY, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: Timed Out\n", __func__));
+		status = QLA_ERROR;
+		goto exit_get_isns_tgt_attrs;
+	}
+
+	rsp = (struct isnsp_response *) isns_tgts->Buffer;
+	if (rsp) {
+		switch (ntohl(rsp->status_code)) {
+		case ISNS_STS_SUCCESS:
+		case ISNS_STS_NO_SUCH_ENTRY:
+			break;
+		default:
+                        status = QLA_ERROR;
+			break;
+		}
+	}
+
+exit_get_isns_tgt_attrs:
+	return status;
+}
+
+static int ql4_get_isns_tgts_buff(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	struct scsi_qla_host *ha;
+	EXT_ISNS_TARGETS_BUFFER *isns_tgts = NULL;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+	    !ioctl->RequestAdr || !ioctl->RequestLen |
+		(ioctl->ResponseLen < sizeof(EXT_ISNS_TARGETS_BUFFER))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_isns_tgts;
+	}
+
+	isns_tgts = (EXT_ISNS_TARGETS_BUFFER *) ql4im_ha->tmp_buf;
+	memset(isns_tgts, 0, sizeof(EXT_ISNS_TARGETS_BUFFER));
+
+	/*
+	 * Copy iSNS Server info from the user's buffer
+	 */
+	if ((status = copy_from_user((void *)isns_tgts,
+                Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+                        offsetof(EXT_ISNS_TARGETS_BUFFER, Buffer))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		status = (-EFAULT);
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		ioctl->ResponseLen = 0;
+		goto exit_get_isns_tgts;
+	}
+
+	/*
+	 * Make sure the iSNS sevrer is connected & registered prior to
+	 * retrieving iSNS targets, as sometimes the Application can
+	 * disconnect from the iSNS server without the driver's knowledge.
+	 *
+	 * NOTE: We only need to check the the iSNS connection status for
+	 * the first iteration of this function.
+	 */
+	if (!strlen(isns_tgts->LastIscsiName)) {
+		uint8_t is_isns_active = ha->ql4_is_isns_active(ha);
+
+		if (test_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP, &ha->isns.flags) &&
+		    (is_isnsv4_enabled(ha) || is_isnsv6_enabled(ha)) &&
+		    (is_isns_active == ISNS_STATUS_NOT_ACTIVE)) {
+			unsigned long wtime;
+			__u8 retry;
+
+			DEBUG2(ql4_info(ha, "%s: "
+				      "Waiting for iSNS Server to start ...\n",
+				      __func__));
+			ha->ql4_isns_start_svc(ha);
+
+			for (retry = 1; retry <= 2; retry++) {
+				/* Wait for iSNS registration to complete */
+				wtime = jiffies + ISNS_DEREG_TOV * HZ;
+				while (!time_after_eq(jiffies, wtime)) {
+					/* iSNS Server connection and
+					registration completed successfuly */
+					if (test_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+					&ha->isns.flags))
+						break;
+
+					/* iSNS Server connection failed */
+					if (atomic_read(&ha->isns.state) ==
+						ISNS_STATE_TCP_DISCONNECTED)
+						break;
+
+					set_current_state(TASK_UNINTERRUPTIBLE);
+					schedule_timeout(1 * HZ);
+				}
+				if ((retry == 1) &&
+				    (!test_bit(ISNS_FLAG_ISNS_SCN_REGISTERED,
+					&ha->isns.flags)))
+					DEBUG2(ql4_info(ha, "%s:"
+					     "Retry register iSNS Server\n",
+						__func__));
+			}
+		}
+	}
+
+	if (atomic_read(&ha->isns.state) == ISNS_STATE_TCP_DISCONNECTED) {
+		DEBUG2(ql4_info(ha, "%s: iSNS Server Not Connected\n",
+		    __func__));
+
+		status = (-EPERM);
+		ioctl->Status = EXT_STATUS_SERVICE_NOT_ENABLED;
+		ioctl->ResponseLen = 0;
+		goto exit_get_isns_tgts;
+	}
+
+	if (!test_bit(ISNS_FLAG_ISNS_SCN_REGISTERED, &ha->isns.flags)) {
+		DEBUG2(ql4_info(ha, "%s: Error: iSNS SCN Not "
+			"Registered. Cannot retrive target database.\n",
+			__func__));
+
+		status = -EPERM;
+		ioctl->Status = EXT_STATUS_SERVICE_NOT_ENABLED;
+		ioctl->ResponseLen = 0;
+		goto exit_get_isns_tgts;
+	}
+
+	/*
+	 * Retrieve the iSNS targets buffer
+	 */
+	DEBUG2(ql4_info(ha, "%s: Incoming iSCSI Name = \"%s\"\n",
+                __func__, isns_tgts->LastIscsiName));
+
+	status = ql4_get_next_isns_tgt_name(ha, isns_tgts);
+	if (status == QLA_SUCCESS) {
+		if (!strlen(isns_tgts->LastIscsiName)) {
+			ioctl->ResponseLen = offsetof(EXT_ISNS_TARGETS_BUFFER, Buffer);
+			ioctl->Status = EXT_STATUS_OK;
+		} else {
+			DEBUG2(ql4_info(ha, "%s: Next iSCSI Name = \"%s\"\n",
+				__func__, isns_tgts->LastIscsiName));
+			status = ql4_get_isns_tgt_attrs(ha, isns_tgts);
+			ioctl->ResponseLen = offsetof(EXT_ISNS_TARGETS_BUFFER, Buffer) +
+				isns_tgts->BufferSize;
+			ioctl->Status = EXT_STATUS_OK;
+		}
+	}
+	if (status != QLA_SUCCESS) {
+		status = (-EFAULT);
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->ResponseLen = offsetof(EXT_ISNS_TARGETS_BUFFER, Buffer);
+	}
+
+	DEBUG3(ql4_info(ha, "%s: dump isns_tgts structure: 0x%p,  (0x%x)\n",
+                __func__, isns_tgts, ioctl->ResponseLen));
+	DEBUG3(ql4_dump_buffer((unsigned char *)isns_tgts, ioctl->ResponseLen));
+
+	/*
+	 * Copy the data from the dma buffer to the user's data space
+	 */
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+                ioctl->AddrMode), isns_tgts, sizeof(*isns_tgts))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		status = (-EFAULT);
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		ioctl->ResponseLen = 0;
+		goto exit_get_isns_tgts;
+	}
+exit_get_isns_tgts:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return status;
+}
+
+static int ql4_get_stat_iscsi_block(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	EXT_HBA_PORT_STAT_ISCSI_BLOCK *pstat;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+	if (!ioctl->ResponseAdr || !ioctl->ResponseLen ||
+		(ioctl->ResponseLen < sizeof(EXT_HBA_PORT_STAT_ISCSI_BLOCK))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_stat_iscsi_block;
+	}
+
+	pstat = (EXT_HBA_PORT_STAT_ISCSI_BLOCK *)ql4im_ha->dma_v;
+	memset(pstat, 0, sizeof(EXT_HBA_PORT_STAT_ISCSI_BLOCK));
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_GET_MANAGEMENT_DATA;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_get_stat_iscsi_block;
+	}
+
+	/*
+	 * Copy the local data to the user's buffer
+	 */
+	ioctl->Status = EXT_STATUS_OK;
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode), pstat,
+			   sizeof(EXT_HBA_PORT_STAT_ISCSI_BLOCK))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_get_stat_iscsi_block:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_ext_get_data(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	struct scsi_qla_host *ha;
+	int status;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	switch (ioctl->SubCode) {
+	case EXT_SC_GET_STATISTICS_GEN:
+		status = ql4_get_statistics_gen(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_STATISTICS_ISCSI:
+		status = ql4_get_statistics_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_DEVICE_ENTRY_ISCSI:
+	case EXT_SC_GET_DEVICE_ENTRY_DEFAULTS_ISCSI:
+		status = ql4_get_device_entry_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_INIT_FW_ISCSI:
+	case EXT_SC_GET_INIT_FW_DEFAULTS_ISCSI:
+		status = ql4_get_init_fw_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_ACB:
+		status = ql4_get_acb(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_NEIGHBOR_CACHE:
+		status = ql4_get_cache(ql4im_ha, ioctl,
+				MBOX_CMD_GET_IPV6_NEIGHBOR_CACHE);
+		break;
+	case EXT_SC_GET_DESTINATION_CACHE:
+		status = ql4_get_cache(ql4im_ha, ioctl,
+				MBOX_CMD_GET_IPV6_DEST_CACHE);
+		break;
+	case EXT_SC_GET_DEFAULT_ROUTER_LIST:
+		status = ql4_get_cache(ql4im_ha, ioctl,
+				MBOX_CMD_GET_IPV6_DEF_ROUTER_LIST);
+		break;
+	case EXT_SC_GET_LOCAL_PREFIX_LIST:
+		status = ql4_get_cache(ql4im_ha, ioctl,
+				MBOX_CMD_GET_IPV6_LCL_PREFIX_LIST);
+		break;
+	case EXT_SC_GET_ISNS_SERVER:
+		status = ql4_get_isns_server(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_ISNS_TARGETS_BUFFER:
+		status = ql4_get_isns_tgts_buff(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_GET_STATISTICS_ISCSI_BLOCK:
+		status = ql4_get_stat_iscsi_block(ql4im_ha, ioctl);
+		break;
+
+	default:
+		DEBUG2(ql4_info(ha, "%s: unsupported external get "
+		    "data sub-command code (%X)\n", __func__, ioctl->SubCode));
+
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+		break;
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(0);
+}
+
+static int ql4_rst_statistics_gen(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+	/*
+	 * Reset the general statistics fields
+	 */
+	ha->adapter_error_count = 0;
+	ha->device_error_count = 0;
+	ha->total_io_count = 0;
+	ha->total_mbytes_xferred = 0;
+	ha->isr_count = 0;
+	ha->link_failure_count = 0;
+	ha->invalid_crc_count = 0;
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(QLA_SUCCESS);
+}
+
+static int ql4_rst_statistics_iscsi(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	/*
+	 * Make the mailbox call
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_MANAGEMENT_DATA;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = 0;
+	mbox_cmd[3] = 0;
+
+	ioctl->Status = EXT_STATUS_OK;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: get mngmt data for index [%d] failed! "
+		    "w/ mailbox ststus 0x%x\n", __func__, ioctl->Instance,
+			mbox_sts[0]));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(QLA_SUCCESS);
+}
+
+static int ql4_set_device_entry_iscsi(struct hba_ioctl *ql4im_ha,
+				    EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	struct dev_db_entry *pfw_ddb_entry;
+	EXT_DEVICE_ENTRY_ISCSI *pdev_entry;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if ((ioctl->RequestLen < sizeof(EXT_DEVICE_ENTRY_ISCSI)) ||
+		!ioctl->RequestAdr){
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_set_dev_entry;
+	}
+
+	pdev_entry = (EXT_DEVICE_ENTRY_ISCSI *)ql4im_ha->tmp_buf;
+	memset(pdev_entry, 0, sizeof(EXT_DEVICE_ENTRY_ISCSI));
+
+	/*
+	 * Copy the IOCTL EXT_DEVICE_ENTRY_ISCSI buffer from the user's
+	 * data space
+	 */
+	if ((status = copy_from_user((uint8_t *)pdev_entry,
+				     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     ioctl->RequestLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from user's "
+		    "memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_dev_entry;
+	}
+
+	/*
+	 * Transfer data from IOCTL's EXT_DEVICE_ENTRY_ISCSI buffer to
+	 * Fw's DEV_DB_ENTRY buffer
+	 */
+	pfw_ddb_entry = (struct dev_db_entry *)ql4im_ha->dma_v;
+	memset(pfw_ddb_entry, 0, sizeof(struct dev_db_entry));
+
+	pfw_ddb_entry->options		=
+		cpu_to_le16(pdev_entry->Control << 8 | pdev_entry->Options);
+	pfw_ddb_entry->tsid		= cpu_to_le16(pdev_entry->TargetSessID);
+	pfw_ddb_entry->exec_count	= cpu_to_le16(pdev_entry->ExeCount);
+	pfw_ddb_entry->ddb_link		= cpu_to_le16(pdev_entry->DDBLink);
+	memcpy(pfw_ddb_entry->isid, pdev_entry->InitiatorSessID,
+	    sizeof(pdev_entry->InitiatorSessID));
+
+	pfw_ddb_entry->exec_throttle =
+	    cpu_to_le16(pdev_entry->DeviceInfo.ExeThrottle);
+	pfw_ddb_entry->iscsi_max_snd_data_seg_len =
+	    cpu_to_le16(pdev_entry->DeviceInfo.InitMarkerlessInt);
+	pfw_ddb_entry->iscsi_options =
+	    cpu_to_le16(pdev_entry->DeviceInfo.iSCSIOptions);
+	pfw_ddb_entry->tcp_options =
+	    cpu_to_le16(pdev_entry->DeviceInfo.TCPOptions);
+	pfw_ddb_entry->ip_options =
+	    cpu_to_le16(pdev_entry->DeviceInfo.IPOptions);
+	pfw_ddb_entry->iscsi_max_rcv_data_seg_len =
+	    cpu_to_le16(pdev_entry->DeviceInfo.MaxPDUSize);
+	pfw_ddb_entry->iscsi_first_burst_len =
+	    cpu_to_le16(pdev_entry->DeviceInfo.FirstBurstSize);
+	pfw_ddb_entry->iscsi_def_time2wait =
+	    cpu_to_le16(pdev_entry->DeviceInfo.LogoutMinTime);
+	pfw_ddb_entry->iscsi_def_time2retain =
+	    cpu_to_le16(pdev_entry->DeviceInfo.LogoutMaxTime);
+	pfw_ddb_entry->iscsi_max_outsnd_r2t =
+	    cpu_to_le16(pdev_entry->DeviceInfo.MaxOutstandingR2T);
+	pfw_ddb_entry->ka_timeout =
+	    cpu_to_le16(pdev_entry->DeviceInfo.KeepAliveTimeout);
+	pfw_ddb_entry->port =
+	    cpu_to_le16(pdev_entry->DeviceInfo.PortNumber);
+	pfw_ddb_entry->iscsi_max_burst_len =
+	    cpu_to_le16(pdev_entry->DeviceInfo.MaxBurstSize);
+	pfw_ddb_entry->def_timeout =
+	    cpu_to_le16(pdev_entry->DeviceInfo.TaskMgmtTimeout);
+	memcpy(pfw_ddb_entry->tgt_addr, pdev_entry->DeviceInfo.TargetAddr,
+	    sizeof(pdev_entry->DeviceInfo.TargetAddr));
+
+	memcpy(pfw_ddb_entry->ip_addr, pdev_entry->EntryInfo.IPAddr.IPAddress,
+	    sizeof(pdev_entry->EntryInfo.IPAddr.IPAddress));
+	memcpy(pfw_ddb_entry->iscsi_name, pdev_entry->EntryInfo.iSCSIName,
+	    sizeof(pdev_entry->EntryInfo.iSCSIName));
+	memcpy(pfw_ddb_entry->iscsi_alias, pdev_entry->EntryInfo.Alias,
+	    sizeof(pdev_entry->EntryInfo.Alias));
+
+	/*
+	 * Make the IOCTL call
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SET_DATABASE_ENTRY;
+	mbox_cmd[1] = (uint32_t) ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+
+	ioctl->Status = EXT_STATUS_OK;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: SET DDB Entry failed\n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+	}
+
+exit_set_dev_entry:
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int
+ql4_set_init_fw_iscsi(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	EXT_INIT_FW_ISCSI *pinit_fw;
+	struct init_fw_ctrl_blk *pinit_fw_cb;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if ((ioctl->RequestLen < sizeof(EXT_INIT_FW_ISCSI)) ||
+		!ioctl->RequestAdr){
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_set_init_fw;
+	}
+
+	pinit_fw = (EXT_INIT_FW_ISCSI *)ql4im_ha->tmp_buf;
+	memset(pinit_fw, 0, sizeof(EXT_INIT_FW_ISCSI));
+
+	/*
+	 * Copy the data from the user's buffer
+	 */
+	if ((status = copy_from_user((uint8_t *)pinit_fw,
+				     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(EXT_INIT_FW_ISCSI))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_init_fw;
+	}
+
+	/*
+	 * First get Initialize Firmware Control Block, so as not to
+	 * destroy unaffected data
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_GET_INIT_FW_CTRL_BLOCK;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	if (ha->acb_version == ACB_SUPPORTED) {
+		mbox_cmd[4] = ha->ifcb_size;
+	}
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_set_init_fw;
+	}
+
+	/*
+	 * Transfer Data from Local buffer to DMA buffer
+	 */
+	pinit_fw_cb = (struct init_fw_ctrl_blk *)ql4im_ha->dma_v;
+	memset(pinit_fw_cb, 0, sizeof(struct init_fw_ctrl_blk));
+
+	pinit_fw_cb->pri.version	     = pinit_fw->Version;
+	pinit_fw_cb->pri.fw_options	     = cpu_to_le16(pinit_fw->FWOptions);
+	pinit_fw_cb->pri.add_fw_options    = cpu_to_le16(pinit_fw->AddFWOptions);
+	memcpy(pinit_fw_cb->pri.ipv4_addr, pinit_fw->IPAddr.IPAddress,
+	    MIN(sizeof(pinit_fw_cb->pri.ipv4_addr),
+	    sizeof(pinit_fw->IPAddr.IPAddress)));
+	memcpy(pinit_fw_cb->pri.ipv4_subnet, pinit_fw->SubnetMask.IPAddress,
+	    MIN(sizeof(pinit_fw_cb->pri.ipv4_subnet),
+	    sizeof(pinit_fw->SubnetMask.IPAddress)));
+	memcpy(pinit_fw_cb->pri.ipv4_gw_addr, pinit_fw->Gateway.IPAddress,
+	    MIN(sizeof(pinit_fw_cb->pri.ipv4_gw_addr),
+	    sizeof(pinit_fw->Gateway.IPAddress)));
+	memcpy(pinit_fw_cb->pri.pri_dns_srvr_ip, pinit_fw->DNSConfig.IPAddr.IPAddress,
+	    MIN(sizeof(pinit_fw_cb->pri.pri_dns_srvr_ip),
+	    sizeof(pinit_fw->DNSConfig.IPAddr.IPAddress)));
+	memcpy(pinit_fw_cb->pri.iscsi_alias, pinit_fw->Alias,
+	    MIN(sizeof(pinit_fw_cb->pri.iscsi_alias), sizeof(pinit_fw->Alias)));
+	memcpy(pinit_fw_cb->pri.iscsi_name, pinit_fw->iSCSIName,
+	    MIN(sizeof(pinit_fw_cb->pri.iscsi_name),
+	    sizeof(pinit_fw->iSCSIName)));
+
+	pinit_fw_cb->pri.exec_throttle =
+	    cpu_to_le16(pinit_fw->DeviceInfo.ExeThrottle);
+	pinit_fw_cb->pri.iscsi_opts =
+	    cpu_to_le16(pinit_fw->DeviceInfo.iSCSIOptions);
+	pinit_fw_cb->pri.ipv4_tcp_opts = cpu_to_le16(pinit_fw->DeviceInfo.TCPOptions);
+	pinit_fw_cb->pri.ipv4_ip_opts = cpu_to_le16(pinit_fw->DeviceInfo.IPOptions);
+	pinit_fw_cb->pri.iscsi_max_pdu_size = cpu_to_le16(pinit_fw->DeviceInfo.MaxPDUSize);
+	pinit_fw_cb->pri.iscsi_fburst_len =
+	    cpu_to_le16(pinit_fw->DeviceInfo.FirstBurstSize);
+	pinit_fw_cb->pri.iscsi_def_time2wait =
+	    cpu_to_le16(pinit_fw->DeviceInfo.LogoutMinTime);
+	pinit_fw_cb->pri.iscsi_def_time2retain =
+	    cpu_to_le16(pinit_fw->DeviceInfo.LogoutMaxTime);
+	pinit_fw_cb->pri.iscsi_max_outstnd_r2t =
+	    cpu_to_le16(pinit_fw->DeviceInfo.MaxOutstandingR2T);
+	pinit_fw_cb->pri.conn_ka_timeout =
+	    cpu_to_le16(pinit_fw->DeviceInfo.KeepAliveTimeout);
+	pinit_fw_cb->pri.ipv4_port = cpu_to_le16(pinit_fw->DeviceInfo.PortNumber);
+	pinit_fw_cb->pri.iscsi_max_burst_len =
+	    cpu_to_le16(pinit_fw->DeviceInfo.MaxBurstSize);
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_INITIALIZE_FIRMWARE;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	if (ha->acb_version == ACB_SUPPORTED) {
+		mbox_cmd[4] = ha->ifcb_size;
+		mbox_cmd[5] = (IFCB_VER_MAX << 8) | IFCB_VER_MIN;
+	}
+
+	ioctl->Status = EXT_STATUS_OK;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+	}
+
+exit_set_init_fw:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int
+ql4_set_isns_server(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_status;
+	EXT_ISNS_SERVER		*isns;
+	struct addr_ctrl_blk	*flash_ifcb;
+	struct scsi_qla_host	*ha;
+	uint16_t		tcp_options = 0;
+	uint16_t		ipv6_tcp_options = 0;
+	uint16_t		port_number = 0;
+	uint8_t			ip[16];
+	uint8_t			ip_changed = 0;
+	uint8_t			tcp_changed = 0;
+	uint8_t			port_changed = 0;
+	uint8_t                 is_isns_active;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!ioctl->RequestAdr || !ioctl->RequestLen ||
+		(ioctl->RequestLen < sizeof(EXT_ISNS_SERVER))) {
+		DEBUG2(ql4_info(ha, "%s: invalid parameter\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_set_isns;
+	}
+
+	isns = (EXT_ISNS_SERVER *) ql4im_ha->tmp_buf;
+	memset(isns, 0, sizeof(EXT_ISNS_SERVER));
+
+	/*
+	 * iSNS Server info from the user's buffer
+	 */
+	if ((status = copy_from_user((void *)isns,
+                Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+                        sizeof(EXT_ISNS_SERVER))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n",  __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_isns;
+	}
+
+	/* If IPv6 is not supported and an IPv6 address is specified -- ERROR */
+	if (!is_ipv6_enabled(ha) &&
+		isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IPV6) {
+		DEBUG2(ql4_info(ha, "%s: Error: iSNS IPv6 address specified, "
+			"but IPv6 not supported\n", __func__));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		ioctl->ResponseLen = 0;
+		goto exit_set_isns;
+	}
+
+	DEBUG3(ql4_info(ha, "%s: incoming isns struct (max 20h)... \n",
+		__func__));
+	DEBUG3(ql4_dump_buffer((unsigned char *)isns, 0x20));
+	DEBUG2(ql4_info(ha, "%s: %s iSNS \n", __func__,
+              (isns->PerformiSNSDiscovery) ? "Enable" : "Disable"));
+
+	if (isns->PerformiSNSDiscovery == 0) {
+		set_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags);
+	}
+
+	/*
+	 * First get Flash Initialize Firmware Control Block,
+	 * so as not to destroy unaffected data
+	 */
+	flash_ifcb = (struct addr_ctrl_blk *) ql4im_ha->dma_v;
+	memset(flash_ifcb, 0, sizeof(*flash_ifcb));
+	status = ql4_read_flash_ifcb(ha, ql4im_ha->dma_p, sizeof(*flash_ifcb),
+		&mbox_status);
+	if (status == QLA_ERROR) {
+		DEBUG2(ql4_info(ha, "%s: READ FLASH command failed \n",
+		    __func__));
+
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_status;
+		goto exit_set_isns;
+	}
+
+	/* Save incoming flash info locally */
+	memset(&ip[0], 0, sizeof(ip));
+        if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IP)
+		memcpy(&ip[0], flash_ifcb->ipv4_isns_svr_ip,
+			min(sizeof(ip), sizeof(flash_ifcb->ipv4_isns_svr_ip)));
+	else
+		memcpy(&ip[0], flash_ifcb->ipv6_isns_svr_ip,
+			min(sizeof(ip), sizeof(flash_ifcb->ipv6_isns_svr_ip)));
+
+	tcp_options = le16_to_cpu(flash_ifcb->ipv4_tcp_opts);
+	ipv6_tcp_options = le16_to_cpu(flash_ifcb->ipv6_tcp_opts);
+	port_number = le16_to_cpu(flash_ifcb->isns_svr_port);
+
+	/*
+         * Update local copy of IFCB variables as determined by parameters
+         * from the user's iSNS structure.
+         */
+	if (isns->PerformiSNSDiscovery) {
+		if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IP)
+			tcp_options |= TOPT_ISNSv4_ENABLE;
+		else
+			ipv6_tcp_options |= IPV6_TCPOPT_ISNSv6_ENABLE;
+		port_number = EXT_DEF_ISNS_WELL_KNOWN_PORT;
+		memcpy(&ip[0], isns->IPAddr.IPAddress,
+		       min(sizeof(isns->IPAddr.IPAddress),
+			   sizeof(flash_ifcb->ipv6_isns_svr_ip)));
+	} else {
+		if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IP)
+			tcp_options &= ~TOPT_ISNSv4_ENABLE;
+		else
+			ipv6_tcp_options &= ~IPV6_TCPOPT_ISNSv6_ENABLE;
+		memset(&ip[0], 0, sizeof(ip));
+	}
+
+	/* Find out what changed */
+	port_changed = (port_number != le16_to_cpu(flash_ifcb->isns_svr_port));
+	tcp_changed |= (tcp_options != le16_to_cpu(flash_ifcb->ipv4_tcp_opts));
+	tcp_changed |= (ipv6_tcp_options !=
+				le16_to_cpu(flash_ifcb->ipv6_tcp_opts));
+
+	if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IP)
+		ip_changed |= (memcmp(&ip[0], flash_ifcb->ipv4_isns_svr_ip,
+				    min(sizeof(ip),
+					sizeof(flash_ifcb->ipv4_isns_svr_ip)))
+				!= 0);
+	else
+		ip_changed |= (memcmp(&ip[0], flash_ifcb->ipv6_isns_svr_ip,
+				    min(sizeof(ip),
+					sizeof(flash_ifcb->ipv6_isns_svr_ip)))
+				!= 0);
+
+	if (ip_changed || port_changed || tcp_changed) {
+		/* Copy local IFCB data to IFCB struct, then write flash */
+		flash_ifcb->ipv4_tcp_opts = cpu_to_le16(tcp_options);
+		flash_ifcb->ipv6_tcp_opts = cpu_to_le16(ipv6_tcp_options);
+		flash_ifcb->isns_svr_port = cpu_to_le16(port_number);
+		if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IP)
+			memcpy(flash_ifcb->ipv4_isns_svr_ip, &ip[0],
+				min(sizeof(ip),
+				sizeof(flash_ifcb->ipv4_isns_svr_ip)));
+		else
+			memcpy(flash_ifcb->ipv6_isns_svr_ip, &ip[0],
+				min(sizeof(ip),
+				sizeof(flash_ifcb->ipv6_isns_svr_ip)));
+
+		status = ql4_write_flash_ifcb(ha, ql4im_ha->dma_p,
+			sizeof(*flash_ifcb), &mbox_status);
+		if (status == QLA_ERROR) {
+			DEBUG2(ql4_info(ha, "%s: WRITE FLASH command "
+					"failed \n", __func__));
+			ioctl->Status = EXT_STATUS_MAILBOX;
+			ioctl->DetailStatus = mbox_status;
+			ioctl->ResponseLen = 0;
+			goto exit_set_isns;
+		}
+		DEBUG2(ql4_info(ha, "%s: WRITE FLASH command "
+				"successful \n", __func__));
+
+		/*
+		 * Update internal iSNS info
+		 */
+		if (isns->IPAddr.Type == EXT_DEF_TYPE_ISCSI_IPV6) {
+			ha->ipv6_tcp_options = ipv6_tcp_options;
+
+			if (ipv6_tcp_options & IPV6_TCPOPT_ISNSv6_ENABLE)
+				set_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+					&ha->isns.flags);
+			else
+				clear_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+					  &ha->isns.flags);
+		}
+		else {
+			ha->tcp_options = tcp_options;
+
+			if (tcp_options & TOPT_ISNSv4_ENABLE)
+				set_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+					&ha->isns.flags);
+			else
+				clear_bit(ISNS_FLAG_ISNS_ENABLED_IN_ISP,
+					  &ha->isns.flags);
+		}
+
+		ha->ql4_isns_populate_server_ip(ha, flash_ifcb);
+		is_isns_active = ha->ql4_is_isns_active(ha);
+
+		/*
+		 * Start/Restart/Stop iSNS server, if requested
+		 */
+		if ((isns->FeaturesRequest & EXT_DEF_IMMEDIATE_ISNS_CONFIG)
+			!= 0) {
+			if (!ql4_is_memzero(&ip[0], sizeof(ip)))
+				status = ha->ql4_isns_start_svc(ha);
+			else if (is_isns_active == ISNS_STATUS_ACTIVE)
+				status = ha->ql4_isns_stop_svc(ha);
+
+			if (status == QLA_SUCCESS)
+				isns->FeaturesResponse |=
+				EXT_DEF_IMMEDIATE_ISNS_CONFIG;
+			else
+				isns->FeaturesResponse &=
+				~EXT_DEF_IMMEDIATE_ISNS_CONFIG;
+		}
+	} else {
+		DEBUG2(ql4_info(ha, "%s: Nothing changed! "
+			"Don't write flash\n", __func__));
+	}
+
+	/*
+	 * Return iSNS Connection Status , if requested.
+	 */
+	if ((isns->FeaturesRequest & EXT_DEF_RETURN_ISNS_CONN_STATUS) != 0) {
+		is_isns_active = ha->ql4_is_isns_active(ha);
+		DEBUG2(ql4_info(ha, "%s: ISNS SERVICE CONNECTION STATUS = "
+			"\"%s\"\n", __func__,
+			(is_isns_active == ISNS_STATUS_ACTIVE)
+			? "Connected" : "Not Connected"));
+		isns->FeaturesResponse |= EXT_DEF_RETURN_ISNS_CONN_STATUS;
+		isns->iSNSServerConnOpen = is_isns_active == ISNS_STATUS_ACTIVE;
+	} else {
+		isns->FeaturesResponse &= ~EXT_DEF_RETURN_ISNS_CONN_STATUS;
+	}
+
+	/*
+	 * Complete IOCTL successfully
+	 *----------------------------*/
+	ioctl->Status = EXT_STATUS_OK;
+	ioctl->ResponseLen = 0;
+
+exit_set_isns:
+	clear_bit(ISNS_FLAG_DISABLE_IN_PROGRESS, &ha->isns.flags);
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int
+ql4_set_acb(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	uint32_t	mbox_cmd[MBOX_REG_COUNT];
+	uint32_t	mbox_sts[MBOX_REG_COUNT];
+	void *pacb;
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ha->firmware_version[0] == 2) {
+                DEBUG2(ql4_info(ha, "%s: Not supported by 2-series firmware.\n",
+                                __func__));
+
+                ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+                ioctl->ResponseLen = 0;
+                goto exit_set_acb;
+        }
+
+	if ((ioctl->RequestLen < EXT_DEF_ACB_SIZE) ||
+		!ioctl->RequestAdr){
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_set_acb;
+	}
+
+	pacb = (void *)ql4im_ha->dma_v;
+	memset(pacb, 0, EXT_DEF_ACB_SIZE);
+
+	/*
+	 * Copy the data from the user's buffer
+	 */
+	if ((status = copy_from_user((uint8_t *)pacb,
+				     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     EXT_DEF_ACB_SIZE)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data to user's "
+		    "memory area\n", __func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_acb;
+	}
+
+	/*
+	 * First get Initialize Firmware Control Block, so as not to
+	 * destroy unaffected data
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SET_ACB;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = MSDW(ql4im_ha->dma_p);
+	mbox_cmd[4] = ioctl->RequestLen;
+
+	ioctl->Status = EXT_STATUS_OK;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, MBOX_REG_COUNT, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+		goto exit_set_acb;
+	}
+	ioctl->ResponseLen = mbox_sts[4];
+
+exit_set_acb:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_ext_set_data(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+
+	switch (ioctl->SubCode) {
+	case EXT_SC_RST_STATISTICS_GEN:
+		status = ql4_rst_statistics_gen(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_RST_STATISTICS_ISCSI:
+		status = ql4_rst_statistics_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_SET_DEVICE_ENTRY_ISCSI:
+		status = ql4_set_device_entry_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_SET_INIT_FW_ISCSI:
+		status = ql4_set_init_fw_iscsi(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_SET_ISNS_SERVER:
+		status = ql4_set_isns_server(ql4im_ha, ioctl);
+		break;
+	case EXT_SC_SET_ACB:
+		status = ql4_set_acb(ql4im_ha, ioctl);
+		break;
+	default:
+		DEBUG2(printk("%s: unsupported set data sub-command code "
+			"(%X)\n", __func__, ioctl->SubCode));
+
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+		break;
+	}
+	return(status);
+}
+
+/* End of External ioctls */
+
+static void
+ql4_scsi_pt_done(struct scsi_cmnd *cmd)
+{
+	struct scsi_qla_host	*ha;
+	struct hba_ioctl *ql4im_ha;
+
+
+	ha = (struct scsi_qla_host *)cmd->device->host->hostdata;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ql4im_ha = ql4im_get_adapter_handle(ha->instance);
+	if (ql4im_ha) {
+		/* Reset in_progress flag and wakeup ioctl completion semaphore
+		 * for the SCSI Passthru thread.
+		 * But first check to see if cmd has already
+		 * timed out, because we don't want to get the
+		 * up/down semaphore counters off.
+		 */
+		if (ql4im_ha->pt_in_progress == 1) {
+			ql4im_ha->pt_in_progress = 0;
+			/* Call up only if the timer has not already fired.
+			 * If the cmd timed out, up was already called by
+			 * ql4_scsi_pt_cmd_timeout.  If the cmd completes
+			 * after timeout, we don't want to call up again.
+			 */
+			if (del_timer_sync(&ql4im_ha->pt_cmpl_timer))
+                                up(&ql4im_ha->pt_cmpl_sem);
+		} else {
+			DEBUG2(ql4_info(ha, "%s: already timed out\n",
+				__func__));
+		}
+	} else
+		DEBUG2(ql4_info(ha, "%s: NULL HBA\n", __func__));
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return;
+}
+
+
+/**
+ * ql4_scsi_pt_cmd_timeout - Command timeout handler
+ * @sp - Pointer to SCSI Request Block
+ *
+ * This routine gets invoked if the command times out.
+ * Call up to wakeup the ioctl completion semaphore and return to
+ * the SCSI passthru function.
+ *
+ * NOTE: Since this is routine runs in atomic context and cannot be interrupted,
+ * we have to invoke the reset handlers after we return to the SCSI Passthru
+ * thread.
+ *
+ * Context: Atomic
+ **/
+void ql4_scsi_pt_cmd_timeout(struct srb *sp)
+{
+	struct scsi_qla_host *ha;
+	struct hba_ioctl *ql4im_ha;
+
+	ha = sp->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ql4im_ha = ql4im_get_adapter_handle(ha->instance);
+	if (!ql4im_ha) {
+		DEBUG2(ql4_info(ha, "%s: NULL HBA\n", __func__));
+		LEAVE_IOCTL(__func__, ha->host_no);
+		return;
+	}
+
+	up(&ql4im_ha->pt_cmpl_sem);
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+/**
+ * ql4_add_timer_to_cmd - Adds timer to command
+ * @sp - Pointer to SCSI Request Block
+ *
+ * This routine creates a timer for the specified command. The timeout
+ * is usually the command time from kernel minus 2 secs.
+ *
+ * Context: Kernel context.
+ **/
+void ql4_add_timer_to_cmd(struct hba_ioctl *ql4im_ha, struct srb *srb_t)
+{
+	init_timer(&(ql4im_ha->pt_cmpl_timer));
+	ql4im_ha->pt_cmpl_timer.expires = jiffies + (SCSI_PT_CMD_TOV * HZ);
+	ql4im_ha->pt_cmpl_timer.data = (unsigned long) srb_t;
+	ql4im_ha->pt_cmpl_timer.function =
+		(void (*) (unsigned long))ql4_scsi_pt_cmd_timeout;
+	add_timer(&ql4im_ha->pt_cmpl_timer);
+}
+
+/**
+ * ql4_add_timer_to_cmd - Deletes timer from specified command
+ * @timer - Pointer to command timer
+ *
+ * Context: Kernel/Interrupt context.
+ **/
+void
+ql4_delete_timer_from_cmd(struct timer_list *timer)
+{
+
+	if (del_timer_sync(timer)) {
+		timer->function =  NULL;
+		timer->data = (unsigned long) NULL;
+	}
+}
+
+static int ql4_scsi_passthru(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	struct ddb_entry	*ddb_entry;
+	EXT_SCSI_PASSTHRU_ISCSI *pscsi_pass;
+	struct scsi_cmnd	*pscsi_cmd;
+	struct srb		*srb;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (!test_bit(AF_ONLINE, &ha->flags)) {
+		DEBUG2(ql4_info(ha, "%s: command not pocessed, "
+			"adapter link down.\n", __func__));
+		ioctl->Status = EXT_STATUS_HBA_NOT_READY;
+		goto exit_scsi_pass;
+	}
+
+	pscsi_pass = (EXT_SCSI_PASSTHRU_ISCSI *)ql4im_ha->tmp_buf;
+	memset(pscsi_pass, 0, sizeof(EXT_SCSI_PASSTHRU_ISCSI));
+
+	if ((status = copy_from_user((uint8_t *)pscsi_pass,
+				     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(EXT_SCSI_PASSTHRU_ISCSI))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy passthru struct "
+			"from user's memory area.\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_scsi_pass;
+	}
+
+	if (pscsi_pass->Addr.Target >= MAX_DDB_ENTRIES) {
+		ioctl->Status = EXT_STATUS_ERR;
+		goto exit_scsi_pass;
+	}
+
+	ddb_entry = get_ddb_from_osid(ha, pscsi_pass->Addr.Target);
+
+	if ((ddb_entry == NULL) ||
+		(ddb_entry == (struct ddb_entry *)INVALID_ENTRY)){
+		DEBUG2(ql4_info(ha, "%s: invalid device (t%d) specified.\n",
+		    __func__, pscsi_pass->Addr.Target));
+
+		ioctl->Status = EXT_STATUS_DEV_NOT_FOUND;
+		goto exit_scsi_pass;
+	}
+	if (ddb_entry->fw_ddb_device_state != DDB_DS_SESSION_ACTIVE) {
+		DEBUG2(ql4_info(ha, "%s: device (t%d) not in active state\n",
+			__func__, pscsi_pass->Addr.Target));
+
+		ioctl->Status = EXT_STATUS_DEVICE_NOT_READY;
+		goto exit_scsi_pass;
+	}
+
+	srb = &ql4im_ha->pt_srb;
+	memset(srb, 0, sizeof(struct srb));
+
+	pscsi_cmd = &ql4im_ha->pt_scsi_cmd;
+	memset(pscsi_cmd, 0, sizeof(struct scsi_cmnd));
+
+	pscsi_cmd->device = &ql4im_ha->pt_scsi_device;
+	memset(pscsi_cmd->device, 0, sizeof(struct scsi_device));
+
+	pscsi_cmd->request = &ql4im_ha->pt_request;
+	memset(pscsi_cmd->request, 0, sizeof(struct request));
+
+	memset(ql4im_ha->dma_v, 0, ql4im_ha->dma_len);
+
+	pscsi_cmd->device->channel = pscsi_pass->Addr.Bus;
+	pscsi_cmd->device->id = pscsi_pass->Addr.Target;
+	pscsi_cmd->device->lun = pscsi_pass->Addr.Lun;
+	pscsi_cmd->device->host = ha->host;
+	pscsi_cmd->device->hostdata = ddb_entry;
+
+#ifndef QLA_SLES11
+	pscsi_cmd->request_buffer = ql4im_ha->dma_v;
+	pscsi_cmd->use_sg = 0;
+#endif
+	pscsi_cmd->scsi_done = ql4_scsi_pt_done;
+
+	pscsi_cmd->SCp.ptr = (char *) srb;
+	srb->cmd = pscsi_cmd;
+	srb->flags |= SRB_SCSI_PASSTHRU;
+	srb->ha = ha;
+	srb->dma_handle = ql4im_ha->dma_p;
+	srb->ddb = ddb_entry;
+	kref_init(&srb->srb_ref);
+
+	srb->dma_len = 0;
+
+	if (pscsi_pass->CdbLength == 6 || pscsi_pass->CdbLength == 10 ||
+	    pscsi_pass->CdbLength == 12 || pscsi_pass->CdbLength == 16) {
+		pscsi_cmd->cmd_len = pscsi_pass->CdbLength;
+	} else {
+		DEBUG2(ql4_info(ha, "%s: Unsupported CDB length 0x%x \n",
+			__func__, pscsi_cmd->cmd_len));
+
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_scsi_pass;
+	}
+
+	if (pscsi_pass->Direction == EXT_DEF_SCSI_PASSTHRU_DATA_IN) {
+		pscsi_cmd->sc_data_direction = DMA_FROM_DEVICE;
+		srb->dma_len = ioctl->ResponseLen -
+                    sizeof(EXT_SCSI_PASSTHRU_ISCSI);
+
+	} else if (pscsi_pass->Direction ==  EXT_DEF_SCSI_PASSTHRU_DATA_OUT) {
+		pscsi_cmd->sc_data_direction = DMA_TO_DEVICE;
+		srb->dma_len = ioctl->RequestLen -
+                    sizeof(EXT_SCSI_PASSTHRU_ISCSI);
+
+		/* Sending user data from ioctl->ResponseAddr to SCSI
+		 * command buffer
+		 */
+		if ((status = copy_from_user((uint8_t *)
+				ql4im_ha->dma_v,
+				Q64BIT_TO_PTR(ioctl->RequestAdr,
+					ioctl->AddrMode) +
+				sizeof(EXT_SCSI_PASSTHRU_ISCSI),
+					srb->dma_len)) != 0) {
+			DEBUG2(ql4_info(ha, "%s: unable to copy write buffer "
+				"from user's memory area.\n", __func__));
+
+			ioctl->Status = EXT_STATUS_COPY_ERR;
+			goto exit_scsi_pass;
+		}
+	} else {
+		pscsi_cmd->sc_data_direction = DMA_NONE;
+#ifndef QLA_SLES11
+		pscsi_cmd->request_buffer  = 0;
+#endif
+	}
+#ifndef QLA_SLES11
+	pscsi_cmd->request_bufflen = srb->dma_len;
+#else
+	pscsi_cmd->sdb.length = srb->dma_len;
+	pscsi_cmd->cmnd = ql4im_ha->cmnd;
+	pscsi_cmd->sense_buffer = ql4im_ha->sense_buffer;
+#endif
+
+	memcpy(pscsi_cmd->cmnd, pscsi_pass->Cdb, pscsi_cmd->cmd_len);
+
+	DEBUG4(ql4_info(ha, "%d:%d:%d: %s:\n",
+		pscsi_cmd->device->channel,
+		pscsi_cmd->device->id, pscsi_cmd->device->lun, __func__));
+
+	if (!test_bit(AF_ONLINE, &ha->flags)) {
+		DEBUG2(ql4_info(ha, "%s: command not pocessed, "
+			"adapter link down.\n", __func__));
+		ioctl->Status = EXT_STATUS_HBA_NOT_READY;
+		ql4im_ha->pt_in_progress = 0;
+		goto exit_scsi_pass;
+	}
+
+	/* Add timer to command and send command to ISP */
+	srb->cc_stat = IOCTL_INVALID_STATUS;
+	ql4im_ha->pt_in_progress = 1;
+	ql4_add_timer_to_cmd(ql4im_ha, srb);
+
+	if (ha->ql4cmd(ha, srb) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: error sending cmd to isp\n",
+		    __func__));
+		ql4im_ha->pt_in_progress = 0;
+		ioctl->Status = EXT_STATUS_DEV_NOT_FOUND;
+		goto exit_scsi_pass;
+	}
+
+	down(&ql4im_ha->pt_cmpl_sem);
+
+	/* ---
+	 * Return here from either ql4_scsi_pt_done or ql4_scsi_pt_cmd_timeout
+	 * --- */
+
+	ql4_delete_timer_from_cmd(&ql4im_ha->pt_cmpl_timer);
+
+	/* If command timed out, try to recover */
+	if (ql4im_ha->pt_in_progress) {
+		DEBUG2(ql4_info(ha, "%s: ERROR = command timeout.\n",
+			__func__));
+
+		status = ha->host->hostt->eh_device_reset_handler(
+			&ql4im_ha->pt_scsi_cmd);
+
+		if (status != QLA_SUCCESS)
+			status = ha->host->hostt->eh_host_reset_handler(
+				&ql4im_ha->pt_scsi_cmd);
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ql4im_ha->pt_in_progress = 0;
+		goto exit_scsi_pass;
+	}
+
+	DEBUG4(ql4_info(ha, "\tresult 0x%x cc_stat 0x%x\n", pscsi_cmd->result,
+		srb->cc_stat));
+	ioctl->DetailStatus = pscsi_cmd->result & 0xFFFF;
+	pscsi_pass->Reserved[0] = (uint8_t) (pscsi_cmd->result & 0xFFFF);
+	pscsi_pass->Reserved[1] = (uint8_t) srb->cc_stat;
+
+	if (((pscsi_cmd->result >> 16) == DID_OK) &&
+		((pscsi_cmd->result & 0xFFFF) == SCSI_CHECK_CONDITION)) {
+		pscsi_pass->Reserved[2] =
+			(uint8_t)(sizeof(pscsi_cmd->sense_buffer));
+
+		memcpy(pscsi_pass->SenseData, pscsi_cmd->sense_buffer,
+		    MIN(sizeof(pscsi_cmd->sense_buffer),
+		    sizeof(pscsi_pass->SenseData)));
+
+		DEBUG10(ql4_info(ha, "%s: sense data dump:\n", __func__));
+	}
+	pscsi_pass->Reserved[3] = (uint8_t) host_byte(pscsi_cmd->result);
+	pscsi_pass->Reserved[6] = (uint8_t) 0;
+	pscsi_pass->Reserved[7] = (uint8_t) 0;
+
+	if ((pscsi_cmd->result >> 16) == DID_OK) {
+
+		ioctl->Status = EXT_STATUS_OK;
+
+	} else if (srb->cc_stat == SCS_DATA_UNDERRUN) {
+		DEBUG2(ql4_info(ha, "%s: Data underrun.  Resid = 0x%x\n",
+			__func__, QL_GET_SCSI_RESID(pscsi_cmd)));
+
+		ioctl->Status = EXT_STATUS_DATA_UNDERRUN;
+		pscsi_pass->Reserved[4] = MSB(QL_GET_SCSI_RESID(pscsi_cmd));
+		pscsi_pass->Reserved[5] = LSB(QL_GET_SCSI_RESID(pscsi_cmd));
+
+	} else if (srb->cc_stat == SCS_DATA_OVERRUN) {
+		DEBUG2(ql4_info(ha, "%s: Data overrun.  Resid = 0x%x\n",
+			__func__, QL_GET_SCSI_RESID(pscsi_cmd)));
+
+		ioctl->Status = EXT_STATUS_DATA_OVERRUN;
+		pscsi_pass->Reserved[4] = MSB(QL_GET_SCSI_RESID(pscsi_cmd));
+		pscsi_pass->Reserved[5] = LSB(QL_GET_SCSI_RESID(pscsi_cmd));
+
+	} else {
+		DEBUG2(ql4_info(ha, "%s: Command completed in ERROR. "
+		    "cs=%04x, ss=%-4x\n", __func__,
+		    srb->cc_stat, (pscsi_cmd->result & 0xFFFF)));
+
+		if ((pscsi_cmd->result & 0xFFFF) != SCSI_GOOD) {
+			ioctl->Status = EXT_STATUS_SCSI_STATUS;
+		} else {
+			ioctl->Status = EXT_STATUS_ERR;
+		}
+	}
+
+	if (copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+			 pscsi_pass, sizeof(EXT_SCSI_PASSTHRU_ISCSI)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy passthru struct "
+			"to user's memory area.\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_scsi_pass;
+	}
+
+	if (pscsi_pass->Direction == EXT_DEF_SCSI_PASSTHRU_DATA_IN) {
+		void	*xfer_ptr = Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						  ioctl->AddrMode) +
+				    sizeof(EXT_SCSI_PASSTHRU_ISCSI);
+		uint32_t xfer_len = ioctl->ResponseLen -
+				    sizeof(EXT_SCSI_PASSTHRU_ISCSI);
+
+		if (srb->cc_stat == SCS_DATA_UNDERRUN && QL_GET_SCSI_RESID(pscsi_cmd)) {
+			xfer_len -= QL_GET_SCSI_RESID(pscsi_cmd);
+		}
+
+		if ((status = copy_to_user(xfer_ptr, ql4im_ha->dma_v,
+		    xfer_len)) != 0) {
+			DEBUG2(ql4_info(ha, "%s: unable to copy READ data "
+			    "to user's memory area.\n", __func__));
+
+			ioctl->Status = EXT_STATUS_COPY_ERR;
+		}
+	}
+
+exit_scsi_pass:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+
+static int ql4_get_hbacnt(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	int		status = 0;
+	EXT_HBA_COUNT	hba_cnt;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	memset(&hba_cnt, 0, sizeof(EXT_HBA_COUNT));
+	hba_cnt.HbaCnt = ql4im_get_hba_count();
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+		&hba_cnt, sizeof(hba_cnt))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: failed to copy data\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_hbacnt;
+	}
+
+	DEBUG2(ql4_info(ha, "%s: hbacnt is %d\n", __func__, hba_cnt.HbaCnt));
+	ioctl->Status = EXT_STATUS_OK;
+
+exit_get_hbacnt:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_diag_mode(struct hba_ioctl *ql4im_ha,
+			 EXT_IOCTL_ISCSI *ioctl) {
+	int status = 0;
+	u_long wait_time, reset_time;
+	struct scsi_qla_host *ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+	ioctl->Status = EXT_STATUS_OK;
+
+	switch(ioctl->SubCode) {
+		case INT_SC_SET_DIAG_MODE:
+			DEBUG2(ql4_info(ha, "%s: Set Quiescent mode\n",
+					__func__));
+			if (test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags)) {
+				ql4_info(ha, "%s: Device already in "
+					"quiescent mode\n", __func__);
+				break;
+			}
+
+			set_bit(AF_QUIESCE_OWNER, &ha->flags);
+			set_bit(DPC_HA_NEED_QUIESCENT, &ha->dpc_flags);
+
+			wait_time = jiffies + (30 * HZ);
+			while (!time_after_eq(jiffies, wait_time)) {
+				ssleep(1);
+				if (test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags)) {
+					ioctl->Status = EXT_STATUS_OK;
+					break;
+				}
+			}
+
+			/* AF_QUIESCE_OWNER is reset after qsnt mode is cleared */
+			if (!test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags)) {
+				ql4_info(ha, "%s: Setting quiescent mode"
+					" timed out, ha flags=0x%lx,"
+					" dpc_flags=0x%lx!\n",
+					__func__, ha->flags, ha->dpc_flags);
+				ioctl->Status = EXT_STATUS_ERR;
+				status = QLA_ERROR;
+			} else
+				DEBUG2(ql4_info(ha, "%s: Device "
+				"quiescent mode set\n", __func__));
+			break;
+
+		case INT_SC_RESET_DIAG_MODE:
+			if (!test_bit(AF_QUIESCE_OWNER, &ha->flags) &&
+				!test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags)) {
+				ql4_info(ha, "%s: Device not in qsnt "
+					"mode or function not quiesce owner, "
+					"ha->flags=0x%ld, ha->dpc_flags=0x%lx!\n",
+					__func__, ha->flags, ha->dpc_flags);
+				break;
+			}
+			DEBUG2(ql4_info(ha, "%s: Reset Quiescent mode\n",
+					__func__));
+			set_bit(DPC_RESET_QUIESCENT, &ha->dpc_flags);
+			reset_time = jiffies + (30 * HZ);
+			while (!time_after_eq(jiffies, reset_time)) {
+				ssleep(1);
+				if (!test_bit(DPC_QUIESCE_ACTIVE,
+								&ha->dpc_flags)) {
+					ioctl->Status = EXT_STATUS_OK;
+					break;
+				}
+			}
+
+			if (test_bit(DPC_QUIESCE_ACTIVE, &ha->dpc_flags)) {
+				ql4_info(ha, "%s: Resetting quiescent"
+				" mode timed out!!!\n", __func__);
+				ioctl->Status = EXT_STATUS_ERR;
+			} else
+				DEBUG2(ql4_info(ha, "%s: Device "
+				"quiescent mode reset\n", __func__));
+			clear_bit(AF_QUIESCE_OWNER, &ha->flags);
+			break;
+
+		default:
+			DEBUG2(ql4_info(ha, "%s: Invalid Quiescent mode"
+					" request\n", __func__));
+			ioctl->Status = EXT_STATUS_INVALID_REQUEST;
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return status;
+}
+
+/**
+ * ql4_update_beacon - Enable/Disable beacon
+ * @ql4im_ha : Pointer to host adapter structure.
+ * @ioctl    : IOCTL structure from application.
+ * @mbox_cmd : Mailbox received from application.
+ * @mbox_sts : Mailbox status to send back.
+ *
+ * This routine enables or disables beacon for specified host,
+ * based on the mailbox command sent by application.
+ **/
+void ql4_update_beacon(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl,
+			uint32_t *mbox_cmd, uint32_t *mbox_sts)
+{
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) !=
+			QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: MBOX_CMD_UPDATE_BEACON, failed w/ "
+					"status %04X", __func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+}
+
+/*
+ * ql4_get_diag_data
+ *  This routine is used to get diagnostics data from the f/w.
+ *  Supports TEST_INTERNAL_LOOPBACK_DIAG and TEST_EXTERNAL_LOOPBACK_DIAG.
+ *  Ioctl can be enhanced for other test codes when F/w supports it.
+ *
+ *  Returns:
+ *  QLA_SUCCESS - command completed successfully, either with or without
+ *          errors in the Status field of the main ioctl structure
+ *      -EINVAL      - command is invalid
+ *      -ENOMEM      - memory allocation failed
+ */
+static int ql4_get_diag_data(struct hba_ioctl *ql4im_ha,
+					EXT_IOCTL_ISCSI *ioctl) {
+	int status = 0;
+	INT_DIAG_TEST_RESULT *results;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+	ioctl->Status = EXT_STATUS_OK;
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	results = kzalloc(sizeof(INT_DIAG_TEST_RESULT), GFP_KERNEL);
+	if (results == NULL) {
+		ql4_warn(ha, "%s: kzalloc failed\n", __func__);
+		status = -ENOMEM;
+		goto exit_iscsi_diag;
+	}
+
+	if (!ioctl->RequestAdr ||
+		ioctl->RequestLen > sizeof(INT_DIAG_TEST_RESULT)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		status = -ENOMEM;
+		goto exit_iscsi_diag_free_mem;
+	}
+
+	if ((status = copy_from_user(results,
+			Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+			ioctl->RequestLen) != 0)) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+					"user's memory area status=%d\n",
+					__func__, status));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_iscsi_diag_free_mem;
+	}
+
+	/* Check if it's call for beacon operation */
+	if (results->mbCmd[0] == MBOX_CMD_UPDATE_BEACON) {
+		ql4_update_beacon(ql4im_ha, ioctl, results->mbCmd, mbox_sts);
+		goto beacon_exit;
+	}
+
+	/*
+	 * Send the mailbox command
+	 */
+	mbox_cmd[0] = MBOX_CMD_GET_DIAGNOSTICS_DATA;
+	mbox_cmd[1] = results->mbCmd[1];
+
+	switch(mbox_cmd[1])  {
+	case TEST_INTERNAL_LOOPBACK_DIAG:
+	case TEST_EXTERNAL_LOOPBACK_DIAG:
+		/* Update mbox[2-7] with src_addr, dest_addr, transfer_size,
+		 * flags from ioctl and call ha->ql4mbx
+		 */
+		mbox_cmd[2] = results->mbCmd[2]; /* Source low_addr */
+		mbox_cmd[3] = results->mbCmd[3]; /* source high_addr */
+		mbox_cmd[4] = results->mbCmd[4]; /* destination low_addr */
+		mbox_cmd[5] = results->mbCmd[5]; /* destination high_addr */
+		mbox_cmd[6] = results->mbCmd[6]; /* transfer size */
+		mbox_cmd[7] = results->mbCmd[7]; /* flags */
+		break;
+
+	default:
+		DEBUG2(ql4_info(ha, "%s: diagnostics results "
+			"opcode %d not supported \n", __func__, mbox_cmd[1]));
+
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+		status = -EINVAL;
+		goto exit_iscsi_diag_free_mem;
+		break;
+	}
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, MBOX_REG_COUNT, &mbox_cmd[0],
+			&mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+
+		switch(mbox_cmd[1]) {
+		case TEST_INTERNAL_LOOPBACK_DIAG:
+		case TEST_EXTERNAL_LOOPBACK_DIAG:
+			ioctl->DetailStatus = mbox_sts[0]; /* Completion Stat*/
+			ioctl->Reserved1 = mbox_sts[1]; /* Failure Type */
+			DEBUG2(ql4_info(ha, "%s: diagnostics results "
+				"completion_status=0x%x, failure_type=%d\n",
+				__func__, mbox_sts[0], mbox_sts[1]));
+			break;
+
+		default:
+			break;
+		}
+	}
+beacon_exit:
+	memcpy(results->mbSts, mbox_sts, sizeof(results->mbSts));
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+					ioctl->AddrMode), results,
+					ioctl->ResponseLen)) != 0) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n",
+				__func__));
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	}
+
+exit_iscsi_diag_free_mem:
+	kfree(results);
+
+exit_iscsi_diag:
+	DEBUG2(ql4_info(ha, "%s: diagnostics/beacon results status=%d, "
+		"ioctl->status=%d, detailed status=0x%x, failure_type=%d\n",
+		__func__, status, ioctl->Status,
+		mbox_sts[0], mbox_sts[1]));
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_hostno(struct hba_ioctl *ql4im_ha,
+				EXT_IOCTL_ISCSI *ioctl)
+{
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ioctl->HbaSelect = ql4im_ha->ha->host_no;
+	ioctl->Status = EXT_STATUS_OK;
+
+	DEBUG4(ql4_info(ha, "%s: nce is %d\n", __func__, ioctl->HbaSelect));
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(0);
+}
+
+static int ql4_driver_specific(struct hba_ioctl *ql4im_ha,
+					EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	EXT_LN_DRIVER_DATA	data;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ioctl->ResponseLen < sizeof(EXT_LN_DRIVER_DATA)) {
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		DEBUG2(ql4_info(ha, "%s: ERROR ResponseLen too small.\n",
+				__func__));
+		goto exit_driver_specific;
+	}
+
+	data.DrvVer.Major = drvr_major;
+	data.DrvVer.Minor = drvr_minor;
+	data.DrvVer.Patch = drvr_patch;
+	data.DrvVer.Beta  = drvr_beta;
+
+	if (is_qla4010(ql4im_ha->ha))
+		data.AdapterModel = EXT_DEF_QLA4010_DRIVER;
+	else if (is_qla4022(ql4im_ha->ha))
+		data.AdapterModel = EXT_DEF_QLA4022_DRIVER;
+
+	status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+			      &data, sizeof(EXT_LN_DRIVER_DATA));
+
+	if (status) {
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		DEBUG2(ql4_info(ha, "%s: ERROR copy resp buf\n", __func__));
+	}
+
+exit_driver_specific:
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_disable_acb(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host	*ha;
+	int			count = 600;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ha->firmware_version[0] == 2) {
+                DEBUG2(ql4_info(ha, "%s: Not supported by 2-series firmware.\n",
+                                __func__));
+
+                ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+                ioctl->ResponseLen = 0;
+		return status;
+        }
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_DISABLE_ACB;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = ioctl->Reserved1;
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, MBOX_REG_COUNT, &mbox_cmd[0],
+					&mbox_sts[0]) != QLA_SUCCESS) {
+		if (mbox_sts[0] == MBOX_STS_INTERMEDIATE_COMPLETION) {
+
+			while (count--) {
+				memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+				memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+				mbox_cmd[0] = MBOX_CMD_GET_IP_ADDR_STATE;
+				mbox_cmd[1] = ioctl->Instance;
+				if (ha->ql4mbx(ha, MBOX_REG_COUNT, 8,
+					&mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+					DEBUG2(ql4_info(ha, "%s: command failed \n",
+						__func__));
+					ioctl->Status = EXT_STATUS_ERR;
+					ioctl->DetailStatus = mbox_sts[0];
+					break;
+				} else {
+					if (!(mbox_sts[1] & 0xF0000000))
+						break;
+					else
+						msleep(100);
+				}
+			}
+			if (!count)
+				ioctl->Status = EXT_STATUS_ERR;
+		} else {
+			ioctl->Status = EXT_STATUS_ERR;
+			ioctl->DetailStatus = mbox_sts[0];
+		}
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_send_router_sol(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host	*ha;
+	uint32_t		ip_addr;
+	EXT_SEND_ROUTER_SOL	sr_sol;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if (ioctl->ResponseLen < sizeof(EXT_LN_DRIVER_DATA)) {
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		DEBUG2(ql4_info(ha, "%s: ERROR ResponseLen too small.\n",
+				__func__));
+		goto exit_sndr_sol;
+	}
+
+	if ((status = copy_from_user((uint8_t *)&sr_sol,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(sr_sol))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_sndr_sol;
+	}
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_SEND_IPV6_ROUTER_SOL;
+	mbox_cmd[1] = ioctl->Instance;
+	mbox_cmd[2] = sr_sol.Flags;
+	memcpy(&ip_addr, &sr_sol.Addr.IPAddress, sizeof(ip_addr));
+	mbox_cmd[3] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &sr_sol.Addr.IPAddress[4], sizeof(ip_addr));
+	mbox_cmd[4] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &sr_sol.Addr.IPAddress[8], sizeof(ip_addr));
+	mbox_cmd[5] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &sr_sol.Addr.IPAddress[12], sizeof(ip_addr));
+	mbox_cmd[6] = cpu_to_le32(ip_addr);
+
+	ioctl->Status = EXT_STATUS_OK;
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed \n", __func__));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+	}
+	ioctl->VendorSpecificStatus[0] = mbox_sts[0];
+	ioctl->VendorSpecificStatus[1] = mbox_sts[1];
+
+exit_sndr_sol:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+/* Start of Internal ioctls */
+
+static int ql4_ping(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	INT_PING		ping;
+	uint32_t		ip_addr;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if ((status = copy_from_user((uint8_t *)&ping,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(ping))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_ping;
+	}
+
+	/*
+	 * Issue Mailbox Command
+	 */
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_PING;
+	mbox_cmd[1] = ping.Reserved;
+	memcpy(&ip_addr, &ping.IPAddr.IPAddress, sizeof(ip_addr));
+	mbox_cmd[2] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &ping.IPAddr.IPAddress[4], sizeof(ip_addr));
+	mbox_cmd[3] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &ping.IPAddr.IPAddress[8], sizeof(ip_addr));
+	mbox_cmd[4] = cpu_to_le32(ip_addr);
+	memcpy(&ip_addr, &ping.IPAddr.IPAddress[12], sizeof(ip_addr));
+	mbox_cmd[5] = cpu_to_le32(ip_addr);
+	mbox_cmd[6] = cpu_to_le32(ping.PacketSize);
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 7, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: command failed, Status %04x Error %04x\n",
+		    __func__, mbox_sts[0], mbox_sts[6]));
+
+		ioctl->Status = EXT_STATUS_ERR;
+		ioctl->DetailStatus = mbox_sts[0];
+	}
+
+exit_ping:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_flash(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	uint32_t		data_len;
+	uint32_t		data_offset;
+	INT_ACCESS_FLASH	*puser_flash;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	puser_flash = Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode);
+
+	if ((status = copy_from_user((void *)&data_len,
+				 (void *)&puser_flash->DataLen,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataLen copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_flash;
+	}
+	if (data_len > sizeof(puser_flash->FlashData)) {
+		DEBUG2(ql4_info(ha, " %s: DataLen invalid 0x%x\n",
+			__func__, data_len));
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_get_flash;
+	}
+
+	if ((status = copy_from_user((void *)&data_offset,
+				 (void *)&puser_flash->DataOffset,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataOffset copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_flash;
+	}
+	DUMP_GET_FLASH(data_offset, data_len);
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_READ_FLASH;
+	mbox_cmd[1] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[2] = MSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = data_offset;
+	mbox_cmd[4] = data_len;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, " %s: READ_FLASH failed st 0x%x\n",
+			__func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		ioctl->VendorSpecificStatus[0] = mbox_sts[1];
+		goto exit_get_flash;
+	}
+
+	puser_flash = Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode);
+	/*
+	 * Copy local DMA buffer to user's response data area
+	 */
+	if ((status = copy_to_user(&puser_flash->FlashData[0],
+                                   ql4im_ha->dma_v,
+				   data_len)) != 0) {
+		DEBUG2(ql4_info(ha, " %s: FlashData to user failed\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_flash;
+	}
+	if ((status = copy_to_user(&puser_flash->DataLen,
+                                   &data_len,
+				   sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataLen to user failed\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_flash;
+	}
+	if ((status = copy_to_user(&puser_flash->DataOffset,
+                                   &data_offset,
+				   sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataOffset to user failed\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_get_flash;
+	}
+
+	ioctl->Status = EXT_STATUS_OK;
+	ioctl->ResponseLen = data_len;
+
+exit_get_flash:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_get_host_no(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if ((status = copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr,
+						 ioctl->AddrMode),
+                                   &(ha->host_no),
+				   sizeof(ha->host_no))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: failed to copy data\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+	} else {
+		ioctl->Status = EXT_STATUS_OK;
+	}
+
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+static int ql4_get_core_dump(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	INT_ACCESS_CORE_DUMP	cdump, *puser_cdump;
+	struct scsi_qla_host	*ha;
+	void			*pdump;
+	int 			dump_img_size;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	if ((status = copy_from_user((uint8_t *)&cdump,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(cdump))) != 0) {
+		DEBUG2(ql4_info(ha, ": %s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_core_dump;
+	}
+
+        ioctl->Status = EXT_STATUS_OK;
+
+	if (is_qla8022(ha)) {
+		if (!test_bit(AF_82XX_FW_DUMPED, &ha->flags)) {
+			ioctl->Status = EXT_STATUS_ERR;
+			DEBUG2(ql4_info(ha, ": %s: FW Dump not available\n",
+					 __func__));
+			goto exit_core_dump;
+		}
+
+		/* For acutal dump use the ha->fw_dump memory, no need to do a vamlloc */
+		if((cdump.Offset == 0) && 
+		   cdump.DataLen != DUMP_IMAGE_HEADER_SIZE)
+			ql4im_ha->core = ha->fw_dump;
+
+		/* Used only to allocate memory for first header */	
+		dump_img_size = DUMP_IMAGE_HEADER_SIZE;
+	} else {
+		dump_img_size = DUMP_IMAGE_SIZE;
+		ha->fw_dump_size = DUMP_IMAGE_SIZE;
+	}
+
+	if ((!cdump.DataLen) || (cdump.Offset >= ha->fw_dump_size))
+		goto exit_core_dump;
+
+	if (ql4im_ha->core == NULL) {
+		if((ql4im_ha->core = vmalloc(dump_img_size)) == NULL){
+			ioctl->Status = EXT_STATUS_NO_MEMORY;
+			goto exit_core_dump;
+		}
+		ql4_core_dump(ha, ql4im_ha->core);
+	}
+
+
+	puser_cdump = Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode);
+	pdump = (unsigned char *)ql4im_ha->core + cdump.Offset;
+
+        ioctl->ResponseLen = cdump.DataLen;
+
+	if ((cdump.Offset + cdump.DataLen) > ha->fw_dump_size) {
+		cdump.LastBlockFlag = 1;
+		/* Adjust the user space response length */
+		ioctl->ResponseLen = ha->fw_dump_size - cdump.Offset;
+		if (copy_to_user(puser_cdump, &cdump, sizeof(cdump)) != 0) {
+			DEBUG2(ql4_info(ha, " %s: unable to copy data to user's "
+			"memory area\n", __func__));
+			ioctl->Status = EXT_STATUS_COPY_ERR;
+		}
+	} else
+		cdump.LastBlockFlag = 0;
+
+        if (copy_to_user(&puser_cdump->Data[0], pdump, ioctl->ResponseLen) != 0) {
+                DEBUG2(ql4_info(ha, " %s: unable to copy data to user's "
+                    "memory area\n", __func__));
+                ioctl->Status = EXT_STATUS_COPY_ERR;
+        }
+
+        if (is_qla8022(ha) && 
+		(cdump.Offset == 0) && 
+			(cdump.DataLen == DUMP_IMAGE_HEADER_SIZE)) {
+			if(ql4im_ha->core)
+				vfree(ql4im_ha->core);
+	}
+
+	if (cdump.LastBlockFlag) {
+	        if (!is_qla8022(ha))
+			vfree(ql4im_ha->core);
+		ql4im_ha->core = NULL;
+		clear_bit(AF_82XX_FW_DUMPED, &ha->flags);
+	}
+exit_core_dump:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_int_get_data(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int	status = 0;
+
+	switch (ioctl->SubCode) {
+	case INT_SC_GET_FLASH:
+		status = ql4_get_flash(ql4im_ha, ioctl);
+		break;
+	case INT_SC_GET_HOST_NO:
+		status = ql4_get_host_no(ql4im_ha, ioctl);
+		break;
+	case INT_SC_GET_CORE_DUMP:
+		status = ql4_get_core_dump(ql4im_ha, ioctl);
+		break;
+	default:
+		DEBUG2(ql4_info(ql4im_ha->ha, "%s: unsupported internal get "
+			" data sub-command code (%X)\n", __func__,
+			ioctl->SubCode));
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+		break;
+	}
+
+	return status;
+}
+
+static int ql4_set_flash(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int			status = 0;
+	uint32_t		mbox_cmd[MBOX_REG_COUNT];
+	uint32_t		mbox_sts[MBOX_REG_COUNT];
+	uint32_t		area_type;
+	uint32_t		data_len;
+	uint32_t		data_offset;
+	uint32_t		data_options;
+	INT_ACCESS_FLASH	*puser_flash;
+	struct scsi_qla_host	*ha;
+
+	ha = ql4im_ha->ha;
+
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	puser_flash = Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode);
+
+	if ((status = copy_from_user((void *)&area_type,
+				 (void *)&puser_flash->AreaType,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: AreaType copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_flash;
+	}
+
+	if ((status = copy_from_user((void *)&data_len,
+				 (void *)&puser_flash->DataLen,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataLen copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_flash;
+	}
+	if (data_len > sizeof(puser_flash->FlashData)) {
+		DEBUG2(ql4_info(ha, " %s: DataLen invalid 0x%x\n",
+			__func__, data_len));
+		ioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_set_flash;
+	}
+
+	if ((status = copy_from_user((void *)&data_offset,
+				 (void *)&puser_flash->DataOffset,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: DataOffset copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_flash;
+	}
+
+	if ((status = copy_from_user((void *)&data_options,
+				 (void *)&puser_flash->Options,
+				 sizeof (uint32_t))) != 0) {
+		DEBUG2(ql4_info(ha, " %s: Options copy error\n",
+			__func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_flash;
+	}
+
+	if ((status = copy_from_user((void *)ql4im_ha->dma_v,
+				(void *)&puser_flash->FlashData[0],
+				data_len)) != 0) {
+		DEBUG2(ql4_info(ha, " %s: FlashData copy error\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_set_flash;
+	}
+
+	DUMP_SET_FLASH(data_offset, data_len, data_options);
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_WRITE_FLASH;
+	mbox_cmd[1] = LSDW(ql4im_ha->dma_p);
+	mbox_cmd[2] = MSDW(ql4im_ha->dma_p);
+	mbox_cmd[3] = data_offset;
+	mbox_cmd[4] = data_len;
+	mbox_cmd[5] = data_options;
+
+	ioctl->Status = EXT_STATUS_OK;
+	ioctl->ResponseLen = data_len;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, " %s: WRITE_FLASH failed st 0x%x\n",
+			__func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		ioctl->VendorSpecificStatus[0] = mbox_sts[1];
+	}
+	msleep(10);
+exit_set_flash:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+/**
+ * ql4_int_set_data
+ *	This routine calls set data IOCTLs based on the IOCTL Sub Code.
+ *	Kernel context.
+ **/
+static int ql4_int_set_data(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int	status = 0;
+
+	switch (ioctl->SubCode) {
+	case INT_SC_SET_FLASH:
+		status = ql4_set_flash(ql4im_ha, ioctl);
+		break;
+	default:
+		DEBUG2(ql4_info(ql4im_ha->ha, "%s: unsupported subCode(0x%x)\n",
+			__func__, ioctl->SubCode));
+
+		ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+		break;
+	}
+
+	return status;
+}
+
+/**
+ * ql4_hba_reset
+ *	This routine resets the specified HBA.
+ **/
+static int ql4_hba_reset(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	uint8_t		status = 0;
+	u_long		wait_time;
+	int		dpc_wait_bit;
+	INT_HBA_RESET	hba_reset = { 0 };
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ql4im_ha->aen_read = 0;
+
+	if ((status = copy_from_user((uint8_t *)&hba_reset,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof (INT_HBA_RESET))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from user's "
+		    "memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_hba_reset;
+	}
+
+	if (hba_reset.ResetFlag == HBA_RESET_FUNCTION_RESET) {
+		set_bit(DPC_RESET_HA_FW_CONTEXT, &ha->dpc_flags);
+		dpc_wait_bit = DPC_RESET_HA_FW_CONTEXT;
+	}
+	else if (hba_reset.ResetFlag == HBA_RESET_CHIP_RESET) {
+		set_bit(DPC_RESET_HA, &ha->dpc_flags);
+		dpc_wait_bit = DPC_RESET_HA;
+	}
+	else {
+		DEBUG2(ql4_info(ha, "%s: invalid reset request (%d)\n",
+			      __func__, hba_reset.ResetFlag));
+
+		ioctl->Status = EXT_STATUS_INVALID_REQUEST;
+		goto exit_hba_reset;
+	}
+
+	wait_time = jiffies + (180 * HZ);
+
+	while (!time_after_eq(jiffies, wait_time)) {
+		ssleep(1);
+
+		if ((!test_bit(dpc_wait_bit, &ha->dpc_flags))
+			&& test_bit(AF_ONLINE, &ha->flags)) {
+			msleep(30);
+			ioctl->Status = EXT_STATUS_OK;
+			goto exit_hba_reset;
+		}
+	}
+
+	ioctl->Status = EXT_STATUS_ERR;
+	status= QLA_ERROR;
+
+exit_hba_reset:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+/**
+ * ql4_copy_fw_flash
+ *	This routine requests copying the FW image in FLASH from primary-to-
+ *	secondary or secondary-to-primary.
+ **/
+static int ql4_copy_fw_flash(struct hba_ioctl *ql4im_ha, EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	INT_COPY_FW_FLASH copy_flash;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+
+	ioctl->Status = EXT_STATUS_OK;
+
+	if ((status = copy_from_user((uint8_t *)&copy_flash,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof (INT_COPY_FW_FLASH))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from user's "
+		    "memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_copy_flash;
+	}
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+
+	mbox_cmd[0] = MBOX_CMD_COPY_FLASH;
+	mbox_cmd[1] = copy_flash.Options;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 2, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: COPY_FLASH failed w/ "
+		    "status %04X\n", __func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		ioctl->DetailStatus = mbox_sts[0];
+		ioctl->VendorSpecificStatus[0] = mbox_sts[1];
+	}
+
+exit_copy_flash:
+	LEAVE_IOCTL(__func__, ha->host_no);
+
+	return(status);
+}
+
+/**
+ * ql4_restore_factory_defaults
+ *	This routine restores factory defaults of the adapter.
+**/
+static int ql4_restore_factory_defaults(struct hba_ioctl *ql4im_ha,
+					EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	INT_RESTORE_FACTORY_DEFAULTS defaults;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ioctl->RequestLen > sizeof(INT_RESTORE_FACTORY_DEFAULTS)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_defaults;
+	}
+
+	if ((status = copy_from_user((void *)&defaults,
+                                     Q64BIT_TO_PTR(ioctl->RequestAdr,
+						   ioctl->AddrMode),
+				     sizeof(INT_RESTORE_FACTORY_DEFAULTS))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+		    "user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_defaults;
+	}
+
+	memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+	memset(&mbox_sts, 0, sizeof(mbox_sts));
+	mbox_cmd[0] = MBOX_CMD_RESTORE_FACTORY_DEFAULTS;
+	mbox_cmd[3] = defaults.BlockMask;
+        mbox_cmd[4] = defaults.IFCBMask1;
+        mbox_cmd[5] = defaults.IFCBMask2;
+
+	if (ha->ql4mbx(ha, MBOX_REG_COUNT, 1, &mbox_cmd[0], &mbox_sts[0]) != QLA_SUCCESS) {
+		DEBUG2(ql4_info(ha, "%s: RESTORE_FACTORY_DEFAULTS failed w/ "
+		    "status %04X\n", __func__, mbox_sts[0]));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+	}
+
+exit_defaults:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+static int ql4_logout(struct hba_ioctl *ql4im_ha,
+			EXT_IOCTL_ISCSI *ioctl)
+{
+	int status = 0;
+	INT_LOGOUT_ISCSI lo;
+	uint32_t mbox_cmd[MBOX_REG_COUNT];
+	uint32_t mbox_sts[MBOX_REG_COUNT];
+	struct scsi_qla_host *ha;
+	struct ddb_entry *ddb_entry = NULL;
+	uint32_t old_ddb_state;
+
+	ha = ql4im_ha->ha;
+	ENTER_IOCTL(__func__, ha->host_no);
+	ioctl->Status = EXT_STATUS_OK;
+
+	if (ioctl->RequestLen > sizeof(INT_LOGOUT_ISCSI)) {
+		DEBUG2(ql4_info(ha, "%s: memory area too small\n", __func__));
+
+		ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+		goto exit_logout;
+	}
+
+	if ((status = copy_from_user((void *)&lo,
+			Q64BIT_TO_PTR(ioctl->RequestAdr, ioctl->AddrMode),
+				sizeof(INT_LOGOUT_ISCSI))) != 0) {
+		DEBUG2(ql4_info(ha, "%s: unable to copy data from "
+			"user's memory area\n", __func__));
+
+		ioctl->Status = EXT_STATUS_COPY_ERR;
+		goto exit_logout;
+	}
+
+	DEBUG2(ql4_info(ha, ": %s: TgtId=0x%04x ConId=0x%04x Opt=0x%04x NTId=0x%08x\n",
+			__func__, lo.TargetID, lo.ConnectionID,
+			lo.Options, lo.NewTargetID));
+
+	if (lo.TargetID >= MAX_DDB_ENTRIES) {
+		ioctl->Status = EXT_STATUS_ERR;
+		DEBUG2(ql4_info(ha, "%s: fw_ddb_index %d out of range"
+				"\n", __func__, lo.TargetID));
+		goto exit_logout;
+	}
+
+	ddb_entry = ha->fw_ddb_index_map[lo.TargetID];
+	if ((ddb_entry == NULL) ||
+		(ddb_entry == (struct ddb_entry *)INVALID_ENTRY)) {
+		DEBUG2(dev_info(&ha->pdev->dev, "%s: ddb[%d] ddb_entry NULL\n",
+				__func__, lo.TargetID));
+		ioctl->Status = EXT_STATUS_MAILBOX;
+		goto exit_logout;
+	}
+
+	old_ddb_state = ddb_entry->fw_ddb_device_state;
+
+	if (lo.Options & INT_DEF_CLOSE_SESSION ||
+	    lo.Options & INT_DEF_DELETE_DDB) {
+		set_bit(DF_NO_RELOGIN, &ddb_entry->flags);
+
+		memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+		memset(&mbox_sts, 0, sizeof(mbox_sts));
+		mbox_cmd[0] = MBOX_CMD_CONN_CLOSE;
+		mbox_cmd[1] = lo.TargetID;
+		mbox_cmd[3] = LOGOUT_OPTION_RESET;
+		if (lo.Options & INT_DEF_DELETE_DDB)
+			mbox_cmd[3] |= LOGOUT_OPTION_FREE_DDB;
+
+		if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0])
+			!= QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s:  MBOX failed w/ "
+				"cmd0=0x%04x cmd1=0x%04x cmd3=0x%04x, "
+				"sts0=0x%04x sts1=0x%04x sts4=0x%04x \n",
+				__func__, mbox_cmd[0], mbox_cmd[1], mbox_cmd[3],
+				mbox_sts[0], mbox_sts[1], mbox_sts[4]));
+			ioctl->Status = EXT_STATUS_MAILBOX;
+			goto exit_logout;
+		}
+	}
+
+	/* WORKAROUND For 4032: Additional mailbox call to free DDB needed if
+	 * incoming ddb state is SESSION_ACTIVE.
+	 * NOTE: Workaround needed for firmware backward compatibility.
+	 * However, algorithm allows for this bug being fixed in future
+	 * firmware versions by not making additional mbx 31 call if the
+	 * new ddb state goes to unassigned. */
+	if (!is_qla8022(ha) &&
+	     (old_ddb_state == DDB_DS_SESSION_ACTIVE ||
+	      lo.Options & INT_DEF_DELETE_DDB)) {
+
+		/* Wait for logout to complete:  QLA spec. states we should
+		 * wait for the AEN after calling "Close Connection (56)"
+		 * before calling "Free Device Database Entry (31h)". */
+		u_long wait_time = jiffies + (LOGOUT_TOV * HZ);
+		uint32_t fw_ddb_device_state = ddb_entry->fw_ddb_device_state;
+
+		memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+		memset(&mbox_sts, 0, sizeof(mbox_sts));
+		mbox_cmd[0] = MBOX_CMD_GET_DATABASE_ENTRY;
+		mbox_cmd[1] = lo.TargetID;
+
+		while (!time_after_eq(jiffies, wait_time)) {
+			if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0],
+				&mbox_sts[0]) != QLA_SUCCESS)
+				break;
+
+			fw_ddb_device_state = mbox_sts[4];
+			DEBUG2(ql4_info(ha, "%s:  DDB[%d] state %d\n",
+				__func__, lo.TargetID,
+				fw_ddb_device_state));
+
+			if (fw_ddb_device_state == DDB_DS_UNASSIGNED ||
+			    fw_ddb_device_state == DDB_DS_NO_CONNECTION_ACTIVE)
+				break;
+			ssleep(1);
+		}
+
+		/* If DDB was already freed, do not issue additional
+		 * mailbox command to free it. */
+		if (fw_ddb_device_state == DDB_DS_UNASSIGNED)
+			goto exit_logout;
+
+		if (fw_ddb_device_state != DDB_DS_NO_CONNECTION_ACTIVE) {
+			ioctl->Status = EXT_STATUS_MAILBOX;
+			DEBUG2(ql4_info(ha, "%s:  Unable to free DDB"
+				" 0x%x.  state (0x%x)\n", __func__, lo.TargetID,
+				fw_ddb_device_state));
+			goto exit_logout;
+		}
+
+		memset(&mbox_cmd, 0, sizeof(mbox_cmd));
+		memset(&mbox_sts, 0, sizeof(mbox_sts));
+		mbox_cmd[0] = MBOX_CMD_FREE_DATABASE_ENTRY;
+		mbox_cmd[1] = lo.TargetID;
+
+		if (ha->ql4mbx(ha, MBOX_REG_COUNT, 5, &mbox_cmd[0], &mbox_sts[0])
+			!= QLA_SUCCESS) {
+			DEBUG2(ql4_info(ha, "%s:  MBOX failed w/ "
+				"cmd0=0x%04x cmd1=0x%04x, "
+				"sts0=0x%04x sts1=0x%04x sts4=0x%04x \n",
+				__func__, mbox_cmd[0], mbox_cmd[1],
+				mbox_sts[0], mbox_sts[1], mbox_sts[4]));
+			ioctl->Status = EXT_STATUS_MAILBOX;
+			goto exit_logout;
+		}
+	}
+
+exit_logout:
+	LEAVE_IOCTL(__func__, ha->host_no);
+	return(status);
+}
+
+/* End of Internal ioctls */
+
+/**
+ * ql4_ioctl
+ *	This the main entry point for all ioctl requests
+ *
+ * Input:
+ *	dev - pointer to SCSI device structure
+ *	cmd - internal or external ioctl command code
+ *	arg - pointer to the main ioctl structure
+ *
+ *	Instance field in ioctl structure - to determine which device to
+ *	perform ioctl
+ *	HbaSelect field in ioctl structure - to determine which adapter to
+ *	perform ioctl
+ *
+ * Output:
+ *	The resulting data/status is returned via the main ioctl structure.
+ *
+ *	When Status field in ioctl structure is valid for normal command errors
+ *	this function returns 0 (QLA_SUCCESS).
+ *
+ *      All other return values indicate ioctl/system specific error which
+ *	prevented the actual ioctl command from completing.
+ *
+ * Returns:
+ *	 QLA_SUCCESS - command completed successfully, either with or without
+ *			errors in the Status field of the main ioctl structure
+ *	-EFAULT      - arg pointer is NULL or memory access error
+ *	-EINVAL      - command is invalid
+ *	-ENOMEM      - memory allocation failed
+ *
+ * Context:
+ *	Kernel context.
+ **/
+int
+qla4xxx_ioctl(int cmd, void *arg)
+{
+	EXT_IOCTL_ISCSI *pioctl = NULL;
+	struct hba_ioctl *ql4im_ha = NULL;
+	struct scsi_qla_host *ha;
+	int status = 0;	/* ioctl status; errno value when function returns */
+
+	
+	/* Catch any non-exioct ioctls */
+	if (_IOC_TYPE(cmd) != QLMULTIPATH_MAGIC) {
+		printk("valid ioctl magic number received.\n");
+		status = -EINVAL;
+		goto exit_qla4xxx_ioctl0;
+	}
+
+	/*
+	 * Allocate ioctl structure buffer to support multiple concurrent
+	 * entries. NO static structures allowed.
+	 */
+	pioctl = kzalloc(sizeof(EXT_IOCTL_ISCSI), GFP_ATOMIC);
+	if (pioctl == NULL) {
+		printk("%s: kzalloc failed\n", __func__);
+		status = -ENOMEM;
+		goto exit_qla4xxx_ioctl0;
+	}
+
+	/*
+	 * Check to see if we can access the ioctl command structure
+	 */
+	if (!ql4_access_ok(arg)) {
+		DEBUG2(printk("%s: access_ok error.\n", __func__));
+		status = (-EFAULT);
+		goto exit_qla4xxx_ioctl1;
+	}
+
+	/*
+	 * Copy the ioctl command structure from user space to local structure
+	 */
+	if ((status = copy_from_user((uint8_t *)pioctl, arg,
+	    sizeof(EXT_IOCTL_ISCSI)))) {
+		DEBUG2(printk("%s: copy_from_user error.\n",
+		    __func__));
+
+		goto exit_qla4xxx_ioctl1;
+	}
+
+	/*DEBUG10(printk(ha, "EXT_IOCTL_ISCSI structure dump: \n");)
+	DEBUG10(ql4im_dump_dwords(pioctl, sizeof(*pioctl));)
+	*/
+
+        /* check signature of this ioctl */
+	if (memcmp(pioctl->Signature, EXT_DEF_REGULAR_SIGNATURE,
+	    sizeof(EXT_DEF_REGULAR_SIGNATURE)) != 0) {
+		DEBUG2(printk("%s: signature did not match. "
+		    "received cmd=%x arg=%p signature=%s.\n",
+		    __func__, cmd, arg, pioctl->Signature));
+		pioctl->Status = EXT_STATUS_INVALID_PARAM;
+		goto exit_qla4xxx_ioctl;
+	}
+
+        /* check version of this ioctl */
+        if (pioctl->Version > EXT_VERSION) {
+                printk("ioctl interface version not supported = %d.\n",
+                    pioctl->Version);
+
+		pioctl->Status = EXT_STATUS_UNSUPPORTED_VERSION;
+		goto exit_qla4xxx_ioctl;
+        }
+
+	/*
+	 * Get the adapter handle for the corresponding adapter instance
+	 */
+	ql4im_ha = ql4im_get_adapter_handle(pioctl->HbaSelect);
+	if (ql4im_ha == NULL) {
+		DEBUG2(printk("%s: NULL HBA select %d\n",
+			__func__, pioctl->HbaSelect));
+		pioctl->Status = EXT_STATUS_DEV_NOT_FOUND;
+		goto exit_qla4xxx_ioctl;
+	}
+
+	ha = ql4im_ha->ha;
+
+	if (!test_bit(AF_ONLINE, &ha->flags)) {
+		pioctl->Status = EXT_STATUS_HBA_NOT_READY;
+		goto exit_qla4xxx_ioctl;
+	}
+
+	mutex_lock(&ql4im_ha->ioctl_sem);
+	if (ql4im_ha->flag & HBA_IOCTL_BUSY) {
+		pioctl->Status = EXT_STATUS_BUSY;
+	} else {
+		ql4im_ha->flag |= HBA_IOCTL_BUSY;
+		pioctl->Status = EXT_STATUS_OK;
+	}
+	mutex_unlock(&ql4im_ha->ioctl_sem);
+
+	if (pioctl->Status == EXT_STATUS_BUSY) {
+		DEBUG2(ql4_info(ha, "%s: busy\n", __func__));
+		goto exit_qla4xxx_ioctl;
+	}
+
+	/*
+	 * Issue the ioctl command
+	 */
+	switch (cmd) {
+
+	case EXT_CC_QUERY:
+		status = ql4_query(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_REG_AEN:
+		status = ql4_reg_aen(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_GET_AEN:
+		status = ql4_get_aen(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_GET_DATA:
+		status = ql4_ext_get_data(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_SET_DATA:
+		status = ql4_ext_set_data(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_SEND_SCSI_PASSTHRU:
+		status = ql4_scsi_passthru(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_GET_HBACNT:
+		status = ql4_get_hbacnt(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_GET_HOST_NO:
+		status = ql4_get_hostno(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_DRIVER_SPECIFIC:
+		status = ql4_driver_specific(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_GET_PORT_DEVICE_NAME:
+		status = ql4_get_port_device_name(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_DISABLE_ACB:
+		status = ql4_disable_acb(ql4im_ha, pioctl);
+		break;
+
+	case EXT_CC_SEND_ROUTER_SOL:
+		status = ql4_send_router_sol(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_RESTORE_FACTORY_DEFAULTS:
+		status = ql4_restore_factory_defaults(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_DIAG_PING:
+		status = ql4_ping(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_GET_DATA:
+		status = ql4_int_get_data(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_SET_DATA:
+		status = ql4_int_set_data(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_HBA_RESET:
+		status = ql4_hba_reset(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_COPY_FW_FLASH:
+		status = ql4_copy_fw_flash(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_LOGOUT_ISCSI:
+		status = ql4_logout(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_DIAG_MODE:
+		status = ql4_diag_mode(ql4im_ha, pioctl);
+		break;
+
+	case INT_CC_DIAG_TEST:
+		status = ql4_get_diag_data(ql4im_ha, pioctl);
+		break;
+
+	default:
+		DEBUG2(ql4_info(ha, "%s: unsupported command code (%x)\n",
+		    __func__, (uint32_t)cmd));
+
+		pioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+	}
+
+	if (!(ql4im_ha->flag & HBA_IOCTL_BUSY)) {
+		DEBUG2(ql4_info(ha, "%s: flag already clear!\n", __func__));
+	}
+	mutex_lock(&ql4im_ha->ioctl_sem);
+	ql4im_ha->flag &= ~HBA_IOCTL_BUSY;
+	mutex_unlock(&ql4im_ha->ioctl_sem);
+
+exit_qla4xxx_ioctl:
+	status = copy_to_user(arg, (void *)pioctl, sizeof(EXT_IOCTL_ISCSI));
+exit_qla4xxx_ioctl1:
+	kfree(pioctl);
+exit_qla4xxx_ioctl0:
+
+	return(status);
+}
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_os.c
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_os.c
@@ -0,0 +1,425 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+/******************************************************************************
+ *             Please see release.txt for revision history.                   *
+ *                                                                            *
+ ******************************************************************************
+ * Function Table of Contents:
+ ****************************************************************************/
+
+#include <linux/version.h>
+#include <linux/vmalloc.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/klist.h>
+#include <linux/smp_lock.h>
+
+#include "ql4_def.h"
+#include "ql4im_def.h"
+
+/* Restrict compilation to 2.6.18 or greater */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,18)
+#error "This module does not support kernel versions earlier than 2.6.18"
+#endif
+
+#define QL4_MODULE_NAME	"qla4xxx"
+
+static struct klist *ha_list;
+static int hba_count = 0;
+
+int qisioctl_error_logging = 1; /* 0 = off, 1 = log errors */
+module_param(qisioctl_error_logging, int, S_IRUGO | S_IRUSR);
+MODULE_PARM_DESC(qisioctl_error_logging,
+         "Option to enable extended error logging\n "
+         "\t\t 0 - no logging (Default)\n"
+	 "\t\t 1 - debug logging\n"
+	 "\t\t 2 - extended error logging");
+
+unsigned dbg_level = 0;
+
+static struct hba_ioctl *hba[EXT_DEF_MAX_HBAS];
+
+static struct class *apidev_class = NULL;
+static int apidev_major;
+extern void qla4xxx_hostlist;
+
+extern char qla4xxx_version_str[40];
+uint8_t drvr_major = 5;
+uint8_t drvr_minor = 0;
+uint8_t drvr_patch = 5;
+uint8_t drvr_beta = 9;
+char drvr_ver[40];
+#define DEFAULT_VER	"5.00.05b9-k"
+
+static int
+apidev_ioctl(struct inode *inode, struct file *fp, unsigned int cmd,
+    unsigned long arg)
+{
+	return (qla4xxx_ioctl((int)cmd, (void*)arg));
+}
+
+#ifdef CONFIG_COMPAT
+static long
+qla4xxx_ioctl32(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	int rval = -ENOIOCTLCMD;
+
+	lock_kernel();
+	rval = qla4xxx_ioctl((int)cmd, (void*)arg);
+	unlock_kernel();
+
+	return rval;
+}
+#endif
+
+static struct file_operations apidev_fops = {
+	.owner = THIS_MODULE,
+	.ioctl = apidev_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl = qla4xxx_ioctl32,
+#endif
+};
+
+static char *getval(char *ver, uint8_t *val)
+{
+	*val = 0;
+
+        while (ver &&(*ver != '\0')&&(*ver != '.')&&(*ver != '-')&&
+                (*ver >= '0')&&(*ver <= '9')) {
+                *val = *val * 10 + *ver - '0';
+                ver++;
+        }
+        return ver;
+}
+
+struct hba_ioctl *ql4im_get_adapter_handle(uint16_t instance)
+{
+	if (instance >= EXT_DEF_MAX_HBAS)
+		return NULL;
+	return hba[instance];
+}
+
+static int ql4_ioctl_alloc(int hba_idx, struct klist_node *node)
+{
+	struct hba_ioctl *haioctl;
+
+	haioctl = kzalloc(sizeof(struct hba_ioctl), GFP_ATOMIC);
+	if (haioctl == NULL)
+		return -ENOMEM;
+
+	memset(haioctl, 0, sizeof(struct hba_ioctl));
+	hba[hba_idx] = haioctl;
+
+	haioctl->ha  = (struct scsi_qla_host *)node;
+	haioctl->dma_v = pci_alloc_consistent(haioctl->ha->pdev,
+					QL_DMA_BUF_SIZE,
+					&haioctl->dma_p);
+
+	if (haioctl->dma_v == NULL) {
+		ql4_warn(haioctl->ha, "qisitoctl: %s: %d: pcialloc failed\n",
+			__func__, hba_idx);
+		kfree(haioctl);
+		hba[hba_idx] = NULL;
+		return -ENOMEM;
+	}
+	mutex_init(&haioctl->ioctl_sem);
+	init_MUTEX_LOCKED(&haioctl->pt_cmpl_sem);
+
+	haioctl->dma_len = QL_DMA_BUF_SIZE;
+
+	return 0;
+}
+
+static void ql4_ioctl_free(void)
+{
+	int i;
+	struct hba_ioctl *haioctl;
+
+	for (i = 0; i < EXT_DEF_MAX_HBAS; i++) {
+		if ((haioctl = hba[i]) != NULL) {
+			pci_free_consistent(haioctl->ha->pdev,
+					QL_DMA_BUF_SIZE,
+					haioctl->dma_v,
+					haioctl->dma_p);
+			kfree(haioctl);
+		}
+		hba[i] = NULL;
+	}
+}
+
+#ifndef __VMKLNX__
+uint32_t
+ql4im_get_hba_count(void)
+{
+	return(hba_count);
+}
+
+static void get_drvr_version(void)
+{
+	char *ver;
+
+	ver = ((char *)(&qla4xxx_version_str[0]));
+	if (ver == NULL) {
+		strcpy(drvr_ver, DEFAULT_VER);
+		printk("qisioctl: symbol_get(qla4xxx_version_str) "
+			 "failed\n");
+		return;
+	}
+
+	strcpy(drvr_ver, ver);
+
+	ver = drvr_ver;
+
+        ver = getval(ver, &drvr_major);
+
+        if (ver && *ver == '.') ver++;
+
+        ver = getval(ver, &drvr_minor);
+
+        if (ver && *ver == '.') ver++;
+
+        ver = getval(ver, &drvr_patch);
+
+	drvr_beta = 0;
+        if (ver && *ver == 'b') {
+                ver++;
+                ver = getval(ver, &drvr_beta);
+        }
+
+	printk("qisioctl: drvr_ver %s major %d minor %d patch %d "
+		 "beta %d\n",
+		drvr_ver, drvr_major, drvr_minor, drvr_patch, drvr_beta);
+}
+
+static int ql4_ioctl_init(void)
+{
+	ENTER(__func__);
+
+	apidev_class = class_create(THIS_MODULE, QL4_MODULE_NAME);
+	if (IS_ERR(apidev_class)) {
+		DEBUG2(printk("qisioctl: %s: Unable to sysfs class\n",
+			__func__));
+		apidev_class = NULL;
+		return 1;
+	}
+	DEBUG4(printk("qisioctl: %s: apidev_class=%p.\n", __func__,
+		apidev_class));
+
+	apidev_major = register_chrdev(0, QL4_MODULE_NAME, &apidev_fops);
+	if (apidev_major < 0) {
+		DEBUG2(printk("qisioctl: %s: Unable to register CHAR "
+			"device (%d)\n", __func__, apidev_major));
+
+		class_destroy(apidev_class);
+		apidev_class = NULL;
+		return apidev_major;
+	}
+	DEBUG4(printk("qisioctl: %s: apidev_major=%d.\n", __func__,
+			apidev_major));
+
+#ifdef QLA_SLES11
+	device_create(apidev_class, NULL, MKDEV(apidev_major, 0), NULL,
+			QL4_MODULE_NAME);
+#else
+	class_device_create(apidev_class, NULL, MKDEV(apidev_major, 0), NULL,
+			QL4_MODULE_NAME);
+#endif
+	LEAVE(__func__);
+	return 0;
+}
+
+static void ql4_ioctl_exit(void)
+{
+	ENTER(__func__);
+
+	if (!apidev_class)
+		return;
+
+#ifdef QLA_SLES11
+	device_destroy(apidev_class, MKDEV(apidev_major, 0));
+#else
+	class_device_destroy(apidev_class, MKDEV(apidev_major, 0));
+#endif
+
+	unregister_chrdev(apidev_major, QL4_MODULE_NAME);
+
+	class_destroy(apidev_class);
+
+	apidev_class = NULL;
+
+	LEAVE(__func__);
+}
+
+int ql4im_init(void)
+{
+	struct klist_node *node;
+	struct klist_iter iter;
+
+	ENTER( __func__ );
+
+	memset(&hba, 0,  sizeof(hba));
+
+	switch (qisioctl_error_logging) {
+	case 2:
+		dbg_level = (QL_DBG_1|QL_DBG_2|QL_DBG_4|QL_DBG_10|QL_DBG_11);
+		break;
+	case 1:
+		dbg_level = (QL_DBG_1|QL_DBG_2);
+		break;
+	}
+
+	ha_list = &qla4xxx_hostlist;
+	if (ha_list == NULL) {
+		printk("qistioctl: ha_list == NULL\n");
+		goto error_ql4im_init;
+	}
+	DEBUG1(printk("qisioctl: %s: ha_list %p.\n", __func__, ha_list));
+
+	get_drvr_version();
+	if (ql4_ioctl_init())
+		goto error_ql4im_init;
+
+	klist_iter_init(ha_list, &iter);
+	DEBUG1(printk("qisioctl: %s: klist_iter_init successful \n",
+			__func__));
+	while ((node = klist_next(&iter)) != NULL) {
+		ql4_ioctl_alloc(hba_count, node);
+		hba_count++;
+		DEBUG1(printk("qisioctl: %s: node = %p\n", __func__,
+			node));
+	}
+	klist_iter_exit(&iter);
+
+	printk("QLogic iSCSI IOCTL Module ver: v%s\n", QL4IM_VERSION);
+	LEAVE( __func__ );
+	return 0;
+
+error_ql4im_init:
+	LEAVE( __func__ );
+	return -ENODEV;
+}
+
+void __exit ql4im_exit(void)
+{
+	ENTER( __func__ );
+	ql4_ioctl_free();
+	ql4_ioctl_exit();
+	LEAVE( __func__ );
+}
+
+#else
+/* These functions used for the imbedded VMware ioctl module */
+#include "ql4_version.h"
+uint32_t
+ql4im_get_hba_count(void)
+{
+	int i;
+
+	hba_count = 0;
+	for (i = 0; i < EXT_DEF_MAX_HBAS; i++)
+		if (hba[i] != NULL)
+			hba_count++;
+	return(hba_count);
+}
+
+static void get_drvr_version(void)
+{
+	char *ver = (char *)QLA4XXX_DRIVER_VERSION;
+
+	strcpy(drvr_ver, ver);
+	ver = drvr_ver;
+        ver = getval(ver, &drvr_major);
+        if (ver && *ver == '.') ver++;
+
+        ver = getval(ver, &drvr_minor);
+        if (ver && *ver == '.') ver++;
+
+        ver = getval(ver, &drvr_patch);
+	drvr_beta = 0;
+        if (ver && *ver == 'b') {
+                ver++;
+                ver = getval(ver, &drvr_beta);
+        }
+	ql4_info(ha, "qisioctl: %s: ver %s maj %d min %d pat %d beta %d\n",
+		__func__, drvr_ver, drvr_major, drvr_minor, drvr_patch,
+		drvr_beta);
+}
+
+static int ql4_ioctl_init(void)
+{
+	ENTER(__func__);
+
+	apidev_major = register_chrdev(0, QL4_MODULE_NAME, &apidev_fops);
+	if (apidev_major < 0) {
+		DEBUG2(ql4_info(ha, "qisioctl: %s: Unable to register CHAR "
+			"device (%d)\n", __func__, apidev_major));
+		ql4_info(ha, "qisioctl: %s: Unable to register CHAR "
+			 "device (%d)\n", __func__, apidev_major);
+		return apidev_major;
+	}
+	DEBUG4(ql4_info(ha, "qisioctl: %s: apidev_major=%d.\n", __func__,
+			apidev_major));
+	ql4_info(ha, "qisioctl: %s: apidev_major=%d.\n", __func__,
+		 apidev_major);
+
+	LEAVE(__func__);
+	return 0;
+}
+
+static void ql4_ioctl_exit(void)
+{
+	ENTER(__func__);
+	unregister_chrdev(apidev_major, QL4_MODULE_NAME);
+	LEAVE(__func__);
+}
+
+int ql4im_mem_alloc(int hba_idx, struct scsi_qla_host *ha)
+{
+	return ql4_ioctl_alloc(hba_idx, (struct klist_node *)ha);
+}
+
+void ql4im_mem_free(int hba_idx)
+{
+	struct hba_ioctl *haioctl;
+
+	if ((haioctl = hba[hba_idx]) != NULL) {
+		pci_free_consistent(haioctl->ha->pdev,
+				QL_DMA_BUF_SIZE,
+				haioctl->dma_v,
+				haioctl->dma_p);
+		kfree(haioctl);
+	}
+	hba[hba_idx] = NULL;
+}
+
+int ql4im_init(void)
+{
+	int i ;
+
+	ENTER( __func__ );
+
+	get_drvr_version();
+
+	for (i = 0; i < EXT_DEF_MAX_HBAS; i++)
+		hba[i] = NULL;
+
+	if (ql4_ioctl_init())
+		return -ENODEV;
+
+	LEAVE(__func__);
+	return 0;
+}
+
+void ql4im_exit(void)
+{
+	ENTER( __func__ );
+	ql4_ioctl_exit();
+	LEAVE( __func__ );
+}
+#endif
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_os.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_os.h
@@ -0,0 +1,88 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+/*
+ * Encapsulates all VMWare Specific code for ioctls
+ */
+
+#ifndef _QL4IM_OS_H_
+#define _QL4IM_OS_H_
+
+#ifdef __VMKLNX__
+#include <vmklinux26_scsi.h>  /* for vmklnx_get_vmhba_name */
+
+#define ql4_access_ok(x) 1
+#define QL4_DDB_TO_TGTID(ddb_entry) ddb_entry->sess->targetID
+
+static inline int ql4_get_port_device_name(struct hba_ioctl *ql4im_ha,
+                                        EXT_IOCTL_ISCSI *ioctl)
+{
+        int                     status = 0;
+        EXT_GET_PORT_DEVICE_NAME data;
+        struct scsi_qla_host    *ha;
+        char                    *vmhba_name;
+        int                     len;
+
+        ha = ql4im_ha->ha;
+        ENTER_IOCTL(__func__, ha->host_no);
+
+        if (ioctl->ResponseLen < sizeof(EXT_GET_PORT_DEVICE_NAME)) {
+                ioctl->Status = EXT_STATUS_BUFFER_TOO_SMALL;
+                DEBUG2(printk("qisioctl: %s: ERROR ResponseLen too small.\n",
+			__func__));
+                goto exit_get_port_device_name;
+        }
+
+        memset(&data, 0, sizeof(EXT_GET_PORT_DEVICE_NAME));
+
+        vmhba_name = vmklnx_get_vmhba_name(ha->host);
+        if (vmhba_name) {
+                len = MIN(strlen(vmhba_name), sizeof(data.deviceName));
+                strncpy(data.deviceName, vmhba_name, len);
+        }
+
+        status =
+		copy_to_user(Q64BIT_TO_PTR(ioctl->ResponseAdr, ioctl->AddrMode),
+                              &data, sizeof(EXT_GET_PORT_DEVICE_NAME));
+
+        if (status) {
+                ioctl->Status = EXT_STATUS_COPY_ERR;
+                DEBUG2(printk("qisioctl: %s: ERROR copy resp buf\n", __func__));
+        }
+
+exit_get_port_device_name:
+        LEAVE_IOCTL(__func__, ha->host_no);
+
+        return(status);
+}
+
+#else
+
+#define ql4_access_ok(arg) access_ok(VERIFY_WRITE, arg, sizeof(EXT_IOCTL_ISCSI))
+
+#define QL4_DDB_TO_TGTID(ddb_entry) ddb_entry->sess->target_id
+
+static inline int ql4_get_port_device_name(struct hba_ioctl *ql4im_ha,
+                                        EXT_IOCTL_ISCSI *ioctl)
+{
+	DEBUG2(printk("qisioctl%lx: %s: EXT_CC_GET_PORT_DEVICE_NAME"
+		" unsupported command code\n",
+		ql4im_ha->ha->host_no, __func__));
+
+	ioctl->Status = EXT_STATUS_UNSUPPORTED_SUBCODE;
+	return 0;
+}
+
+#endif
+
+#ifdef QLA_SLES11
+#define QL_GET_SCSI_RESID(cmd) scsi_get_resid(cmd)
+#else
+#define QL_GET_SCSI_RESID(cmd) pscsi_cmd->resid
+#endif
+
+#endif /*_QL4IM_OS_H_*/
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/ql4im_version.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/ql4im_version.h
@@ -0,0 +1,12 @@
+/*
+ * QLogic iSCSI IOCTL Module
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#define QL4IM_VERSION   "2.02.15.02.05.06-c0"
+#define QL4IM_MAJOR_VER 2
+#define QL4IM_MINOR_VER 2
+#define QL4IM_PATCH_VER 15
+#define QL4IM_BETA_VER	0
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/qlinioct.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/qlinioct.h
@@ -0,0 +1,525 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef _QLINIOCT_H_
+#define _QLINIOCT_H_
+
+#include "qlisioln.h"
+
+/*
+   Ioctl
+*/
+
+/*
+  General
+*/
+
+/*
+ * Command Codes definitions
+ */
+#define INT_CC_GET_DATA			EXT_CC_RESERVED0A_OS
+#define INT_CC_SET_DATA			EXT_CC_RESERVED0B_OS
+#define INT_CC_DIAG_PING		EXT_CC_RESERVED0C_OS
+#define INT_CC_ISCSI_LOOPBACK		EXT_CC_RESERVED0D_OS
+#define INT_CC_HBA_RESET		EXT_CC_RESERVED0E_OS
+#define INT_CC_COPY_FW_FLASH		EXT_CC_RESERVED0F_OS
+#define INT_CC_LOGOUT_ISCSI		EXT_CC_RESERVED0G_OS
+#define INT_CC_FW_PASSTHRU		EXT_CC_RESERVED0H_OS
+#define INT_CC_IOCB_PASSTHRU		EXT_CC_RESERVED0I_OS
+#define INT_CC_RESTORE_FACTORY_DEFAULTS EXT_CC_RESERVED0J_OS
+#define INT_CC_DIAG_MODE               EXT_CC_RESERVED0K_OS
+#define INT_CC_DIAG_TEST               EXT_CC_RESERVED0L_OS
+
+/*
+ * Sub codes for diag mode
+ * Use in combination with INT_CC_DIAG_MODE in ioctl call
+ */
+#define INT_SC_SET_DIAG_MODE   0
+#define INT_SC_RESET_DIAG_MODE 1
+
+/*
+ * Sub codes for Get Data.
+ * Use in combination with INT_GET_DATA as the ioctl code
+ */
+#define INT_SC_GET_FLASH			1
+#define INT_SC_GET_CORE_DUMP			2
+
+/*
+ * Sub codes for Set Data.
+ * Use in combination with INT_SET_DATA as the ioctl code
+ */
+#define INT_SC_SET_FLASH			1
+
+#define INT_DEF_DNS_ENABLE                  0x0100
+#define INT_SC_GET_HOST_NO                    3
+
+/*
+ * ***********************************************************************
+ * INIT_FW_ISCSI_ALL
+ * ***********************************************************************
+ */
+typedef struct _INT_INIT_FW_ISCSI_ALL {
+	UINT8   Version;					/* 1   */
+	UINT8   Reserved0;					/* 1   */
+	UINT16  FWOptions;					/* 2   */
+	UINT16  exeThrottle;					/* 2   */
+	UINT8   retryCount;					/* 1   */
+	UINT8   retryDelay;					/* 1   */
+	UINT16  EthernetMTU;					/* 2   */
+	UINT16  addFWOptions;					/* 2   */
+	UINT8   HeartBeat;					/* 1   */
+	UINT8   Reserved1;					/* 1   */
+	UINT16  Reserved2;					/* 2   */
+	UINT16  ReqQOutPtr;					/* 2   */
+	UINT16  RespQInPtr;					/* 2   */
+	UINT16  ReqQLen;					/* 2   */
+	UINT16  RespQLen;					/* 2   */
+	UINT32  ReqQAddr[2];					/* 8   */
+	UINT32  RespQAddr[2];					/* 8   */
+	UINT32  IntRegBufAddr[2];				/* 8   */
+	UINT16  iSCSIOptions;					/* 2   */
+	UINT16  TCPOptions;					/* 2   */
+	UINT16  IPOptions;					/* 2   */
+	UINT16  MaxRxDataSegmentLen;				/* 2   */
+	UINT16  recvMarkerInt;					/* 2   */
+	UINT16  sendMarkerInt;					/* 2   */
+	UINT16  Reserved3;					/* 2   */
+	UINT16  firstBurstSize;					/* 2   */
+	UINT16  DefaultTime2Wait;				/* 2   */
+	UINT16  DefaultTime2Retain;				/* 2   */
+	UINT16  maxOutstandingR2T;				/* 2   */
+	UINT16  keepAliveTimeout;				/* 2   */
+	UINT16  portNumber;					/* 2   */
+	UINT16  maxBurstSize;					/* 2   */
+	UINT32  Reserved4;					/* 4   */
+	UINT8   IPAddr[16];					/* 16  */
+	UINT8   SubnetMask[16];					/* 16  */
+	UINT8   IPGateway[16];					/* 16  */
+	UINT8   DNSsvrIP[4];					/* 4  */
+	UINT8   DNSsecSvrIP[4];					/* 4  */
+	UINT8   Reserved5[8];					/* 8    */
+	UINT8   Alias[EXT_DEF_ISCSI_ALIAS_LEN];			/* 32  */
+	UINT32  targetAddr0;					/* 4   */
+	UINT32  targetAddr1;					/* 4   */
+	UINT32  CHAPTableAddr0;					/* 4   */
+	UINT32  CHAPTableAddr1;					/* 4   */
+	UINT8   EthernetMACAddr[6];				/* 6   */
+	UINT16  TargetPortalGrp;				/* 2   */
+	UINT8   SendScale;					/* 1   */
+	UINT8   RecvScale;					/* 1   */
+	UINT8   TypeOfService;					/* 1   */
+	UINT8   Time2Live;					/* 1   */
+	UINT16  VLANPriority;					/* 2   */
+	UINT16  Reserved6;					/* 2   */
+	UINT8   SecondaryIPAddr[16];				/* 16  */
+	UINT8   iSNSServerAdr[4];				/* 4    */
+	UINT16  iSNSServerPort;					/* 2    */
+	UINT8   Reserved7[10];					/* 10  */
+	UINT8   SLPDAAddr[16];					/* 16  */
+	UINT8   iSCSIName[EXT_DEF_ISCSI_NAME_LEN];		/* 256 */
+} INT_INIT_FW_ISCSI_ALL, *PINT_INIT_FW_ISCSI_ALL;		/* 512 */
+
+/*
+ * ***********************************************************************
+ * INT_DEVICE_ENTRY_ISCSI_ALL
+ * ***********************************************************************
+ */
+typedef struct _INT_DEVICE_ENTRY_ISCSI_ALL {
+	UINT8   Options;					/* 1 */
+	UINT8   Control;					/* 1 */
+	UINT16  exeThrottle;					/* 2 */
+	UINT16  exeCount;					/* 2 */
+	UINT8   retryCount;					/* 1 */
+	UINT8   retryDelay;					/* 1 */
+	UINT16  iSCSIOptions;					/* 2 */
+	UINT16  TCPOptions;					/* 2 */
+	UINT16  IPOptions;					/* 2 */
+	UINT16  MaxRxDataSegmentLen;				/* 2 */
+	UINT16  RecvMarkerInterval;				/* 2 */
+	UINT16  SendMarkerInterval;				/* 2 */
+	UINT16  MaxTxDataSegmentLen;				/* 2 */
+	UINT16  firstBurstSize;					/* 2 */
+	UINT16  DefaultTime2Wait;				/* 2 */
+	UINT16  DefaultTime2Retain;				/* 2 */
+	UINT16  maxOutstandingR2T;				/* 2 */
+	UINT16  keepAliveTimeout;				/* 2 */
+	UINT8   InitiatorSessID[EXT_DEF_ISCSI_ISID_SIZE];	/* 6 */
+	UINT16  TargetSessID;					/* 2 */
+	UINT16  portNumber;					/* 2 */
+	UINT16  maxBurstSize;					/* 2 */
+	UINT16  taskMngmntTimeout;				/* 2 */
+	UINT16  Reserved0;					/* 2 */
+	UINT8   IPAddress[16];					/* 16  */
+	UINT8   Alias[EXT_DEF_ISCSI_ALIAS_LEN];			/* 32  */
+	UINT8   targetAddr[EXT_DEF_ISCSI_TADDR_SIZE];		/* 32  */
+	/* need to find new definition XXX */
+	UINT8   res[64];
+	UINT8   iSCSIName[EXT_DEF_ISCSI_NAME_LEN];		/* 256 */
+	UINT16  ddbLink;					/* 2   */
+	UINT16  chapTableIndex;					/* 2   */
+	UINT16  targetPortalGrp;				/* 2   */
+	UINT16  Reserved1;					/* 2   */
+	UINT32  statSN;						/* 4 */
+	UINT32  expStatSN;					/* 4 */
+} INT_DEVICE_ENTRY_ISCSI_ALL, *PINT_DEVICE_ENTRY_ISCSI_ALL;	/* 464 */
+
+/*
+ * ****************************************************************************
+ * INT_DEVDDB_ENTRY
+ * ****************************************************************************
+ */
+
+typedef struct _FLASH_DEVDB_ENTRY {
+	INT_DEVICE_ENTRY_ISCSI_ALL      entryData;		/* 0-1C7   */
+	UINT8                           RES0[0x2C];		/* 1C8-1FB */
+	UINT16                          ddbValidCookie;		/* 1FC-1FD */
+	UINT16                          ddbValidSize;		/* 1FE-1FF */
+} FLASH_DEVDB_ENTRY, *PFLASH_DEVDB_ENTRY;
+
+/*
+ * ****************************************************************************
+ * INT_FLASH_INITFW
+ * ****************************************************************************
+ */
+
+typedef struct _FLASH_INITFW {
+	INT_INIT_FW_ISCSI_ALL   initFWData;
+	UINT32                  validCookie;
+} FLASH_INITFW, *PFLASH_INITFW;
+
+
+/*
+ * ***********************************************************************
+ * INT_ACCESS_FLASH
+ * ***********************************************************************
+ */
+
+#define INT_DEF_AREA_TYPE_FW_IMAGE1		0x01
+#define INT_DEF_AREA_TYPE_FW_IMAGE2		0x02
+#define INT_DEF_AREA_TYPE_DRIVER		0x03
+#define INT_DEF_AREA_TYPE_DDB			0x04
+#define INT_DEF_AREA_TYPE_INIT_FW		0x05
+#define INT_DEF_AREA_TYPE_SYS_INFO		0x06
+
+#define INT_DEF_FLASH_BLK_SIZE			0x4000
+#define INT_DEF_FLASH_PHYS_BLK_SIZE		0x20000
+
+#define INT_ISCSI_FW_IMAGE2_FLASH_OFFSET	0x01000000
+#define INT_ISCSI_SYSINFO_FLASH_OFFSET		0x02000000
+#define INT_ISCSI_DRIVER_FLASH_OFFSET		0x03000000
+#define INT_ISCSI_INITFW_FLASH_OFFSET		0x04000000
+#define INT_ISCSI_DDB_FLASH_OFFSET		0x05000000
+#define INT_ISCSI_CHAP_FLASH_OFFSET		0x06000000
+#define INT_ISCSI_FW_IMAGE1_FLASH_OFFSET	0x07000000
+#define INT_ISCSI_BIOS_FLASH_OFFSET		0x0d000000
+#define INT_ISCSI_OFFSET_MASK			0x00FFFFFF
+#define INT_ISCSI_PAGE_MASK			0x0F000000
+
+#define INT_ISCSI_ACCESS_FLASH			0x00000000
+#define INT_ISCSI_ACCESS_RAM			0x10000000
+#define INT_ISCSI_ACCESS_MASK			0xF0000000
+
+/* WRITE_FLASH option definitions */
+#define INT_WRITE_FLASH_OPT_HOLD		0 /* Write data to FLASH but
+						     do not Commit */
+#define INT_WRITE_FLASH_OPT_CLEAR_REMAINING	1 /* Write data to FLASH but
+						     do not Commit any data
+						     not written before
+						     commit will be cleared
+						     (set to 0xFF)	*/
+#define INT_WRITE_FLASH_OPT_COMMIT_DATA		2 /* Commit (Burn) data to
+						     FLASH */
+
+
+typedef struct _INT_ACCESS_FLASH {
+	UINT32  AreaType;					/* 4   */
+	UINT32  DataLen;					/* 4   */
+	UINT32  DataOffset;					/* 4   */
+	UINT8   FlashData[INT_DEF_FLASH_BLK_SIZE];		/* 0x4000 */
+	UINT32  Options;					/* 4   */
+} INT_ACCESS_FLASH, *PINT_ACCESS_FLASH;				/* 0x4010 */
+
+/*
+ * ****************************************************************************
+ * INT_FLASH_DRIVER_PARAM
+ * ****************************************************************************
+ */
+
+typedef struct _INT_FLASH_DRIVER_PARAM {
+	UINT16  DiscoveryTimeOut;				/* 2   */
+	UINT16  PortDownTimeout;				/* 2   */
+	UINT32  Reserved[32];					/* 128 */
+} INT_FLASH_DRIVER_PARAM, *PINT_FLASH_DRIVER_PARAM;		/* 132 */
+
+
+#define VALID_FLASH_INITFW		0x11BEAD5A
+
+#define FLASH_ISCSI_MAX_DDBS		64
+#define FLASH_DDB_VALID_COOKIE		0x9034 /* this value indicates this
+						  entry in flash is valid */
+#define FLASH_DDB_INVALID_COOKIE	0x0    /* this value is used to set
+						  the entry to invalid    */
+
+/*
+ * ****************************************************************************
+ * INT_HBA_SYS_INFO
+ * ****************************************************************************
+ */
+
+typedef struct _INT_HBA_SYS_INFO {
+	UINT32  cookie;						/* 4   */
+	UINT32  physAddrCount;					/* 4   */
+	UINT8   macAddr0[6];					/* 6   */
+	UINT8   reserved0[2];					/* 2   */
+	UINT8   macAddr1[6];					/* 6   */
+	UINT8   reserved1[2];					/* 2   */
+	UINT8   macAddr2[6];					/* 6   */
+	UINT8   reserved2[2];					/* 2   */
+	UINT8   macAddr3[6];					/* 6   */
+	UINT8   reserved3[2];					/* 2   */
+	UINT8   vendorId[128];					/* 128 */
+	UINT8   productId[128];					/* 128 */
+	UINT32  serialNumber;					/* 4   */
+	UINT32  pciDeviceVendor;				/* 4   */
+	UINT32  pciDeviceId;					/* 4   */
+	UINT32  pciSubsysVendor;				/* 4   */
+	UINT32  pciSubsysId;					/* 4   */
+	UINT32  crumbs;						/* 4   */
+	UINT32  enterpriseNumber;				/* 4   */
+	UINT32  crumbs2;					/* 4   */
+} INT_HBA_SYS_INFO, *PINT_HBA_SYS_INFO;				/* 328 */
+
+/*
+ * ****************************************************************************
+ * INT_FW_DW_HDR
+ * ****************************************************************************
+ */
+
+/* File header for FW */
+typedef struct _INT_FW_DL_HDR {
+	UINT32  Size;		/* download size, excluding DL_HDR & EXT_HDR*/
+	UINT32  Checksum;	/* Checksum of download file, excluding DL_HDR
+				   & EXT_HDR */
+	UINT32  HdrChecksum;	/* Checksum of header area should be zero */
+	UINT32  Flags;		/* See Flags bits defined above */
+	UINT32  Cookie;		/* Target specific identifier */
+	UINT32  Target;		/* Target specific identifier */
+	UINT32  Reserved0;	/* Reserved */
+	UINT32  Reserved1;	/* Reserved */
+	UINT8   Copyright[64];	/* Copyright */
+	UINT8   Version[32];	/* Version String */
+} INT_FW_DL_HDR, *PINT_FW_DL_HDR;
+
+/* File header for BIOS */
+typedef struct _INT_BIOS_HDR {
+	UINT8   BIOSidCode55;
+	UINT8   BIOSidCodeAA;
+	UINT8   reserved[52];
+	UINT8   BIOSminorVer;
+	UINT8   BIOSmajorVer;
+} INT_BIOS_HDR, *PINT_BIOS_HDR;
+
+typedef struct _INT_SDMBIOS_NVRAM {
+	UINT16  Flags;
+	UINT8   PriID;
+	UINT64  PriLUN;
+	UINT8   SecID;
+	UINT64  SecLUN;
+} INT_SDMBIOS_NVRAM, *PINT_SDMBIOS_NVRAM;
+
+/*
+ * ****************************************************************************
+ * INT_HBA_RESET
+ * ****************************************************************************
+ */
+
+typedef struct _INT_HBA_RESET {
+	UINT32  ResetFlag;					/* 4  */
+#define HBA_RESET_FUNCTION_RESET		0
+#define HBA_RESET_CHIP_RESET			1
+	UINT32  Reserved[1];					/* 4  */
+} INT_HBA_RESET, *PINT_HBA_RESET;				/* 8  */
+
+/*
+ * ****************************************************************************
+ * INT_COPY_FW_FLASH
+ * ****************************************************************************
+ */
+
+typedef struct _INT_COPY_FW_FLASH {
+	UINT32  Options;					/* 4  */
+} INT_COPY_FW_FLASH, *PINT_COPY_FW_FLASH;			/* 4  */
+
+#define INT_COPY_FLASH_PRIMARY_TO_SECONDARY	0
+#define INT_COPY_FLASH_SECONDARY_TO_PRIMARY	1
+
+/*
+ * ****************************************************************************
+ * INT_LOGOUT_ISCSI
+ * ****************************************************************************
+ */
+
+/* Logout Options */
+
+#define INT_DEF_CLOSE_SESSION			0x0001
+#define INT_DEF_RELOGIN_CONNECTION		0x0002
+#define INT_DEF_DELETE_DDB			0x0004
+#define INT_DEF_REINDEX_DDB			0x0008
+
+typedef struct _INT_LOGOUT_ISCSI {
+	UINT16    TargetID;					/* 2   */
+	UINT16    ConnectionID;					/* 2   */
+	UINT16    Options;					/* 2   */
+	UINT32    NewTargetID;					/* 4   */
+} INT_LOGOUT_ISCSI, *PINT_LOGOUT_ISCSI;				/* 10  */
+
+/*
+ * ****************************************************************************
+ * INT_PING
+ * ****************************************************************************
+ */
+
+typedef struct _INT_PING {
+	EXT_ISCSI_IP_ADDR       IPAddr;				/* 20  */
+	UINT16                  PacketSize;			/* 2   */
+	UINT16                  Reserved;			/* 2   */
+} INT_PING, *PINT_PING;						/* 24  */
+
+/*
+ * ****************************************************************************
+ * INT_DIAG_TEST_RESULT
+ * ****************************************************************************
+ */
+
+/* Opcodes for ql4_iscsi_diag */
+#define TEST_LOCAL_RAM_SIZE                    2
+#define TEST_LOCAL_RAM_RDWR                    3
+#define TEST_RISC_RAM                          4
+#define TEST_NVRAM                             5
+#define TEST_FLASH_ROM                         6
+#define TEST_INTERNAL_LOOPBACK_DIAG 7
+#define TEST_EXTERNAL_LOOPBACK_DIAG 8
+#define TEST_DMA_TRANSFER                      9
+
+#define MB_REG_COUNT                           8
+
+typedef struct _INT_DIAG_TEST_RESULT {
+     UINT32      mbCmd[MB_REG_COUNT];
+     UINT32      mbSts[MB_REG_COUNT];
+     UINT32      Reserved[16];
+} INT_DIAG_TEST_RESULT, *PINT_DIAG_TEST_RESULT;
+
+/*
+ * ****************************************************************************
+ * INT_IOCB_PASSTHRU
+ * ****************************************************************************
+ */
+
+#define INT_DEF_IOCB_BUF_SIZE			64
+#define INT_DEF_IOCB_DATA_SIZE			1500
+
+typedef struct _INT_IOCB_PASSTHRU {
+	UINT32    SendDMAOffset;				/* 4    */
+	UINT32    RspDMAOffset;					/* 4    */
+	UINT8     IOCBCmdBuffer[INT_DEF_IOCB_BUF_SIZE];		/* 64   */
+	UINT8     IOCBStatusBuffer[INT_DEF_IOCB_BUF_SIZE];	/* 64   */
+	UINT32    SendDataLen;					/* 4    */
+	UINT8     SendData[INT_DEF_IOCB_DATA_SIZE];		/* 1500 */
+	UINT32    RspDataLen;					/* 4    */
+	UINT8     RspData[INT_DEF_IOCB_DATA_SIZE];		/* 1500 */
+	UINT32    Reserved;					/* 4    */
+} INT_IOCB_PASSTHRU, *PINT_IOCB_PASSTHRU;			/* 3148 */
+
+
+/*
+ * ****************************************************************************
+ * INT_CC_FW_PASSTHRU
+ * ****************************************************************************
+ */
+
+/* FW PASSTHRU Defines */
+#define INT_DEF_FW_PASSHTRU_BLK_SIZE		0x4000
+
+#define INT_DEF_DATA_TYPE_CHAP_TABLE		0x0001
+#define INT_DEF_DATA_TYPE_DDB			0x0002
+#define INT_DEF_DATA_TYPE_INITFW		0x0003
+#define INT_DEF_DATA_TYPE_FW_IMAGE		0x0004
+
+#define INT_DEF_DATA_LOCATION_HBA_FLASH		0x0001
+#define INT_DEF_DATA_LOCATION_HBA_RAM		0x0002
+
+#define INT_DEF_DATA_READ			0x0001
+#define INT_DEF_DATA_WRITE			0x0002
+
+#define INT_DEF_DATA_INIT			0x0001
+#define INT_DEF_DATA_COMMIT			0x0002
+
+/*
+ * ****************************************************************************
+ * INT_RESTORE_FACTORY_DEFAULTS
+ * ****************************************************************************
+ */
+
+#define INT_DEF_FACT_DFLT_MASK_IFCB		0x00000001
+#define INT_DEF_FACT_DFLT_MASK_DDB		0x00000002
+#define INT_DEF_FACT_DFLT_MASK_CHAP		0x00000004
+#define INT_DEF_FACT_DFLT_MASK_IPSEC		0x00000008
+#define INT_DEF_FACT_DFLT_MASK_NVRAM		0x00000010
+#define INT_DEF_FACT_DFLT_MASK_INVERSE_INITFW   0x02000000
+
+#define INT_DEF_FACT_DFLT_IFCB_ALL		0xffffffff
+#define INT_DEF_FACT_DFLT_IFCB_FW_OPT		0x00000001
+#define INT_DEF_FACT_DFLT_IFCB_MTU		0x00000002
+#define INT_DEF_FACT_DFLT_IFCB_ADD_FW_OPT	0x00000004
+#define INT_DEF_FACT_DFLT_IFCB_HEARTBEAT	0x00000008
+#define INT_DEF_FACT_DFLT_IFCB_ISCSI_OPT	0x00000010
+#define INT_DEF_FACT_DFLT_IFCB_TCP_OPT		0x00000020
+#define INT_DEF_FACT_DFLT_IFCB_IP_OPT		0x00000040
+#define INT_DEF_FACT_DFLT_IFCB_MAX_RECV_SEG_LEN	0x00000080
+#define INT_DEF_FACT_DFLT_IFCB_FIRST_BURST_LEN	0x00000100
+#define INT_DEF_FACT_DFLT_IFCB_MAX_OUTSTANDING_R2T	0x00000200
+#define INT_DEF_FACT_DFLT_IFCB_ISCSI_PORT_NUM	0x00000400
+#define INT_DEF_FACT_DFLT_IFCB_MAX_BURST_LEN	0x00000800
+#define INT_DEF_FACT_DFLT_IFCB_IP_ADDR		0x00001000
+#define INT_DEF_FACT_DFLT_IFCB_SUBNET_MASK	0x00002000
+#define INT_DEF_FACT_DFLT_IFCB_GATEWAY_ADDR	0x00004000
+#define INT_DEF_FACT_DFLT_IFCB_PRI_DNS_ADDR	0x00008000
+#define INT_DEF_FACT_DFLT_IFCB_SEC_DNS_ADDR	0x00010000
+#define INT_DEF_FACT_DFLT_IFCB_MIN_EPHMRL_PORT_NUM	0x00020000
+#define INT_DEF_FACT_DFLT_IFCB_MAX_EPHMRL_PORT_NUM	0x00040000
+#define INT_DEF_FACT_DFLT_IFCB_ABORT_TIMER	0x00080000
+#define INT_DEF_FACT_DFLT_IFCB_ISCSI_ALIAS	0x00100000
+#define INT_DEF_FACT_DFLT_IFCB_TCP_WIN_SCALE	0x00200000
+#define INT_DEF_FACT_DFLT_IFCB_SEC_IP_ADDR	0x00400000
+#define INT_DEF_FACT_DFLT_IFCB_ISNS_IP_ADDR	0x00800000
+#define INT_DEF_FACT_DFLT_IFCB_ISNS_PORT_NUM	0x01000000
+#define INT_DEF_FACT_DFLT_IFCB_ISCSI_NAME	0x02000000
+
+typedef struct _INT_RESTORE_FACTORY_DEFAULTS
+{
+	UINT32	BlockMask;					/* 4   */
+	UINT32	IFCBMask1;					/* 4   */
+	UINT32	IFCBMask2;					/* 4   */
+	UINT32	Reserved[5];					/* 20  */
+} INT_RESTORE_FACTORY_DEFAULTS, *PINT_RESTORE_FACTORY_DEFAULTS; /* 32  */
+
+/*
+ * ****************************************************************************
+ * INT_ACCESS_CORE_DUMP
+ * ****************************************************************************
+ */
+
+typedef struct _INT_ACCESS_CORE_DUMP {
+	uint32_t	DataLen;				/* 4  - 0x00 */
+	uint32_t	Offset;					/* 4  - 0x04 */
+	uint8_t		LastBlockFlag;				/* 1  - 0x08 */
+	uint8_t		Reserved[7];				/* 7  - 0x09 */
+	uint8_t		Data[];					/* 0  - 0x10 */
+} INT_ACCESS_CORE_DUMP, *PINT_ACCESS_CORE_DUMP;                 /* 0x10  */
+
+#define CORE_DUMP_HEADER_SIZE                   0x256
+#endif /* _QLINIOCT_H_ */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/qlisioct.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/qlisioct.h
@@ -0,0 +1,899 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+/*
+ * File Name: qlisioct.h
+ *
+ */
+#ifndef _QLISIOCT_H
+#define _QLISIOCT_H
+
+/*
+ * NOTE: the following version defines must be updated each time the
+ *	 changes made may affect the backward compatibility of the
+ *	 input/output relations of the IOCTL functions.
+ */
+#define EXT_VERSION				6
+
+/*
+ * OS independent General definitions
+ */
+#define EXT_DEF_SIGNATURE_SIZE			8
+#define EXT_DEF_SERIAL_NUM_SIZE			4
+#define EXT_DEF_MAX_STR_SIZE			128
+
+#define EXT_DEF_ADDR_MODE_32			1
+#define EXT_DEF_ADDR_MODE_64			2
+
+/*
+ * ****************************************************************************
+ * OS type definitions
+ * ****************************************************************************
+ */
+#ifdef _MSC_VER					/* NT */
+
+#include "qlisiont.h"
+
+#elif defined(linux)				/* Linux */
+
+#include "qlisioln.h"
+
+#elif defined(sun) || defined(__sun)		/* Solaris */
+
+#include "qlisioso.h"
+
+#endif
+
+/*
+ * ****************************************************************************
+ * OS dependent General configuration defines
+ * ****************************************************************************
+ */
+#define EXT_DEF_MAX_HBA				EXT_DEF_MAX_HBA_OS
+#define EXT_DEF_MAX_BUS				EXT_DEF_MAX_BUS_OS
+#define EXT_DEF_MAX_TARGET			EXT_DEF_MAX_TARGET_OS
+#define EXT_DEF_MAX_LUN				EXT_DEF_MAX_LUN_OS
+
+/*
+ * Addressing mode used by the user application
+ */
+#define EXT_ADDR_MODE				EXT_ADDR_MODE_OS
+
+/*
+ * Command Codes definitions
+ */
+#define EXT_CC_QUERY				EXT_CC_QUERY_OS
+#define EXT_CC_REG_AEN				EXT_CC_REG_AEN_OS
+#define EXT_CC_GET_AEN				EXT_CC_GET_AEN_OS
+#define EXT_CC_GET_DATA				EXT_CC_GET_DATA_OS
+#define EXT_CC_SET_DATA				EXT_CC_SET_DATA_OS
+#define EXT_CC_SEND_SCSI_PASSTHRU		EXT_CC_SEND_SCSI_PASSTHRU_OS
+#define EXT_CC_SEND_ISCSI_PASSTHRU		EXT_CC_SEND_ISCSI_PASSTHRU_OS
+#define EXT_CC_DISABLE_ACB			EXT_CC_DISABLE_ACB_OS
+#define EXT_CC_SEND_ROUTER_SOL			EXT_CC_SEND_ROUTER_SOL_OS
+
+/*
+ * ****************************************************************************
+ * EXT_IOCTL_ISCSI
+ * ****************************************************************************
+ */
+/*
+ * EXT_IOCTL_ISCSI SubCode definition.
+ * These macros are being used for setting SubCode field in EXT_IOCTL_ISCSI
+ * structure.
+ */
+
+/*
+ * Sub codes for Query.
+ * Uses in combination with EXT_QUERY as the ioctl code.
+ */
+#define EXT_SC_QUERY_HBA_ISCSI_NODE		1
+#define EXT_SC_QUERY_HBA_ISCSI_PORTAL		2
+#define EXT_SC_QUERY_DISC_ISCSI_NODE		3
+#define EXT_SC_QUERY_DISC_ISCSI_PORTAL		4
+#define EXT_SC_QUERY_DISC_LUN                   5
+#define EXT_SC_QUERY_DRIVER			6
+#define EXT_SC_QUERY_FW				7
+#define EXT_SC_QUERY_CHIP			8
+#define EXT_SC_QUERY_IP_STATE			9
+#define EXT_SC_QUERY_DEVICE_CURRENT_IP		10
+
+/*
+ * Sub codes for Get Data.
+ * Use in combination with EXT_GET_DATA as the ioctl code
+ */
+#define EXT_SC_GET_STATISTICS_GEN		1
+#define EXT_SC_GET_STATISTICS_ISCSI		2
+#define EXT_SC_GET_DEVICE_ENTRY_ISCSI		3
+#define EXT_SC_GET_INIT_FW_ISCSI		4
+#define EXT_SC_GET_INIT_FW_DEFAULTS_ISCSI	5
+#define EXT_SC_GET_DEVICE_ENTRY_DEFAULTS_ISCSI	6
+#define EXT_SC_GET_ISNS_SERVER			7
+#define EXT_SC_GET_ISNS_DISCOVERED_TARGETS	8
+#define EXT_SC_GET_ACB				9
+#define EXT_SC_GET_NEIGHBOR_CACHE		10
+#define EXT_SC_GET_DESTINATION_CACHE		11
+#define EXT_SC_GET_DEFAULT_ROUTER_LIST		12
+#define EXT_SC_GET_LOCAL_PREFIX_LIST		13
+#define EXT_SC_GET_STATISTICS_ISCSI_BLOCK	14
+#define EXT_SC_GET_ISNS_TARGETS_BUFFER		15
+
+/*
+ * Sub codes for Set Data.
+ * Use in combination with EXT_SET_DATA as the ioctl code
+ */
+#define EXT_SC_RST_STATISTICS_GEN		1
+#define EXT_SC_RST_STATISTICS_ISCSI		2
+#define EXT_SC_SET_DEVICE_ENTRY_ISCSI		3
+#define EXT_SC_SET_INIT_FW_ISCSI		4
+#define EXT_SC_SET_ISNS_SERVER			5
+#define EXT_SC_SET_ACB				6
+
+/*
+ * Status.  These macros are being used for setting Status field in
+ * EXT_IOCTL_ISCSI structure.
+ */
+#define EXT_STATUS_OK				0
+#define EXT_STATUS_ERR				1
+#define EXT_STATUS_BUSY				2
+#define EXT_STATUS_PENDING			3
+#define EXT_STATUS_SUSPENDED			4
+#define EXT_STATUS_RETRY_PENDING		5
+#define EXT_STATUS_INVALID_PARAM		6
+#define EXT_STATUS_DATA_OVERRUN			7
+#define EXT_STATUS_DATA_UNDERRUN		8
+#define EXT_STATUS_DEV_NOT_FOUND		9
+#define EXT_STATUS_COPY_ERR			10
+#define EXT_STATUS_MAILBOX			11
+#define EXT_STATUS_UNSUPPORTED_SUBCODE		12
+#define EXT_STATUS_UNSUPPORTED_VERSION		13
+#define EXT_STATUS_MS_NO_RESPONSE		14
+#define EXT_STATUS_SCSI_STATUS			15
+#define EXT_STATUS_BUFFER_TOO_SMALL		16
+#define EXT_STATUS_NO_MEMORY			17
+#define EXT_STATUS_UNKNOWN			18
+#define EXT_STATUS_UNKNOWN_DSTATUS		19
+#define EXT_STATUS_INVALID_REQUEST		20
+#define EXT_STATUS_DEVICE_NOT_READY		21
+#define EXT_STATUS_DEVICE_OFFLINE		22
+#define EXT_STATUS_HBA_NOT_READY		23
+#define EXT_STATUS_HBA_QUEUE_FULL		24
+#define EXT_STATUS_BUFFER_HEADER_TOO_SMALL	25
+#define EXT_STATUS_SERVICE_NOT_ENABLED		26
+
+/*
+ * Detail Status contains the SCSI bus status codes.
+ */
+#define EXT_DSTATUS_GOOD			0x00
+#define EXT_DSTATUS_CHECK_CONDITION		0x02
+#define EXT_DSTATUS_CONDITION_MET		0x04
+#define EXT_DSTATUS_BUSY			0x08
+#define EXT_DSTATUS_INTERMEDIATE		0x10
+#define EXT_DSTATUS_INTERMEDIATE_COND_MET	0x14
+#define EXT_DSTATUS_RESERVATION_CONFLICT	0x18
+#define EXT_DSTATUS_COMMAND_TERMINATED		0x22
+#define EXT_DSTATUS_QUEUE_FULL			0x28
+
+/*
+ * Detail Status contains one of the following codes
+ * when Status = EXT_STATUS_INVALID_PARAM or
+ *	       = EXT_STATUS_DEV_NOT_FOUND
+ */
+#define EXT_DSTATUS_NOADNL_INFO			0x00
+#define EXT_DSTATUS_HBA_INST			0x01
+#define EXT_DSTATUS_TARGET			0x02
+#define EXT_DSTATUS_LUN				0x03
+#define EXT_DSTATUS_REQUEST_LEN			0x04
+#define EXT_DSTATUS_PATH_INDEX			0x05
+
+/*
+ * FLASH error status
+*/
+#define EXT_FLASH_NO_INFO			0x00
+#define EXT_FLASH_NO_MEMORY			0x0a
+#define EXT_FLASH_FW_IMAGE_INVALID		0x0b
+#define EXT_FLASH_NO_BKUP_FW_IMAGE		0x0c
+#define EXT_FLASH_ERROR_ACCESSING_FLASH		0x0d
+
+/*
+ * Defines for VendorSpecificStatus
+ */
+#define VENDOR_SPECIFIC_STATUS_MB_STATUS_INDEX		0 /* [0-4]  mbSts */
+#define VENDOR_SPECIFIC_STATUS_MB_COMMAND_INDEX		5 /* [5-10] mbCmd */
+#define VENDOR_SPECIFIC_STATUS_IOSB_COMPLETION_INDEX	0
+#define VENDOR_SPECIFIC_STATUS_SCSI_STATUS_INDEX	1
+
+
+typedef struct _EXT_IOCTL_ISCSI {
+	UINT8	Signature[EXT_DEF_SIGNATURE_SIZE];	/* 8   - 0x00 */
+	UINT16	AddrMode;				/* 2   - 0x08 */
+	UINT16	Version;				/* 2   - 0x0A */
+	UINT16	SubCode;				/* 2   - 0x0C */
+	UINT16	Instance;				/* 2   - 0x0E */
+	UINT32	Status;					/* 4   - 0x10 */
+	UINT32	DetailStatus;				/* 4   - 0x14 */
+	UINT32	Reserved1;				/* 4   - 0x18 */
+	UINT32	RequestLen;				/* 4   - 0x1C */
+	UINT32	ResponseLen;				/* 4   - 0x20 */
+	UINT64	RequestAdr;				/* 8   - 0x24 */
+	UINT64	ResponseAdr;				/* 8   - 0x2C */
+	UINT16	HbaSelect;				/* 2   - 0x34 */
+	UINT32	VendorSpecificStatus[11];		/* 44  - 0x38 */
+	UINT64	Signature2;				/* 8   - 0x64 */
+} __attribute__((packed)) EXT_IOCTL_ISCSI, *PEXT_IOCTL_ISCSI;	/* 108  - 0x6C*/
+
+/*
+ * ****************************************************************************
+ * EXT_ISCSI_DEVICE
+ * ****************************************************************************
+ */
+/* Device Type */
+#define EXT_DEF_ISCSI_REMOTE			0x02
+#define EXT_DEF_ISCSI_LOCAL			0x01
+
+#define EXT_ISCSI_ENABLE_DHCP			0x01
+
+#define EXT_DEF_ISCSI_TADDR_SIZE		32
+
+typedef struct _EXT_ISCSI_DEVICE {
+	UINT16	DeviceType;				/* 2   */
+	UINT16	ExeThrottle;				/* 2   */
+	UINT16	InitMarkerlessInt;			/* 2   */
+	UINT8	RetryCount;				/* 1   */
+	UINT8	RetryDelay;				/* 1   */
+	UINT16	iSCSIOptions;				/* 2   */
+	UINT16	TCPOptions;				/* 2   */
+	UINT16	IPOptions;				/* 2   */
+	UINT16	MaxPDUSize;				/* 2   */
+	UINT16	FirstBurstSize;				/* 2   */
+	UINT16	LogoutMinTime;				/* 2   */
+	UINT16	LogoutMaxTime;				/* 2   */
+	UINT16	MaxOutstandingR2T;			/* 2   */
+	UINT16	KeepAliveTimeout;			/* 2   */
+	UINT16	PortNumber;				/* 2   */
+	UINT16	MaxBurstSize;				/* 2   */
+	UINT16	TaskMgmtTimeout;			/* 2   */
+	UINT8	TargetAddr[EXT_DEF_ISCSI_TADDR_SIZE];	/* 32  */
+} EXT_ISCSI_DEVICE, *PEXT_ISCSI_DEVICE;		/* 64  */
+
+/*
+ * ****************************************************************************
+ * EXT_ISCSI_IP_ADDR
+ * ****************************************************************************
+ */
+#define EXT_DEF_IP_ADDR_SIZE			16
+#define EXT_DEF_TYPE_ISCSI_IP			0
+#define EXT_DEF_TYPE_ISCSI_IPV6			1
+
+typedef struct _EXT_ISCSI_IP_ADDR {
+	UINT8	IPAddress[EXT_DEF_IP_ADDR_SIZE];	/* 16  */
+	UINT16	Type;					/* 2   */
+	UINT16	Reserved;				/* 2   */
+} EXT_ISCSI_IP_ADDR, *PEXT_ISCSI_IP_ADDR;		/* 20  */
+
+/*
+ * ****************************************************************************
+ * EXT_NODE_INFO_ISCSI
+ * ****************************************************************************
+ */
+#define EXT_DEF_ISCSI_NAME_LEN			256
+#define EXT_DEF_ISCSI_ALIAS_LEN			32
+
+typedef struct _EXT_NODE_INFO_ISCSI {
+	EXT_ISCSI_IP_ADDR IPAddr;			/* 20  */
+	UINT8	iSCSIName[EXT_DEF_ISCSI_NAME_LEN];	/* 256 */
+	UINT8	Alias[EXT_DEF_ISCSI_ALIAS_LEN];		/* 32  */
+	UINT16	PortalCount;				/* 2   */
+	UINT8	Reserved[10];				/* 10  */
+} EXT_NODE_INFO_ISCSI, *PEXT_NODE_INFO_ISCSI;		/* 320 */
+
+/*
+ * ****************************************************************************
+ * EXT_SCSI_ADDR_ISCSI
+ * ****************************************************************************
+ */
+typedef struct _EXT_SCSI_ADDR_ISCSI {
+	UINT16	Bus;					/* 2   */
+	UINT16	Target;					/* 2   */
+	UINT16	Lun;					/* 2   */
+	UINT16	Padding[5];				/* 10  */
+} EXT_SCSI_ADDR_ISCSI, *PEXT_SCSI_ADDR_ISCSI;		/* 16  */
+
+/*
+ * ****************************************************************************
+ * EXT_REG_AEN_ISCSI
+ * ****************************************************************************
+ */
+#define EXT_DEF_ENABLE_AENS		0x00000000
+#define EXT_DEF_ENABLE_NO_AENS		0xFFFFFFFF
+
+typedef struct _EXT_REG_AEN_ISCSI {
+	UINT32	Enable;					/* 4   */
+	UINT32	Reserved[3];				/* 12  */
+} EXT_REG_AEN_ISCSI, *PEXT_REG_AEN_ISCSI;		/* 16  */
+
+/*
+ * ****************************************************************************
+ * EXT_ASYNC_EVENT
+ * ****************************************************************************
+ */
+
+/* Required # of entries in the queue buffer allocated. */
+#define EXT_DEF_MAX_AEN_QUEUE			EXT_DEF_MAX_AEN_QUEUE_OS
+#define EXT_DEF_MAX_AEN_PAYLOAD			7
+
+typedef struct _EXT_ASYNC_EVENT {
+	UINT32	AsyncEventCode;				/* 4   */
+	UINT32	Payload[EXT_DEF_MAX_AEN_PAYLOAD];	/* 28  */
+} EXT_ASYNC_EVENT, *PEXT_ASYNC_EVENT;			/* 32  */
+
+/*
+ * ****************************************************************************
+ * EXT_CHIP_INFO
+ * ****************************************************************************
+ */
+typedef struct _EXT_CHIP_INFO {
+	UINT16	VendorId;				/* 2   */
+	UINT16	DeviceId;				/* 2   */
+	UINT16	SubVendorId;				/* 2   */
+	UINT16	SubSystemId;				/* 2   */
+	UINT16	BoardID;				/* 2   */
+	UINT16	ChipRevision;				/* 2   */
+	UINT16	Reserved[34];				/* 68  */
+} EXT_CHIP_INFO, *PEXT_CHIP_INFO;			/* 80  */
+
+#define CHIP_REVISION_VALID	0x4000  /* Chip Revision Valid Bit */
+
+/*
+ * ****************************************************************************
+ * EXT_DEVICE_ENTRY_ISCSI
+ * ****************************************************************************
+ */
+/* Options */
+#define EXT_DEF_ISCSI_GRANT_ACCESS		0x04
+#define EXT_DEF_ISCSI_TARGET_DEVICE		0x02
+#define EXT_DEF_ISCSI_INITIATOR_DEVICE		0x01
+
+/* Control */
+#define EXT_DEF_SESS_RECVRY_IN_PROCESS		0x10
+#define EXT_DEF_ISCSI_TRANSMITTING		0x08
+#define EXT_DEF_ISCSI_TX_LINKED			0x04
+#define EXT_DEF_ISCSI_QUEUE_ABORTED		0x02
+#define EXT_DEF_ISCSI_TX_LOGGED_IN		0x01
+
+/* DeviceState */
+#define EXT_DEF_DEV_STATE_UNASSIGNED		0x00
+#define EXT_DEF_DEV_STATE_NO_CONNECTION_ACTIVE	0x01
+#define EXT_DEF_DEV_STATE_DISCOVERY		0x02
+#define EXT_DEF_DEV_STATE_NO_SESSION_ACTIVE	0x03
+#define EXT_DEF_DEV_STATE_SESSION_ACTIVE	0x04
+#define EXT_DEF_DEV_STATE_LOGGING_OUT		0x05
+#define EXT_DEF_DEV_STATE_SESSION_FAILED	0x06
+#define EXT_DEF_DEV_STATE_OPENING		0x07
+
+#define EXT_DEF_ISCSI_ISID_SIZE			6
+#define EXT_DEF_ISCSI_USER_ID_SIZE		32
+#define EXT_DEF_ISCSI_PASSWORD_SIZE		32
+
+typedef struct _EXT_DEVICE_ENTRY_ISCSI {
+	UINT8	Options;				/* 1   */
+	UINT8	Control;				/* 1   */
+	UINT8	InitiatorSessID[EXT_DEF_ISCSI_ISID_SIZE];	/* 6   */
+	UINT16	TargetSessID;				/* 2   */
+	UINT32	ReservedFlags;				/* 4   */
+	UINT8	UserID[EXT_DEF_ISCSI_USER_ID_SIZE];	/* 32  */
+	UINT8	Password[EXT_DEF_ISCSI_PASSWORD_SIZE];	/* 32  */
+	EXT_ISCSI_DEVICE	DeviceInfo;		/* 64  */
+	EXT_NODE_INFO_ISCSI	EntryInfo;		/* 320 */
+	UINT16	ExeCount;				/* 2   */
+	UINT32	NumValid;				/* 4   */
+	UINT32	NextValid;				/* 4   */
+	UINT32	DeviceState;				/* 4   */
+	UINT16	DDBLink;				/* 2   */
+	UINT16	Reserved[17];				/* 34  */
+} EXT_DEVICE_ENTRY_ISCSI, *PEXT_DEVICE_ENTRY_ISCSI;	/* 512 */
+
+/*
+ * ****************************************************************************
+ * EXT_DEST_ADDR_ISCSI
+ * ****************************************************************************
+ */
+typedef struct _EXT_DEST_ADDR_ISCSI {
+	UINT8	iSCSINameStr[EXT_DEF_ISCSI_NAME_LEN];	/* 256 */
+	UINT16	SessionID;				/* 2   */
+	UINT16	ConnectionID;				/* 2   */
+	UINT16	PortNumber;				/* 2   */
+	UINT16	Reserved[3];				/* 6   */
+} EXT_DEST_ADDR_ISCSI, *PEXT_DEST_ADDR_ISCSI;		/* 268 */
+
+/*
+ * ****************************************************************************
+ * EXT_DISC_ISCSI_PORTAL
+ * ****************************************************************************
+ */
+typedef struct _EXT_DISC_ISCSI_PORTAL {
+	EXT_ISCSI_IP_ADDR	IPAddr;			/* 20  */
+	UINT16	NodeCount;				/* 2   */
+	UINT8	HostName[EXT_DEF_MAX_STR_SIZE];		/* 128 */
+	UINT16	PortNumber;				/* 2   */
+	UINT16	Reserved;				/* 2   */
+} EXT_DISC_ISCSI_PORTAL, *PEXT_DISC_ISCSI_PORTAL;	/* 154 */
+
+/*
+ * ****************************************************************************
+ * EXT_DISC_ISCSI_NODE
+ * ****************************************************************************
+ */
+typedef struct _EXT_DISC_ISCSI_NODE {
+	UINT16	SessionID;				/* 2   */
+	UINT16	ConnectionID;				/* 2   */
+	UINT16	PortalGroupID;				/* 2   */
+	EXT_NODE_INFO_ISCSI	NodeInfo;		/* 320 */
+	EXT_SCSI_ADDR_ISCSI	ScsiAddr;		/* 16  */
+	UINT16	Reserved;				/* 2   */
+} EXT_DISC_ISCSI_NODE, *PEXT_DISC_ISCSI_NODE;		/* 344 */
+
+/*
+ * ****************************************************************************
+ * EXT_DNS
+ * ****************************************************************************
+ */
+typedef struct _EXT_DNS {
+	EXT_ISCSI_IP_ADDR	IPAddr;			/* 20  */
+	UINT8	Reserved[132];				/* 132 */
+} EXT_DNS, *PEXT_DNS;					/* 152 */
+
+/*
+ * ****************************************************************************
+ * EXT_DRIVER_INFO
+ * ****************************************************************************
+ */
+typedef struct _EXT_DRIVER_INFO {
+	UINT8	Version[EXT_DEF_MAX_STR_SIZE];		/* 128 */
+	UINT16	NumOfBus;				/* 2   */
+	UINT16	TargetsPerBus;				/* 2   */
+	UINT16	LunPerTarget;				/* 2   */
+	UINT16	LunPerTargetOS;				/* 2   */
+	UINT32	MaxTransferLen;				/* 4   */
+	UINT32	MaxDataSegments;			/* 4   */
+	UINT16	DmaBitAddresses;			/* 2   */
+	UINT16	IoMapType;				/* 2   */
+	UINT32	Attrib;					/* 4   */
+	UINT32	InternalFlags[4];			/* 16  */
+	UINT32	Reserved[8];				/* 32  */
+} EXT_DRIVER_INFO, *PEXT_DRIVER_INFO;			/* 200 */
+
+/*
+ * ****************************************************************************
+ * EXT_FW_INFO
+ * ****************************************************************************
+ */
+typedef struct _EXT_FW_INFO {
+	UINT8	Version[EXT_DEF_MAX_STR_SIZE];		/* 128 */
+	UINT32	Attrib;					/* 4   */
+	UINT32	Reserved[8];				/* 32  */
+} EXT_FW_INFO, *PEXT_FW_INFO;				/* 164 */
+
+/*
+ * ****************************************************************************
+ * EXT_HBA_ISCSI_NODE
+ * ****************************************************************************
+ */
+typedef struct _EXT_HBA_ISCSI_NODE {
+	UINT8	DeviceName[EXT_DEF_MAX_STR_SIZE];	/* 128 */
+	UINT16	PortNumber;				/* 2   */
+	EXT_NODE_INFO_ISCSI	NodeInfo;		/* 320 */
+	UINT16	Reserved;				/* 2   */
+} EXT_HBA_ISCSI_NODE, *PEXT_HBA_ISCSI_NODE;		/* 452 */
+
+/*
+ * ****************************************************************************
+ * EXT_HBA_ISCSI_PORTAL
+ * ****************************************************************************
+ */
+#define EXT_DEF_MAC_ADDR_SIZE			6
+
+/* State */
+#define EXT_DEF_CARD_STATE_READY		1
+#define EXT_DEF_CARD_STATE_CONFIG_WAIT		2
+#define EXT_DEF_CARD_STATE_LOGIN		3
+#define EXT_DEF_CARD_STATE_ERROR		4
+
+/* Type */
+#define EXT_DEF_TYPE_COPPER			1
+#define EXT_DEF_TYPE_OPTICAL			2
+
+#define EXT_DEF_SERIAL_NUM_SIZE			4
+
+typedef struct _EXT_HBA_ISCSI_PORTAL {
+	EXT_ISCSI_IP_ADDR IPAddr;			/* 20  */
+	UINT8	MacAddr[EXT_DEF_MAC_ADDR_SIZE];		/* 6   */
+	UINT8	Padding[2];				/* 2   */
+	UINT32	SerialNum;				/* 4   */
+	UINT8	Manufacturer[EXT_DEF_MAX_STR_SIZE];	/* 128 */
+	UINT8	Model[EXT_DEF_MAX_STR_SIZE];		/* 128 */
+	UINT8	DriverVersion[EXT_DEF_MAX_STR_SIZE];	/* 128 */
+	UINT8	FWVersion[EXT_DEF_MAX_STR_SIZE];	/* 128 */
+	UINT8	OptRomVersion[EXT_DEF_MAX_STR_SIZE];	/* 128 */
+	UINT16	State;					/* 2   */
+	UINT16	Type;					/* 2   */
+	UINT32	DriverAttr;				/* 4   */
+	UINT32	FWAttr;					/* 4   */
+	UINT16	DiscTargetCount;			/* 2   */
+	UINT32	Reserved;				/* 4   */
+} EXT_HBA_ISCSI_PORTAL, *PEXT_HBA_ISCSI_PORTAL;	/* 686 */
+
+/*
+ * ****************************************************************************
+ * EXT_HBA_PORT_STAT_GEN
+ * ****************************************************************************
+ */
+typedef struct _EXT_HBA_PORT_STAT_GEN {
+	UINT64	HBAPortErrorCount;			/* 8   */
+	UINT64	DevicePortErrorCount;			/* 8   */
+	UINT64	IoCount;				/* 8   */
+	UINT64	MBytesCount;				/* 8   */
+	UINT64	InterruptCount;				/* 8   */
+	UINT64	LinkFailureCount;			/* 8   */
+	UINT64	InvalidCrcCount;			/* 8   */
+	UINT32	Reserved[2];				/* 8   */
+} EXT_HBA_PORT_STAT_GEN, *PEXT_HBA_PORT_STAT_GEN;	/* 64  */
+
+/*
+ * ****************************************************************************
+ * EXT_HBA_PORT_STAT_ISCSI
+ * ****************************************************************************
+ */
+typedef struct _EXT_HBA_PORT_STAT_ISCSI {
+	UINT64	MACTxFramesCount;			/* 8   */
+	UINT64	MACTxBytesCount;			/* 8   */
+	UINT64	MACRxFramesCount;			/* 8   */
+	UINT64	MACRxBytesCount;			/* 8   */
+	UINT64	MACCRCErrorCount;			/* 8   */
+	UINT64	MACEncodingErrorCount;			/* 8   */
+	UINT64	IPTxPacketsCount;			/* 8   */
+	UINT64	IPTxBytesCount;				/* 8   */
+	UINT64	IPTxFragmentsCount;			/* 8   */
+	UINT64	IPRxPacketsCount;			/* 8   */
+	UINT64	IPRxBytesCount;				/* 8   */
+	UINT64	IPRxFragmentsCount;			/* 8   */
+	UINT64	IPDatagramReassemblyCount;		/* 8   */
+	UINT64	IPv6RxPacketsCount;			/* 8   */
+	UINT64	IPRxPacketErrorCount;			/* 8   */
+	UINT64	IPReassemblyErrorCount;			/* 8   */
+	UINT64	TCPTxSegmentsCount;			/* 8   */
+	UINT64	TCPTxBytesCount;			/* 8   */
+	UINT64	TCPRxSegmentsCount;			/* 8   */
+	UINT64	TCPRxBytesCount;			/* 8   */
+	UINT64	TCPTimerExpiredCount;			/* 8   */
+	UINT64	TCPRxACKCount;				/* 8   */
+	UINT64	TCPTxACKCount;				/* 8   */
+	UINT64	TCPRxErrorSegmentCount;			/* 8   */
+	UINT64	TCPWindowProbeUpdateCount;		/* 8   */
+	UINT64	iSCSITxPDUCount;			/* 8   */
+	UINT64	iSCSITxBytesCount;			/* 8   */
+	UINT64	iSCSIRxPDUCount;			/* 8   */
+	UINT64	iSCSIRxBytesCount;			/* 8   */
+	UINT64	iSCSICompleteIOsCount;			/* 8   */
+	UINT64	iSCSIUnexpectedIORxCount;		/* 8   */
+	UINT64	iSCSIFormatErrorCount;			/* 8   */
+	UINT64	iSCSIHeaderDigestCount;			/* 8   */
+	UINT64	iSCSIDataDigestErrorCount;		/* 8   */
+	UINT64	iSCSISeqErrorCount;			/* 8   */
+	UINT32	Reserved[2];				/* 8   */
+} EXT_HBA_PORT_STAT_ISCSI, *PEXT_HBA_PORT_STAT_ISCSI;	/* 272 */
+
+/*
+ * ****************************************************************************
+ * EXT_HBA_PORT_STAT_ISCSI_BLOCK
+ * ****************************************************************************
+ */
+typedef struct _EXT_HBA_PORT_STAT_ISCSI_BLOCK {
+	UINT8	DataBlock[4096];
+} EXT_HBA_PORT_STAT_ISCSI_BLOCK, *PEXT_HBA_PORT_STAT_ISCSI_BLOCK;  /* 4096 */
+
+/*
+ * ****************************************************************************
+ * EXT_INIT_FW_ISCSI
+ * ****************************************************************************
+ */
+#define EXT_DEF_FW_MARKER_DISABLE		0x0400
+#define EXT_DEF_FW_ACCESS_CONTROL_ENABLE	0x0080
+#define EXT_DEF_FW_SESSION_MODE_ENABLE		0x0040
+#define EXT_DEF_FW_INITIATOR_MODE_ENABLE	0x0020
+#define EXT_DEF_FW_TARGET_MODE_ENABLE		0x0010
+#define EXT_DEF_FW_FAST_STATUS_ENABLE		0x0008
+#define EXT_DEF_FW_DMA_INT_ENABLE		0x0004
+#define EXT_DEF_FW_SENSE_BUFF_DESC_ENABLE	0x0002
+
+typedef struct _EXT_INIT_FW_ISCSI {
+	UINT8	Reserved1;				/* 1   */
+	UINT8	Version;				/* 1   */
+	UINT16	FWOptions;				/* 2   */
+	UINT16	AddFWOptions;				/* 2   */
+	UINT16	WakeupThreshold;			/* 2   */
+	EXT_ISCSI_IP_ADDR	IPAddr;			/* 20  */
+	EXT_ISCSI_IP_ADDR	SubnetMask;		/* 20  */
+	EXT_ISCSI_IP_ADDR	Gateway;		/* 20  */
+	EXT_DNS	DNSConfig;				/* 152 */
+	UINT8	Alias[EXT_DEF_ISCSI_ALIAS_LEN];		/* 32  */
+	UINT8	iSCSIName[EXT_DEF_ISCSI_NAME_LEN];	/* 256 */
+	EXT_ISCSI_DEVICE	DeviceInfo;		/* 64  */
+	UINT8	Reserved[4];				/* 4   */
+} EXT_INIT_FW_ISCSI , *PEXT_INIT_FW_ISCSI;		/* 576 */
+
+/*
+ * ****************************************************************************
+ * EXT_ISCSI_PASSTHRU
+ * ****************************************************************************
+ */
+#define EXT_DEF_ISCSI_PASSTHRU_PDU_LENGTH	64
+
+#define EXT_DEF_ISCSI_PASSTHRU_DATA_IN		1
+#define EXT_DEF_ISCSI_PASSTHRU_DATA_OUT	2
+
+typedef struct _EXT_ISCSI_PASSTHRU {
+	EXT_DEST_ADDR_ISCSI Addr;			/* 268 */
+	UINT16	Direction;				/* 2   */
+	UINT32	PduInLength;				/* 4   */
+	UINT8	PduIn[EXT_DEF_ISCSI_PASSTHRU_PDU_LENGTH];	/* 64  */
+	UINT32	PduOutLength;				/* 4   */
+	UINT8	PduOut[EXT_DEF_ISCSI_PASSTHRU_PDU_LENGTH];	/* 64  */
+	UINT32	Flags;					/* 4   */
+	UINT32	Reserved;				/* 4   */
+} EXT_ISCSI_PASSTHRU, *PEXT_ISCSI_PASSTHRU;		/* 282 */
+
+/*
+ * ****************************************************************************
+ * EXT_SCSI_PASSTHRU_ISCSI
+ * ****************************************************************************
+ */
+#define EXT_DEF_SCSI_PASSTHRU_CDB_LENGTH	16
+
+#define EXT_DEF_SCSI_PASSTHRU_DATA_IN		1
+#define EXT_DEF_SCSI_PASSTHRU_DATA_OUT		2
+
+#define EXT_DEF_SCSI_SENSE_DATA_SIZE		256
+
+typedef struct _EXT_SCSI_PASSTHRU_ISCSI {
+	EXT_SCSI_ADDR_ISCSI Addr;			/* 16  */
+	UINT8	Direction;				/* 1   */
+	UINT8	CdbLength;				/* 1   */
+	UINT8	Cdb[EXT_DEF_SCSI_PASSTHRU_CDB_LENGTH];	/* 16  */
+	UINT8	Reserved[16];				/* 16  */
+	UINT8	SenseData[EXT_DEF_SCSI_SENSE_DATA_SIZE];/* 256 */
+} EXT_SCSI_PASSTHRU_ISCSI, *PEXT_SCSI_PASSTHRU_ISCSI;	/* 306 */
+
+
+/*
+ * ****************************************************************************
+ * EXT_ISNS_SERVER
+ * ****************************************************************************
+ */
+
+#define EXT_DEF_ISNS_WELL_KNOWN_PORT		3205
+
+typedef struct _EXT_ISNS_SERVER {
+	UINT8	PerformiSNSDiscovery;			/* 1  : 00-00 */
+	UINT8	AutomaticiSNSDiscovery;			/* 1  : 01-01 */
+	UINT8	iSNSNotSupported;			/* 1  : 02-02 */
+	UINT8	iSNSServerConnOpen;			/* 1  : 03-03 */
+	EXT_ISCSI_IP_ADDR	IPAddr;			/* 20 : 04-17 */
+	UINT16	PortNumber;				/* 2  : 18-19 */
+	UINT8	FeaturesRequest;			/* 1  : 1A-1A */
+	UINT8	FeaturesResponse;			/* 1  : 1B-1B */
+		#define EXT_DEF_IMMEDIATE_ISNS_CONFIG   0x01
+                #define EXT_DEF_RETURN_ISNS_CONN_STATUS 0x02
+
+	UINT8	InitiatorName[EXT_DEF_ISCSI_NAME_LEN];	/* 256: 1C-11B */
+	UINT32	Reserved3;				/* 4  : 11C-11F */
+} EXT_ISNS_SERVER, *PEXT_ISNS_SERVER;			/* 288: 120h */
+
+/*
+ * ****************************************************************************
+ * EXT_ISNS_TARGETS_BUFFER
+ * ****************************************************************************
+ */
+
+#define EXT_DEF_MAX_ISNS_TARGET_BUFFER_SIZE	0x4000
+
+typedef struct _EXT_ISNS_TARGETS_BUFFER
+{
+	UINT8   LastIscsiName[EXT_DEF_ISCSI_NAME_LEN];  /* 256   - 0x00 */
+	UINT8	Reserved[28];				/* 28    - 0x100 */
+	UINT32  BufferSize;                             /* 4     - 0x11C */
+	UINT8	Buffer[EXT_DEF_MAX_ISNS_TARGET_BUFFER_SIZE];
+							/* 16384 - 0x120 */
+} EXT_ISNS_TARGETS_BUFFER, *PEXT_ISNS_TARGETS_BUFFER;
+							/* 16672 - 0x4120 */
+
+/*
+ * ****************************************************************************
+ * EXT_ISNS_DISCOVERED_TARGET_PORTAL
+ * ****************************************************************************
+ */
+
+typedef struct _EXT_ISNS_DISCOVERED_TARGET_PORTAL
+{
+	EXT_ISCSI_IP_ADDR	IPAddr;			/* 20 */
+	UINT16	PortNumber;				/* 2 */
+	UINT16	Reserved;				/* 2 */
+} EXT_ISNS_DISCOVERED_TARGET_PORTAL, *PEXT_ISNS_DISCOVERED_TARGET_PORTAL;
+							/* 24 */
+
+/*
+ * ****************************************************************************
+ * EXT_ISNS_DISCOVERED_TARGET
+ * ****************************************************************************
+ */
+
+#define EXT_DEF_ISNS_MAX_PORTALS		4
+
+typedef struct _EXT_ISNS_DISCOVERED_TARGET
+{
+	UINT32	NumPortals;				/* 4 */
+	EXT_ISNS_DISCOVERED_TARGET_PORTAL Portal[EXT_DEF_ISNS_MAX_PORTALS];	/* 96 */
+	UINT32	DDID;					/* 4 */
+	UINT8	NameString[EXT_DEF_ISCSI_NAME_LEN];	/* 256 */
+	UINT8	Alias[EXT_DEF_ISCSI_ALIAS_LEN];		/* 32 */
+} EXT_ISNS_DISCOVERED_TARGET, *PEXT_ISNS_DISCOVERED_TARGET;	/* 392 */
+
+/*
+ * ****************************************************************************
+ * EXT_ISNS_DISCOVERED_TARGETS
+ * ****************************************************************************
+ */
+
+#define EXT_DEF_NUM_ISNS_DISCOVERED_TARGETS	32
+
+typedef struct _EXT_ISNS_DISCOVERED_TARGETS
+{
+	UINT32  iSNSDiscoveredTargetIndexStart;		/* 4 */
+	UINT32	NumiSNSDiscoveredTargets;		/* 4 */
+	EXT_ISNS_DISCOVERED_TARGET
+		iSNSDiscoveredTargets[EXT_DEF_NUM_ISNS_DISCOVERED_TARGETS];
+							/* 12544 */
+} EXT_ISNS_DISCOVERED_TARGETS, *PEXT_ISNS_DISCOVERED_TARGETS;
+							/* 12548 */
+
+
+/*
+ * ****************************************************************************
+ * ACB Defines
+ * ****************************************************************************
+ */
+
+#define EXT_DEF_ACB_SIZE				0x300
+
+typedef struct _EXT_ACB
+{
+	UINT8 Buffer[EXT_DEF_ACB_SIZE];
+} EXT_ACB, *PEXT_ACB;                                   /* 0x300 */
+
+/* Specifies which ACB for all ACB IOCTLs*/
+#define EXT_DEF_ACB_PRIMARY				0
+#define EXT_DEF_ACB_SECONDARY				1
+
+/* Specifies Command Option for EXT_CC_DISABLE IOCTL */
+#define EXT_DEF_ACB_CMD_OPTION_NOT_FORCED		0x0000
+#define EXT_DEF_ACB_CMD_OPTION_FORCED			0x0001
+
+/* Specifies Parameter Error for EXT_CC_SET_DATA|EXT_SC_SET_ACB IOCTL */
+#define EXT_DEF_ACB_PARAM_ERR_INVALID_VALUE		0x0001
+#define EXT_DEF_ACB_PARAM_ERR_INVALID_SIZE		0x0002
+#define EXT_DEF_ACB_PARAM_ERR_INVALID_ADDR		0x0003
+
+/* Specifies the type of InitFW for the get defaults */
+#define EXT_DEF_VERSION_1						0x0000
+#define EXT_DEF_VERSION_2						0x0001
+
+
+/*
+ * ****************************************************************************
+ * QUERY_IP_STATE Defines
+ * ****************************************************************************
+ */
+
+typedef struct _EXT_QUERY_IP_STATE
+{
+	UINT8	IP_ACBState[4];				/* 4 */
+	UINT32	ValidLifetime;                          /* 4 */
+	UINT32	PreferredLifetime;                      /* 4 */
+	UINT8	IPAddressInfo1[4];                      /* 4 */
+	UINT8	IPAddressInfo2[4];                      /* 4 */
+	UINT8	IPAddressInfo3[4];                      /* 4 */
+	UINT8	IPAddressInfo4[4];                      /* 4 */
+	UINT8	Reserved[4];                            /* 4 */
+} EXT_QUERY_IP_STATE, *PEXT_QUERY_IP_STATE;
+
+
+/*
+ * ****************************************************************************
+ * NEIGHBOR_CACHE Defines
+ * ****************************************************************************
+ */
+typedef struct _EXT_NEIGHBOR_CACHE {
+	UINT32	CacheBufferSize;                        /* 4 */
+	UINT8	Reserved[4];                            /* 4 */
+	UINT8	Buffer[0];
+} EXT_NEIGHBOR_CACHE, *PEXT_NEIGHBOR_CACHE;
+
+#define EXT_DEF_IPv6INFO_ALL_ENTRIES			0xFFFFFFFF
+#define EXT_DEF_NEIGHBOR_CACHE_SIZE			0x28 /* 40 decimal */
+
+/*
+ * ****************************************************************************
+ * DESTINATION_CACHE Defines
+ * ****************************************************************************
+ */
+typedef struct _EXT_DESTINATION_CACHE {
+	UINT32	CacheBufferSize;                        /* 4 */
+	UINT8	Reserved[4];                            /* 4 */
+	UINT8	Buffer[0];
+} EXT_DESTINATION_CACHE, *PEXT_DESTINATION_CACHE;
+
+#define EXT_DEF_DESTINATION_CACHE_SIZE			0x38 /* 56 decimal */
+
+/*
+ * ****************************************************************************
+ * ROUTER_LIST Defines
+ * ****************************************************************************
+ */
+typedef struct _EXT_ROUTER_LIST {
+	UINT32	CacheBufferSize;                        /* 4 */
+	UINT8	Reserved[4];                            /* 4 */
+	UINT8	Buffer[0];
+} EXT_ROUTER_LIST, *PEXT_ROUTER_LIST;
+
+#define EXT_DEF_ROUTER_LISTE_SIZE			0x28 /* 40 decimal */
+
+/*
+ * ****************************************************************************
+ * PREFIX_LIST Defines
+ * ****************************************************************************
+ */
+typedef struct _EXT_PREFIX_LIST {
+	UINT32	CacheBufferSize;                        /* 4 */
+	UINT8	Reserved[4];                            /* 4 */
+	UINT8	Buffer[0];
+} EXT_PREFIX_LIST, *PEXT_PREFIX_LIST;
+
+#define EXT_DEF_PREFIX_LIST_SIZE			0x20
+
+/*
+ * ****************************************************************************
+ * SEND_ROUTER_SOL Defines
+ * ****************************************************************************
+ */
+typedef struct _EXT_SEND_ROUTER_SOL {
+	EXT_ISCSI_IP_ADDR	Addr;                   /* 20 */
+	UINT32			Flags;                  /* 4  */
+	UINT8			Reserved[8];            /* 8  */
+} EXT_SEND_ROUTER_SOL, *PEXT_SEND_ROUTER_SOL;
+
+#define EXT_DEF_SOURCE_NOT_AVAIL			0x0001
+#define EXT_DEF_ADDRESS_NOT_RESOLVED			0x0002
+#define EXT_DEF_NCB_FAIL				0x0003
+#define EXT_DEF_TIMEOUT					0x0004
+#define EXT_DEF_IPV6_DISABLED				0x0005
+#define EXT_DEF_EVENT_ERROR				0x0006
+
+/*
+ * ****************************************************************************
+ * QUERY_DEVICE_CURRENT_IP Defines
+ * ****************************************************************************
+ */
+
+typedef struct _EXT_QUERY_DEVICE_CURRENT_IP {
+	EXT_ISCSI_IP_ADDR	Addr;		/* 20 */
+	UINT32			DeviceState;	/* 4  */
+	UINT16			TCPPort;	/* 2  */
+	UINT8			Flags[2];	/* 2  */
+	UINT8			Reserved[4];	/* 4  */
+} EXT_QUERY_DEVICE_CURRENT_IP, *PEXT_QUERY_DEVICE_CURRENT_IP;	/* 32 */
+
+#endif /* _QLISIOCT_H */
diff -r ddeb2d9800e5 drivers/scsi/qla4xxx/qlisioln.h
--- /dev/null
+++ b/drivers/scsi/qla4xxx/qlisioln.h
@@ -0,0 +1,244 @@
+/*
+ * QLogic iSCSI HBA Driver
+ * Copyright (c)  2003-2011 QLogic Corporation
+ *
+ * See LICENSE.qla4xxx for copyright and licensing details.
+ */
+
+#ifndef _QLISIOLN_H_
+#define _QLISIOLN_H_
+
+#include <linux/ioctl.h>
+
+#ifdef APILIB
+#include <stdint.h>
+#include <linux/types.h>
+#endif
+
+#ifndef INT8
+#define	INT8	int8_t
+#endif
+#ifndef INT16
+#define	INT16	int16_t
+#endif
+#ifndef INT32
+#define	INT32	int32_t
+#endif
+#ifndef UINT8
+#define	UINT8	uint8_t
+#endif
+#ifndef UINT16
+#define	UINT16	uint16_t
+#endif
+#ifndef UINT32
+#define	UINT32	uint32_t
+#endif
+
+#ifndef UINT64
+#define UINT64  unsigned long long
+#endif
+
+#ifndef BOOLEAN
+#define BOOLEAN uint8_t
+#endif
+
+
+#if BITS_PER_LONG <= 32
+#define EXT_ADDR_MODE_OS  EXT_DEF_ADDR_MODE_32
+#else
+#define EXT_ADDR_MODE_OS  EXT_DEF_ADDR_MODE_64
+#endif
+
+
+#define QLMULTIPATH_MAGIC 'z'
+
+#define _QLBUILD   /* for qlisioct.h to enable include of qinsdmgt.h */
+
+
+
+/* max index values */
+#define	EXT_DEF_MAX_HBA_OS		63	/* 0 - 0x3F */
+#define EXT_DEF_MAX_HBAS		64
+
+#define	EXT_DEF_MAX_BUS_OS		1
+
+#define	EXT_DEF_MAX_TARGET_OS		255	/* 0 - 0xFF */
+#define EXT_DEF_MAX_TARGETS		256
+
+#define	EXT_DEF_MAX_LUN_OS		255	/* 0 - 0xFF */
+#define EXT_DEF_MAX_LUNS		256
+
+#define EXT_DEF_MAX_AEN_QUEUE_OS        256
+
+#define EXT_DEF_USE_HBASELECT		0x02	/* bit 1: HbaSelect field is
+						 * used to specify destination
+						 * HBA of each command.
+						 * SetInstance cmd is now
+						 * issued only once during
+						 * API initialization.
+						 */
+
+
+#define EXT_DEF_REGULAR_SIGNATURE	"QLOGIC"
+
+
+/*************************************************************/
+/*                       Command codes                       */
+/*-----------------------------------------------------------*/
+/* Correctly defined to work on both 32bit and 64bit kernels */
+/*************************************************************/
+#define	QL_IOCTL_BASE(idx)	\
+    _IOWR(QLMULTIPATH_MAGIC, idx, EXT_IOCTL_ISCSI)
+
+#define	QL_IOCTL_CMD(idx)	QL_IOCTL_BASE(idx)
+
+
+/***********************************
+ * These are regular command codes
+ * idx range from 0x00 to 0x2f
+ ***********************************/
+#define EXT_DEF_REG_CC_START_IDX	0x00
+
+#define EXT_CC_QUERY_OS				/* QUERY */	\
+    QL_IOCTL_CMD(0x00)
+
+#define EXT_CC_REG_AEN_OS			/* REG_AEN */ \
+    QL_IOCTL_CMD(0x01)
+
+#define EXT_CC_GET_AEN_OS			/* GET_AEN */ \
+    QL_IOCTL_CMD(0x02)
+
+#define EXT_CC_GET_DATA_OS			/* GET_DATA */ \
+    QL_IOCTL_CMD(0x03)
+
+#define EXT_CC_SET_DATA_OS			/* SET_DATA */ \
+    QL_IOCTL_CMD(0x04)
+
+#define EXT_CC_SEND_SCSI_PASSTHRU_OS		/* SCSI_PASSTHRU */ \
+    QL_IOCTL_CMD(0x05)
+
+#define EXT_CC_SEND_ISCSI_PASSTHRU_OS		/* ISCSI_PASSTHRU */ \
+    QL_IOCTL_CMD(0x06)
+
+#define EXT_CC_DISABLE_ACB_OS			/* DISABLE_ACB */ \
+    QL_IOCTL_CMD(0x07)
+
+#define EXT_CC_SEND_ROUTER_SOL_OS		/* SEND_ROUTER_SOL */ \
+    QL_IOCTL_CMD(0x08)
+
+#define EXT_DEF_REG_CC_END_IDX		0x08
+
+/***********************************
+ * Internal command codes
+ * idx range from 0x10 to 0x2f
+ ***********************************/
+#define EXT_DEF_INT_CC_START_IDX	0x10
+
+#define EXT_CC_RESERVED0A_OS					\
+    QL_IOCTL_CMD(0x10)
+#define EXT_CC_RESERVED0B_OS					\
+    QL_IOCTL_CMD(0x11)
+#define EXT_CC_RESERVED0C_OS					\
+    QL_IOCTL_CMD(0x12)
+#define EXT_CC_RESERVED0D_OS					\
+    QL_IOCTL_CMD(0x13)
+#define EXT_CC_RESERVED0E_OS					\
+    QL_IOCTL_CMD(0x14)
+#define EXT_CC_RESERVED0F_OS					\
+    QL_IOCTL_CMD(0x15)
+#define EXT_CC_RESERVED0G_OS					\
+    QL_IOCTL_CMD(0x16)
+#define EXT_CC_RESERVED0H_OS					\
+    QL_IOCTL_CMD(0x17)
+#define EXT_CC_RESERVED0I_OS					\
+    QL_IOCTL_CMD(0x18)
+#define EXT_CC_RESERVED0J_OS					\
+    QL_IOCTL_CMD(0x19)
+#define EXT_CC_RESERVED0K_OS                                   \
+    QL_IOCTL_CMD(0x1a)
+#define EXT_CC_RESERVED0L_OS                                   \
+    QL_IOCTL_CMD(0x1b)
+
+#define EXT_DEF_INT_CC_END_IDX		0x1b
+
+/***********************************
+ * NextGen Failover ioctl command
+ * codes range from 0x37 to 0x4f.
+ * See qlnfoln.h
+ ***********************************/
+
+/***********************************
+ * These are a Linux driver specific
+ * commands.
+ * idx range from highest value 0xff
+ * and in decreasing order.
+ ***********************************/
+#define EXT_DEF_DRV_SPC_CC_START_IDX	0xff
+
+#define EXT_CC_GET_HBACNT			/* GET_HBACNT */ \
+    QL_IOCTL_CMD(0xff)
+
+#define EXT_CC_GET_HOST_NO			/* SET_INSTANCE */ \
+    QL_IOCTL_CMD(0xfe)
+
+#define EXT_CC_DRIVER_SPECIFIC			/* DRIVER_SPECIFIC */ \
+    QL_IOCTL_CMD(0xfc)
+
+
+#define EXT_CC_GET_PORT_DEVICE_NAME	QL_IOCTL_CMD(0xfb)
+
+#define EXT_DEF_DRV_SPC_CC_END_IDX	0xfb
+
+/******************************/
+/* Response struct definition */
+/******************************/
+
+/*
+ * HBA Count
+ */
+typedef struct _EXT_HBA_COUNT {
+	UINT16	HbaCnt;				/* 2 */
+} EXT_HBA_COUNT, *PEXT_HBA_COUNT;		/* 2 */
+
+/*
+ * Driver Specific
+ */
+typedef struct _EXT_LN_DRV_VERSION {
+	UINT8   Major;
+	UINT8   Minor;
+	UINT8   Patch;
+	UINT8   Beta;
+	UINT8   Reserved[4];
+} EXT_LN_DRV_VERSION;				/* 8 */
+
+/*
+ * Get Port Device Name (VMWare Specific)
+ */
+typedef struct _EXT_GET_PORT_DEVICE_NAME {
+	UINT8	deviceName[32];
+	UINT8   reserved[32];
+} EXT_GET_PORT_DEVICE_NAME;
+
+typedef struct _EXT_LN_DRIVER_DATA {
+	EXT_LN_DRV_VERSION	DrvVer;		/* 8 */
+	UINT32	Flags;				/* 4 */
+	UINT32	AdapterModel;			/* 4 */
+	UINT32	Reserved[12];			/* 48 */
+} EXT_LN_DRIVER_DATA, *PEXT_LN_DRIVER_DATA;	/* 64 */
+
+/* Bit defines for the Flags field */
+#define EXT_DEF_NGFO_CAPABLE		0x0001	/* bit 0 */
+
+/* Bit defines for the AdapterModel field */
+/* bit 0 to bit 7 are used by FC driver. when adding new bit
+ * definitions they must be unique among all supported drivers
+ */
+#define EXT_DEF_QLA4010_DRIVER		0x0100	/* bit 8 */
+#define EXT_DEF_QLA4022_DRIVER		0x0200	/* bit 9 */
+
+#define EXT_DEF_QLA4XXX_DRIVER				\
+    (EXT_DEF_QLA4010_DRIVER | EXT_DEF_QLA4022_DRIVER)
+
+
+
+#endif //_QLISIOLN_H_
