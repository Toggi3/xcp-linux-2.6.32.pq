diff -r fc7f59d8fe82 drivers/xen/Kconfig
--- a/drivers/xen/Kconfig	Thu Jul 01 00:15:32 2010 -0700
+++ b/drivers/xen/Kconfig	Thu Jul 01 00:19:11 2010 -0700
@@ -66,23 +66,6 @@
 	  as files, in memory, or on other hosts across the network.  This
 	  driver can safely coexist with the existing blockback driver.
 
-config XEN_BLKDEV_TAP2
-	tristate "Block-device tap backend driver 2"
-	depends on XEN_BACKEND
-	default XEN_BACKEND
-	help
-	  The block tap driver is an alternative to the block back driver
-	  and allows VM block requests to be redirected to userspace through
-	  a device interface.  The tap allows user-space development of
-	  high-performance block backends, where disk images may be implemented
-	  as files, in memory, or on other hosts across the network.  This
-	  driver can safely coexist with the existing blockback driver.
-
-config XEN_BLKBACK_PAGEMAP
-	tristate
-	depends on XEN_BLKDEV_BACKEND != n && XEN_BLKDEV_TAP2 != n
-	default XEN_BLKDEV_BACKEND || XEN_BLKDEV_TAP2
-
 config XEN_NETDEV_BACKEND
 	tristate "Network-device backend driver"
         depends on XEN_BACKEND && NET
@@ -441,4 +424,4 @@
          Create entries under /sys/hypervisor describing the Xen
 	 hypervisor environment.  When running native or in another
 	 virtual environment, /sys/hypervisor will still be present,
-	 but will have no xen contents.
\ No newline at end of file
+	 but will have no xen contents.
diff -r fc7f59d8fe82 drivers/xen/Makefile
--- a/drivers/xen/Makefile	Thu Jul 01 00:15:32 2010 -0700
+++ b/drivers/xen/Makefile	Thu Jul 01 00:19:11 2010 -0700
@@ -22,7 +22,6 @@
 obj-$(CONFIG_XENFS)		+= xenfs/
 obj-$(CONFIG_XEN_SYS_HYPERVISOR)	+= sys-hypervisor.o
 obj-$(CONFIG_XEN_BLKDEV_BACKEND)	+= blkback/
-obj-$(CONFIG_XEN_BLKDEV_TAP2)           += blktap2/
 obj-$(CONFIG_XEN_NETDEV_BACKEND)	+= netback/
 obj-$(CONFIG_XEN_TPMDEV_BACKEND)	+= tpmback/
 obj-$(CONFIG_XEN_BLKDEV_FRONTEND)	+= blkfront/
diff -r fc7f59d8fe82 drivers/xen/blkback/Makefile
--- a/drivers/xen/blkback/Makefile	Thu Jul 01 00:15:32 2010 -0700
+++ b/drivers/xen/blkback/Makefile	Thu Jul 01 00:19:11 2010 -0700
@@ -1,4 +1,3 @@
 obj-$(CONFIG_XEN_BLKDEV_BACKEND) := blkbk.o
-obj-$(CONFIG_XEN_BLKBACK_PAGEMAP) += blkback-pagemap.o
 
 blkbk-y	:= blkback.o xenbus.o interface.o vbd.o
diff -r fc7f59d8fe82 drivers/xen/blkback/blkback-pagemap.c
--- a/drivers/xen/blkback/blkback-pagemap.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,96 +0,0 @@
-#include <linux/module.h>
-#include "blkback-pagemap.h"
-
-static int blkback_pagemap_size;
-static struct blkback_pagemap *blkback_pagemap;
-
-static inline int
-blkback_pagemap_entry_clear(struct blkback_pagemap *map)
-{
-	static struct blkback_pagemap zero;
-	return !memcmp(map, &zero, sizeof(zero));
-}
-
-int
-blkback_pagemap_init(int pages)
-{
-	blkback_pagemap = kzalloc(pages * sizeof(struct blkback_pagemap),
-				  GFP_KERNEL);
-	if (!blkback_pagemap)
-		return -ENOMEM;
-
-	blkback_pagemap_size = pages;
-	return 0;
-}
-EXPORT_SYMBOL_GPL(blkback_pagemap_init);
-
-void
-blkback_pagemap_set(int idx, struct page *page,
-		    domid_t domid, busid_t busid, grant_ref_t gref)
-{
-	struct blkback_pagemap *entry;
-
-	BUG_ON(!blkback_pagemap);
-	BUG_ON(idx >= blkback_pagemap_size);
-
-	SetPageBlkback(page);
-	set_page_private(page, idx);
-
-	entry = blkback_pagemap + idx;
-	if (!blkback_pagemap_entry_clear(entry)) {
-		printk("overwriting pagemap %d: d %u b %u g %u\n",
-		       idx, entry->domid, entry->busid, entry->gref);
-		BUG();
-	}
-
-	entry->domid = domid;
-	entry->busid = busid;
-	entry->gref  = gref;
-}
-EXPORT_SYMBOL_GPL(blkback_pagemap_set);
-
-void
-blkback_pagemap_clear(struct page *page)
-{
-	int idx;
-	struct blkback_pagemap *entry;
-
-	idx = (int)page_private(page);
-
-	BUG_ON(!blkback_pagemap);
-	BUG_ON(!PageBlkback(page));
-	BUG_ON(idx >= blkback_pagemap_size);
-
-	entry = blkback_pagemap + idx;
-	if (blkback_pagemap_entry_clear(entry)) {
-		printk("clearing empty pagemap %d\n", idx);
-		BUG();
-	}
-
-	memset(entry, 0, sizeof(*entry));
-}
-EXPORT_SYMBOL_GPL(blkback_pagemap_clear);
-
-struct blkback_pagemap
-blkback_pagemap_read(struct page *page)
-{
-	int idx;
-	struct blkback_pagemap *entry;
-
-	idx = (int)page_private(page);
-
-	BUG_ON(!blkback_pagemap);
-	BUG_ON(!PageBlkback(page));
-	BUG_ON(idx >= blkback_pagemap_size);
-
-	entry = blkback_pagemap + idx;
-	if (blkback_pagemap_entry_clear(entry)) {
-		printk("reading empty pagemap %d\n", idx);
-		BUG();
-	}
-
-	return *entry;
-}
-EXPORT_SYMBOL(blkback_pagemap_read);
-
-MODULE_LICENSE("Dual BSD/GPL");
diff -r fc7f59d8fe82 drivers/xen/blkback/blkback-pagemap.h
--- a/drivers/xen/blkback/blkback-pagemap.h	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,37 +0,0 @@
-#ifndef _BLKBACK_PAGEMAP_H_
-#define _BLKBACK_PAGEMAP_H_
-
-#include <linux/mm.h>
-#include <xen/interface/xen.h>
-#include <xen/interface/grant_table.h>
-
-typedef unsigned int busid_t;
-
-struct blkback_pagemap {
-	domid_t          domid;
-	busid_t          busid;
-	grant_ref_t      gref;
-};
-
-#if defined(CONFIG_XEN_BLKBACK_PAGEMAP) || defined(CONFIG_XEN_BLKBACK_PAGEMAP_MODULE)
-
-int blkback_pagemap_init(int);
-void blkback_pagemap_set(int, struct page *, domid_t, busid_t, grant_ref_t);
-void blkback_pagemap_clear(struct page *);
-struct blkback_pagemap blkback_pagemap_read(struct page *);
-
-#else /* CONFIG_XEN_BLKBACK_PAGEMAP */
-
-static inline int blkback_pagemap_init(int pages) { return 0; }
-static inline void blkback_pagemap_set(int idx, struct page *page, domid_t dom,
-				       busid_t bus, grant_ref_t gnt) {}
-static inline void blkback_pagemap_clear(struct page *page) {}
-static inline struct blkback_pagemap blkback_pagemap_read(struct page *page)
-{
-	BUG();
-	return (struct blkback_pagemap){-1, -1, -1};
-}
-
-#endif /* CONFIG_XEN_BLKBACK_PAGEMAP */
-
-#endif
diff -r fc7f59d8fe82 drivers/xen/blkback/blkback.c
--- a/drivers/xen/blkback/blkback.c	Thu Jul 01 00:15:32 2010 -0700
+++ b/drivers/xen/blkback/blkback.c	Thu Jul 01 00:19:11 2010 -0700
@@ -177,7 +177,6 @@
 		handle = pending_handle(req, i);
 		if (handle == BLKBACK_INVALID_HANDLE)
 			continue;
-		blkback_pagemap_clear(pending_page(req, i));
 		gnttab_set_unmap_op(&unmap[invcount], vaddr(req, i),
 				    GNTMAP_host_map, handle);
 		pending_handle(req, i) = BLKBACK_INVALID_HANDLE;
@@ -482,11 +481,6 @@
 			ret |= GENERAL_ERR;
             if(map[i].status == GNTST_eagain)
 			    ret |= EAGAIN_ERR;
-		} else {
-			blkback_pagemap_set(vaddr_pagenr(pending_req, i),
-					    pending_page(pending_req, i),
-					    blkif->domid, req->handle,
-					    req->seg[i].gref);
 		}
 
 		pending_handle(pending_req, i) = map[i].handle;
@@ -668,9 +662,6 @@
 					mmap_pages, GFP_KERNEL);
 	pending_pages         = alloc_empty_pages_and_pagevec(mmap_pages);
 
-	if (blkback_pagemap_init(mmap_pages))
-		goto out_of_memory;
-
 	if (!pending_reqs || !pending_grant_handles || !pending_pages)
 		goto out_of_memory;
 
diff -r fc7f59d8fe82 drivers/xen/blkback/common.h
--- a/drivers/xen/blkback/common.h	Thu Jul 01 00:15:32 2010 -0700
+++ b/drivers/xen/blkback/common.h	Thu Jul 01 00:19:11 2010 -0700
@@ -43,8 +43,6 @@
 #include <xen/gnttab.h>
 #include <xen/driver_util.h>
 #include <xen/xenbus.h>
-#include "blkback-pagemap.h"
-
 
 #define DPRINTK(_f, _a...)			\
 	pr_debug("(file=%s, line=%d) " _f,	\
diff -r fc7f59d8fe82 drivers/xen/blktap2/Makefile
--- a/drivers/xen/blktap2/Makefile	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,4 +0,0 @@
-obj-$(CONFIG_XEN_BLKDEV_TAP2) := blktap2.o
-
-blktap2-y := control.o ring.o wait_queue.o device.o request.o
-blktap2-$(CONFIG_SYSFS) += sysfs.o
diff -r fc7f59d8fe82 drivers/xen/blktap2/blktap.h
--- a/drivers/xen/blktap2/blktap.h	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,254 +0,0 @@
-#ifndef _BLKTAP_H_
-#define _BLKTAP_H_
-
-#include <linux/fs.h>
-#include <linux/poll.h>
-#include <linux/cdev.h>
-#include <linux/init.h>
-#include <linux/scatterlist.h>
-#include <xen/blkif.h>
-#include <xen/gnttab.h>
-
-//#define ENABLE_PASSTHROUGH
-
-extern int blktap_debug_level;
-
-#define BTPRINTK(level, tag, force, _f, _a...)				\
-	do {								\
-		if (blktap_debug_level > level &&			\
-		    (force || printk_ratelimit()))			\
-			printk(tag "%s: " _f, __func__, ##_a);		\
-	} while (0)
-
-#define BTDBG(_f, _a...)             BTPRINTK(8, KERN_DEBUG, 1, _f, ##_a)
-#define BTINFO(_f, _a...)            BTPRINTK(0, KERN_INFO, 0, _f, ##_a)
-#define BTWARN(_f, _a...)            BTPRINTK(0, KERN_WARNING, 0, _f, ##_a)
-#define BTERR(_f, _a...)             BTPRINTK(0, KERN_ERR, 0, _f, ##_a)
-
-#define MAX_BLKTAP_DEVICE            256
-
-#define BLKTAP_CONTROL               1
-#define BLKTAP_RING_FD               2
-#define BLKTAP_RING_VMA              3
-#define BLKTAP_DEVICE                4
-#define BLKTAP_SYSFS                 5
-#define BLKTAP_PAUSE_REQUESTED       6
-#define BLKTAP_PAUSED                7
-#define BLKTAP_SHUTDOWN_REQUESTED    8
-#define BLKTAP_PASSTHROUGH           9
-#define BLKTAP_DEFERRED              10
-
-/* blktap IOCTLs: */
-#define BLKTAP2_IOCTL_KICK_FE        1
-#define BLKTAP2_IOCTL_ALLOC_TAP	     200
-#define BLKTAP2_IOCTL_FREE_TAP       201
-#define BLKTAP2_IOCTL_CREATE_DEVICE  202
-#define BLKTAP2_IOCTL_SET_PARAMS     203
-#define BLKTAP2_IOCTL_PAUSE          204
-#define BLKTAP2_IOCTL_REOPEN         205
-#define BLKTAP2_IOCTL_RESUME         206
-
-#define BLKTAP2_MAX_MESSAGE_LEN      256
-
-#define BLKTAP2_RING_MESSAGE_PAUSE   1
-#define BLKTAP2_RING_MESSAGE_RESUME  2
-#define BLKTAP2_RING_MESSAGE_CLOSE   3
-
-#define BLKTAP_REQUEST_FREE          0
-#define BLKTAP_REQUEST_PENDING       1
-
-/*
- * The maximum number of requests that can be outstanding at any time
- * is determined by
- *
- *   [mmap_alloc * MAX_PENDING_REQS * BLKIF_MAX_SEGMENTS_PER_REQUEST] 
- *
- * where mmap_alloc < MAX_DYNAMIC_MEM.
- *
- * TODO:
- * mmap_alloc is initialised to 2 and should be adjustable on the fly via
- * sysfs.
- */
-#define BLK_RING_SIZE		__CONST_RING_SIZE(blkif, PAGE_SIZE)
-#define MAX_DYNAMIC_MEM		BLK_RING_SIZE
-#define MAX_PENDING_REQS	BLK_RING_SIZE
-#define MMAP_PAGES (MAX_PENDING_REQS * BLKIF_MAX_SEGMENTS_PER_REQUEST)
-#define MMAP_VADDR(_start, _req, _seg)					\
-        (_start +                                                       \
-         ((_req) * BLKIF_MAX_SEGMENTS_PER_REQUEST * PAGE_SIZE) +        \
-         ((_seg) * PAGE_SIZE))
-
-#define blktap_get(_b) (atomic_inc(&(_b)->refcnt))
-#define blktap_put(_b)					\
-	do {						\
-		if (atomic_dec_and_test(&(_b)->refcnt))	\
-			wake_up(&(_b)->wq);		\
-	} while (0)
-
-struct blktap;
-
-struct grant_handle_pair {
-	grant_handle_t                 kernel;
-	grant_handle_t                 user;
-};
-#define INVALID_GRANT_HANDLE           0xFFFF
-
-struct blktap_handle {
-	unsigned int                   ring;
-	unsigned int                   device;
-	unsigned int                   minor;
-};
-
-struct blktap_params {
-	char                           name[BLKTAP2_MAX_MESSAGE_LEN];
-	unsigned long long             capacity;
-	unsigned long                  sector_size;
-};
-
-struct blktap_device {
-	int                            users;
-	spinlock_t                     lock;
-	struct gendisk                *gd;
-
-#ifdef ENABLE_PASSTHROUGH
-	struct block_device           *bdev;
-#endif
-};
-
-struct blktap_ring {
-	struct vm_area_struct         *vma;
-	blkif_front_ring_t             ring;
-	struct vm_foreign_map          foreign_map;
-	unsigned long                  ring_vstart;
-	unsigned long                  user_vstart;
-
-	int                            response;
-
-	wait_queue_head_t              poll_wait;
-
-	dev_t                          devno;
-	struct device                 *dev;
-	atomic_t                       sysfs_refcnt;
-	struct mutex                   sysfs_mutex;
-};
-
-struct blktap_statistics {
-	unsigned long                  st_print;
-	int                            st_rd_req;
-	int                            st_wr_req;
-	int                            st_oo_req;
-	int                            st_rd_sect;
-	int                            st_wr_sect;
-	s64                            st_rd_cnt;
-	s64                            st_rd_sum_usecs;
-	s64                            st_rd_max_usecs;
-	s64                            st_wr_cnt;
-	s64                            st_wr_sum_usecs;
-	s64                            st_wr_max_usecs;	
-};
-
-struct blktap_request {
-	uint64_t                       id;
-	uint16_t                       usr_idx;
-
-	uint8_t                        status;
-	atomic_t                       pendcnt;
-	uint8_t                        nr_pages;
-	unsigned short                 operation;
-
-	struct timeval                 time;
-	struct grant_handle_pair       handles[BLKIF_MAX_SEGMENTS_PER_REQUEST];
-	struct list_head               free_list;
-};
-
-struct blktap {
-	int                            minor;
-	pid_t                          pid;
-	atomic_t                       refcnt;
-	unsigned long                  dev_inuse;
-
-	struct blktap_params           params;
-
-	struct rw_semaphore            tap_sem;
-
-	struct blktap_ring             ring;
-	struct blktap_device           device;
-
-	int                            pending_cnt;
-	struct blktap_request         *pending_requests[MAX_PENDING_REQS];
-	struct scatterlist             sg[BLKIF_MAX_SEGMENTS_PER_REQUEST];
-
-	wait_queue_head_t              wq;
-	struct list_head               deferred_queue;
-
-	struct blktap_statistics       stats;
-};
-
-extern struct blktap *blktaps[MAX_BLKTAP_DEVICE];
-
-static inline int
-blktap_active(struct blktap *tap)
-{
-	return test_bit(BLKTAP_RING_VMA, &tap->dev_inuse);
-}
-
-static inline int
-blktap_validate_params(struct blktap *tap, struct blktap_params *params)
-{
-	/* TODO: sanity check */
-	params->name[sizeof(params->name) - 1] = '\0';
-	BTINFO("%s: capacity: %llu, sector-size: %lu\n",
-	       params->name, params->capacity, params->sector_size);
-	return 0;
-}
-
-int blktap_control_destroy_device(struct blktap *);
-
-int blktap_ring_init(int *);
-int blktap_ring_free(void);
-int blktap_ring_create(struct blktap *);
-int blktap_ring_destroy(struct blktap *);
-int blktap_ring_pause(struct blktap *);
-int blktap_ring_resume(struct blktap *);
-void blktap_ring_kick_user(struct blktap *);
-
-int blktap_sysfs_init(void);
-void blktap_sysfs_free(void);
-int blktap_sysfs_create(struct blktap *);
-int blktap_sysfs_destroy(struct blktap *);
-
-int blktap_device_init(int *);
-void blktap_device_free(void);
-int blktap_device_create(struct blktap *);
-int blktap_device_destroy(struct blktap *);
-int blktap_device_pause(struct blktap *);
-int blktap_device_resume(struct blktap *);
-void blktap_device_restart(struct blktap *);
-void blktap_device_finish_request(struct blktap *,
-				  blkif_response_t *,
-				  struct blktap_request *);
-void blktap_device_fail_pending_requests(struct blktap *);
-#ifdef ENABLE_PASSTHROUGH
-int blktap_device_enable_passthrough(struct blktap *,
-				     unsigned, unsigned);
-#endif
-
-void blktap_defer(struct blktap *);
-void blktap_run_deferred(void);
-
-int blktap_request_pool_init(void);
-void blktap_request_pool_free(void);
-int blktap_request_pool_grow(void);
-int blktap_request_pool_shrink(void);
-struct blktap_request *blktap_request_allocate(struct blktap *);
-void blktap_request_free(struct blktap *, struct blktap_request *);
-struct page *request_to_page(struct blktap_request *, int);
-
-static inline unsigned long
-request_to_kaddr(struct blktap_request *req, int seg)
-{
-	unsigned long pfn = page_to_pfn(request_to_page(req, seg));
-	return (unsigned long)pfn_to_kaddr(pfn);
-}
-
-#endif
diff -r fc7f59d8fe82 drivers/xen/blktap2/control.c
--- a/drivers/xen/blktap2/control.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,278 +0,0 @@
-#include <linux/module.h>
-#include <linux/miscdevice.h>
-
-#include "blktap.h"
-
-static DEFINE_SPINLOCK(blktap_control_lock);
-struct blktap *blktaps[MAX_BLKTAP_DEVICE];
-
-static int ring_major;
-static int device_major;
-static int blktap_control_registered;
-
-static void
-blktap_control_initialize_tap(struct blktap *tap)
-{
-	int minor = tap->minor;
-
-	memset(tap, 0, sizeof(*tap));
-	set_bit(BLKTAP_CONTROL, &tap->dev_inuse);
-	init_rwsem(&tap->tap_sem);
-	sg_init_table(tap->sg, BLKIF_MAX_SEGMENTS_PER_REQUEST);
-	init_waitqueue_head(&tap->wq);
-	atomic_set(&tap->refcnt, 0);
-
-	tap->minor = minor;
-}
-
-static struct blktap *
-blktap_control_create_tap(void)
-{
-	int minor;
-	struct blktap *tap;
-
-	tap = kmalloc(sizeof(*tap), GFP_KERNEL);
-	if (unlikely(!tap))
-		return NULL;
-
-	blktap_control_initialize_tap(tap);
-
-	spin_lock_irq(&blktap_control_lock);
-	for (minor = 0; minor < MAX_BLKTAP_DEVICE; minor++)
-		if (!blktaps[minor])
-			break;
-
-	if (minor == MAX_BLKTAP_DEVICE) {
-		kfree(tap);
-		tap = NULL;
-		goto out;
-	}
-
-	tap->minor = minor;
-	blktaps[minor] = tap;
-
-out:
-	spin_unlock_irq(&blktap_control_lock);
-	return tap;
-}
-
-static struct blktap *
-blktap_control_allocate_tap(void)
-{
-	int err, minor;
-	struct blktap *tap;
-
-	/*
-	 * This is called only from the ioctl, which
-	 * means we should always have interrupts enabled.
-	 */
-	BUG_ON(irqs_disabled());
-
-	spin_lock_irq(&blktap_control_lock);
-
-	for (minor = 0; minor < MAX_BLKTAP_DEVICE; minor++) {
-		tap = blktaps[minor];
-		if (!tap)
-			goto found;
-
-		if (!tap->dev_inuse) {
-			blktap_control_initialize_tap(tap);
-			goto found;
-		}
-	}
-
-	tap = NULL;
-
-found:
-	spin_unlock_irq(&blktap_control_lock);
-
-	if (!tap) {
-		tap = blktap_control_create_tap();
-		if (!tap)
-			return NULL;
-	}
-
-	err = blktap_ring_create(tap);
-	if (err) {
-		BTERR("ring creation failed: %d\n", err);
-		clear_bit(BLKTAP_CONTROL, &tap->dev_inuse);
-		return NULL;
-	}
-
-	BTINFO("allocated tap %p\n", tap);
-	return tap;
-}
-
-static int
-blktap_control_ioctl(struct inode *inode, struct file *filp,
-		     unsigned int cmd, unsigned long arg)
-{
-	unsigned long dev;
-	struct blktap *tap;
-
-	switch (cmd) {
-	case BLKTAP2_IOCTL_ALLOC_TAP: {
-		struct blktap_handle h;
-
-		tap = blktap_control_allocate_tap();
-		if (!tap) {
-			BTERR("error allocating device\n");
-			return -ENOMEM;
-		}
-
-		h.ring   = ring_major;
-		h.device = device_major;
-		h.minor  = tap->minor;
-
-		if (copy_to_user((struct blktap_handle __user *)arg,
-				 &h, sizeof(h))) {
-			blktap_control_destroy_device(tap);
-			return -EFAULT;
-		}
-
-		return 0;
-	}
-
-	case BLKTAP2_IOCTL_FREE_TAP:
-		dev = arg;
-
-		if (dev >= MAX_BLKTAP_DEVICE || !blktaps[dev])
-			return -EINVAL;
-
-		blktap_control_destroy_device(blktaps[dev]);
-		return 0;
-	}
-
-	return -ENOIOCTLCMD;
-}
-
-static struct file_operations blktap_control_file_operations = {
-	.owner    = THIS_MODULE,
-	.ioctl    = blktap_control_ioctl,
-};
-
-static struct miscdevice blktap_misc = {
-	.minor    = MISC_DYNAMIC_MINOR,
-	.name     = "blktap-control",
-	.fops     = &blktap_control_file_operations,
-};
-
-int
-blktap_control_destroy_device(struct blktap *tap)
-{
-	int err;
-	unsigned long inuse;
-
-	if (!tap)
-		return 0;
-
-	set_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse);
-
-	for (;;) {
-		inuse = tap->dev_inuse;
-		err   = blktap_device_destroy(tap);
-		if (err)
-			goto wait;
-
-		inuse = tap->dev_inuse;
-		err   = blktap_ring_destroy(tap);
-		if (err)
-			goto wait;
-
-		inuse = tap->dev_inuse;
-		err   = blktap_sysfs_destroy(tap);
-		if (err)
-			goto wait;
-
-		break;
-
-	wait:
-		BTDBG("inuse: 0x%lx, dev_inuse: 0x%lx\n",
-		      inuse, tap->dev_inuse);
-		if (wait_event_interruptible(tap->wq, tap->dev_inuse != inuse))
-			break;
-	}
-
-	clear_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse);
-
-	if (tap->dev_inuse == (1UL << BLKTAP_CONTROL)) {
-		err = 0;
-		clear_bit(BLKTAP_CONTROL, &tap->dev_inuse);
-	}
-
-	return err;
-}
-
-static int __init
-blktap_control_init(void)
-{
-	int err;
-
-	err = misc_register(&blktap_misc);
-	if (err) {
-		BTERR("misc_register failed for control device");
-		return err;
-	}
-
-	blktap_control_registered = 1;
-	return 0;
-}
-
-static void
-blktap_control_free(void)
-{
-	int i;
-
-	for (i = 0; i < MAX_BLKTAP_DEVICE; i++)
-		blktap_control_destroy_device(blktaps[i]);
-
-	if (blktap_control_registered)
-		if (misc_deregister(&blktap_misc) < 0)
-			BTERR("misc_deregister failed for control device");
-}
-
-static void
-blktap_exit(void)
-{
-	blktap_control_free();
-	blktap_ring_free();
-	blktap_sysfs_free();
-	blktap_device_free();
-	blktap_request_pool_free();
-}
-
-static int __init
-blktap_init(void)
-{
-	int err;
-
-	err = blktap_request_pool_init();
-	if (err)
-		return err;
-
-	err = blktap_device_init(&device_major);
-	if (err)
-		goto fail;
-
-	err = blktap_ring_init(&ring_major);
-	if (err)
-		goto fail;
-
-	err = blktap_sysfs_init();
-	if (err)
-		goto fail;
-
-	err = blktap_control_init();
-	if (err)
-		goto fail;
-
-	return 0;
-
-fail:
-	blktap_exit();
-	return err;
-}
-
-module_init(blktap_init);
-module_exit(blktap_exit);
-MODULE_LICENSE("Dual BSD/GPL");
diff -r fc7f59d8fe82 drivers/xen/blktap2/device.c
--- a/drivers/xen/blktap2/device.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,1187 +0,0 @@
-#include <linux/fs.h>
-#include <linux/blkdev.h>
-#include <linux/cdrom.h>
-#include <linux/hdreg.h>
-#include <linux/module.h>
-#include <linux/version.h>
-#include <asm/tlbflush.h>
-
-#include <scsi/scsi.h>
-#include <scsi/scsi_ioctl.h>
-
-#include <xen/xenbus.h>
-#include <xen/interface/io/blkif.h>
-
-#include "blktap.h"
-
-#include "../blkback/blkback-pagemap.h"
-
-#if 0
-#define DPRINTK_IOCTL(_f, _a...) printk(KERN_ALERT _f, ## _a)
-#else
-#define DPRINTK_IOCTL(_f, _a...) ((void)0)
-#endif
-
-struct blktap_grant_table {
-	int cnt;
-	struct gnttab_map_grant_ref grants[BLKIF_MAX_SEGMENTS_PER_REQUEST * 2];
-};
-
-static int blktap_device_major;
-
-static inline struct blktap *
-dev_to_blktap(struct blktap_device *dev)
-{
-	return container_of(dev, struct blktap, device);
-}
-
-static int
-blktap_device_open(struct block_device *bd, fmode_t mode)
-{
-	struct blktap *tap;
-	struct blktap_device *dev = bd->bd_disk->private_data;
-
-	if (!dev)
-		return -ENOENT;
-
-	tap = dev_to_blktap(dev);
-	if (!blktap_active(tap) ||
-	    test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse))
-		return -ENOENT;
-
-	dev->users++;
-
-	return 0;
-}
-
-static int
-blktap_device_release(struct gendisk *disk, fmode_t mode)
-{
-	struct blktap_device *dev = disk->private_data;
-	struct blktap *tap = dev_to_blktap(dev);
-
-	dev->users--;
-	if (test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse))
-		blktap_device_destroy(tap);
-
-	return 0;
-}
-
-static int
-blktap_device_getgeo(struct block_device *bd, struct hd_geometry *hg)
-{
-	/* We don't have real geometry info, but let's at least return
-	   values consistent with the size of the device */
-	sector_t nsect = get_capacity(bd->bd_disk);
-	sector_t cylinders = nsect;
-
-	hg->heads = 0xff;
-	hg->sectors = 0x3f;
-	sector_div(cylinders, hg->heads * hg->sectors);
-	hg->cylinders = cylinders;
-	if ((sector_t)(hg->cylinders + 1) * hg->heads * hg->sectors < nsect)
-		hg->cylinders = 0xffff;
-	return 0;
-}
-
-static int
-blktap_device_ioctl(struct block_device *bd, fmode_t mode,
-		    unsigned command, unsigned long argument)
-{
-	int i;
-
-	DPRINTK_IOCTL("command: 0x%x, argument: 0x%lx\n",
-		      command, (long)argument);
-
-	switch (command) {
-#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,16)
-	case HDIO_GETGEO: {
-		struct hd_geometry geo;
-		int ret;
-
-                if (!argument)
-                        return -EINVAL;
-
-		geo.start = get_start_sect(bd);
-		ret = blktap_device_getgeo(bd, &geo);
-		if (ret)
-			return ret;
-
-		if (copy_to_user((struct hd_geometry __user *)argument, &geo,
-				 sizeof(geo)))
-                        return -EFAULT;
-
-                return 0;
-	}
-#endif
-	case CDROMMULTISESSION:
-		BTDBG("FIXME: support multisession CDs later\n");
-		for (i = 0; i < sizeof(struct cdrom_multisession); i++)
-			if (put_user(0, (char __user *)(argument + i)))
-				return -EFAULT;
-		return 0;
-
-	case SCSI_IOCTL_GET_IDLUN:
-		if (!access_ok(VERIFY_WRITE, argument, 
-			sizeof(struct scsi_idlun)))
-			return -EFAULT;
-
-		/* return 0 for now. */
-		__put_user(0, &((struct scsi_idlun __user *)argument)->dev_id);
-		__put_user(0, 
-			&((struct scsi_idlun __user *)argument)->host_unique_id);
-		return 0;
-
-	default:
-		/*printk(KERN_ALERT "ioctl %08x not supported by Xen blkdev\n",
-		  command);*/
-		return -EINVAL; /* same return as native Linux */
-	}
-
-	return 0;
-}
-
-static const struct block_device_operations blktap_device_file_operations = {
-	.owner     = THIS_MODULE,
-	.open      = blktap_device_open,
-	.release   = blktap_device_release,
-	.ioctl     = blktap_device_ioctl,
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,16)
-	.getgeo    = blktap_device_getgeo
-#endif
-};
-
-static int
-blktap_map_uaddr_fn(pte_t *ptep, struct page *pmd_page,
-		    unsigned long addr, void *data)
-{
-	pte_t *pte = (pte_t *)data;
-
-	BTDBG("ptep %p -> %012llx\n", ptep, (unsigned long long)pte_val(*pte));
-	set_pte(ptep, *pte);
-	return 0;
-}
-
-static int
-blktap_map_uaddr(struct vm_area_struct *vma, unsigned long address, pte_t pte)
-{
-	return apply_to_page_range(vma ? vma->vm_mm : NULL, address,
-				   PAGE_SIZE, blktap_map_uaddr_fn, &pte);
-}
-
-static int
-blktap_umap_uaddr_fn(pte_t *ptep, struct page *pmd_page,
-		     unsigned long addr, void *data)
-{
-	struct vm_area_struct *vma = data;
-
-	BTDBG("ptep %p\n", ptep);
-	xen_ptep_get_and_clear_full(vma, addr, ptep, 1);
-	return 0;
-}
-
-static int
-blktap_umap_uaddr(struct vm_area_struct *vma, unsigned long address)
-{
-	struct mm_struct *mm = NULL;
-
-	if (!vma) {
-#ifdef CONFIG_X86
-		if (HYPERVISOR_update_va_mapping(address, __pte(0),
-						 UVMF_INVLPG|UVMF_ALL))
-			BUG();
-		return 1;
-#endif
-	} else
-		mm = vma->vm_mm;
-	return apply_to_page_range(mm, address,
-				   PAGE_SIZE, blktap_umap_uaddr_fn, vma);
-}
-
-static inline void
-flush_tlb_kernel_page(unsigned long kvaddr)
-{
-#ifdef CONFIG_X86
-	xen_invlpg_all(kvaddr);
-#else
-	flush_tlb_kernel_range(kvaddr, kvaddr + PAGE_SIZE);
-#endif
-}
-
-/*
- * tap->tap_sem held on entry
- */
-static void
-blktap_device_fast_flush(struct blktap *tap, struct blktap_request *request)
-{
-	uint64_t ptep;
-	int ret, usr_idx;
-	unsigned int i, cnt;
-	struct page **map, *page;
-	struct blktap_ring *ring;
-	struct grant_handle_pair *khandle;
-	unsigned long kvaddr, uvaddr, offset;
-	struct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST * 2];
-	grant_handle_t self_gref[BLKIF_MAX_SEGMENTS_PER_REQUEST];
-	int self_gref_nr = 0;
-
-	cnt     = 0;
-	ring    = &tap->ring;
-	usr_idx = request->usr_idx;
-	map     = ring->foreign_map.map;
-
-	if (!ring->vma)
-		return;
-
-	if (xen_feature(XENFEAT_auto_translated_physmap))
-		zap_page_range(ring->vma, 
-			       MMAP_VADDR(ring->user_vstart, usr_idx, 0),
-			       request->nr_pages << PAGE_SHIFT, NULL);
-
-	for (i = 0; i < request->nr_pages; i++) {
-		kvaddr = request_to_kaddr(request, i);
-		uvaddr = MMAP_VADDR(ring->user_vstart, usr_idx, i);
-
-		khandle = request->handles + i;
-
-		if (khandle->kernel != INVALID_GRANT_HANDLE) {
-			gnttab_set_unmap_op(&unmap[cnt], kvaddr,
-					    GNTMAP_host_map, khandle->kernel);
-			cnt++;
-			set_phys_to_machine(__pa(kvaddr) >> PAGE_SHIFT,
-					    INVALID_P2M_ENTRY);
-		}
-
-		if (khandle->user != INVALID_GRANT_HANDLE) {
-			BUG_ON(xen_feature(XENFEAT_auto_translated_physmap));
-			if (create_lookup_pte_addr(ring->vma->vm_mm,
-						   uvaddr, &ptep) != 0) {
-				BTERR("Couldn't get a pte addr!\n");
-				return;
-			}
-
-			gnttab_set_unmap_op(&unmap[cnt], ptep,
-					    GNTMAP_host_map
-					    | GNTMAP_application_map
-					    | GNTMAP_contains_pte,
-					    khandle->user);
-			cnt++;
-		}
-
-		offset = (uvaddr - ring->vma->vm_start) >> PAGE_SHIFT;
-
-		BTDBG("offset: 0x%08lx, page: %p, request: %p, usr_idx: %d, "
-		      "seg: %d, kvaddr: 0x%08lx, khandle: %u, uvaddr: "
-		      "0x%08lx, handle: %u\n", offset, map[offset], request,
-		      usr_idx, i, kvaddr, khandle->kernel, uvaddr,
-		      khandle->user);
-
-		page = map[offset];
-		if (page) {
-			ClearPageReserved(map[offset]);
-			if (PageBlkback(page)) {
-				ClearPageBlkback(page);
-				set_page_private(page, 0);
-			} else if (
-				xen_feature(XENFEAT_auto_translated_physmap)) {
-				self_gref[self_gref_nr] = khandle->kernel;
-				self_gref_nr++;
-			}
-		}
-		map[offset] = NULL;
-
-		khandle->kernel = INVALID_GRANT_HANDLE;
-		khandle->user   = INVALID_GRANT_HANDLE;
-	}
-
-	if (cnt) {
-		ret = HYPERVISOR_grant_table_op(GNTTABOP_unmap_grant_ref,
-						unmap, cnt);
-		BUG_ON(ret);
-	}
-
-	if (!xen_feature(XENFEAT_auto_translated_physmap))
-		zap_page_range(ring->vma, 
-			       MMAP_VADDR(ring->user_vstart, usr_idx, 0), 
-			       request->nr_pages << PAGE_SHIFT, NULL);
-	else {
-		for (i = 0; i < self_gref_nr; i++) {
-			gnttab_end_foreign_access_ref(self_gref[i]);
-		}
-	}
-}
-
-/*
- * tap->tap_sem held on entry
- */
-static void
-blktap_unmap(struct blktap *tap, struct blktap_request *request)
-{
-	int i, usr_idx;
-	unsigned long kvaddr;
-
-	usr_idx = request->usr_idx;
-	down_write(&tap->ring.vma->vm_mm->mmap_sem);
-
-	for (i = 0; i < request->nr_pages; i++) {
-		kvaddr = request_to_kaddr(request, i);
-		BTDBG("request: %p, seg: %d, kvaddr: 0x%08lx, khandle: %u, "
-		      "uvaddr: 0x%08lx, uhandle: %u\n", request, i,
-		      kvaddr, request->handles[i].kernel,
-		      MMAP_VADDR(tap->ring.user_vstart, usr_idx, i),
-		      request->handles[i].user);
-
-		if (!xen_feature(XENFEAT_auto_translated_physmap) &&
-		    request->handles[i].kernel == INVALID_GRANT_HANDLE) {
-			if (blktap_umap_uaddr(NULL, kvaddr) == 0)
-				flush_tlb_kernel_page(kvaddr);
-			set_phys_to_machine(__pa(kvaddr) >> PAGE_SHIFT,
-					    INVALID_P2M_ENTRY);
-		}
-	}
-
-	blktap_device_fast_flush(tap, request);
-	up_write(&tap->ring.vma->vm_mm->mmap_sem);
-}
-
-/*
- * called if the tapdisk process dies unexpectedly.
- * fail and release any pending requests and disable queue.
- */
-void
-blktap_device_fail_pending_requests(struct blktap *tap)
-{
-	int usr_idx;
-	struct request *req;
-	struct blktap_device *dev;
-	struct blktap_request *request;
-
-	if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse))
-		return;
-
-	down_write(&tap->tap_sem);
-
-	dev = &tap->device;
-	for (usr_idx = 0; usr_idx < MAX_PENDING_REQS; usr_idx++) {
-		request = tap->pending_requests[usr_idx];
-		if (!request || request->status != BLKTAP_REQUEST_PENDING)
-			continue;
-
-		BTERR("%u:%u: failing pending %s of %d pages\n",
-		      blktap_device_major, tap->minor,
-		      (request->operation == BLKIF_OP_READ ?
-		       "read" : "write"), request->nr_pages);
-
-		blktap_unmap(tap, request);
-		req = (struct request *)(unsigned long)request->id;
-		blk_end_request_all(req, -ENODEV);
-		blktap_request_free(tap, request);
-	}
-
-	up_write(&tap->tap_sem);
-
-	spin_lock_irq(&dev->lock);
-
-	/* fail any future requests */
-	dev->gd->queue->queuedata = NULL;
-	blk_start_queue(dev->gd->queue);
-
-	spin_unlock_irq(&dev->lock);
-}
-
-/*
- * tap->tap_sem held on entry
- */
-void
-blktap_device_finish_request(struct blktap *tap,
-			     blkif_response_t *res,
-			     struct blktap_request *request)
-{
-	struct request *req;
-
-	blktap_unmap(tap, request);
-
-	req = (struct request *)(unsigned long)request->id;
-
-	BTDBG("req %p res status %d operation %d/%d id %lld\n", req,
-	      res->status, res->operation, request->operation,
-	      (unsigned long long)res->id);
-
-	switch (request->operation) {
-	case BLKIF_OP_READ:
-	case BLKIF_OP_WRITE:
-		if (unlikely(res->status != BLKIF_RSP_OKAY))
-			BTERR("Bad return from device data "
-				"request: %x\n", res->status);
-		blk_end_request_all(req,
-			res->status == BLKIF_RSP_OKAY ? 0 : -EIO);
-		break;
-	default:
-		BUG();
-	}
-
-	blktap_request_free(tap, request);
-}
-
-static int
-blktap_prep_foreign(struct blktap *tap,
-		    struct blktap_request *request,
-		    blkif_request_t *blkif_req,
-		    unsigned int seg, struct page *page,
-		    struct blktap_grant_table *table)
-{
-	uint64_t ptep;
-	uint32_t flags;
-	struct page *tap_page;
-	struct blktap_ring *ring;
-	struct blkback_pagemap map;
-	unsigned long uvaddr, kvaddr;
-
-	ring = &tap->ring;
-	map  = blkback_pagemap_read(page);
-	blkif_req->seg[seg].gref = map.gref;
-
-	uvaddr = MMAP_VADDR(ring->user_vstart, request->usr_idx, seg);
-	kvaddr = request_to_kaddr(request, seg);
-	flags  = GNTMAP_host_map |
-		(request->operation == BLKIF_OP_WRITE ? GNTMAP_readonly : 0);
-
-	gnttab_set_map_op(&table->grants[table->cnt],
-			  kvaddr, flags, map.gref, map.domid);
-	table->cnt++;
-
-	/* enable chained tap devices */
-	tap_page = request_to_page(request, seg);
-	set_page_private(tap_page, page_private(page));
-	SetPageBlkback(tap_page);
-
-	if (xen_feature(XENFEAT_auto_translated_physmap))
-		return 0;
-
-	if (create_lookup_pte_addr(ring->vma->vm_mm, uvaddr, &ptep)) {
-		BTERR("couldn't get a pte addr!\n");
-		return -1;
-	}
-
-	flags |= GNTMAP_application_map | GNTMAP_contains_pte;
-	gnttab_set_map_op(&table->grants[table->cnt],
-			  ptep, flags, map.gref, map.domid);
-	table->cnt++;
-
-	return 0;
-}
-
-static int
-blktap_map_foreign(struct blktap *tap,
-		   struct blktap_request *request,
-		   blkif_request_t *blkif_req,
-		   struct blktap_grant_table *table)
-{
-	struct page *page;
-	int i, grant, err, usr_idx;
-	struct blktap_ring *ring;
-	unsigned long uvaddr, foreign_mfn;
-
-	if (!table->cnt)
-		return 0;
-
-	err = HYPERVISOR_grant_table_op(GNTTABOP_map_grant_ref,
-					table->grants, table->cnt);
-	BUG_ON(err);
-
-	grant   = 0;
-	usr_idx = request->usr_idx;
-	ring    = &tap->ring;
-
-	for (i = 0; i < request->nr_pages; i++) {
-		if (!blkif_req->seg[i].gref)
-			continue;
-
-		uvaddr = MMAP_VADDR(ring->user_vstart, usr_idx, i);
-
-		if (unlikely(table->grants[grant].status)) {
-			BTERR("invalid kernel buffer: could not remap it\n");
-            /* This should never happen: blkback should handle eagain first */
-            BUG_ON(table->grants[grant].status == GNTST_eagain);
-			err |= 1;
-			table->grants[grant].handle = INVALID_GRANT_HANDLE;
-		}
-
-		request->handles[i].kernel = table->grants[grant].handle;
-		foreign_mfn = table->grants[grant].dev_bus_addr >> PAGE_SHIFT;
-		grant++;
-
-		if (xen_feature(XENFEAT_auto_translated_physmap))
-			goto done;
-
-		if (unlikely(table->grants[grant].status)) {
-			BTERR("invalid user buffer: could not remap it\n");
-			err |= 1;
-			table->grants[grant].handle = INVALID_GRANT_HANDLE;
-		}
-
-		request->handles[i].user = table->grants[grant].handle;
-		grant++;
-
-	done:
-		if (err)
-			continue;
-
-		page = request_to_page(request, i);
-
-		if (!xen_feature(XENFEAT_auto_translated_physmap))
-			set_phys_to_machine(page_to_pfn(page),
-					    FOREIGN_FRAME(foreign_mfn));
-		else if (vm_insert_page(ring->vma, uvaddr, page))
-			err |= 1;
-
-		BTDBG("pending_req: %p, seg: %d, page: %p, "
-		      "kvaddr: 0x%p, khandle: %u, uvaddr: 0x%08lx, "
-		      "uhandle: %u\n", request, i, page,
-		      pfn_to_kaddr(page_to_pfn(page)),
-		      request->handles[i].kernel,
-		      uvaddr, request->handles[i].user);
-	}
-
-	return err;
-}
-
-static int
-blktap_map(struct blktap *tap,
-	   struct blktap_request *request,
-	   unsigned int seg, struct page *page)
-{
-	pte_t pte;
-	int usr_idx;
-	struct blktap_ring *ring;
-	unsigned long uvaddr, kvaddr;
-	int err = 0;
-
-	ring    = &tap->ring;
-	usr_idx = request->usr_idx;
-	uvaddr  = MMAP_VADDR(ring->user_vstart, usr_idx, seg);
-	kvaddr  = request_to_kaddr(request, seg);
-
-	if (!xen_feature(XENFEAT_auto_translated_physmap)) {
-		pte = mk_pte(page, ring->vma->vm_page_prot);
-		blktap_map_uaddr(ring->vma, uvaddr,
-				 pte_mkspecial(pte_mkwrite(pte)));
-		flush_tlb_page(ring->vma, uvaddr);
-		blktap_map_uaddr(NULL, kvaddr, mk_pte(page, PAGE_KERNEL));
-		flush_tlb_kernel_page(kvaddr);
-
-		set_phys_to_machine(__pa(kvaddr) >> PAGE_SHIFT, pte_mfn(pte));
-		request->handles[seg].kernel = INVALID_GRANT_HANDLE;
-	} else {
-		/* grant this page access to self domain and map it. */
-		domid_t domid = 0; /* XXX my domian id: grant table hypercall
-				      doesn't understand DOMID_SELF */
-		int gref;
-		uint32_t flags;
-		struct gnttab_map_grant_ref map;
-		struct page *tap_page;
-
-		gref = gnttab_grant_foreign_access(
-			domid, page_to_pfn(page),
-			(request->operation == BLKIF_OP_WRITE)?
-			GTF_readonly: 0);
-
-		flags  = GNTMAP_host_map |
-			(request->operation == BLKIF_OP_WRITE ?
-			 GNTMAP_readonly : 0);
-
-		gnttab_set_map_op(&map, kvaddr, flags, gref, domid);
-
-		/* enable chained tap devices */
-		tap_page = request_to_page(request, seg);
-		set_page_private(tap_page, page_private(page));
-		SetPageBlkback(tap_page);
-
-		err = HYPERVISOR_grant_table_op(GNTTABOP_map_grant_ref,
-						&map, 1);
-		BUG_ON(err);
-        /* We are not expecting the grant op to fail */
-        BUG_ON(map.status != GNTST_okay);
-
-		err = vm_insert_page(ring->vma, uvaddr, tap_page);
-		if (err) {
-			struct gnttab_unmap_grant_ref unmap;
-			gnttab_set_unmap_op(&unmap, kvaddr,
-					    GNTMAP_host_map, gref);
-			VOID(HYPERVISOR_grant_table_op(
-				GNTTABOP_unmap_grant_ref, &unmap, 1));
-		} else
-			request->handles[seg].kernel = gref;
-	}
-	request->handles[seg].user = INVALID_GRANT_HANDLE;
-
-	BTDBG("pending_req: %p, seg: %d, page: %p, kvaddr: 0x%08lx, "
-	      "uvaddr: 0x%08lx\n", request, seg, page, kvaddr,
-	      uvaddr);
-
-	return err;
-}
-
-static int
-blktap_device_process_request(struct blktap *tap,
-			      struct blktap_request *request,
-			      struct request *req)
-{
-	struct page *page;
-	int i, usr_idx, err;
-	struct blktap_ring *ring;
-	struct scatterlist *sg;
-	struct blktap_grant_table table;
-	unsigned int fsect, lsect, nr_sects;
-	unsigned long offset, uvaddr;
-	struct blkif_request blkif_req, *target;
-
-	err = -1;
-	memset(&table, 0, sizeof(table));
-
-	if (!blktap_active(tap))
-		goto out;
-
-	ring    = &tap->ring;
-	usr_idx = request->usr_idx;
-	blkif_req.id = usr_idx;
-	blkif_req.sector_number = (blkif_sector_t)blk_rq_pos(req);
-	blkif_req.handle = 0;
-	blkif_req.operation = rq_data_dir(req) ?
-		BLKIF_OP_WRITE : BLKIF_OP_READ;
-
-	request->id        = (unsigned long)req;
-	request->operation = blkif_req.operation;
-	request->status    = BLKTAP_REQUEST_PENDING;
-	do_gettimeofday(&request->time);
-
-	nr_sects = 0;
-	request->nr_pages = 0;
-	blkif_req.nr_segments = blk_rq_map_sg(req->q, req, tap->sg);
-	BUG_ON(blkif_req.nr_segments > BLKIF_MAX_SEGMENTS_PER_REQUEST);
-	for_each_sg(tap->sg, sg, blkif_req.nr_segments, i) {
-			fsect = sg->offset >> 9;
-			lsect = fsect + (sg->length >> 9) - 1;
-			nr_sects += sg->length >> 9;
-
-			blkif_req.seg[i] =
-				(struct blkif_request_segment) {
-				.gref       = 0,
-				.first_sect = fsect,
-				.last_sect  = lsect };
-
-			if (PageBlkback(sg_page(sg))) {
-				/* foreign page -- use xen */
-				if (blktap_prep_foreign(tap,
-							request,
-							&blkif_req,
-							i,
-							sg_page(sg),
-							&table))
-					goto out;
-			} else {
-				/* do it the old fashioned way */
-				if (blktap_map(tap,
-					       request,
-					       i,
-					       sg_page(sg)))
-					goto out;
-			}
-
-			uvaddr = MMAP_VADDR(ring->user_vstart, usr_idx, i);
-			offset = (uvaddr - ring->vma->vm_start) >> PAGE_SHIFT;
-			page   = request_to_page(request, i);
-			ring->foreign_map.map[offset] = page;
-			SetPageReserved(page);
-
-			BTDBG("mapped uaddr %08lx to page %p pfn 0x%lx\n",
-			      uvaddr, page, page_to_pfn(page));
-			BTDBG("offset: 0x%08lx, pending_req: %p, seg: %d, "
-			      "page: %p, kvaddr: %p, uvaddr: 0x%08lx\n",
-			      offset, request, i,
-			      page, pfn_to_kaddr(page_to_pfn(page)), uvaddr);
-
-			request->nr_pages++;
-	}
-
-	if (blktap_map_foreign(tap, request, &blkif_req, &table))
-		goto out;
-
-	/* Finally, write the request message to the user ring. */
-	target = RING_GET_REQUEST(&ring->ring, ring->ring.req_prod_pvt);
-	memcpy(target, &blkif_req, sizeof(blkif_req));
-	target->id = request->usr_idx;
-	wmb(); /* blktap_poll() reads req_prod_pvt asynchronously */
-	ring->ring.req_prod_pvt++;
-
-	if (rq_data_dir(req)) {
-		tap->stats.st_wr_sect += nr_sects;
-		tap->stats.st_wr_req++;
-	} else {
-		tap->stats.st_rd_sect += nr_sects;
-		tap->stats.st_rd_req++;
-	}
-
-	err = 0;
-
-out:
-	if (err)
-		blktap_device_fast_flush(tap, request);
-	return err;
-}
-
-#ifdef ENABLE_PASSTHROUGH
-#define rq_for_each_bio_safe(_bio, _tmp, _req)				\
-	if ((_req)->bio)						\
-		for (_bio = (_req)->bio;				\
-		     _bio && ((_tmp = _bio->bi_next) || 1);		\
-		     _bio = _tmp)
-
-static void
-blktap_device_forward_request(struct blktap *tap, struct request *req)
-{
-	struct bio *bio, *tmp;
-	struct blktap_device *dev;
-
-	dev = &tap->device;
-
-	rq_for_each_bio_safe(bio, tmp, req) {
-		bio->bi_bdev = dev->bdev;
-		submit_bio(bio->bi_rw, bio);
-	}
-}
-
-static void
-blktap_device_close_bdev(struct blktap *tap)
-{
-	struct blktap_device *dev;
-
-	dev = &tap->device;
-
-	if (dev->bdev)
-		blkdev_put(dev->bdev);
-
-	dev->bdev = NULL;
-	clear_bit(BLKTAP_PASSTHROUGH, &tap->dev_inuse);
-}
-
-static int
-blktap_device_open_bdev(struct blktap *tap, u32 pdev)
-{
-	struct block_device *bdev;
-	struct blktap_device *dev;
-
-	dev = &tap->device;
-
-	bdev = open_by_devnum(pdev, FMODE_WRITE);
-	if (IS_ERR(bdev)) {
-		BTERR("opening device %x:%x failed: %ld\n",
-		      MAJOR(pdev), MINOR(pdev), PTR_ERR(bdev));
-		return PTR_ERR(bdev);
-	}
-
-	if (!bdev->bd_disk) {
-		BTERR("device %x:%x doesn't exist\n",
-		      MAJOR(pdev), MINOR(pdev));
-		blkdev_put(dev->bdev);
-		return -ENOENT;
-	}
-
-	dev->bdev = bdev;
-	set_bit(BLKTAP_PASSTHROUGH, &tap->dev_inuse);
-
-	/* TODO: readjust queue parameters */
-
-	BTINFO("set device %d to passthrough on %x:%x\n",
-	       tap->minor, MAJOR(pdev), MINOR(pdev));
-
-	return 0;
-}
-
-int
-blktap_device_enable_passthrough(struct blktap *tap,
-				 unsigned major, unsigned minor)
-{
-	u32 pdev;
-	struct blktap_device *dev;
-
-	dev  = &tap->device;
-	pdev = MKDEV(major, minor);
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return -EINVAL;
-
-	if (dev->bdev) {
-		if (pdev)
-			return -EINVAL;
-		blktap_device_close_bdev(tap);
-		return 0;
-	}
-
-	return blktap_device_open_bdev(tap, pdev);
-}
-#endif
-
-/*
- * dev->lock held on entry
- */
-static void
-blktap_device_run_queue(struct blktap *tap)
-{
-	int queued, err;
-	struct request_queue *rq;
-	struct request *req;
-	struct blktap_ring *ring;
-	struct blktap_device *dev;
-	struct blktap_request *request;
-
-	queued = 0;
-	ring   = &tap->ring;
-	dev    = &tap->device;
-	rq     = dev->gd->queue;
-
-	BTDBG("running queue for %d\n", tap->minor);
-
-	while ((req = blk_peek_request(rq)) != NULL) {
-		if (RING_FULL(&ring->ring)) {
-		wait:
-			/* Avoid pointless unplugs. */
-			blk_stop_queue(rq);
-			blktap_defer(tap);
-			break;
-		}
-
-		blk_start_request(req);
-
-		if (!blk_fs_request(req)) {
-			__blk_end_request_all(req, -EIO);
-			continue;
-		}
-
-		if (blk_barrier_rq(req)) {
-			__blk_end_request_all(req, -EOPNOTSUPP);
-			continue;
-		}
-
-#ifdef ENABLE_PASSTHROUGH
-		if (test_bit(BLKTAP_PASSTHROUGH, &tap->dev_inuse)) {
-			blktap_device_forward_request(tap, req);
-			continue;
-		}
-#endif
-
-		request = blktap_request_allocate(tap);
-		if (!request) {
-			tap->stats.st_oo_req++;
-			goto wait;
-		}
-
-		BTDBG("req %p: dev %d cmd %p, sec 0x%llx, (0x%x/0x%x) "
-		      "buffer:%p [%s], pending: %p\n", req, tap->minor,
-		      req->cmd, (unsigned long long)blk_rq_pos(req),
-		      blk_rq_cur_sectors(req), blk_rq_sectors(req), req->buffer,
-		      rq_data_dir(req) ? "write" : "read", request);
-
-		spin_unlock_irq(&dev->lock);
-		down_read(&tap->tap_sem);
-
-		err = blktap_device_process_request(tap, request, req);
-		if (!err)
-			queued++;
-		else {
-			blk_end_request_all(req, err);
-			blktap_request_free(tap, request);
-		}
-
-		up_read(&tap->tap_sem);
-		spin_lock_irq(&dev->lock);
-	}
-
-	if (queued)
-		blktap_ring_kick_user(tap);
-}
-
-/*
- * dev->lock held on entry
- */
-static void
-blktap_device_do_request(struct request_queue *rq)
-{
-	struct request *req;
-	struct blktap *tap;
-	struct blktap_device *dev;
-
-	dev = rq->queuedata;
-	if (!dev)
-		goto fail;
-
-	tap = dev_to_blktap(dev);
-	if (!blktap_active(tap))
-		goto fail;
-
-	if (test_bit(BLKTAP_PAUSED, &tap->dev_inuse) ||
-	    test_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse)) {
-		blktap_defer(tap);
-		return;
-	}
-
-	blktap_device_run_queue(tap);
-	return;
-
-fail:
-	while ((req = blk_peek_request(rq))) {
-		BTERR("device closed: failing secs %llu - %llu\n",
-		      (unsigned long long)blk_rq_pos(req),
-		      (unsigned long long)blk_rq_pos(req)
-		      + blk_rq_cur_sectors(req));
-		blk_start_request(req);
-		__blk_end_request_all(req, -EIO);
-	}
-}
-
-void
-blktap_device_restart(struct blktap *tap)
-{
-	struct blktap_device *dev;
-
-	dev = &tap->device;
-
-	if (blktap_active(tap) && RING_FULL(&tap->ring.ring)) {
-		blktap_defer(tap);
-		return;
-	}
-
-	if (test_bit(BLKTAP_PAUSED, &tap->dev_inuse) ||
-	    test_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse)) {
-		blktap_defer(tap);
-		return;
-	}
-
-	spin_lock_irq(&dev->lock);
-
-	/* Re-enable calldowns. */
-	if (dev->gd) {
-		struct request_queue *rq = dev->gd->queue;
-
-		if (blk_queue_stopped(rq))
-			blk_start_queue(rq);
-
-		/* Kick things off immediately. */
-		blktap_device_do_request(rq);
-	}
-
-	spin_unlock_irq(&dev->lock);
-}
-
-static void
-blktap_device_configure(struct blktap *tap)
-{
-	struct request_queue *rq;
-	struct blktap_device *dev = &tap->device;
-
-	if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse) || !dev->gd)
-		return;
-
-	dev = &tap->device;
-	rq  = dev->gd->queue;
-
-	spin_lock_irq(&dev->lock);
-
-	set_capacity(dev->gd, tap->params.capacity);
-
-	/* Hard sector size and max sectors impersonate the equiv. hardware. */
-	blk_queue_logical_block_size(rq, tap->params.sector_size);
-	blk_queue_max_sectors(rq, 512);
-
-	/* Each segment in a request is up to an aligned page in size. */
-	blk_queue_segment_boundary(rq, PAGE_SIZE - 1);
-	blk_queue_max_segment_size(rq, PAGE_SIZE);
-
-	/* Ensure a merged request will fit in a single I/O ring slot. */
-	blk_queue_max_phys_segments(rq, BLKIF_MAX_SEGMENTS_PER_REQUEST);
-	blk_queue_max_hw_segments(rq, BLKIF_MAX_SEGMENTS_PER_REQUEST);
-
-	/* Make sure buffer addresses are sector-aligned. */
-	blk_queue_dma_alignment(rq, 511);
-
-	spin_unlock_irq(&dev->lock);
-}
-
-int
-blktap_device_resume(struct blktap *tap)
-{
-	int err;
-
-	if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse) || !blktap_active(tap))
-		return -ENODEV;
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return 0;
-
-	err = blktap_ring_resume(tap);
-	if (err)
-		return err;
-
-	/* device size may have changed */
-	blktap_device_configure(tap);
-
-	BTDBG("restarting device\n");
-	blktap_device_restart(tap);
-
-	return 0;
-}
-
-int
-blktap_device_pause(struct blktap *tap)
-{
-	unsigned long flags;
-	struct blktap_device *dev = &tap->device;
-
-	if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse) || !blktap_active(tap))
-		return -ENODEV;
-
-	if (test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return 0;
-
-	spin_lock_irqsave(&dev->lock, flags);
-
-	blk_stop_queue(dev->gd->queue);
-	set_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse);
-
-	spin_unlock_irqrestore(&dev->lock, flags);
-
-	return blktap_ring_pause(tap);
-}
-
-int
-blktap_device_destroy(struct blktap *tap)
-{
-	struct blktap_device *dev = &tap->device;
-	struct gendisk *gd = dev->gd;
-
-	if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse))
-		return 0;
-
-	BTINFO("destroy device %d users %d\n", tap->minor, dev->users);
-
-	if (dev->users)
-		return -EBUSY;
-
-	spin_lock_irq(&dev->lock);
-	/* No more blktap_device_do_request(). */
-	blk_stop_queue(gd->queue);
-	clear_bit(BLKTAP_DEVICE, &tap->dev_inuse);
-	dev->gd = NULL;
-	spin_unlock_irq(&dev->lock);
-
-#ifdef ENABLE_PASSTHROUGH
-	if (dev->bdev)
-		blktap_device_close_bdev(tap);
-#endif
-
-	del_gendisk(gd);
-	blk_cleanup_queue(gd->queue);
-	put_disk(gd);
-
-	wake_up(&tap->wq);
-
-	return 0;
-}
-
-int
-blktap_device_create(struct blktap *tap)
-{
-	int minor, err;
-	struct gendisk *gd;
-	struct request_queue *rq;
-	struct blktap_device *dev;
-
-	gd    = NULL;
-	rq    = NULL;
-	dev   = &tap->device;
-	minor = tap->minor;
-
-	if (test_bit(BLKTAP_DEVICE, &tap->dev_inuse))
-		return -EEXIST;
-
-	if (blktap_validate_params(tap, &tap->params))
-		return -EINVAL;
-
-	BTINFO("minor %d sectors %Lu sector-size %lu\n",
-	       minor, tap->params.capacity, tap->params.sector_size);
-
-	err = -ENODEV;
-
-	gd = alloc_disk(1);
-	if (!gd)
-		goto error;
-
-	if (minor < 26)
-		sprintf(gd->disk_name, "tapdev%c", 'a' + minor);
-	else
-		sprintf(gd->disk_name, "tapdev%c%c",
-			'a' + ((minor / 26) - 1), 'a' + (minor % 26));
-
-	gd->major = blktap_device_major;
-	gd->first_minor = minor;
-	gd->fops = &blktap_device_file_operations;
-	gd->private_data = dev;
-
-	spin_lock_init(&dev->lock);
-	rq = blk_init_queue(blktap_device_do_request, &dev->lock);
-	if (!rq)
-		goto error;
-
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,10)
-	elevator_init(rq, "noop");
-#else
-	elevator_init(rq, &elevator_noop);
-#endif
-
-	gd->queue     = rq;
-	rq->queuedata = dev;
-	dev->gd       = gd;
-
-	set_bit(BLKTAP_DEVICE, &tap->dev_inuse);
-	blktap_device_configure(tap);
-
-	add_disk(gd);
-
-	err = 0;
-	goto out;
-
- error:
-	if (gd)
-		del_gendisk(gd);
-	if (rq)
-		blk_cleanup_queue(rq);
-
- out:
-	BTINFO("creation of %u:%u: %d\n", blktap_device_major, tap->minor, err);
-	return err;
-}
-
-int __init
-blktap_device_init(int *maj)
-{
-	int major;
-
-	/* Dynamically allocate a major for this device */
-	major = register_blkdev(0, "tapdev");
-	if (major < 0) {
-		BTERR("Couldn't register blktap device\n");
-		return -ENOMEM;
-	}	
-
-	blktap_device_major = *maj = major;
-	BTINFO("blktap device major %d\n", major);
-
-	return 0;
-}
-
-void
-blktap_device_free(void)
-{
-	if (blktap_device_major)
-		unregister_blkdev(blktap_device_major, "tapdev");
-}
diff -r fc7f59d8fe82 drivers/xen/blktap2/request.c
--- a/drivers/xen/blktap2/request.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,296 +0,0 @@
-#include <linux/spinlock.h>
-#include <xen/balloon.h>
-
-#include "blktap.h"
-
-#define MAX_BUCKETS                      8
-#define BUCKET_SIZE                      MAX_PENDING_REQS
-
-#define BLKTAP_POOL_CLOSING              1
-
-struct blktap_request_bucket;
-
-struct blktap_request_handle {
-	int                              slot;
-	uint8_t                          inuse;
-	struct blktap_request            request;
-	struct blktap_request_bucket    *bucket;
-};
-
-struct blktap_request_bucket {
-	atomic_t                         reqs_in_use;
-	struct blktap_request_handle     handles[BUCKET_SIZE];
-	struct page                    **foreign_pages;
-};
-
-struct blktap_request_pool {
-	spinlock_t                       lock;
-	uint8_t                          status;
-	struct list_head                 free_list;
-	atomic_t                         reqs_in_use;
-	wait_queue_head_t                wait_queue;
-	struct blktap_request_bucket    *buckets[MAX_BUCKETS];
-};
-
-static struct blktap_request_pool pool;
-
-static inline struct blktap_request_handle *
-blktap_request_to_handle(struct blktap_request *req)
-{
-	return container_of(req, struct blktap_request_handle, request);
-}
-
-static void
-blktap_request_pool_init_request(struct blktap_request *request)
-{
-	int i;
-
-	request->usr_idx  = -1;
-	request->nr_pages = 0;
-	request->status   = BLKTAP_REQUEST_FREE;
-	INIT_LIST_HEAD(&request->free_list);
-	for (i = 0; i < ARRAY_SIZE(request->handles); i++) {
-		request->handles[i].user   = INVALID_GRANT_HANDLE;
-		request->handles[i].kernel = INVALID_GRANT_HANDLE;
-	}
-}
-
-static int
-blktap_request_pool_allocate_bucket(void)
-{
-	int i, idx;
-	unsigned long flags;
-	struct blktap_request *request;
-	struct blktap_request_handle *handle;
-	struct blktap_request_bucket *bucket;
-
-	bucket = kzalloc(sizeof(struct blktap_request_bucket), GFP_KERNEL);
-	if (!bucket)
-		goto fail;
-
-	bucket->foreign_pages = alloc_empty_pages_and_pagevec(MMAP_PAGES);
-	if (!bucket->foreign_pages)
-		goto fail;
-
-	spin_lock_irqsave(&pool.lock, flags);
-
-	idx = -1;
-	for (i = 0; i < MAX_BUCKETS; i++) {
-		if (!pool.buckets[i]) {
-			idx = i;
-			pool.buckets[idx] = bucket;
-			break;
-		}
-	}
-
-	if (idx == -1) {
-		spin_unlock_irqrestore(&pool.lock, flags);
-		goto fail;
-	}
-
-	for (i = 0; i < BUCKET_SIZE; i++) {
-		handle  = bucket->handles + i;
-		request = &handle->request;
-
-		handle->slot   = i;
-		handle->inuse  = 0;
-		handle->bucket = bucket;
-
-		blktap_request_pool_init_request(request);
-		list_add_tail(&request->free_list, &pool.free_list);
-	}
-
-	spin_unlock_irqrestore(&pool.lock, flags);
-
-	return 0;
-
-fail:
-	if (bucket && bucket->foreign_pages)
-		free_empty_pages_and_pagevec(bucket->foreign_pages, MMAP_PAGES);
-	kfree(bucket);
-	return -ENOMEM;
-}
-
-static void
-blktap_request_pool_free_bucket(struct blktap_request_bucket *bucket)
-{
-	if (!bucket)
-		return;
-
-	BTDBG("freeing bucket %p\n", bucket);
-
-	free_empty_pages_and_pagevec(bucket->foreign_pages, MMAP_PAGES);
-	kfree(bucket);
-}
-
-struct page *
-request_to_page(struct blktap_request *req, int seg)
-{
-	struct blktap_request_handle *handle = blktap_request_to_handle(req);
-	int idx = handle->slot * BLKIF_MAX_SEGMENTS_PER_REQUEST + seg;
-	return handle->bucket->foreign_pages[idx];
-}
-
-int
-blktap_request_pool_shrink(void)
-{
-	int i, err;
-	unsigned long flags;
-	struct blktap_request_bucket *bucket;
-
-	err = -EAGAIN;
-
-	spin_lock_irqsave(&pool.lock, flags);
-
-	/* always keep at least one bucket */
-	for (i = 1; i < MAX_BUCKETS; i++) {
-		bucket = pool.buckets[i];
-		if (!bucket)
-			continue;
-
-		if (atomic_read(&bucket->reqs_in_use))
-			continue;
-
-		blktap_request_pool_free_bucket(bucket);
-		pool.buckets[i] = NULL;
-		err = 0;
-		break;
-	}
-
-	spin_unlock_irqrestore(&pool.lock, flags);
-
-	return err;
-}
-
-int
-blktap_request_pool_grow(void)
-{
-	return blktap_request_pool_allocate_bucket();
-}
-
-struct blktap_request *
-blktap_request_allocate(struct blktap *tap)
-{
-	int i;
-	uint16_t usr_idx;
-	unsigned long flags;
-	struct blktap_request *request;
-
-	usr_idx = -1;
-	request = NULL;
-
-	spin_lock_irqsave(&pool.lock, flags);
-
-	if (pool.status == BLKTAP_POOL_CLOSING)
-		goto out;
-
-	for (i = 0; i < ARRAY_SIZE(tap->pending_requests); i++)
-		if (!tap->pending_requests[i]) {
-			usr_idx = i;
-			break;
-		}
-
-	if (usr_idx == (uint16_t)-1)
-		goto out;
-
-	if (!list_empty(&pool.free_list)) {
-		request = list_entry(pool.free_list.next,
-				     struct blktap_request, free_list);
-		list_del(&request->free_list);
-	}
-
-	if (request) {
-		struct blktap_request_handle *handle;
-
-		atomic_inc(&pool.reqs_in_use);
-
-		handle = blktap_request_to_handle(request);
-		atomic_inc(&handle->bucket->reqs_in_use);
-		handle->inuse = 1;
-
-		request->usr_idx = usr_idx;
-
-		tap->pending_requests[usr_idx] = request;
-		tap->pending_cnt++;
-	}
-
-out:
-	spin_unlock_irqrestore(&pool.lock, flags);
-	return request;
-}
-
-void
-blktap_request_free(struct blktap *tap, struct blktap_request *request)
-{
-	int free;
-	unsigned long flags;
-	struct blktap_request_handle *handle;
-
-	BUG_ON(request->usr_idx >= ARRAY_SIZE(tap->pending_requests));
-	handle = blktap_request_to_handle(request);
-
-	spin_lock_irqsave(&pool.lock, flags);
-
-	handle->inuse = 0;
-	tap->pending_requests[request->usr_idx] = NULL;
-	blktap_request_pool_init_request(request);
-	list_add(&request->free_list, &pool.free_list);
-	atomic_dec(&handle->bucket->reqs_in_use);
-	free = atomic_dec_and_test(&pool.reqs_in_use);
-
-	spin_unlock_irqrestore(&pool.lock, flags);
-
-	if (--tap->pending_cnt == 0)
-		wake_up_interruptible(&tap->wq);
-
-	if (free)
-		wake_up(&pool.wait_queue);
-}
-
-void
-blktap_request_pool_free(void)
-{
-	int i;
-	unsigned long flags;
-
-	spin_lock_irqsave(&pool.lock, flags);
-
-	pool.status = BLKTAP_POOL_CLOSING;
-	while (atomic_read(&pool.reqs_in_use)) {
-		spin_unlock_irqrestore(&pool.lock, flags);
-		wait_event(pool.wait_queue, !atomic_read(&pool.reqs_in_use));
-		spin_lock_irqsave(&pool.lock, flags);
-	}
-
-	for (i = 0; i < MAX_BUCKETS; i++) {
-		blktap_request_pool_free_bucket(pool.buckets[i]);
-		pool.buckets[i] = NULL;
-	}
-
-	spin_unlock_irqrestore(&pool.lock, flags);
-}
-
-int __init
-blktap_request_pool_init(void)
-{
-	int i, err;
-
-	memset(&pool, 0, sizeof(pool));
-
-	spin_lock_init(&pool.lock);
-	INIT_LIST_HEAD(&pool.free_list);
-	atomic_set(&pool.reqs_in_use, 0);
-	init_waitqueue_head(&pool.wait_queue);
-
-	for (i = 0; i < 2; i++) {
-		err = blktap_request_pool_allocate_bucket();
-		if (err)
-			goto fail;
-	}
-
-	return 0;
-
-fail:
-	blktap_request_pool_free();
-	return err;
-}
diff -r fc7f59d8fe82 drivers/xen/blktap2/ring.c
--- a/drivers/xen/blktap2/ring.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,612 +0,0 @@
-#include <linux/module.h>
-#include <linux/signal.h>
-
-#include "blktap.h"
-
-static int blktap_ring_major;
-
-static inline struct blktap *
-vma_to_blktap(struct vm_area_struct *vma)
-{
-	struct vm_foreign_map *m = vma->vm_private_data;
-	struct blktap_ring *r = container_of(m, struct blktap_ring, foreign_map);
-	return container_of(r, struct blktap, ring);
-}
-
- /* 
-  * BLKTAP - immediately before the mmap area,
-  * we have a bunch of pages reserved for shared memory rings.
-  */
-#define RING_PAGES 1
-
-static int
-blktap_read_ring(struct blktap *tap)
-{
-	/* This is called to read responses from the ring. */
-	int usr_idx;
-	RING_IDX rc, rp;
-	blkif_response_t res;
-	struct blktap_ring *ring;
-	struct blktap_request *request;
-
-	down_read(&tap->tap_sem);
-
-	ring = &tap->ring;
-	if (!ring->vma) {
-		up_read(&tap->tap_sem);
-		return 0;
-	}
-
-	/* for each outstanding message on the ring  */
-	rp = ring->ring.sring->rsp_prod;
-	rmb();
-
-	for (rc = ring->ring.rsp_cons; rc != rp; rc++) {
-		memcpy(&res, RING_GET_RESPONSE(&ring->ring, rc), sizeof(res));
-		mb(); /* rsp_cons read by RING_FULL() in do_block_io_op(). */
-		++ring->ring.rsp_cons;
-
-		usr_idx = (int)res.id;
-		if (usr_idx >= MAX_PENDING_REQS ||
-		    !tap->pending_requests[usr_idx]) {
-			BTWARN("Request %d/%d invalid [%x], tapdisk %d%p\n",
-			       rc, rp, usr_idx, tap->pid, ring->vma);
-			continue;
-		}
-
-		request = tap->pending_requests[usr_idx];
-		BTDBG("request %p response #%d id %x\n", request, rc, usr_idx);
-		blktap_device_finish_request(tap, &res, request);
-	}
-
-	up_read(&tap->tap_sem);
-
-	blktap_run_deferred();
-
-	return 0;
-}
-
-static int
-blktap_ring_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
-{
-	/*
-	 * if the page has not been mapped in by the driver then return
-	 * VM_FAULT_SIGBUS to the domain.
-	 */
-
-	return VM_FAULT_SIGBUS;
-}
-
-static pte_t
-blktap_ring_clear_pte(struct vm_area_struct *vma,
-		      unsigned long uvaddr,
-		      pte_t *ptep, int is_fullmm)
-{
-	pte_t copy;
-	struct blktap *tap;
-	unsigned long kvaddr;
-	struct page **map, *page;
-	struct blktap_ring *ring;
-	struct blktap_request *request;
-	struct grant_handle_pair *khandle;
-	struct gnttab_unmap_grant_ref unmap[2];
-	int offset, seg, usr_idx, count = 0;
-
-	tap  = vma_to_blktap(vma);
-	ring = &tap->ring;
-	map  = ring->foreign_map.map;
-	BUG_ON(!map);	/* TODO Should this be changed to if statement? */
-
-	/*
-	 * Zap entry if the address is before the start of the grant
-	 * mapped region.
-	 */
-	if (uvaddr < ring->user_vstart)
-		return xen_ptep_get_and_clear_full(vma, uvaddr,
-						   ptep, is_fullmm);
-
-	offset  = (int)((uvaddr - ring->user_vstart) >> PAGE_SHIFT);
-	usr_idx = offset / BLKIF_MAX_SEGMENTS_PER_REQUEST;
-	seg     = offset % BLKIF_MAX_SEGMENTS_PER_REQUEST;
-
-	offset  = (int)((uvaddr - vma->vm_start) >> PAGE_SHIFT);
-	page    = map[offset];
-	if (page) {
-		ClearPageReserved(page);
-		if (PageBlkback(page)) {
-			ClearPageBlkback(page);
-			set_page_private(page, 0);
-		}
-	}
-	map[offset] = NULL;
-
-	request = tap->pending_requests[usr_idx];
-	kvaddr  = request_to_kaddr(request, seg);
-	khandle = request->handles + seg;
-
-	if (khandle->kernel != INVALID_GRANT_HANDLE) {
-		gnttab_set_unmap_op(&unmap[count], kvaddr, 
-				    GNTMAP_host_map, khandle->kernel);
-		count++;
-
-		set_phys_to_machine(__pa(kvaddr) >> PAGE_SHIFT, 
-				    INVALID_P2M_ENTRY);
-	}
-
-
-	if (khandle->user != INVALID_GRANT_HANDLE) {
-		BUG_ON(xen_feature(XENFEAT_auto_translated_physmap));
-
-		copy = *ptep;
-		gnttab_set_unmap_op(&unmap[count], virt_to_machine(ptep), 
-				    GNTMAP_host_map 
-				    | GNTMAP_application_map 
-				    | GNTMAP_contains_pte,
-				    khandle->user);
-		count++;
-	} else
-		copy = xen_ptep_get_and_clear_full(vma, uvaddr, ptep,
-						   is_fullmm);
-
-	if (count)
-		if (HYPERVISOR_grant_table_op(GNTTABOP_unmap_grant_ref,
-					      unmap, count))
-			BUG();
-
-	khandle->kernel = INVALID_GRANT_HANDLE;
-	khandle->user   = INVALID_GRANT_HANDLE;
-
-	return copy;
-}
-
-static void
-blktap_ring_vm_unmap(struct vm_area_struct *vma)
-{
-	struct blktap *tap = vma_to_blktap(vma);
-
-	down_write(&tap->tap_sem);
-	clear_bit(BLKTAP_RING_VMA, &tap->dev_inuse);
-	clear_bit(BLKTAP_PAUSED, &tap->dev_inuse);
-	clear_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse);
-	up_write(&tap->tap_sem);
-}
-
-static void
-blktap_ring_vm_close(struct vm_area_struct *vma)
-{
-	struct blktap *tap = vma_to_blktap(vma);
-	struct blktap_ring *ring = &tap->ring;
-
-	blktap_ring_vm_unmap(vma);                 /* fail future requests */
-	blktap_device_fail_pending_requests(tap);  /* fail pending requests */
-	blktap_device_restart(tap);                /* fail deferred requests */
-
-	down_write(&tap->tap_sem);
-
-	zap_page_range(vma, vma->vm_start, vma->vm_end - vma->vm_start, NULL);
-
-	kfree(ring->foreign_map.map);
-	ring->foreign_map.map = NULL;
-
-	/* Free the ring page. */
-	ClearPageReserved(virt_to_page(ring->ring.sring));
-	free_page((unsigned long)ring->ring.sring);
-
-	BTINFO("unmapping ring %d\n", tap->minor);
-	ring->ring.sring = NULL;
-	ring->vma = NULL;
-
-	up_write(&tap->tap_sem);
-
-	wake_up(&tap->wq);
-}
-
-static struct vm_operations_struct blktap_ring_vm_operations = {
-	.close    = blktap_ring_vm_close,
-	.unmap    = blktap_ring_vm_unmap,
-	.fault    = blktap_ring_fault,
-	.zap_pte  = blktap_ring_clear_pte,
-};
-
-static int
-blktap_ring_open(struct inode *inode, struct file *filp)
-{
-	int idx;
-	struct blktap *tap;
-
-	idx = iminor(inode);
-	if (idx < 0 || idx >= MAX_BLKTAP_DEVICE || blktaps[idx] == NULL) {
-		BTERR("unable to open device blktap%d\n", idx);
-		return -ENODEV;
-	}
-
-	tap = blktaps[idx];
-
-	BTINFO("opening device blktap%d\n", idx);
-
-	if (!test_bit(BLKTAP_CONTROL, &tap->dev_inuse))
-		return -ENODEV;
-
-	/* Only one process can access ring at a time */
-	if (test_and_set_bit(BLKTAP_RING_FD, &tap->dev_inuse))
-		return -EBUSY;
-
-	filp->private_data = tap;
-	BTINFO("opened device %d\n", tap->minor);
-
-	return 0;
-}
-
-static int
-blktap_ring_release(struct inode *inode, struct file *filp)
-{
-	struct blktap *tap = filp->private_data;
-
-	BTINFO("freeing device %d\n", tap->minor);
-	clear_bit(BLKTAP_RING_FD, &tap->dev_inuse);
-	filp->private_data = NULL;
-	wake_up(&tap->wq);	
-	return 0;
-}
-
-/* Note on mmap:
- * We need to map pages to user space in a way that will allow the block
- * subsystem set up direct IO to them.  This couldn't be done before, because
- * there isn't really a sane way to translate a user virtual address down to a 
- * physical address when the page belongs to another domain.
- *
- * My first approach was to map the page in to kernel memory, add an entry
- * for it in the physical frame list (using alloc_lomem_region as in blkback)
- * and then attempt to map that page up to user space.  This is disallowed
- * by xen though, which realizes that we don't really own the machine frame
- * underlying the physical page.
- *
- * The new approach is to provide explicit support for this in xen linux.
- * The VMA now has a flag, VM_FOREIGN, to indicate that it contains pages
- * mapped from other vms.  vma->vm_private_data is set up as a mapping 
- * from pages to actual page structs.  There is a new clause in get_user_pages
- * that does the right thing for this sort of mapping.
- */
-static int
-blktap_ring_mmap(struct file *filp, struct vm_area_struct *vma)
-{
-	int size, err;
-	struct page **map;
-	struct blktap *tap;
-	blkif_sring_t *sring;
-	struct blktap_ring *ring;
-
-	tap   = filp->private_data;
-	ring  = &tap->ring;
-	map   = NULL;
-	sring = NULL;
-
-	if (!tap || test_and_set_bit(BLKTAP_RING_VMA, &tap->dev_inuse))
-		return -ENOMEM;
-
-	size = (vma->vm_end - vma->vm_start) >> PAGE_SHIFT;
-	if (size != (MMAP_PAGES + RING_PAGES)) {
-		BTERR("you _must_ map exactly %lu pages!\n",
-		      MMAP_PAGES + RING_PAGES);
-		return -EAGAIN;
-	}
-
-	/* Allocate the fe ring. */
-	sring = (blkif_sring_t *)get_zeroed_page(GFP_KERNEL);
-	if (!sring) {
-		BTERR("Couldn't alloc sring.\n");
-		goto fail_mem;
-	}
-
-	map = kzalloc(size * sizeof(struct page *), GFP_KERNEL);
-	if (!map) {
-		BTERR("Couldn't alloc VM_FOREIGN map.\n");
-		goto fail_mem;
-	}
-
-	SetPageReserved(virt_to_page(sring));
-    
-	SHARED_RING_INIT(sring);
-	FRONT_RING_INIT(&ring->ring, sring, PAGE_SIZE);
-
-	ring->ring_vstart = vma->vm_start;
-	ring->user_vstart = ring->ring_vstart + (RING_PAGES << PAGE_SHIFT);
-
-	/* Map the ring pages to the start of the region and reserve it. */
-	if (xen_feature(XENFEAT_auto_translated_physmap))
-		err = vm_insert_page(vma, vma->vm_start,
-				     virt_to_page(ring->ring.sring));
-	else
-		err = remap_pfn_range(vma, vma->vm_start,
-				      __pa(ring->ring.sring) >> PAGE_SHIFT,
-				      PAGE_SIZE, vma->vm_page_prot);
-	if (err) {
-		BTERR("Mapping user ring failed: %d\n", err);
-		goto fail;
-	}
-
-	/* Mark this VM as containing foreign pages, and set up mappings. */
-	ring->foreign_map.map = map;
-	vma->vm_private_data = &ring->foreign_map;
-	vma->vm_flags |= VM_FOREIGN;
-	vma->vm_flags |= VM_DONTCOPY;
-	vma->vm_flags |= VM_RESERVED;
-	vma->vm_ops = &blktap_ring_vm_operations;
-
-#ifdef CONFIG_X86
-	vma->vm_mm->context.has_foreign_mappings = 1;
-#endif
-
-	tap->pid = current->pid;
-	BTINFO("blktap: mapping pid is %d\n", tap->pid);
-
-	ring->vma = vma;
-	return 0;
-
- fail:
-	/* Clear any active mappings. */
-	zap_page_range(vma, vma->vm_start, 
-		       vma->vm_end - vma->vm_start, NULL);
-	ClearPageReserved(virt_to_page(sring));
- fail_mem:
-	free_page((unsigned long)sring);
-	kfree(map);
-
-	return -ENOMEM;
-}
-
-static inline void
-blktap_ring_set_message(struct blktap *tap, int msg)
-{
-	struct blktap_ring *ring = &tap->ring;
-
-	down_read(&tap->tap_sem);
-	if (ring->ring.sring)
-		ring->ring.sring->pad[0] = msg;
-	up_read(&tap->tap_sem);
-}
-
-static int
-blktap_ring_ioctl(struct inode *inode, struct file *filp,
-		  unsigned int cmd, unsigned long arg)
-{
-	struct blktap_params params;
-	struct blktap *tap = filp->private_data;
-
-	BTDBG("%d: cmd: %u, arg: %lu\n", tap->minor, cmd, arg);
-
-	switch(cmd) {
-	case BLKTAP2_IOCTL_KICK_FE:
-		/* There are fe messages to process. */
-		return blktap_read_ring(tap);
-
-	case BLKTAP2_IOCTL_CREATE_DEVICE:
-		if (!arg)
-			return -EINVAL;
-
-		if (copy_from_user(&params, (struct blktap_params __user *)arg,
-				   sizeof(params))) {
-			BTERR("failed to get params\n");
-			return -EFAULT;
-		}
-
-		if (blktap_validate_params(tap, &params)) {
-			BTERR("invalid params\n");
-			return -EINVAL;
-		}
-
-		tap->params = params;
-		return blktap_device_create(tap);
-
-	case BLKTAP2_IOCTL_SET_PARAMS:
-		if (!arg)
-			return -EINVAL;
-
-		if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-			return -EINVAL;
-
-		if (copy_from_user(&params, (struct blktap_params __user *)arg,
-				   sizeof(params))) {
-			BTERR("failed to get params\n");
-			return -EFAULT;
-		}
-
-		if (blktap_validate_params(tap, &params)) {
-			BTERR("invalid params\n");
-			return -EINVAL;
-		}
-
-		tap->params = params;
-		return 0;
-
-	case BLKTAP2_IOCTL_PAUSE:
-		if (!test_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse))
-			return -EINVAL;
-
-		set_bit(BLKTAP_PAUSED, &tap->dev_inuse);
-		clear_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse);
-
-		blktap_ring_set_message(tap, 0);
-		wake_up_interruptible(&tap->wq);
-
-		return 0;
-
-
-	case BLKTAP2_IOCTL_REOPEN:
-		if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-			return -EINVAL;
-
-		if (!arg)
-			return -EINVAL;
-
-		if (copy_to_user((char __user *)arg,
-				 tap->params.name,
-				 strlen(tap->params.name) + 1))
-			return -EFAULT;
-
-		blktap_ring_set_message(tap, 0);
-		wake_up_interruptible(&tap->wq);
-
-		return 0;
-
-	case BLKTAP2_IOCTL_RESUME:
-		if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-			return -EINVAL;
-
-		tap->ring.response = (int)arg;
-		if (!tap->ring.response)
-			clear_bit(BLKTAP_PAUSED, &tap->dev_inuse);
-
-		blktap_ring_set_message(tap, 0);
-		wake_up_interruptible(&tap->wq);
-
-		return 0;
-	}
-
-	return -ENOIOCTLCMD;
-}
-
-static unsigned int blktap_ring_poll(struct file *filp, poll_table *wait)
-{
-	struct blktap *tap = filp->private_data;
-	struct blktap_ring *ring = &tap->ring;
-
-	poll_wait(filp, &ring->poll_wait, wait);
-	if (ring->ring.sring->pad[0] != 0 ||
-	    ring->ring.req_prod_pvt != ring->ring.sring->req_prod) {
-		RING_PUSH_REQUESTS(&ring->ring);
-		return POLLIN | POLLRDNORM;
-	}
-
-	return 0;
-}
-
-static struct file_operations blktap_ring_file_operations = {
-	.owner    = THIS_MODULE,
-	.open     = blktap_ring_open,
-	.release  = blktap_ring_release,
-	.ioctl    = blktap_ring_ioctl,
-	.mmap     = blktap_ring_mmap,
-	.poll     = blktap_ring_poll,
-};
-
-void
-blktap_ring_kick_user(struct blktap *tap)
-{
-	wake_up_interruptible(&tap->ring.poll_wait);
-}
-
-int
-blktap_ring_resume(struct blktap *tap)
-{
-	int err;
-	struct blktap_ring *ring = &tap->ring;
-
-	if (!blktap_active(tap))
-		return -ENODEV;
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return -EINVAL;
-
-	/* set shared flag for resume */
-	ring->response = 0;
-
-	blktap_ring_set_message(tap, BLKTAP2_RING_MESSAGE_RESUME);
-	blktap_ring_kick_user(tap);
-
-	wait_event_interruptible(tap->wq, ring->response ||
-				 !test_bit(BLKTAP_PAUSED, &tap->dev_inuse));
-
-	err = ring->response;
-	ring->response = 0;
-
-	BTDBG("err: %d\n", err);
-
-	if (err)
-		return err;
-
-	if (test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return -EAGAIN;
-
-	return 0;
-}
-
-int
-blktap_ring_pause(struct blktap *tap)
-{
-	if (!blktap_active(tap))
-		return -ENODEV;
-
-	if (!test_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse))
-		return -EINVAL;
-
-	BTDBG("draining queue\n");
-	wait_event_interruptible(tap->wq, !tap->pending_cnt);
-	if (tap->pending_cnt)
-		return -EAGAIN;
-
-	blktap_ring_set_message(tap, BLKTAP2_RING_MESSAGE_PAUSE);
-	blktap_ring_kick_user(tap);
-
-	BTDBG("waiting for tapdisk response\n");
-	wait_event_interruptible(tap->wq, test_bit(BLKTAP_PAUSED, &tap->dev_inuse));
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse))
-		return -EAGAIN;
-
-	return 0;
-}
-
-int
-blktap_ring_destroy(struct blktap *tap)
-{
-	if (!test_bit(BLKTAP_RING_FD, &tap->dev_inuse) &&
-	    !test_bit(BLKTAP_RING_VMA, &tap->dev_inuse))
-		return 0;
-
-	BTDBG("sending tapdisk close message\n");
-	blktap_ring_set_message(tap, BLKTAP2_RING_MESSAGE_CLOSE);
-	blktap_ring_kick_user(tap);
-
-	return -EAGAIN;
-}
-
-static void
-blktap_ring_initialize(struct blktap_ring *ring, int minor)
-{
-	memset(ring, 0, sizeof(*ring));
-	init_waitqueue_head(&ring->poll_wait);
-	ring->devno = MKDEV(blktap_ring_major, minor);
-}
-
-int
-blktap_ring_create(struct blktap *tap)
-{
-	struct blktap_ring *ring = &tap->ring;
-	blktap_ring_initialize(ring, tap->minor);
-	return blktap_sysfs_create(tap);
-}
-
-int __init
-blktap_ring_init(int *major)
-{
-	int err;
-
-	err = register_chrdev(0, "blktap2", &blktap_ring_file_operations);
-	if (err < 0) {
-		BTERR("error registering blktap ring device: %d\n", err);
-		return err;
-	}
-
-	blktap_ring_major = *major = err;
-	BTINFO("blktap ring major: %d\n", blktap_ring_major);
-	return 0;
-}
-
-int
-blktap_ring_free(void)
-{
-	if (blktap_ring_major)
-		unregister_chrdev(blktap_ring_major, "blktap2");
-
-	return 0;
-}
diff -r fc7f59d8fe82 drivers/xen/blktap2/sysfs.c
--- a/drivers/xen/blktap2/sysfs.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,462 +0,0 @@
-#include <linux/types.h>
-#include <linux/device.h>
-#include <linux/module.h>
-
-#include "blktap.h"
-
-int blktap_debug_level = 1;
-
-static struct class *class;
-static DECLARE_WAIT_QUEUE_HEAD(sysfs_wq);
-
-static inline void
-blktap_sysfs_get(struct blktap *tap)
-{
-	atomic_inc(&tap->ring.sysfs_refcnt);
-}
-
-static inline void
-blktap_sysfs_put(struct blktap *tap)
-{
-	if (atomic_dec_and_test(&tap->ring.sysfs_refcnt))
-		wake_up(&sysfs_wq);
-}
-
-static inline void
-blktap_sysfs_enter(struct blktap *tap)
-{
-	blktap_sysfs_get(tap);               /* pin sysfs device */
-	mutex_lock(&tap->ring.sysfs_mutex);  /* serialize sysfs operations */
-}
-
-static inline void
-blktap_sysfs_exit(struct blktap *tap)
-{
-	mutex_unlock(&tap->ring.sysfs_mutex);
-	blktap_sysfs_put(tap);
-}
-
-static ssize_t blktap_sysfs_pause_device(struct device *,
-					 struct device_attribute *,
-					 const char *, size_t);
-static DEVICE_ATTR(pause, S_IWUSR, NULL, blktap_sysfs_pause_device);
-static ssize_t blktap_sysfs_resume_device(struct device *,
-					  struct device_attribute *,
-					  const char *, size_t);
-static DEVICE_ATTR(resume, S_IWUSR, NULL, blktap_sysfs_resume_device);
-
-static ssize_t
-blktap_sysfs_set_name(struct device *dev, struct device_attribute *attr,
-		      const char *buf, size_t size)
-{
-	int err;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	blktap_sysfs_enter(tap);
-
-	if (!tap->ring.dev ||
-	    test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse)) {
-		err = -ENODEV;
-		goto out;
-	}
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse)) {
-		err = -EPERM;
-		goto out;
-	}
-
-	if (size > BLKTAP2_MAX_MESSAGE_LEN) {
-		err = -ENAMETOOLONG;
-		goto out;
-	}
-
-	if (strnlen(buf, BLKTAP2_MAX_MESSAGE_LEN) >= BLKTAP2_MAX_MESSAGE_LEN) {
-		err = -EINVAL;
-		goto out;
-	}
-
-	snprintf(tap->params.name, sizeof(tap->params.name) - 1, "%s", buf);
-	err = size;
-
-out:
-	blktap_sysfs_exit(tap);	
-	return err;
-}
-
-static ssize_t
-blktap_sysfs_get_name(struct device *dev, struct device_attribute *attr,
-		      char *buf)
-{
-	ssize_t size;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	blktap_sysfs_enter(tap);
-
-	if (!tap->ring.dev)
-		size = -ENODEV;
-	else if (tap->params.name[0])
-		size = sprintf(buf, "%s\n", tap->params.name);
-	else
-		size = sprintf(buf, "%d\n", tap->minor);
-
-	blktap_sysfs_exit(tap);
-
-	return size;
-}
-static DEVICE_ATTR(name, S_IRUSR | S_IWUSR,
-		   blktap_sysfs_get_name, blktap_sysfs_set_name);
-
-static ssize_t
-blktap_sysfs_remove_device(struct device *dev, struct device_attribute *attr,
-			   const char *buf, size_t size)
-{
-	int err;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	if (!tap->ring.dev)
-		return size;
-
-	if (test_and_set_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse))
-		return -EBUSY;
-
-	err = blktap_control_destroy_device(tap);
-
-	return (err ? : size);
-}
-static DEVICE_ATTR(remove, S_IWUSR, NULL, blktap_sysfs_remove_device);
-
-static ssize_t
-blktap_sysfs_pause_device(struct device *dev, struct device_attribute *attr,
-			  const char *buf, size_t size)
-{
-	int err;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	blktap_sysfs_enter(tap);
-
-	BTDBG("pausing %u:%u: dev_inuse: %lu\n",
-	      MAJOR(tap->ring.devno), MINOR(tap->ring.devno), tap->dev_inuse);
-
-	if (!tap->ring.dev ||
-	    test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse)) {
-		err = -ENODEV;
-		goto out;
-	}
-
-	if (test_bit(BLKTAP_PAUSE_REQUESTED, &tap->dev_inuse)) {
-		err = -EBUSY;
-		goto out;
-	}
-
-	if (test_bit(BLKTAP_PAUSED, &tap->dev_inuse)) {
-		err = 0;
-		goto out;
-	}
-
-	err = blktap_device_pause(tap);
-	if (!err) {
-		device_remove_file(dev, &dev_attr_pause);
-		err = device_create_file(dev, &dev_attr_resume);
-	}
-
-out:
-	blktap_sysfs_exit(tap);
-
-	return (err ? err : size);
-}
-
-static ssize_t
-blktap_sysfs_resume_device(struct device *dev, struct device_attribute *attr,
-			   const char *buf, size_t size)
-{
-	int err;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	blktap_sysfs_enter(tap);
-
-	if (!tap->ring.dev ||
-	    test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse)) {
-		err = -ENODEV;
-		goto out;
-	}
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse)) {
-		err = -EINVAL;
-		goto out;
-	}
-
-	err = blktap_device_resume(tap);
-	if (!err) {
-		device_remove_file(dev, &dev_attr_resume);
-		err = device_create_file(dev, &dev_attr_pause);
-	}
-
-out:
-	blktap_sysfs_exit(tap);
-
-	BTDBG("returning %zd\n", (err ? err : size));
-	return (err ? err : size);
-}
-
-#ifdef ENABLE_PASSTHROUGH
-static ssize_t
-blktap_sysfs_enable_passthrough(struct device *dev,
-				struct device_attribute *attr,
-				const char *buf, size_t size)
-{
-	int err;
-	unsigned major, minor;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	BTINFO("passthrough request enabled\n");
-
-	blktap_sysfs_enter(tap);
-
-	if (!tap->ring.dev ||
-	    test_bit(BLKTAP_SHUTDOWN_REQUESTED, &tap->dev_inuse)) {
-		err = -ENODEV;
-		goto out;
-	}
-
-	if (!test_bit(BLKTAP_PAUSED, &tap->dev_inuse)) {
-		err = -EINVAL;
-		goto out;
-	}
-
-	if (test_bit(BLKTAP_PASSTHROUGH, &tap->dev_inuse)) {
-		err = -EINVAL;
-		goto out;
-	}
-
-	err = sscanf(buf, "%x:%x", &major, &minor);
-	if (err != 2) {
-		err = -EINVAL;
-		goto out;
-	}
-
-	err = blktap_device_enable_passthrough(tap, major, minor);
-
-out:
-	blktap_sysfs_exit(tap);
-	BTDBG("returning %d\n", (err ? err : size));
-	return (err ? err : size);
-}
-#endif
-
-static ssize_t
-blktap_sysfs_debug_device(struct device *dev, struct device_attribute *attr,
-			  char *buf)
-{
-	char *tmp;
-	int i, ret;
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	tmp = buf;
-	blktap_sysfs_get(tap);
-
-	if (!tap->ring.dev) {
-		ret = sprintf(tmp, "no device\n");
-		goto out;
-	}
-
-	tmp += sprintf(tmp, "%s (%u:%u), refcnt: %d, dev_inuse: 0x%08lx\n",
-		       tap->params.name, MAJOR(tap->ring.devno),
-		       MINOR(tap->ring.devno), atomic_read(&tap->refcnt),
-		       tap->dev_inuse);
-	tmp += sprintf(tmp, "capacity: 0x%llx, sector size: 0x%lx, "
-		       "device users: %d\n", tap->params.capacity,
-		       tap->params.sector_size, tap->device.users);
-
-	down_read(&tap->tap_sem);
-
-	tmp += sprintf(tmp, "pending requests: %d\n", tap->pending_cnt);
-	for (i = 0; i < MAX_PENDING_REQS; i++) {
-		struct blktap_request *req = tap->pending_requests[i];
-		if (!req)
-			continue;
-
-		tmp += sprintf(tmp, "req %d: id: %llu, usr_idx: %d, "
-			       "status: 0x%02x, pendcnt: %d, "
-			       "nr_pages: %u, op: %d, time: %lu:%lu\n",
-			       i, (unsigned long long)req->id, req->usr_idx,
-			       req->status, atomic_read(&req->pendcnt),
-			       req->nr_pages, req->operation, req->time.tv_sec,
-			       req->time.tv_usec);
-	}
-
-	up_read(&tap->tap_sem);
-	ret = (tmp - buf) + 1;
-
-out:
-	blktap_sysfs_put(tap);
-	BTDBG("%s\n", buf);
-
-	return ret;
-}
-static DEVICE_ATTR(debug, S_IRUSR, blktap_sysfs_debug_device, NULL);
-
-int
-blktap_sysfs_create(struct blktap *tap)
-{
-	struct blktap_ring *ring;
-	struct device *dev;
-	int err, state = 0;
-
-	if (!class)
-		return -ENODEV;
-
-	ring = &tap->ring;
-
-	dev = device_create(class, NULL, ring->devno, tap,
-			    "blktap%d", tap->minor);
-	if (IS_ERR(dev))
-		return PTR_ERR(dev);
-
-	ring->dev = dev;
-
-	mutex_init(&ring->sysfs_mutex);
-	atomic_set(&ring->sysfs_refcnt, 0);
-	set_bit(BLKTAP_SYSFS, &tap->dev_inuse);
-
-	err = device_create_file(dev, &dev_attr_name);
-	if (!err) {
-		++state;
-		err = device_create_file(dev, &dev_attr_remove);
-	}
-	if (!err) {
-		++state;
-		err = device_create_file(dev, &dev_attr_pause);
-	}
-	if (!err) {
-		++state;
-		err = device_create_file(dev, &dev_attr_debug);
-	}
-
-	switch (state * !!err) {
-	case 3: device_remove_file(dev, &dev_attr_pause);
-	case 2: device_remove_file(dev, &dev_attr_remove);
-	case 1: device_remove_file(dev, &dev_attr_name);
-	}
-
-	return err;
-}
-
-static void
-_blktap_sysfs_destroy(struct device *dev)
-{
-	struct blktap *tap = dev_get_drvdata(dev);
-
-	device_remove_file(dev, &dev_attr_name);
-	device_remove_file(dev, &dev_attr_remove);
-	device_remove_file(dev, &dev_attr_pause);
-	device_remove_file(dev, &dev_attr_resume);
-	device_remove_file(dev, &dev_attr_debug);
-
-	device_unregister(dev);
-
-	clear_bit(BLKTAP_SYSFS, &tap->dev_inuse);
-}
-
-int
-blktap_sysfs_destroy(struct blktap *tap)
-{
-	struct blktap_ring *ring;
-	struct device *dev;
-
-	ring = &tap->ring;
-	dev  = ring->dev;
-	if (!class || !dev)
-		return 0;
-
-	ring->dev = NULL;
-	if (wait_event_interruptible(sysfs_wq,
-				     !atomic_read(&tap->ring.sysfs_refcnt)))
-		return -EAGAIN;
-
-	return device_schedule_callback(dev, _blktap_sysfs_destroy);
-}
-
-static ssize_t
-blktap_sysfs_show_verbosity(struct class *class, char *buf)
-{
-	return sprintf(buf, "%d\n", blktap_debug_level);
-}
-
-static ssize_t
-blktap_sysfs_set_verbosity(struct class *class, const char *buf, size_t size)
-{
-	int level;
-
-	if (sscanf(buf, "%d", &level) == 1) {
-		blktap_debug_level = level;
-		return size;
-	}
-
-	return -EINVAL;
-}
-CLASS_ATTR(verbosity, S_IRUSR | S_IWUSR,
-	   blktap_sysfs_show_verbosity, blktap_sysfs_set_verbosity);
-
-static ssize_t
-blktap_sysfs_show_devices(struct class *class, char *buf)
-{
-	int i, ret;
-	struct blktap *tap;
-
-	ret = 0;
-	for (i = 0; i < MAX_BLKTAP_DEVICE; i++) {
-		tap = blktaps[i];
-		if (!tap)
-			continue;
-
-		if (!test_bit(BLKTAP_DEVICE, &tap->dev_inuse))
-			continue;
-
-		ret += sprintf(buf + ret, "%d ", tap->minor);
-		ret += snprintf(buf + ret, sizeof(tap->params.name) - 1,
-				tap->params.name);
-		ret += sprintf(buf + ret, "\n");
-	}
-
-	return ret;
-}
-CLASS_ATTR(devices, S_IRUSR, blktap_sysfs_show_devices, NULL);
-
-void
-blktap_sysfs_free(void)
-{
-	if (!class)
-		return;
-
-	class_remove_file(class, &class_attr_verbosity);
-	class_remove_file(class, &class_attr_devices);
-
-	class_destroy(class);
-}
-
-int __init
-blktap_sysfs_init(void)
-{
-	struct class *cls;
-	int err;
-
-	if (class)
-		return -EEXIST;
-
-	cls = class_create(THIS_MODULE, "blktap2");
-	if (IS_ERR(cls))
-		return PTR_ERR(cls);
-
-	err = class_create_file(cls, &class_attr_verbosity);
-	if (!err) {
-		err = class_create_file(cls, &class_attr_devices);
-		if (err)
-			class_remove_file(cls, &class_attr_verbosity);
-	}
-	if (!err)
-		class = cls;
-	else
-		class_destroy(cls);
-
-	return err;
-}
diff -r fc7f59d8fe82 drivers/xen/blktap2/wait_queue.c
--- a/drivers/xen/blktap2/wait_queue.c	Thu Jul 01 00:15:32 2010 -0700
+++ /dev/null	Thu Jan 01 00:00:00 1970 +0000
@@ -1,40 +0,0 @@
-#include <linux/list.h>
-#include <linux/spinlock.h>
-
-#include "blktap.h"
-
-static LIST_HEAD(deferred_work_queue);
-static DEFINE_SPINLOCK(deferred_work_lock);
-
-void
-blktap_run_deferred(void)
-{
-	LIST_HEAD(queue);
-	struct blktap *tap;
-	unsigned long flags;
-
-	spin_lock_irqsave(&deferred_work_lock, flags);
-	list_splice_init(&deferred_work_queue, &queue);
-	list_for_each_entry(tap, &queue, deferred_queue)
-		clear_bit(BLKTAP_DEFERRED, &tap->dev_inuse);
-	spin_unlock_irqrestore(&deferred_work_lock, flags);
-
-	while (!list_empty(&queue)) {
-		tap = list_entry(queue.next, struct blktap, deferred_queue);
-		list_del_init(&tap->deferred_queue);
-		blktap_device_restart(tap);
-	}
-}
-
-void
-blktap_defer(struct blktap *tap)
-{
-	unsigned long flags;
-
-	spin_lock_irqsave(&deferred_work_lock, flags);
-	if (!test_bit(BLKTAP_DEFERRED, &tap->dev_inuse)) {
-		set_bit(BLKTAP_DEFERRED, &tap->dev_inuse);
-		list_add_tail(&tap->deferred_queue, &deferred_work_queue);
-	}
-	spin_unlock_irqrestore(&deferred_work_lock, flags);
-}
diff -r fc7f59d8fe82 include/linux/mm.h
--- a/include/linux/mm.h	Thu Jul 01 00:15:32 2010 -0700
+++ b/include/linux/mm.h	Thu Jul 01 00:19:11 2010 -0700
@@ -132,12 +132,6 @@
  */
 #define VM_SPECIAL (VM_IO | VM_DONTEXPAND | VM_RESERVED | VM_PFNMAP)
 
-#ifdef CONFIG_XEN
-struct vm_foreign_map {
-	struct page **map;
-};
-#endif
-
 /*
  * mapping from the currently active vm_flags protection bits (the
  * low four bits) to a page protection mask..
@@ -215,9 +209,6 @@
 	 * original value of @ptep. */
 	pte_t (*zap_pte)(struct vm_area_struct *vma,
 			 unsigned long addr, pte_t *ptep, int is_fullmm);
-
-	/* called before close() to indicate no more pages should be mapped */
-	void (*unmap)(struct vm_area_struct *area);
 #endif
 
 #ifdef CONFIG_NUMA
diff -r fc7f59d8fe82 mm/memory.c
--- a/mm/memory.c	Thu Jul 01 00:15:32 2010 -0700
+++ b/mm/memory.c	Thu Jul 01 00:19:11 2010 -0700
@@ -1319,9 +1319,7 @@
 
 #ifdef CONFIG_XEN
 		if (vma && (vma->vm_flags & VM_FOREIGN)) {
-			struct vm_foreign_map *foreign_map =
-				vma->vm_private_data;
-			struct page **map = foreign_map->map;
+			struct page **map = vma->vm_private_data;
 			int offset = (start - vma->vm_start) >> PAGE_SHIFT;
 			if (map[offset] != NULL) {
 			        if (pages) {
diff -r fc7f59d8fe82 mm/mmap.c
--- a/mm/mmap.c	Thu Jul 01 00:15:32 2010 -0700
+++ b/mm/mmap.c	Thu Jul 01 00:19:11 2010 -0700
@@ -1842,14 +1842,6 @@
 	tlb_finish_mmu(tlb, start, end);
 }
 
-static inline void unmap_vma(struct vm_area_struct *vma)
-{
-#ifdef CONFIG_XEN
-	if (unlikely(vma->vm_ops && vma->vm_ops->unmap))
-		vma->vm_ops->unmap(vma);
-#endif
-}
-
 /*
  * Create a list of vma's touched by the unmap, removing them from the mm's
  * vma list as we go..
@@ -1865,7 +1857,6 @@
 	insertion_point = (prev ? &prev->vm_next : &mm->mmap);
 	do {
 		rb_erase(&vma->vm_rb, &mm->mm_rb);
-		unmap_vma(vma);
 		mm->map_count--;
 		tail_vma = vma;
 		vma = vma->vm_next;
@@ -2160,11 +2151,6 @@
 
 	arch_exit_mmap(mm);
 
-#ifdef CONFIG_XEN
-	for (vma = mm->mmap; vma; vma = vma->vm_next)
-		unmap_vma(vma);
-#endif
-
 	vma = mm->mmap;
 	if (!vma)	/* Can happen if dup_mmap() received an OOM */
 		return;
